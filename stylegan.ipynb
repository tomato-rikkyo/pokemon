{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow 2.3でメモリを指定及び節約して使うためのおまじない。\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.run_functions_eagerly(False)\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices[4], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[4], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from math import floor, log2\n",
    "import numpy as np\n",
    "# import time\n",
    "from functools import partial\n",
    "from random import random\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# from datagen import dataGenerator, printProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = 256\n",
    "latent_size = 512\n",
    "BATCH_SIZE = 12\n",
    "# directory = \"Earth\"\n",
    "\n",
    "cha = 48\n",
    "\n",
    "n_layers = int(log2(im_size) - 1)\n",
    "\n",
    "mixed_prob = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像生成のためのノイズを生成する箇所\n",
    "\n",
    "# 潜在空間としてのノイズ生成\n",
    "def noise(n):\n",
    "    return np.random.normal(0.0, 1.0, size = [n, latent_size]).astype('float32')\n",
    "\n",
    "def noiseList(n):\n",
    "    return [noise(n)] * n_layers\n",
    "\n",
    "def mixedList(n):\n",
    "    tt = int(random() * n_layers)\n",
    "    p1 = [noise(n)] * tt\n",
    "    p2 = [noise(n)] * (n_layers - tt)\n",
    "    return p1 + [] + p2\n",
    "\n",
    "# 画像サイズに合わせたノイズ生成\n",
    "def nImage(n):\n",
    "    return np.random.uniform(0.0, 1.0, size = [n, im_size, im_size, 1]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(samples, output, weights):\n",
    "    with tf.GradientTape() as tape:\n",
    "        gradients = tape.gradient(output, samples)[0]\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        gradient_penalty = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        \n",
    "    return K.mean(gradient_penalty * weights)\n",
    "\n",
    "def hinge_d(y_true, y_pred):\n",
    "    return K.mean(K.relu(1.0 + (y_true * y_pred)))\n",
    "\n",
    "def w_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda\n",
    "def AdaIN(x):\n",
    "    #Normalize x[0]\n",
    "\n",
    "    # inputの縦横平均及び標準偏差を取得し、inputを標準化\n",
    "    mean = K.mean(x[0], axis = [1, 2], keepdims = True)\n",
    "    std = K.std(x[0], axis = [1, 2], keepdims = True) + 1e-7\n",
    "    y = (x[0] - mean) / std\n",
    "\n",
    "    #Reshape gamma and beta\n",
    "    pool_shape = [-1, 1, 1, y.shape[-1]]\n",
    "    g = tf.reshape(x[1], pool_shape) + 1.0\n",
    "    b = tf.reshape(x[2], pool_shape)\n",
    "\n",
    "    #Multiply by x[1] (GAMMA) and add x[2] (BETA)\n",
    "    return y * g + b\n",
    "\n",
    "def fade_block(x, block_num):\n",
    "    #Inputs: [small-res (a), big-res (1-a), alpha]\n",
    "    sr = x[0]\n",
    "    br = x[1]\n",
    "    alpha = x[2]\n",
    "\n",
    "    alpha = tf.reshape(alpha, [-1, 1, 1, 1])\n",
    "    alpha = tf.clip(alpha - block_num, 0, 1)\n",
    "\n",
    "    return (sr * alpha) + (br * (1 - alpha))\n",
    "\n",
    "def crop_to_fit(x):\n",
    "\n",
    "    height = x[1].shape[1]\n",
    "    width = x[1].shape[2]\n",
    "\n",
    "    return x[0][:, :height, :width, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blocks\n",
    "def g_block(inp, style, inoise, fil, u = True):\n",
    "\n",
    "    if u:\n",
    "        out = UpSampling2D()(inp)\n",
    "    else:\n",
    "        out = Activation('linear')(inp)\n",
    "\n",
    "    # styleをfilterサイズで変換しgammaとする\n",
    "    gamma = Dense(fil)(style)\n",
    "    \n",
    "    # styleをfilterサイズで変換しbetaとする\n",
    "    beta = Dense(fil)(style)\n",
    "    \n",
    "    # inputをupsampling or linearで出力したものと同じサイズのノイズを抽出する\n",
    "    delta = Lambda(crop_to_fit)([inoise, out])\n",
    "    \n",
    "    # filterサイズでdeltaを変換\n",
    "    delta = Dense(fil, kernel_initializer = 'zeros')(delta)\n",
    "    \n",
    "    # upsampling or linearしたものをConv2dでfilterサイズに畳み込み\n",
    "    out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(out)\n",
    "    \n",
    "    # 生成したノイズを加える\n",
    "    out = add([out, delta])\n",
    "    \n",
    "    # AdaINに通す\n",
    "    out = Lambda(AdaIN)([out, gamma, beta])\n",
    "    \n",
    "    # 活性化\n",
    "    out = LeakyReLU(0.2)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def d_block(inp, fil, p = True):\n",
    "\n",
    "    out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(inp)\n",
    "    out = LeakyReLU(0.2)(out)\n",
    "\n",
    "    if p:\n",
    "        out = AveragePooling2D()(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "\n",
    "    def __init__(self, steps = 1, lr = 0.0001, decay = 0.00001):\n",
    "\n",
    "        #Models\n",
    "        # discriminator\n",
    "        self.D = None\n",
    "        \n",
    "        # style mapping\n",
    "        self.S = None\n",
    "        \n",
    "        # generator\n",
    "        self.G = None\n",
    "\n",
    "        self.GE = None\n",
    "        self.SE = None\n",
    "\n",
    "        self.DM = None\n",
    "        self.AM = None\n",
    "\n",
    "        #Config\n",
    "        self.LR = lr\n",
    "        self.steps = steps\n",
    "        self.beta = 0.999\n",
    "\n",
    "        #Init Models\n",
    "        self.discriminator() #self.Dにdiscriminator作成\n",
    "        self.generator() #self.Sにstylemapping、self.Gにgeneratorを作成\n",
    "\n",
    "        self.GMO = Adam(lr = self.LR, beta_1 = 0, beta_2 = 0.9)\n",
    "        self.DMO = Adam(lr = self.LR * 4, beta_1 = 0, beta_2 = 0.9)\n",
    "\n",
    "        self.GE = model_from_json(self.G.to_json()) # 一度jsonにして同じモデルを生成\n",
    "        self.GE.set_weights(self.G.get_weights()) # そのモデルにgeneratorと同じ形の重みをセット\n",
    "\n",
    "        self.SE = model_from_json(self.S.to_json()) \n",
    "        self.SE.set_weights(self.S.get_weights())\n",
    "\n",
    "    # 判別機生成\n",
    "    def discriminator(self):\n",
    "\n",
    "        # 既存のものがあれば\n",
    "        if self.D:\n",
    "            return self.D\n",
    "\n",
    "\n",
    "        # (256, 256, 3)\n",
    "        inp = Input(shape = [im_size, im_size, 3])\n",
    "\n",
    "        x = d_block(inp, 1 * cha)   #128,128, 48\n",
    "        x = d_block(x, 2 * cha)   #64, 64, 96\n",
    "        x = d_block(x, 3 * cha)   #32, 32, 144\n",
    "        x = d_block(x, 4 * cha)  #16, 16, 192\n",
    "        x = d_block(x, 6 * cha)  #8, 8, 288\n",
    "        x = d_block(x, 8 * cha)  #4, 4, 384\n",
    "        x = d_block(x, 16 * cha, p = False)  #4, 4, 768\n",
    "\n",
    "        x = Flatten()(x) # 12,288\n",
    "\n",
    "        x = Dense(16 * cha, kernel_initializer = 'he_normal')(x) #768\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "\n",
    "        x = Dense(1, kernel_initializer = 'he_normal')(x)\n",
    "\n",
    "        self.D = Model(inputs = inp, outputs = x)\n",
    "\n",
    "        return self.D\n",
    "\n",
    "    def generator(self):\n",
    "        \n",
    "        # 既存のものがあれば\n",
    "        if self.G:\n",
    "            return self.G\n",
    "\n",
    "        # === Style Mapping ===\n",
    "\n",
    "        self.S = Sequential()\n",
    "\n",
    "        self.S.add(Dense(512, input_shape = [latent_size])) #latent_zise=512\n",
    "        self.S.add(LeakyReLU(0.2))\n",
    "        self.S.add(Dense(512))\n",
    "        self.S.add(LeakyReLU(0.2))\n",
    "        self.S.add(Dense(512))\n",
    "        self.S.add(LeakyReLU(0.2))\n",
    "        self.S.add(Dense(512))\n",
    "        self.S.add(LeakyReLU(0.2))\n",
    "\n",
    "\n",
    "        # === Generator ===\n",
    "\n",
    "        #Inputs\n",
    "        inp_style = []\n",
    "\n",
    "        # 中間層の分styleの箱を用意（None, 512） * 7\n",
    "        for i in range(n_layers):\n",
    "            inp_style.append(Input([512]))\n",
    "\n",
    "        # 画像サイズと同じサイズのノイズ用の箱を用意\n",
    "        inp_noise = Input([im_size, im_size, 1])\n",
    "\n",
    "        #Latent（各バッチの前半1/4までを使用？）\n",
    "        x = Lambda(lambda x: x[:, :128])(inp_style[0]) # None, 128\n",
    "\n",
    "        #Actual Model\n",
    "        x = Dense(4*4*4*cha, activation = 'relu', kernel_initializer = 'he_normal')(x) # 3,072\n",
    "        x = Reshape([4, 4, 4*cha])(x) # 4, 4, 192\n",
    "        x = g_block(x, inp_style[0], inp_noise, 16 * cha, u = False)  #4, 4, 768\n",
    "        x = g_block(x, inp_style[1], inp_noise, 8 * cha)  #8, 8, 384\n",
    "        x = g_block(x, inp_style[2], inp_noise, 6 * cha)  #16, 16, 288\n",
    "        x = g_block(x, inp_style[3], inp_noise, 4 * cha)  #32, 32, 192\n",
    "        x = g_block(x, inp_style[4], inp_noise, 3 * cha)   #64, 64, 144\n",
    "        x = g_block(x, inp_style[5], inp_noise, 2 * cha)   #128, 128, 96\n",
    "        x = g_block(x, inp_style[6], inp_noise, 1 * cha)   #256, 256, 48\n",
    "\n",
    "        x = Conv2D(filters = 3, kernel_size = 1, padding = 'same', kernel_initializer = 'he_normal')(x) # 256, 256, 3\n",
    "\n",
    "        self.G = Model(inputs = inp_style + [inp_noise], outputs = x)\n",
    "\n",
    "        return self.G\n",
    "\n",
    "    def GenModel(self):\n",
    "\n",
    "        inp_style = []\n",
    "        style = []\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            inp_style.append(Input([latent_size]))\n",
    "            style.append(self.S(inp_style[-1]))\n",
    "\n",
    "        inp_noise = Input([im_size, im_size, 1])\n",
    "\n",
    "        gf = self.G(style + [inp_noise])\n",
    "\n",
    "        self.GM = Model(inputs = inp_style + [inp_noise], outputs = gf)\n",
    "\n",
    "        return self.GM\n",
    "\n",
    "    def GenModelA(self):\n",
    "\n",
    "        inp_style = []\n",
    "        style = []\n",
    "        trunc = Input([1])\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            inp_style.append(Input([latent_size]))\n",
    "            style.append(self.SE(inp_style[-1]))\n",
    "            style[-1] = Lambda(lambda x: x * trunc)(style[-1])\n",
    "\n",
    "        inp_noise = Input([im_size, im_size, 1])\n",
    "\n",
    "        gf = self.GE(style + [inp_noise])\n",
    "\n",
    "        self.GMA = Model(inputs = inp_style + [inp_noise, trunc], outputs = gf)\n",
    "\n",
    "        return self.GMA\n",
    "\n",
    "    def EMA(self):\n",
    "\n",
    "        for i in range(len(self.G.layers)):\n",
    "            up_weight = self.G.layers[i].get_weights()\n",
    "            old_weight = self.GE.layers[i].get_weights()\n",
    "            new_weight = []\n",
    "            for j in range(len(up_weight)):\n",
    "                new_weight.append(old_weight[j] * self.beta + (1-self.beta) * up_weight[j])\n",
    "            self.GE.layers[i].set_weights(new_weight)\n",
    "\n",
    "        for i in range(len(self.S.layers)):\n",
    "            up_weight = self.S.layers[i].get_weights()\n",
    "            old_weight = self.SE.layers[i].get_weights()\n",
    "            new_weight = []\n",
    "            for j in range(len(up_weight)):\n",
    "                new_weight.append(old_weight[j] * self.beta + (1-self.beta) * up_weight[j])\n",
    "            self.SE.layers[i].set_weights(new_weight)\n",
    "\n",
    "    def MAinit(self):\n",
    "        self.GE.set_weights(self.G.get_weights())\n",
    "        self.SE.set_weights(self.S.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "train_path = os.path.abspath(\"pokemon_jpg/\")\n",
    "images = glob(os.path.join(train_path, \"*.*\"))\n",
    "\n",
    "data = np.stack([img_to_array(load_img(img)) for img in images]) / 255.0\n",
    "\n",
    "class StyleGAN(object):\n",
    "\n",
    "    def __init__(self, steps = 1, lr = 0.0001, decay = 0.00001, silent = True):\n",
    "\n",
    "        # ganネットワーク生成\n",
    "        self.GAN = GAN(steps = steps, lr = lr, decay = decay)\n",
    "        # 生成モデルを生成\n",
    "        self.GAN.GenModel()\n",
    "        # 生成モデルの少し変わったものを生成\n",
    "        self.GAN.GenModelA()\n",
    "\n",
    "        self.GAN.G.summary()\n",
    "\n",
    "#         self.lastblip = time.clock()\n",
    "\n",
    "        self.noise_level = 0\n",
    "\n",
    "        \n",
    "#         self.im = dataGenerator(directory, im_size, flip = True)\n",
    "\n",
    "        # 学習状況をprintするかどうかフラグ\n",
    "        self.silent = silent\n",
    "\n",
    "        #Train Generator to be in the middle, not all the way at real. Apparently works better??\n",
    "        self.ones = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n",
    "        self.zeros = np.zeros((BATCH_SIZE, 1), dtype=np.float32)\n",
    "        self.nones = -self.ones\n",
    "\n",
    "        self.gp_weight = np.array([10.0] * BATCH_SIZE).astype('float32')\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        #Train Alternating\n",
    "        if random() < mixed_prob:\n",
    "            style = mixedList(BATCH_SIZE)\n",
    "        else:\n",
    "            style = noiseList(BATCH_SIZE)\n",
    "            \n",
    "        a, b, c = self.train_step(data, style, nImage(BATCH_SIZE), self.gp_weight)\n",
    "\n",
    "        if self.GAN.steps % 10 == 0:\n",
    "            self.GAN.EMA()\n",
    "\n",
    "        if self.GAN.steps <= 10000 and self.GAN.steps % 1000 == 2:\n",
    "            self.GAN.MAinit()\n",
    "\n",
    "        new_weight = 5/(np.array(c) + 1e-7)\n",
    "        self.gp_weight = self.gp_weight[0] * 0.9 + 0.1 * new_weight\n",
    "        self.gp_weight = np.clip([self.gp_weight] * BATCH_SIZE, 0.01, 10000.0).astype('float32')\n",
    "\n",
    "\n",
    "        #Print info\n",
    "        if self.GAN.steps % 100 == 0 and not self.silent:\n",
    "            print(\"\\n\\nRound \" + str(self.GAN.steps) + \":\")\n",
    "            print(\"D:\", np.array(a))\n",
    "            print(\"G:\", np.array(b))\n",
    "            print(\"GP:\", self.gp_weight[0])\n",
    "\n",
    "#             s = round((time.clock() - self.lastblip), 4)\n",
    "#             self.lastblip = time.clock()\n",
    "\n",
    "#             steps_per_second = 100 / s\n",
    "#             steps_per_minute = steps_per_second * 60\n",
    "#             steps_per_hour = steps_per_minute * 60\n",
    "#             print(\"Steps/Second: \" + str(round(steps_per_second, 2)))\n",
    "#             print(\"Steps/Hour: \" + str(round(steps_per_hour)))\n",
    "\n",
    "#             min1k = floor(1000/steps_per_minute)\n",
    "#             sec1k = floor(1000/steps_per_second) % 60\n",
    "#             print(\"1k Steps: \" + str(min1k) + \":\" + str(sec1k))\n",
    "#             steps_left = 200000 - self.GAN.steps + 1e-7\n",
    "#             hours_left = steps_left // steps_per_hour\n",
    "#             minutes_left = (steps_left // steps_per_minute) % 60\n",
    "\n",
    "#             print(\"Til Completion: \" + str(int(hours_left)) + \"h\" + str(int(minutes_left)) + \"m\")\n",
    "#             print()\n",
    "\n",
    "            #Save Model\n",
    "            if self.GAN.steps % 500 == 0:\n",
    "                self.save(floor(self.GAN.steps / 10000))\n",
    "            if self.GAN.steps % 1000 == 0 or (self.GAN.steps % 100 == 0 and self.GAN.steps < 1000):\n",
    "                self.evaluate(floor(self.GAN.steps / 1000))\n",
    "\n",
    "\n",
    "        printProgressBar(self.GAN.steps % 100, 99, decimals = 0)\n",
    "\n",
    "        self.GAN.steps = self.GAN.steps + 1\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data, style, noise, gp_weights):\n",
    "        \n",
    "        idx = np.random.randint(0, len(data[0]), BATCH_SIZE)\n",
    "        true_imgs = data[idx].astype(\"float32\")\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "          generated_images = self.GAN.GM(style + [noise], training=True)\n",
    "\n",
    "          real_output = self.GAN.D(true_imgs, training=True)\n",
    "          fake_output = self.GAN.D(generated_images, training=True)\n",
    "\n",
    "          gen_loss = K.mean(fake_output)\n",
    "          divergence = K.mean(K.relu(1 + real_output) + K.relu(1 - fake_output))\n",
    "          disc_loss = divergence + gradient_penalty(true_imgs, real_output, gp_weights)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.GAN.GM.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.GAN.D.trainable_variables)\n",
    "\n",
    "        self.GAN.GMO.apply_gradients(zip(gradients_of_generator, self.GAN.GM.trainable_variables))\n",
    "        self.GAN.DMO.apply_gradients(zip(gradients_of_discriminator, self.GAN.D.trainable_variables))\n",
    "\n",
    "        return disc_loss, gen_loss, divergence\n",
    "\n",
    "    def evaluate(self, num = 0, trunc = 1.0):\n",
    "\n",
    "        n1 = noiseList(64)\n",
    "        n2 = nImage(64)\n",
    "        trunc = np.ones([64, 1]) * trunc\n",
    "\n",
    "\n",
    "        generated_images = self.GAN.GM.predict(n1 + [n2], batch_size = BATCH_SIZE)\n",
    "\n",
    "        r = []\n",
    "\n",
    "        for i in range(0, 64, 8):\n",
    "            r.append(np.concatenate(generated_images[i:i+8], axis = 1))\n",
    "\n",
    "        c1 = np.concatenate(r, axis = 0)\n",
    "        c1 = np.clip(c1, 0.0, 1.0)\n",
    "        x = Image.fromarray(np.uint8(c1*255))\n",
    "\n",
    "        x.save(\"Results/i\"+str(num)+\".png\")\n",
    "\n",
    "        # Moving Average\n",
    "\n",
    "        generated_images = self.GAN.GMA.predict(n1 + [n2, trunc], batch_size = BATCH_SIZE)\n",
    "\n",
    "        r = []\n",
    "\n",
    "        for i in range(0, 64, 8):\n",
    "            r.append(np.concatenate(generated_images[i:i+8], axis = 1))\n",
    "\n",
    "        c1 = np.concatenate(r, axis = 0)\n",
    "        c1 = np.clip(c1, 0.0, 1.0)\n",
    "\n",
    "        x = Image.fromarray(np.uint8(c1*255))\n",
    "\n",
    "        x.save(\"Results/i\"+str(num)+\"-ema.png\")\n",
    "\n",
    "        #Mixing Regularities\n",
    "        nn = noise(8)\n",
    "        n1 = np.tile(nn, (8, 1))\n",
    "        n2 = np.repeat(nn, 8, axis = 0)\n",
    "        tt = int(n_layers / 2)\n",
    "\n",
    "        p1 = [n1] * tt\n",
    "        p2 = [n2] * (n_layers - tt)\n",
    "\n",
    "        latent = p1 + [] + p2\n",
    "\n",
    "        generated_images = self.GAN.GMA.predict(latent + [nImage(64), trunc], batch_size = BATCH_SIZE)\n",
    "\n",
    "        r = []\n",
    "\n",
    "        for i in range(0, 64, 8):\n",
    "            r.append(np.concatenate(generated_images[i:i+8], axis = 0))\n",
    "\n",
    "        c1 = np.concatenate(r, axis = 1)\n",
    "        c1 = np.clip(c1, 0.0, 1.0)\n",
    "\n",
    "        x = Image.fromarray(np.uint8(c1*255))\n",
    "\n",
    "        x.save(\"Results/i\"+str(num)+\"-mr.png\")\n",
    "\n",
    "    def saveModel(self, model, name, num):\n",
    "        json = model.to_json()\n",
    "        with open(\"Models/\"+name+\".json\", \"w\") as json_file:\n",
    "            json_file.write(json)\n",
    "\n",
    "        model.save_weights(\"Models/\"+name+\"_\"+str(num)+\".h5\")\n",
    "\n",
    "    def loadModel(self, name, num):\n",
    "\n",
    "        file = open(\"Models/\"+name+\".json\", 'r')\n",
    "        json = file.read()\n",
    "        file.close()\n",
    "\n",
    "        mod = model_from_json(json)\n",
    "        mod.load_weights(\"Models/\"+name+\"_\"+str(num)+\".h5\")\n",
    "\n",
    "        return mod\n",
    "\n",
    "    def save(self, num): #Save JSON and Weights into /Models/\n",
    "        self.saveModel(self.GAN.S, \"sty\", num)\n",
    "        self.saveModel(self.GAN.G, \"gen\", num)\n",
    "        self.saveModel(self.GAN.D, \"dis\", num)\n",
    "\n",
    "        self.saveModel(self.GAN.GE, \"genMA\", num)\n",
    "        self.saveModel(self.GAN.SE, \"styMA\", num)\n",
    "\n",
    "\n",
    "    def load(self, num): #Load JSON and Weights from /Models/\n",
    "\n",
    "        #Load Models\n",
    "        self.GAN.D = self.loadModel(\"dis\", num)\n",
    "        self.GAN.S = self.loadModel(\"sty\", num)\n",
    "        self.GAN.G = self.loadModel(\"gen\", num)\n",
    "\n",
    "        self.GAN.GE = self.loadModel(\"genMA\", num)\n",
    "        self.GAN.SE = self.loadModel(\"styMA\", num)\n",
    "\n",
    "        self.GAN.GenModel()\n",
    "        self.GAN.GenModelA()\n",
    "\n",
    "    def createFrame(self, list1, list2, nIm, alpha = 0, fnum = 0):\n",
    "\n",
    "        n1 = noiseList(list1[0].shape[0])\n",
    "\n",
    "        n1 = [list1 * (1-alpha) + list2 * (alpha)] * n_layers\n",
    "\n",
    "        im = self.GAN.GE.predict(n1 + [nIm], batch_size = BATCH_SIZE)\n",
    "\n",
    "        r = []\n",
    "        for i in range(0, 8*4, 4):\n",
    "            r.append(np.concatenate(im[i : i+4], axis = 0))\n",
    "        c = np.concatenate(r, axis = 1)\n",
    "        c = np.clip(c, 0.0, 1.0)\n",
    "\n",
    "        x = Image.fromarray(np.uint8(c*255), mode = 'RGB')\n",
    "        x.save(\"Results/Frames/frame-\"+str(fnum)+\".png\")\n",
    "\n",
    "    def createWalk(self):\n",
    "\n",
    "        iNoise = self.GAN.SE.predict(noise(32))\n",
    "        noise1 = iNoise.copy()\n",
    "        noise2 = self.GAN.SE.predict(noise(32))\n",
    "        nIm = nImage(32)\n",
    "        k = 0\n",
    "\n",
    "\n",
    "        for round in range(30):\n",
    "            for between in range(120):\n",
    "                alpha = between / 120.0\n",
    "                self.createFrame(noise1, noise2, nIm, alpha, k)\n",
    "                k = k + 1\n",
    "\n",
    "                print(round*120 + between, \"frames.\")\n",
    "\n",
    "            noise1 = noise2.copy()\n",
    "            noise2 = self.GAN.SE.predict(noiseList(32))\n",
    "            if round >= 28:\n",
    "                noise2 = iNoise.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 128)          0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3072)         396288      lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 4, 4, 192)    0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 4, 4, 192)    0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4, 4, 1)      0           input_9[0][0]                    \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 4, 768)    1327872     activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 4, 4, 768)    1536        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 4, 4, 768)    0           conv2d_7[0][0]                   \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 768)          393984      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 768)          393984      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 4, 4, 768)    0           add[0][0]                        \n",
      "                                                                 dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 4, 4, 768)    0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 8, 768)    0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 8, 8, 1)      0           input_9[0][0]                    \n",
      "                                                                 up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 384)    2654592     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 8, 8, 384)    768         lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8, 8, 384)    0           conv2d_8[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 384)          196992      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 384)          196992      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 8, 8, 384)    0           add_1[0][0]                      \n",
      "                                                                 dense_10[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 8, 8, 384)    0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 384)  0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16, 16, 1)    0           input_9[0][0]                    \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 288)  995616      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 16, 16, 288)  576         lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 288)  0           conv2d_9[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 288)          147744      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 288)          147744      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 16, 16, 288)  0           add_2[0][0]                      \n",
      "                                                                 dense_13[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 16, 16, 288)  0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 288)  0           leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 32, 32, 1)    0           input_9[0][0]                    \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 192)  497856      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32, 32, 192)  384         lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 192)  0           conv2d_10[0][0]                  \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 192)          98496       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 192)          98496       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 32, 32, 192)  0           add_3[0][0]                      \n",
      "                                                                 dense_16[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 32, 32, 192)  0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 192)  0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 64, 64, 1)    0           input_9[0][0]                    \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 144)  248976      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64, 64, 144)  288         lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 144)  0           conv2d_11[0][0]                  \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 144)          73872       input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 144)          73872       input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 64, 64, 144)  0           add_4[0][0]                      \n",
      "                                                                 dense_19[0][0]                   \n",
      "                                                                 dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 64, 64, 144)  0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 144 0           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 128, 128, 1)  0           input_9[0][0]                    \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 96) 124512      up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 128, 128, 96) 192         lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 128, 128, 96) 0           conv2d_12[0][0]                  \n",
      "                                                                 dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 96)           49248       input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 96)           49248       input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 128, 128, 96) 0           add_5[0][0]                      \n",
      "                                                                 dense_22[0][0]                   \n",
      "                                                                 dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 128, 128, 96) 0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 256, 256, 96) 0           leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 256, 256, 1)  0           input_9[0][0]                    \n",
      "                                                                 up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 256, 256, 48) 41520       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 256, 256, 48) 96          lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 256, 48) 0           conv2d_13[0][0]                  \n",
      "                                                                 dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 48)           24624       input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 48)           24624       input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 256, 256, 48) 0           add_6[0][0]                      \n",
      "                                                                 dense_25[0][0]                   \n",
      "                                                                 dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 256, 256, 48) 0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 256, 3)  147         leaky_re_lu_18[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 8,261,139\n",
      "Trainable params: 8,261,139\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "_SymbolicException",
     "evalue": "Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'input_18:0' shape=(None, 1) dtype=float32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/Anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n",
      "\u001b[0;31mTypeError\u001b[0m: An op outside of the function building code is being passed\na \"Graph\" tensor. It is possible to have Graph tensors\nleak out of the function building context by including a\ntf.init_scope in your function building code.\nFor example, the following function will fail:\n  @tf.function\n  def has_init_scope():\n    my_constant = tf.constant(1.)\n    with tf.init_scope():\n      added = my_constant * 2\nThe graph tensor has name: input_18:0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31m_SymbolicException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c19f49c4e423>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStyleGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1000001\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ae7c4a55deed>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, num, trunc)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# Moving Average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGMA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m/opt/Anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/opt/Anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/Anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     70\u001b[0m     ]\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m       raise core._SymbolicException(\n\u001b[0m\u001b[1;32m     73\u001b[0m           \u001b[0;34m\"Inputs to eager execution function cannot be Keras symbolic \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m           \"tensors, but found {}\".format(keras_symbolic_tensors))\n",
      "\u001b[0;31m_SymbolicException\u001b[0m: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'input_18:0' shape=(None, 1) dtype=float32>]"
     ]
    }
   ],
   "source": [
    "model = StyleGAN(lr = 0.0001, silent = False)\n",
    "model.evaluate(0)\n",
    "\n",
    "while model.GAN.steps <= 1000001:\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
