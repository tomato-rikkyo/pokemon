{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow 2.3でメモリを指定及び節約して使うためのおまじない。\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, smart_resize\n",
    "\n",
    "INPUT_SHAPE = (64, 64)\n",
    "\n",
    "data = np.array([])\n",
    "train_path = os.path.abspath(\"pokemon_jpg/\")\n",
    "images = glob(os.path.join(train_path, \"*.*\"))\n",
    "\n",
    "data = np.stack([img_to_array(load_img(img).resize(INPUT_SHAPE)) for img in images]) / 127.5 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers import Layer\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input_shape = (64, 64, 3)\n",
    "discriminator_conv_filters = [16,32,64,128]\n",
    "discriminator_conv_kernel_size = [5,5,5,5]\n",
    "discriminator_conv_strides = [2,2,2,2]\n",
    "\n",
    "initial_layer_shape = (4, 4, 128)\n",
    "generator_conv_filters = [64,32,16,3]\n",
    "generator_conv_kernel_size = [5,5,5,5]\n",
    "generator_conv_strides = [2,2,2,2]\n",
    "\n",
    "\n",
    "def generator(z_dim, initial_layer_shape, generator_conv_filters, generator_conv_kernel_size, generator_conv_strides):\n",
    "    generator_input = Input(shape=(z_dim,))\n",
    "    x = generator_input\n",
    "    x = Dense(np.prod(initial_layer_shape), kernel_initializer=\"he_normal\")(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = Reshape(initial_layer_shape)(x)\n",
    "    for i in range(len(generator_conv_filters)):\n",
    "        x = Conv2DTranspose(\n",
    "            filters=generator_conv_filters[i],\n",
    "            kernel_size=generator_conv_kernel_size[i],\n",
    "            padding=\"same\",\n",
    "            strides=generator_conv_strides[i],\n",
    "            kernel_initializer=\"he_normal\")(x)\n",
    "        if i < len(generator_conv_filters) - 1:\n",
    "            x = BatchNormalization(momentum=0.9)(x)\n",
    "            x = LeakyReLU(alpha=0.2)(x)\n",
    "        else:\n",
    "            generator_output = Activation(\"tanh\")(x)\n",
    "            \n",
    "    return Model(generator_input, generator_output)\n",
    "\n",
    "def discriminator(discriminator_input_shape, discriminator_conv_filters, discriminator_conv_kernel_size, discriminator_conv_strides):\n",
    "    discriminator_input = Input(discriminator_input_shape)\n",
    "    x = discriminator_input\n",
    "    \n",
    "    for i in range(len(generator_conv_filters)):\n",
    "        x = Conv2D(filters=discriminator_conv_filters[i],\n",
    "                   kernel_size=discriminator_conv_kernel_size[i],\n",
    "                   padding=\"same\",\n",
    "                   strides=discriminator_conv_strides[i],\n",
    "                   kernel_initializer=\"he_normal\")(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    discriminator_output = Dense(1, activation=None, kernel_initializer=\"he_normal\")(x)\n",
    "    \n",
    "    return Model(discriminator_input, discriminator_output)\n",
    "\n",
    "def wasserstein(y_true, y_pred):\n",
    "        return -K.mean(y_true * y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dims = 100\n",
    "\n",
    "disc = discriminator(discriminator_input_shape, discriminator_conv_filters, discriminator_conv_kernel_size, discriminator_conv_strides)\n",
    "\n",
    "disc.compile(optimizer=Adam(lr=0.0002),\n",
    "             loss=wasserstein)\n",
    "\n",
    "disc.trainable = False\n",
    "\n",
    "gen = generator(z_dims, initial_layer_shape, generator_conv_filters, generator_conv_kernel_size, generator_conv_strides)\n",
    "\n",
    "gan_input = Input(shape=(z_dims,))\n",
    "gan_output = disc(gen(gan_input))\n",
    "gan = Model(gan_input, gan_output)\n",
    "gan.compile(optimizer=Adam(lr=0.0002),\n",
    "            loss=wasserstein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "functional_3 (Functional)    (None, 64, 64, 3)         485603    \n",
      "_________________________________________________________________\n",
      "functional_1 (Functional)    (None, 1)                 272289    \n",
      "=================================================================\n",
      "Total params: 757,892\n",
      "Trainable params: 481,283\n",
      "Non-trainable params: 276,609\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtomato-ai\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.14 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ethereal-smoke-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/tomato-ai/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92_%E6%9C%80%E7%B5%82%E8%AA%B2%E9%A1%8C_transposed\" target=\"_blank\">https://wandb.ai/tomato-ai/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92_%E6%9C%80%E7%B5%82%E8%AA%B2%E9%A1%8C_transposed</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/tomato-ai/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92_%E6%9C%80%E7%B5%82%E8%AA%B2%E9%A1%8C_transposed/runs/2kl8zhhb\" target=\"_blank\">https://wandb.ai/tomato-ai/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92_%E6%9C%80%E7%B5%82%E8%AA%B2%E9%A1%8C_transposed/runs/2kl8zhhb</a><br/>\n",
       "                Run data is saved locally in <code>/workdir/homework/deep_NN/pokemon/wandb/run-20210123_001709-2kl8zhhb</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: (-0.000)(R -0.001, F 0.000)]  [G loss: -0.000] \n",
      "0 [D loss: (-0.000)(R -0.001, F -0.000)]  [G loss: 0.000] \n",
      "1 [D loss: (-0.001)(R -0.001, F -0.000)]  [G loss: 0.001] \n",
      "1 [D loss: (-0.001)(R -0.001, F -0.000)]  [G loss: 0.001] \n",
      "2 [D loss: (-0.001)(R -0.001, F -0.001)]  [G loss: 0.001] \n",
      "2 [D loss: (-0.001)(R -0.002, F -0.001)]  [G loss: 0.002] \n",
      "3 [D loss: (-0.002)(R -0.002, F -0.002)]  [G loss: 0.002] \n",
      "3 [D loss: (-0.002)(R -0.002, F -0.003)]  [G loss: 0.003] \n",
      "4 [D loss: (-0.003)(R -0.003, F -0.004)]  [G loss: 0.005] \n",
      "4 [D loss: (-0.005)(R -0.004, F -0.006)]  [G loss: 0.007] \n",
      "5 [D loss: (-0.007)(R -0.005, F -0.009)]  [G loss: 0.010] \n",
      "5 [D loss: (-0.011)(R -0.008, F -0.013)]  [G loss: 0.015] \n",
      "6 [D loss: (-0.018)(R -0.014, F -0.022)]  [G loss: 0.025] \n",
      "6 [D loss: (-0.033)(R -0.024, F -0.042)]  [G loss: 0.048] \n",
      "7 [D loss: (-0.071)(R -0.046, F -0.097)]  [G loss: 0.111] \n",
      "7 [D loss: (-0.212)(R -0.124, F -0.300)]  [G loss: 0.347] \n",
      "8 [D loss: (-0.788)(R -0.405, F -1.171)]  [G loss: 1.344] \n",
      "8 [D loss: (-3.172)(R -1.704, F -4.640)]  [G loss: 5.190] \n",
      "9 [D loss: (-11.088)(R -6.752, F -15.424)]  [G loss: 16.820] \n",
      "9 [D loss: (-29.198)(R -19.174, F -39.222)]  [G loss: 41.876] \n",
      "10 [D loss: (-55.993)(R -37.562, F -74.425)]  [G loss: 77.393] \n",
      "10 [D loss: (-83.594)(R -58.965, F -108.223)]  [G loss: 110.639] \n",
      "11 [D loss: (-101.513)(R -76.693, F -126.333)]  [G loss: 129.813] \n",
      "11 [D loss: (-107.159)(R -83.582, F -130.737)]  [G loss: 136.479] \n",
      "12 [D loss: (-106.397)(R -85.441, F -127.352)]  [G loss: 135.447] \n",
      "12 [D loss: (-106.455)(R -92.166, F -120.745)]  [G loss: 130.667] \n",
      "13 [D loss: (-101.661)(R -90.579, F -112.743)]  [G loss: 124.442] \n",
      "13 [D loss: (-99.549)(R -95.245, F -103.854)]  [G loss: 117.006] \n",
      "14 [D loss: (-93.089)(R -91.271, F -94.906)]  [G loss: 109.418] \n",
      "14 [D loss: (-91.219)(R -95.146, F -87.293)]  [G loss: 101.521] \n",
      "15 [D loss: (-88.662)(R -97.362, F -79.962)]  [G loss: 94.288] \n",
      "15 [D loss: (-81.627)(R -91.059, F -72.195)]  [G loss: 87.395] \n",
      "16 [D loss: (-82.671)(R -98.256, F -67.086)]  [G loss: 80.861] \n",
      "16 [D loss: (-76.449)(R -91.966, F -60.932)]  [G loss: 74.953] \n",
      "17 [D loss: (-74.315)(R -92.100, F -56.530)]  [G loss: 69.335] \n",
      "17 [D loss: (-71.800)(R -91.453, F -52.147)]  [G loss: 63.933] \n",
      "18 [D loss: (-69.272)(R -90.492, F -48.052)]  [G loss: 59.207] \n",
      "18 [D loss: (-68.965)(R -93.728, F -44.202)]  [G loss: 54.421] \n",
      "19 [D loss: (-65.831)(R -90.710, F -40.952)]  [G loss: 50.426] \n",
      "19 [D loss: (-63.147)(R -88.563, F -37.732)]  [G loss: 46.661] \n",
      "20 [D loss: (-61.632)(R -87.935, F -35.329)]  [G loss: 42.935] \n",
      "20 [D loss: (-60.160)(R -87.909, F -32.412)]  [G loss: 39.573] \n",
      "21 [D loss: (-60.228)(R -90.918, F -29.538)]  [G loss: 36.176] \n",
      "21 [D loss: (-57.008)(R -87.227, F -26.789)]  [G loss: 32.845] \n",
      "22 [D loss: (-57.993)(R -91.020, F -24.967)]  [G loss: 29.978] \n",
      "22 [D loss: (-57.087)(R -91.853, F -22.322)]  [G loss: 26.875] \n",
      "23 [D loss: (-53.888)(R -87.622, F -20.153)]  [G loss: 24.196] \n",
      "23 [D loss: (-55.543)(R -92.432, F -18.653)]  [G loss: 22.117] \n",
      "24 [D loss: (-52.109)(R -86.704, F -17.515)]  [G loss: 20.561] \n",
      "24 [D loss: (-51.165)(R -85.733, F -16.598)]  [G loss: 19.260] \n",
      "25 [D loss: (-50.596)(R -85.086, F -16.105)]  [G loss: 18.395] \n",
      "25 [D loss: (-50.417)(R -84.862, F -15.971)]  [G loss: 17.999] \n",
      "26 [D loss: (-50.011)(R -83.651, F -16.371)]  [G loss: 18.000] \n",
      "26 [D loss: (-49.553)(R -81.983, F -17.122)]  [G loss: 18.292] \n",
      "27 [D loss: (-51.633)(R -85.282, F -17.983)]  [G loss: 18.886] \n",
      "27 [D loss: (-51.200)(R -83.669, F -18.732)]  [G loss: 19.276] \n",
      "28 [D loss: (-49.306)(R -79.128, F -19.483)]  [G loss: 19.918] \n",
      "28 [D loss: (-48.726)(R -77.368, F -20.084)]  [G loss: 20.479] \n",
      "29 [D loss: (-48.145)(R -75.502, F -20.787)]  [G loss: 20.839] \n",
      "29 [D loss: (-47.964)(R -74.842, F -21.086)]  [G loss: 21.203] \n",
      "30 [D loss: (-47.973)(R -74.585, F -21.362)]  [G loss: 21.403] \n",
      "30 [D loss: (-46.708)(R -71.704, F -21.711)]  [G loss: 21.687] \n",
      "31 [D loss: (-46.758)(R -71.213, F -22.304)]  [G loss: 22.221] \n",
      "31 [D loss: (-46.951)(R -70.649, F -23.252)]  [G loss: 23.120] \n",
      "32 [D loss: (-46.202)(R -67.721, F -24.683)]  [G loss: 24.321] \n",
      "32 [D loss: (-48.254)(R -70.206, F -26.301)]  [G loss: 25.858] \n",
      "33 [D loss: (-47.715)(R -67.069, F -28.361)]  [G loss: 27.706] \n",
      "33 [D loss: (-48.256)(R -65.985, F -30.528)]  [G loss: 29.608] \n",
      "34 [D loss: (-48.571)(R -64.077, F -33.065)]  [G loss: 31.915] \n",
      "34 [D loss: (-48.157)(R -60.666, F -35.647)]  [G loss: 34.263] \n",
      "35 [D loss: (-49.488)(R -60.241, F -38.735)]  [G loss: 36.869] \n",
      "35 [D loss: (-50.007)(R -58.635, F -41.379)]  [G loss: 39.156] \n",
      "36 [D loss: (-50.107)(R -56.375, F -43.838)]  [G loss: 41.228] \n",
      "36 [D loss: (-50.663)(R -56.115, F -45.211)]  [G loss: 42.431] \n",
      "37 [D loss: (-50.240)(R -54.829, F -45.652)]  [G loss: 42.578] \n",
      "37 [D loss: (-50.078)(R -54.754, F -45.403)]  [G loss: 42.346] \n",
      "38 [D loss: (-50.747)(R -56.090, F -45.404)]  [G loss: 42.224] \n",
      "38 [D loss: (-50.707)(R -55.787, F -45.627)]  [G loss: 42.460] \n",
      "39 [D loss: (-50.021)(R -54.486, F -45.556)]  [G loss: 42.619] \n",
      "39 [D loss: (-50.330)(R -55.422, F -45.238)]  [G loss: 42.423] \n",
      "40 [D loss: (-49.078)(R -53.238, F -44.919)]  [G loss: 42.386] \n",
      "40 [D loss: (-49.919)(R -55.210, F -44.627)]  [G loss: 42.357] \n",
      "41 [D loss: (-49.495)(R -54.661, F -44.330)]  [G loss: 42.220] \n",
      "41 [D loss: (-48.647)(R -53.478, F -43.816)]  [G loss: 42.216] \n",
      "42 [D loss: (-49.397)(R -55.175, F -43.619)]  [G loss: 42.177] \n",
      "42 [D loss: (-49.414)(R -55.633, F -43.194)]  [G loss: 42.106] \n",
      "43 [D loss: (-48.408)(R -53.822, F -42.994)]  [G loss: 42.192] \n",
      "43 [D loss: (-49.707)(R -56.521, F -42.892)]  [G loss: 42.374] \n",
      "44 [D loss: (-48.826)(R -54.689, F -42.962)]  [G loss: 42.564] \n",
      "44 [D loss: (-48.830)(R -54.539, F -43.120)]  [G loss: 42.855] \n",
      "45 [D loss: (-47.603)(R -51.901, F -43.306)]  [G loss: 43.292] \n",
      "45 [D loss: (-49.258)(R -54.861, F -43.656)]  [G loss: 43.713] \n",
      "46 [D loss: (-49.027)(R -54.195, F -43.858)]  [G loss: 44.020] \n",
      "46 [D loss: (-49.315)(R -54.434, F -44.196)]  [G loss: 44.397] \n",
      "47 [D loss: (-48.575)(R -52.515, F -44.634)]  [G loss: 44.897] \n",
      "47 [D loss: (-50.574)(R -56.454, F -44.693)]  [G loss: 45.126] \n",
      "48 [D loss: (-49.109)(R -53.368, F -44.851)]  [G loss: 45.213] \n",
      "48 [D loss: (-49.233)(R -53.526, F -44.941)]  [G loss: 45.283] \n",
      "49 [D loss: (-50.965)(R -56.907, F -45.023)]  [G loss: 45.394] \n",
      "49 [D loss: (-50.514)(R -55.866, F -45.162)]  [G loss: 45.577] \n",
      "50 [D loss: (-50.013)(R -54.454, F -45.573)]  [G loss: 45.910] \n",
      "50 [D loss: (-50.361)(R -54.853, F -45.869)]  [G loss: 46.193] \n",
      "51 [D loss: (-50.875)(R -55.362, F -46.388)]  [G loss: 46.460] \n",
      "51 [D loss: (-51.987)(R -56.978, F -46.997)]  [G loss: 46.901] \n",
      "52 [D loss: (-51.302)(R -54.970, F -47.635)]  [G loss: 47.437] \n",
      "52 [D loss: (-53.363)(R -58.426, F -48.299)]  [G loss: 47.976] \n",
      "53 [D loss: (-52.288)(R -55.560, F -49.017)]  [G loss: 48.459] \n",
      "53 [D loss: (-52.216)(R -54.807, F -49.624)]  [G loss: 48.811] \n",
      "54 [D loss: (-52.706)(R -55.321, F -50.091)]  [G loss: 49.132] \n",
      "54 [D loss: (-53.746)(R -57.196, F -50.296)]  [G loss: 49.193] \n",
      "55 [D loss: (-54.296)(R -57.920, F -50.671)]  [G loss: 49.323] \n",
      "55 [D loss: (-52.753)(R -54.781, F -50.724)]  [G loss: 49.302] \n",
      "56 [D loss: (-53.126)(R -55.473, F -50.779)]  [G loss: 49.164] \n",
      "56 [D loss: (-53.230)(R -55.783, F -50.676)]  [G loss: 49.010] \n",
      "57 [D loss: (-54.239)(R -57.787, F -50.691)]  [G loss: 48.771] \n",
      "57 [D loss: (-53.601)(R -56.555, F -50.647)]  [G loss: 48.634] \n",
      "58 [D loss: (-53.362)(R -56.058, F -50.666)]  [G loss: 48.471] \n",
      "58 [D loss: (-53.224)(R -55.883, F -50.565)]  [G loss: 48.307] \n",
      "59 [D loss: (-51.987)(R -53.170, F -50.803)]  [G loss: 48.492] \n",
      "59 [D loss: (-54.394)(R -57.552, F -51.237)]  [G loss: 48.686] \n",
      "60 [D loss: (-54.369)(R -56.852, F -51.886)]  [G loss: 49.085] \n",
      "60 [D loss: (-56.086)(R -59.879, F -52.293)]  [G loss: 49.344] \n",
      "61 [D loss: (-54.410)(R -55.865, F -52.954)]  [G loss: 49.860] \n",
      "61 [D loss: (-56.096)(R -58.227, F -53.966)]  [G loss: 50.610] \n",
      "62 [D loss: (-56.546)(R -57.903, F -55.189)]  [G loss: 51.457] \n",
      "62 [D loss: (-56.413)(R -56.437, F -56.390)]  [G loss: 52.409] \n",
      "63 [D loss: (-57.185)(R -56.619, F -57.752)]  [G loss: 53.726] \n",
      "63 [D loss: (-59.514)(R -59.588, F -59.439)]  [G loss: 55.053] \n",
      "64 [D loss: (-59.781)(R -58.746, F -60.816)]  [G loss: 56.383] \n",
      "64 [D loss: (-59.760)(R -57.010, F -62.510)]  [G loss: 57.741] \n",
      "65 [D loss: (-61.247)(R -58.227, F -64.266)]  [G loss: 58.895] \n",
      "65 [D loss: (-61.402)(R -57.806, F -64.998)]  [G loss: 59.768] \n",
      "66 [D loss: (-61.582)(R -57.063, F -66.101)]  [G loss: 60.664] \n",
      "66 [D loss: (-61.788)(R -56.730, F -66.846)]  [G loss: 61.380] \n",
      "67 [D loss: (-62.455)(R -57.343, F -67.568)]  [G loss: 61.791] \n",
      "67 [D loss: (-62.454)(R -57.233, F -67.675)]  [G loss: 62.033] \n",
      "68 [D loss: (-61.259)(R -55.416, F -67.102)]  [G loss: 61.791] \n",
      "68 [D loss: (-61.617)(R -56.284, F -66.951)]  [G loss: 61.606] \n",
      "69 [D loss: (-62.486)(R -58.598, F -66.374)]  [G loss: 61.153] \n",
      "69 [D loss: (-61.303)(R -57.096, F -65.509)]  [G loss: 60.632] \n",
      "70 [D loss: (-61.110)(R -57.408, F -64.811)]  [G loss: 59.966] \n",
      "70 [D loss: (-60.580)(R -57.349, F -63.811)]  [G loss: 59.310] \n",
      "71 [D loss: (-60.473)(R -57.849, F -63.098)]  [G loss: 58.548] \n",
      "71 [D loss: (-58.809)(R -55.731, F -61.887)]  [G loss: 57.673] \n",
      "72 [D loss: (-57.734)(R -54.580, F -60.889)]  [G loss: 56.973] \n",
      "72 [D loss: (-57.284)(R -54.939, F -59.628)]  [G loss: 56.276] \n",
      "73 [D loss: (-57.311)(R -55.897, F -58.726)]  [G loss: 55.412] \n",
      "73 [D loss: (-56.024)(R -54.661, F -57.386)]  [G loss: 54.687] \n",
      "74 [D loss: (-55.923)(R -55.593, F -56.253)]  [G loss: 53.925] \n",
      "74 [D loss: (-54.953)(R -54.582, F -55.324)]  [G loss: 53.276] \n",
      "75 [D loss: (-54.642)(R -54.969, F -54.316)]  [G loss: 52.702] \n",
      "75 [D loss: (-54.329)(R -55.674, F -52.983)]  [G loss: 51.766] \n",
      "76 [D loss: (-53.994)(R -56.087, F -51.902)]  [G loss: 51.001] \n",
      "76 [D loss: (-52.837)(R -54.910, F -50.764)]  [G loss: 50.195] \n",
      "77 [D loss: (-53.550)(R -57.709, F -49.391)]  [G loss: 49.215] \n",
      "77 [D loss: (-50.791)(R -53.321, F -48.260)]  [G loss: 48.291] \n",
      "78 [D loss: (-51.510)(R -56.074, F -46.946)]  [G loss: 47.245] \n",
      "78 [D loss: (-50.881)(R -55.716, F -46.045)]  [G loss: 46.311] \n",
      "79 [D loss: (-48.357)(R -51.636, F -45.078)]  [G loss: 45.420] \n",
      "79 [D loss: (-49.863)(R -55.109, F -44.617)]  [G loss: 44.768] \n",
      "80 [D loss: (-50.067)(R -55.481, F -44.652)]  [G loss: 44.532] \n",
      "80 [D loss: (-50.414)(R -55.851, F -44.976)]  [G loss: 44.476] \n",
      "81 [D loss: (-49.076)(R -52.637, F -45.515)]  [G loss: 44.698] \n",
      "81 [D loss: (-49.504)(R -52.423, F -46.586)]  [G loss: 45.283] \n",
      "82 [D loss: (-51.759)(R -55.564, F -47.954)]  [G loss: 46.068] \n",
      "82 [D loss: (-51.380)(R -53.094, F -49.665)]  [G loss: 47.172] \n",
      "83 [D loss: (-53.257)(R -55.310, F -51.205)]  [G loss: 48.353] \n",
      "83 [D loss: (-53.982)(R -54.916, F -53.048)]  [G loss: 49.721] \n",
      "84 [D loss: (-53.906)(R -53.244, F -54.568)]  [G loss: 51.085] \n",
      "84 [D loss: (-55.064)(R -54.193, F -55.935)]  [G loss: 52.061] \n",
      "85 [D loss: (-55.312)(R -53.657, F -56.967)]  [G loss: 53.069] \n",
      "85 [D loss: (-55.739)(R -54.217, F -57.261)]  [G loss: 53.343] \n",
      "86 [D loss: (-54.961)(R -53.173, F -56.749)]  [G loss: 53.238] \n",
      "86 [D loss: (-54.804)(R -53.729, F -55.878)]  [G loss: 52.742] \n",
      "87 [D loss: (-53.976)(R -53.612, F -54.339)]  [G loss: 51.590] \n",
      "87 [D loss: (-53.051)(R -54.080, F -52.023)]  [G loss: 50.137] \n",
      "88 [D loss: (-51.848)(R -54.131, F -49.564)]  [G loss: 48.280] \n",
      "88 [D loss: (-48.798)(R -50.961, F -46.634)]  [G loss: 46.088] \n",
      "89 [D loss: (-49.054)(R -54.479, F -43.629)]  [G loss: 43.853] \n",
      "89 [D loss: (-47.615)(R -54.462, F -40.769)]  [G loss: 41.482] \n",
      "90 [D loss: (-45.517)(R -53.214, F -37.819)]  [G loss: 39.280] \n",
      "90 [D loss: (-43.960)(R -52.274, F -35.647)]  [G loss: 37.437] \n",
      "91 [D loss: (-43.371)(R -53.380, F -33.362)]  [G loss: 35.576] \n",
      "91 [D loss: (-43.400)(R -55.474, F -31.327)]  [G loss: 34.095] \n",
      "92 [D loss: (-42.156)(R -54.005, F -30.308)]  [G loss: 33.114] \n",
      "92 [D loss: (-42.756)(R -56.220, F -29.292)]  [G loss: 32.361] \n",
      "93 [D loss: (-40.956)(R -52.830, F -29.082)]  [G loss: 32.016] \n",
      "93 [D loss: (-40.992)(R -52.788, F -29.195)]  [G loss: 31.956] \n",
      "94 [D loss: (-42.159)(R -54.699, F -29.619)]  [G loss: 32.304] \n",
      "94 [D loss: (-41.536)(R -52.520, F -30.552)]  [G loss: 32.826] \n",
      "95 [D loss: (-43.533)(R -55.187, F -31.879)]  [G loss: 33.827] \n",
      "95 [D loss: (-43.722)(R -54.035, F -33.410)]  [G loss: 34.954] \n",
      "96 [D loss: (-44.699)(R -54.321, F -35.078)]  [G loss: 36.238] \n",
      "96 [D loss: (-44.982)(R -52.957, F -37.007)]  [G loss: 37.819] \n",
      "97 [D loss: (-45.395)(R -51.626, F -39.163)]  [G loss: 39.382] \n",
      "97 [D loss: (-47.784)(R -54.455, F -41.112)]  [G loss: 40.902] \n",
      "98 [D loss: (-47.813)(R -52.359, F -43.267)]  [G loss: 42.562] \n",
      "98 [D loss: (-49.334)(R -53.472, F -45.195)]  [G loss: 43.963] \n",
      "99 [D loss: (-49.691)(R -52.105, F -47.277)]  [G loss: 45.497] \n",
      "99 [D loss: (-51.039)(R -53.213, F -48.864)]  [G loss: 46.686] \n",
      "100 [D loss: (-51.510)(R -52.933, F -50.086)]  [G loss: 47.415] \n",
      "100 [D loss: (-51.118)(R -51.065, F -51.172)]  [G loss: 48.220] \n",
      "101 [D loss: (-52.379)(R -52.648, F -52.110)]  [G loss: 48.845] \n",
      "101 [D loss: (-53.098)(R -53.492, F -52.705)]  [G loss: 49.326] \n",
      "102 [D loss: (-52.975)(R -52.672, F -53.278)]  [G loss: 49.672] \n",
      "102 [D loss: (-51.361)(R -48.946, F -53.775)]  [G loss: 50.009] \n",
      "103 [D loss: (-52.858)(R -51.721, F -53.995)]  [G loss: 50.179] \n",
      "103 [D loss: (-54.020)(R -53.997, F -54.042)]  [G loss: 50.216] \n",
      "104 [D loss: (-53.441)(R -53.077, F -53.805)]  [G loss: 50.143] \n",
      "104 [D loss: (-52.837)(R -52.287, F -53.388)]  [G loss: 49.794] \n",
      "105 [D loss: (-53.436)(R -54.236, F -52.635)]  [G loss: 49.289] \n",
      "105 [D loss: (-52.865)(R -53.807, F -51.923)]  [G loss: 48.838] \n",
      "106 [D loss: (-53.314)(R -55.812, F -50.815)]  [G loss: 48.069] \n",
      "106 [D loss: (-50.733)(R -51.879, F -49.586)]  [G loss: 47.291] \n",
      "107 [D loss: (-51.047)(R -53.603, F -48.491)]  [G loss: 46.396] \n",
      "107 [D loss: (-51.088)(R -55.225, F -46.951)]  [G loss: 45.450] \n",
      "108 [D loss: (-48.859)(R -52.160, F -45.558)]  [G loss: 44.283] \n",
      "108 [D loss: (-47.928)(R -51.512, F -44.344)]  [G loss: 43.509] \n",
      "109 [D loss: (-48.293)(R -53.489, F -43.097)]  [G loss: 42.505] \n",
      "109 [D loss: (-48.061)(R -54.319, F -41.802)]  [G loss: 41.597] \n",
      "110 [D loss: (-47.393)(R -53.944, F -40.842)]  [G loss: 40.868] \n",
      "110 [D loss: (-45.553)(R -51.310, F -39.797)]  [G loss: 40.075] \n",
      "111 [D loss: (-44.801)(R -50.942, F -38.661)]  [G loss: 39.331] \n",
      "111 [D loss: (-46.160)(R -54.216, F -38.104)]  [G loss: 38.811] \n",
      "112 [D loss: (-44.484)(R -51.644, F -37.324)]  [G loss: 38.272] \n",
      "112 [D loss: (-44.206)(R -51.586, F -36.827)]  [G loss: 37.888] \n",
      "113 [D loss: (-43.452)(R -50.612, F -36.293)]  [G loss: 37.430] \n",
      "113 [D loss: (-43.810)(R -51.407, F -36.213)]  [G loss: 37.356] \n",
      "114 [D loss: (-43.529)(R -50.932, F -36.125)]  [G loss: 37.313] \n",
      "114 [D loss: (-43.526)(R -51.081, F -35.971)]  [G loss: 37.320] \n",
      "115 [D loss: (-42.448)(R -48.631, F -36.266)]  [G loss: 37.508] \n",
      "115 [D loss: (-42.389)(R -48.135, F -36.643)]  [G loss: 37.866] \n",
      "116 [D loss: (-43.426)(R -49.605, F -37.247)]  [G loss: 38.355] \n",
      "116 [D loss: (-44.150)(R -50.257, F -38.042)]  [G loss: 38.953] \n",
      "117 [D loss: (-43.663)(R -48.556, F -38.769)]  [G loss: 39.543] \n",
      "117 [D loss: (-44.067)(R -48.128, F -40.005)]  [G loss: 40.550] \n",
      "118 [D loss: (-45.196)(R -49.374, F -41.017)]  [G loss: 41.370] \n",
      "118 [D loss: (-46.503)(R -50.474, F -42.532)]  [G loss: 42.578] \n",
      "119 [D loss: (-46.800)(R -49.685, F -43.916)]  [G loss: 43.662] \n",
      "119 [D loss: (-47.758)(R -50.078, F -45.439)]  [G loss: 44.913] \n",
      "120 [D loss: (-47.889)(R -48.645, F -47.134)]  [G loss: 46.251] \n",
      "120 [D loss: (-49.041)(R -49.329, F -48.753)]  [G loss: 47.570] \n",
      "121 [D loss: (-51.004)(R -51.695, F -50.314)]  [G loss: 48.822] \n",
      "121 [D loss: (-49.803)(R -47.586, F -52.020)]  [G loss: 50.191] \n",
      "122 [D loss: (-51.754)(R -50.101, F -53.408)]  [G loss: 51.252] \n",
      "122 [D loss: (-52.194)(R -49.560, F -54.829)]  [G loss: 52.377] \n",
      "123 [D loss: (-52.364)(R -48.774, F -55.954)]  [G loss: 53.407] \n",
      "123 [D loss: (-53.052)(R -49.018, F -57.086)]  [G loss: 54.237] \n",
      "124 [D loss: (-52.872)(R -47.752, F -57.991)]  [G loss: 55.065] \n",
      "124 [D loss: (-54.983)(R -51.401, F -58.565)]  [G loss: 55.462] \n",
      "125 [D loss: (-53.772)(R -48.492, F -59.052)]  [G loss: 55.880] \n",
      "125 [D loss: (-54.675)(R -50.190, F -59.161)]  [G loss: 56.148] \n",
      "126 [D loss: (-54.357)(R -49.857, F -58.856)]  [G loss: 55.878] \n",
      "126 [D loss: (-53.653)(R -49.007, F -58.300)]  [G loss: 55.529] \n",
      "127 [D loss: (-53.294)(R -49.139, F -57.449)]  [G loss: 54.896] \n",
      "127 [D loss: (-53.160)(R -49.872, F -56.447)]  [G loss: 53.963] \n",
      "128 [D loss: (-53.195)(R -51.346, F -55.044)]  [G loss: 52.767] \n",
      "128 [D loss: (-51.422)(R -49.503, F -53.342)]  [G loss: 51.435] \n",
      "129 [D loss: (-51.887)(R -52.158, F -51.616)]  [G loss: 49.890] \n",
      "129 [D loss: (-49.493)(R -49.345, F -49.642)]  [G loss: 48.252] \n",
      "130 [D loss: (-48.675)(R -49.913, F -47.437)]  [G loss: 46.569] \n",
      "130 [D loss: (-48.771)(R -51.856, F -45.687)]  [G loss: 44.922] \n",
      "131 [D loss: (-45.543)(R -47.349, F -43.737)]  [G loss: 43.133] \n",
      "131 [D loss: (-44.970)(R -47.883, F -42.056)]  [G loss: 41.580] \n",
      "132 [D loss: (-44.915)(R -49.433, F -40.397)]  [G loss: 40.116] \n",
      "132 [D loss: (-43.813)(R -48.512, F -39.113)]  [G loss: 38.822] \n",
      "133 [D loss: (-43.692)(R -49.542, F -37.842)]  [G loss: 37.482] \n",
      "133 [D loss: (-44.081)(R -51.328, F -36.834)]  [G loss: 36.490] \n",
      "134 [D loss: (-43.114)(R -50.260, F -35.968)]  [G loss: 35.586] \n",
      "134 [D loss: (-42.239)(R -48.996, F -35.481)]  [G loss: 35.012] \n",
      "135 [D loss: (-42.836)(R -50.558, F -35.113)]  [G loss: 34.508] \n",
      "135 [D loss: (-42.708)(R -50.430, F -34.985)]  [G loss: 34.308] \n",
      "136 [D loss: (-43.275)(R -51.504, F -35.047)]  [G loss: 34.267] \n",
      "136 [D loss: (-42.494)(R -49.804, F -35.183)]  [G loss: 34.315] \n",
      "137 [D loss: (-43.263)(R -50.759, F -35.767)]  [G loss: 34.661] \n",
      "137 [D loss: (-42.833)(R -49.414, F -36.253)]  [G loss: 35.053] \n",
      "138 [D loss: (-43.169)(R -49.257, F -37.081)]  [G loss: 35.736] \n",
      "138 [D loss: (-43.490)(R -48.999, F -37.982)]  [G loss: 36.525] \n",
      "139 [D loss: (-45.361)(R -51.799, F -38.923)]  [G loss: 37.394] \n",
      "139 [D loss: (-45.008)(R -50.052, F -39.965)]  [G loss: 38.317] \n",
      "140 [D loss: (-45.811)(R -50.579, F -41.043)]  [G loss: 39.303] \n",
      "140 [D loss: (-46.121)(R -49.923, F -42.318)]  [G loss: 40.382] \n",
      "141 [D loss: (-47.098)(R -50.603, F -43.592)]  [G loss: 41.578] \n",
      "141 [D loss: (-47.609)(R -50.278, F -44.940)]  [G loss: 42.790] \n",
      "142 [D loss: (-47.895)(R -49.663, F -46.126)]  [G loss: 44.001] \n",
      "142 [D loss: (-48.547)(R -49.207, F -47.887)]  [G loss: 45.392] \n",
      "143 [D loss: (-48.942)(R -48.713, F -49.171)]  [G loss: 46.776] \n",
      "143 [D loss: (-51.329)(R -52.142, F -50.516)]  [G loss: 48.137] \n",
      "144 [D loss: (-50.675)(R -49.346, F -52.003)]  [G loss: 49.469] \n",
      "144 [D loss: (-52.047)(R -50.454, F -53.639)]  [G loss: 50.816] \n",
      "145 [D loss: (-52.585)(R -50.348, F -54.822)]  [G loss: 52.027] \n",
      "145 [D loss: (-52.443)(R -48.917, F -55.968)]  [G loss: 53.135] \n",
      "146 [D loss: (-52.963)(R -48.932, F -56.994)]  [G loss: 54.240] \n",
      "146 [D loss: (-53.175)(R -48.342, F -58.008)]  [G loss: 55.221] \n",
      "147 [D loss: (-54.216)(R -49.302, F -59.130)]  [G loss: 56.211] \n",
      "147 [D loss: (-53.941)(R -48.095, F -59.786)]  [G loss: 57.178] \n",
      "148 [D loss: (-55.370)(R -49.884, F -60.855)]  [G loss: 57.996] \n",
      "148 [D loss: (-54.722)(R -47.827, F -61.617)]  [G loss: 58.914] \n",
      "149 [D loss: (-55.553)(R -48.522, F -62.583)]  [G loss: 59.664] \n",
      "149 [D loss: (-55.649)(R -48.130, F -63.169)]  [G loss: 60.521] \n",
      "150 [D loss: (-56.274)(R -48.636, F -63.912)]  [G loss: 61.169] \n",
      "150 [D loss: (-55.623)(R -46.797, F -64.450)]  [G loss: 61.737] \n",
      "151 [D loss: (-56.380)(R -47.747, F -65.012)]  [G loss: 62.258] \n",
      "151 [D loss: (-56.306)(R -47.171, F -65.441)]  [G loss: 62.711] \n",
      "152 [D loss: (-56.741)(R -47.926, F -65.556)]  [G loss: 62.900] \n",
      "152 [D loss: (-57.045)(R -48.760, F -65.329)]  [G loss: 62.990] \n",
      "153 [D loss: (-56.285)(R -47.205, F -65.365)]  [G loss: 62.912] \n",
      "153 [D loss: (-55.605)(R -46.158, F -65.051)]  [G loss: 62.599] \n",
      "154 [D loss: (-55.947)(R -47.832, F -64.062)]  [G loss: 62.160] \n",
      "154 [D loss: (-55.126)(R -46.708, F -63.544)]  [G loss: 61.586] \n",
      "155 [D loss: (-55.810)(R -48.818, F -62.803)]  [G loss: 60.896] \n",
      "155 [D loss: (-54.875)(R -47.810, F -61.941)]  [G loss: 60.078] \n",
      "156 [D loss: (-53.867)(R -46.915, F -60.819)]  [G loss: 59.094] \n",
      "156 [D loss: (-53.419)(R -47.121, F -59.718)]  [G loss: 58.069] \n",
      "157 [D loss: (-53.567)(R -48.729, F -58.406)]  [G loss: 57.028] \n",
      "157 [D loss: (-51.459)(R -45.703, F -57.215)]  [G loss: 55.881] \n",
      "158 [D loss: (-52.691)(R -49.389, F -55.993)]  [G loss: 54.763] \n",
      "158 [D loss: (-49.959)(R -45.190, F -54.728)]  [G loss: 53.510] \n",
      "159 [D loss: (-50.866)(R -48.010, F -53.722)]  [G loss: 52.385] \n",
      "159 [D loss: (-49.328)(R -46.096, F -52.561)]  [G loss: 51.351] \n",
      "160 [D loss: (-49.698)(R -47.984, F -51.412)]  [G loss: 50.247] \n",
      "160 [D loss: (-46.802)(R -43.222, F -50.383)]  [G loss: 49.244] \n",
      "161 [D loss: (-48.799)(R -48.352, F -49.247)]  [G loss: 48.003] \n",
      "161 [D loss: (-48.132)(R -47.916, F -48.348)]  [G loss: 47.213] \n",
      "162 [D loss: (-46.419)(R -45.445, F -47.392)]  [G loss: 45.995] \n",
      "162 [D loss: (-46.385)(R -46.484, F -46.286)]  [G loss: 44.979] \n",
      "163 [D loss: (-45.682)(R -46.085, F -45.279)]  [G loss: 43.839] \n",
      "163 [D loss: (-45.111)(R -45.965, F -44.258)]  [G loss: 42.787] \n",
      "164 [D loss: (-44.787)(R -46.576, F -42.998)]  [G loss: 41.639] \n",
      "164 [D loss: (-43.941)(R -46.108, F -41.774)]  [G loss: 40.323] \n",
      "165 [D loss: (-42.579)(R -44.758, F -40.401)]  [G loss: 38.906] \n",
      "165 [D loss: (-41.214)(R -43.496, F -38.932)]  [G loss: 37.672] \n",
      "166 [D loss: (-40.793)(R -43.814, F -37.772)]  [G loss: 36.481] \n",
      "166 [D loss: (-39.979)(R -43.478, F -36.480)]  [G loss: 35.065] \n",
      "167 [D loss: (-38.843)(R -42.941, F -34.745)]  [G loss: 33.528] \n",
      "167 [D loss: (-37.934)(R -42.443, F -33.425)]  [G loss: 32.413] \n",
      "168 [D loss: (-39.583)(R -46.846, F -32.321)]  [G loss: 31.324] \n",
      "168 [D loss: (-37.470)(R -43.826, F -31.114)]  [G loss: 30.363] \n",
      "169 [D loss: (-36.390)(R -42.278, F -30.503)]  [G loss: 29.668] \n",
      "169 [D loss: (-37.531)(R -45.535, F -29.526)]  [G loss: 28.826] \n",
      "170 [D loss: (-36.997)(R -45.066, F -28.928)]  [G loss: 28.375] \n",
      "170 [D loss: (-35.498)(R -42.517, F -28.479)]  [G loss: 27.905] \n",
      "171 [D loss: (-36.306)(R -44.454, F -28.157)]  [G loss: 27.464] \n",
      "171 [D loss: (-35.799)(R -43.614, F -27.984)]  [G loss: 27.434] \n",
      "172 [D loss: (-35.968)(R -44.067, F -27.869)]  [G loss: 27.446] \n",
      "172 [D loss: (-35.737)(R -43.472, F -28.002)]  [G loss: 27.748] \n",
      "173 [D loss: (-36.368)(R -44.373, F -28.362)]  [G loss: 28.057] \n",
      "173 [D loss: (-36.566)(R -44.121, F -29.011)]  [G loss: 28.721] \n",
      "174 [D loss: (-37.552)(R -45.480, F -29.623)]  [G loss: 29.399] \n",
      "174 [D loss: (-37.523)(R -44.595, F -30.452)]  [G loss: 30.458] \n",
      "175 [D loss: (-37.420)(R -42.983, F -31.857)]  [G loss: 31.500] \n",
      "175 [D loss: (-38.547)(R -44.171, F -32.922)]  [G loss: 32.551] \n",
      "176 [D loss: (-38.666)(R -43.477, F -33.854)]  [G loss: 33.725] \n",
      "176 [D loss: (-40.753)(R -46.437, F -35.069)]  [G loss: 34.631] \n",
      "177 [D loss: (-40.022)(R -44.039, F -36.004)]  [G loss: 35.719] \n",
      "177 [D loss: (-41.463)(R -45.724, F -37.202)]  [G loss: 36.730] \n",
      "178 [D loss: (-42.305)(R -46.653, F -37.956)]  [G loss: 37.492] \n",
      "178 [D loss: (-42.539)(R -46.285, F -38.793)]  [G loss: 38.202] \n",
      "179 [D loss: (-42.736)(R -46.038, F -39.435)]  [G loss: 39.141] \n",
      "179 [D loss: (-43.763)(R -47.565, F -39.960)]  [G loss: 39.522] \n",
      "180 [D loss: (-43.683)(R -47.159, F -40.206)]  [G loss: 39.901] \n",
      "180 [D loss: (-44.257)(R -47.586, F -40.928)]  [G loss: 40.575] \n",
      "181 [D loss: (-44.921)(R -48.768, F -41.074)]  [G loss: 40.607] \n",
      "181 [D loss: (-43.946)(R -46.607, F -41.286)]  [G loss: 40.895] \n",
      "182 [D loss: (-43.694)(R -45.924, F -41.464)]  [G loss: 41.118] \n",
      "182 [D loss: (-44.703)(R -47.744, F -41.662)]  [G loss: 41.194] \n",
      "183 [D loss: (-44.644)(R -47.788, F -41.501)]  [G loss: 41.361] \n",
      "183 [D loss: (-43.665)(R -45.558, F -41.773)]  [G loss: 41.179] \n",
      "184 [D loss: (-44.515)(R -47.437, F -41.593)]  [G loss: 41.234] \n",
      "184 [D loss: (-44.352)(R -47.169, F -41.535)]  [G loss: 41.143] \n",
      "185 [D loss: (-43.653)(R -45.891, F -41.415)]  [G loss: 40.908] \n",
      "185 [D loss: (-43.785)(R -46.144, F -41.426)]  [G loss: 40.647] \n",
      "186 [D loss: (-43.542)(R -45.454, F -41.630)]  [G loss: 40.786] \n",
      "186 [D loss: (-44.483)(R -47.505, F -41.461)]  [G loss: 40.335] \n",
      "187 [D loss: (-45.568)(R -49.761, F -41.374)]  [G loss: 40.481] \n",
      "187 [D loss: (-44.033)(R -46.635, F -41.430)]  [G loss: 39.961] \n",
      "188 [D loss: (-44.233)(R -46.952, F -41.513)]  [G loss: 39.811] \n",
      "188 [D loss: (-45.187)(R -49.289, F -41.086)]  [G loss: 39.100] \n",
      "189 [D loss: (-44.683)(R -48.195, F -41.170)]  [G loss: 38.971] \n",
      "189 [D loss: (-44.197)(R -47.811, F -40.582)]  [G loss: 38.777] \n",
      "190 [D loss: (-43.286)(R -46.012, F -40.560)]  [G loss: 37.822] \n",
      "190 [D loss: (-43.149)(R -46.315, F -39.983)]  [G loss: 37.644] \n",
      "191 [D loss: (-43.652)(R -47.853, F -39.451)]  [G loss: 36.887] \n",
      "191 [D loss: (-42.349)(R -45.238, F -39.460)]  [G loss: 36.605] \n",
      "192 [D loss: (-42.556)(R -45.854, F -39.257)]  [G loss: 35.975] \n",
      "192 [D loss: (-43.157)(R -47.759, F -38.555)]  [G loss: 35.660] \n",
      "193 [D loss: (-43.043)(R -47.736, F -38.350)]  [G loss: 34.587] \n",
      "193 [D loss: (-42.431)(R -47.581, F -37.282)]  [G loss: 34.309] \n",
      "194 [D loss: (-42.783)(R -48.790, F -36.776)]  [G loss: 33.569] \n",
      "194 [D loss: (-42.830)(R -49.728, F -35.933)]  [G loss: 33.333] \n",
      "195 [D loss: (-42.236)(R -48.750, F -35.723)]  [G loss: 32.797] \n",
      "195 [D loss: (-41.579)(R -48.066, F -35.091)]  [G loss: 32.035] \n",
      "196 [D loss: (-43.170)(R -51.592, F -34.748)]  [G loss: 31.552] \n",
      "196 [D loss: (-39.493)(R -44.915, F -34.070)]  [G loss: 31.722] \n",
      "197 [D loss: (-40.420)(R -47.026, F -33.814)]  [G loss: 30.474] \n",
      "197 [D loss: (-41.467)(R -49.553, F -33.381)]  [G loss: 30.801] \n",
      "198 [D loss: (-40.821)(R -48.871, F -32.770)]  [G loss: 30.387] \n",
      "198 [D loss: (-41.300)(R -50.479, F -32.120)]  [G loss: 30.030] \n",
      "199 [D loss: (-39.996)(R -48.522, F -31.471)]  [G loss: 29.504] \n",
      "199 [D loss: (-40.293)(R -49.323, F -31.264)]  [G loss: 28.986] \n",
      "200 [D loss: (-39.894)(R -49.743, F -30.044)]  [G loss: 29.084] \n",
      "200 [D loss: (-38.833)(R -47.799, F -29.866)]  [G loss: 28.147] \n",
      "201 [D loss: (-38.599)(R -48.565, F -28.634)]  [G loss: 27.539] \n",
      "201 [D loss: (-38.396)(R -49.066, F -27.727)]  [G loss: 26.962] \n",
      "202 [D loss: (-38.305)(R -49.179, F -27.432)]  [G loss: 26.298] \n",
      "202 [D loss: (-38.403)(R -50.704, F -26.102)]  [G loss: 25.545] \n",
      "203 [D loss: (-37.436)(R -49.009, F -25.864)]  [G loss: 24.935] \n",
      "203 [D loss: (-37.754)(R -51.440, F -24.068)]  [G loss: 23.789] \n",
      "204 [D loss: (-37.542)(R -51.154, F -23.930)]  [G loss: 23.494] \n",
      "204 [D loss: (-37.196)(R -51.276, F -23.116)]  [G loss: 22.703] \n",
      "205 [D loss: (-36.259)(R -49.938, F -22.581)]  [G loss: 21.811] \n",
      "205 [D loss: (-36.279)(R -49.999, F -22.559)]  [G loss: 21.191] \n",
      "206 [D loss: (-35.608)(R -50.002, F -21.215)]  [G loss: 20.568] \n",
      "206 [D loss: (-36.587)(R -52.427, F -20.748)]  [G loss: 20.079] \n",
      "207 [D loss: (-36.204)(R -52.079, F -20.330)]  [G loss: 18.982] \n",
      "207 [D loss: (-34.810)(R -50.403, F -19.216)]  [G loss: 18.241] \n",
      "208 [D loss: (-34.265)(R -51.308, F -17.221)]  [G loss: 17.832] \n",
      "208 [D loss: (-34.468)(R -51.234, F -17.701)]  [G loss: 17.096] \n",
      "209 [D loss: (-34.811)(R -52.859, F -16.764)]  [G loss: 16.250] \n",
      "209 [D loss: (-34.928)(R -53.706, F -16.151)]  [G loss: 15.631] \n",
      "210 [D loss: (-34.822)(R -53.135, F -16.509)]  [G loss: 15.141] \n",
      "210 [D loss: (-34.348)(R -53.270, F -15.426)]  [G loss: 14.099] \n",
      "211 [D loss: (-35.018)(R -56.405, F -13.632)]  [G loss: 13.232] \n",
      "211 [D loss: (-33.598)(R -55.759, F -11.437)]  [G loss: 12.712] \n",
      "212 [D loss: (-34.767)(R -54.275, F -15.258)]  [G loss: 11.898] \n",
      "212 [D loss: (-34.761)(R -58.673, F -10.848)]  [G loss: 11.244] \n",
      "213 [D loss: (-35.400)(R -57.304, F -13.496)]  [G loss: 10.464] \n",
      "213 [D loss: (-33.362)(R -55.320, F -11.404)]  [G loss: 10.149] \n",
      "214 [D loss: (-34.263)(R -57.064, F -11.463)]  [G loss: 9.297] \n",
      "214 [D loss: (-33.922)(R -56.527, F -11.318)]  [G loss: 8.834] \n",
      "215 [D loss: (-33.785)(R -57.251, F -10.319)]  [G loss: 8.079] \n",
      "215 [D loss: (-32.885)(R -55.894, F -9.877)]  [G loss: 7.938] \n",
      "216 [D loss: (-34.556)(R -58.291, F -10.822)]  [G loss: 7.686] \n",
      "216 [D loss: (-33.912)(R -57.698, F -10.125)]  [G loss: 7.123] \n",
      "217 [D loss: (-33.502)(R -58.164, F -8.840)]  [G loss: 6.305] \n",
      "217 [D loss: (-33.700)(R -58.620, F -8.780)]  [G loss: 6.456] \n",
      "218 [D loss: (-34.789)(R -59.727, F -9.851)]  [G loss: 6.111] \n",
      "218 [D loss: (-33.832)(R -60.222, F -7.443)]  [G loss: 6.192] \n",
      "219 [D loss: (-32.821)(R -58.427, F -7.214)]  [G loss: 6.294] \n",
      "219 [D loss: (-34.288)(R -58.737, F -9.840)]  [G loss: 5.705] \n",
      "220 [D loss: (-32.685)(R -56.535, F -8.836)]  [G loss: 5.671] \n",
      "220 [D loss: (-33.227)(R -59.358, F -7.096)]  [G loss: 5.237] \n",
      "221 [D loss: (-33.636)(R -59.036, F -8.236)]  [G loss: 5.570] \n",
      "221 [D loss: (-32.982)(R -57.449, F -8.514)]  [G loss: 5.486] \n",
      "222 [D loss: (-33.802)(R -58.474, F -9.130)]  [G loss: 5.351] \n",
      "222 [D loss: (-32.470)(R -56.401, F -8.539)]  [G loss: 5.895] \n",
      "223 [D loss: (-33.954)(R -58.464, F -9.445)]  [G loss: 5.634] \n",
      "223 [D loss: (-33.450)(R -58.180, F -8.720)]  [G loss: 5.660] \n",
      "224 [D loss: (-33.715)(R -59.259, F -8.170)]  [G loss: 6.272] \n",
      "224 [D loss: (-33.631)(R -58.521, F -8.740)]  [G loss: 5.993] \n",
      "225 [D loss: (-33.459)(R -59.366, F -7.553)]  [G loss: 5.984] \n",
      "225 [D loss: (-32.974)(R -58.497, F -7.452)]  [G loss: 6.619] \n",
      "226 [D loss: (-35.024)(R -59.484, F -10.564)]  [G loss: 6.359] \n",
      "226 [D loss: (-33.437)(R -59.492, F -7.382)]  [G loss: 6.504] \n",
      "227 [D loss: (-34.010)(R -57.592, F -10.428)]  [G loss: 6.747] \n",
      "227 [D loss: (-34.706)(R -61.958, F -7.455)]  [G loss: 6.608] \n",
      "228 [D loss: (-33.634)(R -58.210, F -9.058)]  [G loss: 6.532] \n",
      "228 [D loss: (-35.214)(R -59.923, F -10.504)]  [G loss: 6.924] \n",
      "229 [D loss: (-32.987)(R -57.275, F -8.700)]  [G loss: 6.401] \n",
      "229 [D loss: (-34.865)(R -58.113, F -11.618)]  [G loss: 6.409] \n",
      "230 [D loss: (-34.224)(R -60.557, F -7.891)]  [G loss: 6.073] \n",
      "230 [D loss: (-33.289)(R -58.805, F -7.773)]  [G loss: 6.085] \n",
      "231 [D loss: (-33.731)(R -59.198, F -8.264)]  [G loss: 5.834] \n",
      "231 [D loss: (-33.091)(R -56.694, F -9.487)]  [G loss: 5.926] \n",
      "232 [D loss: (-33.774)(R -59.228, F -8.321)]  [G loss: 6.141] \n",
      "232 [D loss: (-34.392)(R -59.859, F -8.924)]  [G loss: 5.282] \n",
      "233 [D loss: (-34.459)(R -58.151, F -10.767)]  [G loss: 5.536] \n",
      "233 [D loss: (-34.147)(R -58.000, F -10.294)]  [G loss: 5.312] \n",
      "234 [D loss: (-31.836)(R -57.692, F -5.980)]  [G loss: 5.111] \n",
      "234 [D loss: (-34.776)(R -60.436, F -9.115)]  [G loss: 4.853] \n",
      "235 [D loss: (-33.009)(R -58.550, F -7.467)]  [G loss: 5.209] \n",
      "235 [D loss: (-32.983)(R -57.853, F -8.113)]  [G loss: 4.920] \n",
      "236 [D loss: (-33.865)(R -58.008, F -9.723)]  [G loss: 4.435] \n",
      "236 [D loss: (-32.991)(R -57.323, F -8.659)]  [G loss: 4.446] \n",
      "237 [D loss: (-34.353)(R -58.581, F -10.126)]  [G loss: 4.352] \n",
      "237 [D loss: (-33.233)(R -57.263, F -9.203)]  [G loss: 3.919] \n",
      "238 [D loss: (-33.775)(R -58.314, F -9.236)]  [G loss: 4.181] \n",
      "238 [D loss: (-34.452)(R -58.413, F -10.491)]  [G loss: 3.907] \n",
      "239 [D loss: (-32.100)(R -54.495, F -9.705)]  [G loss: 3.701] \n",
      "239 [D loss: (-34.230)(R -57.871, F -10.588)]  [G loss: 3.636] \n",
      "240 [D loss: (-32.549)(R -54.024, F -11.074)]  [G loss: 4.664] \n",
      "240 [D loss: (-32.018)(R -51.894, F -12.141)]  [G loss: 4.678] \n",
      "241 [D loss: (-31.415)(R -50.922, F -11.908)]  [G loss: 5.180] \n",
      "241 [D loss: (-31.982)(R -51.541, F -12.423)]  [G loss: 5.445] \n",
      "242 [D loss: (-31.668)(R -51.159, F -12.177)]  [G loss: 5.266] \n",
      "242 [D loss: (-31.489)(R -50.182, F -12.795)]  [G loss: 5.907] \n",
      "243 [D loss: (-30.526)(R -47.983, F -13.069)]  [G loss: 6.514] \n",
      "243 [D loss: (-30.617)(R -47.672, F -13.562)]  [G loss: 7.128] \n",
      "244 [D loss: (-31.037)(R -47.983, F -14.090)]  [G loss: 7.881] \n",
      "244 [D loss: (-29.574)(R -44.570, F -14.578)]  [G loss: 8.887] \n",
      "245 [D loss: (-30.819)(R -45.829, F -15.809)]  [G loss: 9.832] \n",
      "245 [D loss: (-30.035)(R -44.018, F -16.053)]  [G loss: 10.905] \n",
      "246 [D loss: (-29.781)(R -42.684, F -16.877)]  [G loss: 11.550] \n",
      "246 [D loss: (-29.504)(R -41.941, F -17.068)]  [G loss: 12.020] \n",
      "247 [D loss: (-29.619)(R -43.299, F -15.938)]  [G loss: 12.520] \n",
      "247 [D loss: (-29.597)(R -42.908, F -16.286)]  [G loss: 12.455] \n",
      "248 [D loss: (-29.877)(R -43.928, F -15.825)]  [G loss: 13.367] \n",
      "248 [D loss: (-29.700)(R -42.678, F -16.722)]  [G loss: 14.025] \n",
      "249 [D loss: (-28.745)(R -41.064, F -16.426)]  [G loss: 14.601] \n",
      "249 [D loss: (-28.786)(R -41.267, F -16.306)]  [G loss: 15.050] \n",
      "250 [D loss: (-29.439)(R -41.358, F -17.521)]  [G loss: 16.022] \n",
      "250 [D loss: (-30.271)(R -43.679, F -16.864)]  [G loss: 16.721] \n",
      "251 [D loss: (-30.582)(R -43.518, F -17.647)]  [G loss: 17.274] \n",
      "251 [D loss: (-29.994)(R -41.954, F -18.033)]  [G loss: 18.036] \n",
      "252 [D loss: (-30.601)(R -42.626, F -18.576)]  [G loss: 19.216] \n",
      "252 [D loss: (-30.508)(R -41.938, F -19.079)]  [G loss: 19.443] \n",
      "253 [D loss: (-30.852)(R -42.800, F -18.905)]  [G loss: 19.954] \n",
      "253 [D loss: (-30.802)(R -41.646, F -19.959)]  [G loss: 20.789] \n",
      "254 [D loss: (-32.277)(R -44.603, F -19.951)]  [G loss: 21.358] \n",
      "254 [D loss: (-32.109)(R -43.496, F -20.722)]  [G loss: 22.099] \n",
      "255 [D loss: (-32.199)(R -43.052, F -21.346)]  [G loss: 22.551] \n",
      "255 [D loss: (-32.910)(R -44.781, F -21.039)]  [G loss: 22.646] \n",
      "256 [D loss: (-32.490)(R -42.761, F -22.219)]  [G loss: 23.468] \n",
      "256 [D loss: (-32.192)(R -42.343, F -22.041)]  [G loss: 23.706] \n",
      "257 [D loss: (-34.475)(R -46.363, F -22.586)]  [G loss: 23.882] \n",
      "257 [D loss: (-34.269)(R -46.056, F -22.482)]  [G loss: 24.137] \n",
      "258 [D loss: (-34.052)(R -45.469, F -22.635)]  [G loss: 24.486] \n",
      "258 [D loss: (-33.801)(R -43.910, F -23.692)]  [G loss: 25.043] \n",
      "259 [D loss: (-35.275)(R -46.743, F -23.808)]  [G loss: 24.898] \n",
      "259 [D loss: (-34.814)(R -45.598, F -24.030)]  [G loss: 25.218] \n",
      "260 [D loss: (-36.007)(R -46.944, F -25.071)]  [G loss: 25.008] \n",
      "260 [D loss: (-34.860)(R -46.271, F -23.449)]  [G loss: 25.417] \n",
      "261 [D loss: (-36.608)(R -47.049, F -26.166)]  [G loss: 25.653] \n",
      "261 [D loss: (-35.358)(R -45.280, F -25.437)]  [G loss: 25.716] \n",
      "262 [D loss: (-35.992)(R -47.123, F -24.861)]  [G loss: 26.031] \n",
      "262 [D loss: (-35.533)(R -47.069, F -23.997)]  [G loss: 26.078] \n",
      "263 [D loss: (-37.125)(R -49.825, F -24.425)]  [G loss: 25.725] \n",
      "263 [D loss: (-37.453)(R -49.711, F -25.195)]  [G loss: 25.502] \n",
      "264 [D loss: (-36.845)(R -47.923, F -25.766)]  [G loss: 25.408] \n",
      "264 [D loss: (-37.315)(R -49.015, F -25.614)]  [G loss: 25.115] \n",
      "265 [D loss: (-36.733)(R -49.198, F -24.268)]  [G loss: 24.839] \n",
      "265 [D loss: (-35.994)(R -47.051, F -24.937)]  [G loss: 25.039] \n",
      "266 [D loss: (-35.251)(R -44.915, F -25.587)]  [G loss: 24.800] \n",
      "266 [D loss: (-36.464)(R -47.599, F -25.328)]  [G loss: 23.896] \n",
      "267 [D loss: (-35.242)(R -47.482, F -23.001)]  [G loss: 23.664] \n",
      "267 [D loss: (-36.091)(R -48.273, F -23.909)]  [G loss: 23.036] \n",
      "268 [D loss: (-35.561)(R -48.233, F -22.890)]  [G loss: 22.621] \n",
      "268 [D loss: (-35.220)(R -49.175, F -21.265)]  [G loss: 22.112] \n",
      "269 [D loss: (-35.923)(R -48.550, F -23.295)]  [G loss: 22.186] \n",
      "269 [D loss: (-36.666)(R -50.526, F -22.807)]  [G loss: 20.810] \n",
      "270 [D loss: (-36.164)(R -49.624, F -22.704)]  [G loss: 20.464] \n",
      "270 [D loss: (-35.968)(R -51.579, F -20.358)]  [G loss: 19.767] \n",
      "271 [D loss: (-36.116)(R -51.093, F -21.139)]  [G loss: 19.135] \n",
      "271 [D loss: (-36.737)(R -52.016, F -21.459)]  [G loss: 18.459] \n",
      "272 [D loss: (-35.067)(R -50.238, F -19.895)]  [G loss: 17.584] \n",
      "272 [D loss: (-34.016)(R -49.296, F -18.737)]  [G loss: 17.032] \n",
      "273 [D loss: (-34.776)(R -50.705, F -18.847)]  [G loss: 16.341] \n",
      "273 [D loss: (-35.592)(R -52.121, F -19.063)]  [G loss: 15.394] \n",
      "274 [D loss: (-32.748)(R -48.788, F -16.707)]  [G loss: 14.708] \n",
      "274 [D loss: (-33.931)(R -50.182, F -17.680)]  [G loss: 13.561] \n",
      "275 [D loss: (-34.388)(R -51.483, F -17.292)]  [G loss: 12.435] \n",
      "275 [D loss: (-33.092)(R -50.036, F -16.148)]  [G loss: 11.814] \n",
      "276 [D loss: (-33.344)(R -51.838, F -14.851)]  [G loss: 11.442] \n",
      "276 [D loss: (-32.848)(R -50.357, F -15.339)]  [G loss: 10.203] \n",
      "277 [D loss: (-33.281)(R -51.934, F -14.627)]  [G loss: 9.678] \n",
      "277 [D loss: (-33.181)(R -53.426, F -12.936)]  [G loss: 8.121] \n",
      "278 [D loss: (-32.012)(R -52.131, F -11.892)]  [G loss: 6.754] \n",
      "278 [D loss: (-32.071)(R -52.157, F -11.984)]  [G loss: 6.176] \n",
      "279 [D loss: (-30.758)(R -50.227, F -11.289)]  [G loss: 4.862] \n",
      "279 [D loss: (-31.721)(R -51.814, F -11.628)]  [G loss: 4.169] \n",
      "280 [D loss: (-32.043)(R -52.811, F -11.274)]  [G loss: 3.809] \n",
      "280 [D loss: (-31.905)(R -53.340, F -10.469)]  [G loss: 3.062] \n",
      "281 [D loss: (-31.852)(R -53.753, F -9.950)]  [G loss: 2.647] \n",
      "281 [D loss: (-29.877)(R -49.179, F -10.575)]  [G loss: 2.254] \n",
      "282 [D loss: (-31.396)(R -52.327, F -10.465)]  [G loss: 1.617] \n",
      "282 [D loss: (-30.235)(R -50.910, F -9.561)]  [G loss: 1.793] \n",
      "283 [D loss: (-28.348)(R -46.949, F -9.747)]  [G loss: 1.309] \n",
      "283 [D loss: (-29.947)(R -50.598, F -9.297)]  [G loss: 1.408] \n",
      "284 [D loss: (-29.909)(R -50.832, F -8.987)]  [G loss: 0.993] \n",
      "284 [D loss: (-28.987)(R -48.965, F -9.009)]  [G loss: 0.945] \n",
      "285 [D loss: (-28.819)(R -49.654, F -7.984)]  [G loss: 0.408] \n",
      "285 [D loss: (-28.301)(R -48.905, F -7.697)]  [G loss: 0.277] \n",
      "286 [D loss: (-27.991)(R -47.853, F -8.129)]  [G loss: 0.006] \n",
      "286 [D loss: (-27.792)(R -48.674, F -6.909)]  [G loss: -0.547] \n",
      "287 [D loss: (-27.477)(R -48.579, F -6.376)]  [G loss: -0.798] \n",
      "287 [D loss: (-25.472)(R -45.613, F -5.330)]  [G loss: -0.681] \n",
      "288 [D loss: (-25.963)(R -46.948, F -4.979)]  [G loss: -0.705] \n",
      "288 [D loss: (-26.328)(R -47.760, F -4.895)]  [G loss: -0.947] \n",
      "289 [D loss: (-25.427)(R -45.820, F -5.035)]  [G loss: -1.154] \n",
      "289 [D loss: (-25.521)(R -46.832, F -4.210)]  [G loss: -1.130] \n",
      "290 [D loss: (-25.679)(R -46.322, F -5.036)]  [G loss: -0.975] \n",
      "290 [D loss: (-25.499)(R -47.354, F -3.644)]  [G loss: -1.959] \n",
      "291 [D loss: (-22.760)(R -43.251, F -2.270)]  [G loss: -1.797] \n",
      "291 [D loss: (-23.068)(R -44.395, F -1.742)]  [G loss: -2.024] \n",
      "292 [D loss: (-25.279)(R -47.268, F -3.290)]  [G loss: -2.137] \n",
      "292 [D loss: (-24.304)(R -45.725, F -2.884)]  [G loss: -2.138] \n",
      "293 [D loss: (-22.989)(R -44.585, F -1.394)]  [G loss: -2.282] \n",
      "293 [D loss: (-22.858)(R -44.325, F -1.390)]  [G loss: -2.174] \n",
      "294 [D loss: (-22.283)(R -43.587, F -0.979)]  [G loss: -2.404] \n",
      "294 [D loss: (-23.233)(R -45.612, F -0.855)]  [G loss: -2.176] \n",
      "295 [D loss: (-23.439)(R -45.607, F -1.271)]  [G loss: -2.091] \n",
      "295 [D loss: (-20.998)(R -40.763, F -1.232)]  [G loss: -1.569] \n",
      "296 [D loss: (-22.867)(R -43.720, F -2.013)]  [G loss: -1.101] \n",
      "296 [D loss: (-21.164)(R -40.213, F -2.114)]  [G loss: -1.003] \n",
      "297 [D loss: (-22.936)(R -43.152, F -2.720)]  [G loss: -0.704] \n",
      "297 [D loss: (-21.598)(R -40.349, F -2.848)]  [G loss: -0.227] \n",
      "298 [D loss: (-23.480)(R -43.246, F -3.714)]  [G loss: 0.488] \n",
      "298 [D loss: (-23.532)(R -42.798, F -4.267)]  [G loss: 0.937] \n",
      "299 [D loss: (-23.285)(R -41.791, F -4.778)]  [G loss: 1.323] \n",
      "299 [D loss: (-22.912)(R -40.551, F -5.272)]  [G loss: 1.786] \n",
      "300 [D loss: (-23.088)(R -39.892, F -6.285)]  [G loss: 2.489] \n",
      "300 [D loss: (-23.804)(R -40.813, F -6.796)]  [G loss: 2.768] \n",
      "301 [D loss: (-23.505)(R -39.663, F -7.346)]  [G loss: 3.114] \n",
      "301 [D loss: (-23.366)(R -39.264, F -7.467)]  [G loss: 3.243] \n",
      "302 [D loss: (-23.355)(R -38.448, F -8.263)]  [G loss: 3.299] \n",
      "302 [D loss: (-24.269)(R -40.105, F -8.433)]  [G loss: 3.471] \n",
      "303 [D loss: (-23.948)(R -39.253, F -8.643)]  [G loss: 3.777] \n",
      "303 [D loss: (-23.836)(R -39.001, F -8.671)]  [G loss: 3.378] \n",
      "304 [D loss: (-24.058)(R -38.938, F -9.178)]  [G loss: 3.202] \n",
      "304 [D loss: (-23.874)(R -38.520, F -9.228)]  [G loss: 3.095] \n",
      "305 [D loss: (-24.669)(R -40.032, F -9.306)]  [G loss: 2.525] \n",
      "305 [D loss: (-22.921)(R -36.223, F -9.620)]  [G loss: 2.615] \n",
      "306 [D loss: (-22.074)(R -34.560, F -9.589)]  [G loss: 2.447] \n",
      "306 [D loss: (-22.707)(R -35.894, F -9.519)]  [G loss: 2.474] \n",
      "307 [D loss: (-23.067)(R -36.127, F -10.007)]  [G loss: 2.285] \n",
      "307 [D loss: (-23.210)(R -36.315, F -10.105)]  [G loss: 2.378] \n",
      "308 [D loss: (-22.376)(R -34.141, F -10.610)]  [G loss: 2.288] \n",
      "308 [D loss: (-22.536)(R -34.784, F -10.287)]  [G loss: 2.400] \n",
      "309 [D loss: (-21.454)(R -32.059, F -10.850)]  [G loss: 2.646] \n",
      "309 [D loss: (-23.403)(R -35.710, F -11.096)]  [G loss: 2.990] \n",
      "310 [D loss: (-22.233)(R -32.863, F -11.602)]  [G loss: 2.715] \n",
      "310 [D loss: (-21.900)(R -31.904, F -11.897)]  [G loss: 3.214] \n",
      "311 [D loss: (-22.343)(R -32.975, F -11.712)]  [G loss: 3.098] \n",
      "311 [D loss: (-20.959)(R -30.681, F -11.238)]  [G loss: 3.444] \n",
      "312 [D loss: (-21.054)(R -30.847, F -11.260)]  [G loss: 3.606] \n",
      "312 [D loss: (-21.051)(R -30.367, F -11.735)]  [G loss: 4.241] \n",
      "313 [D loss: (-21.218)(R -30.613, F -11.823)]  [G loss: 4.065] \n",
      "313 [D loss: (-20.663)(R -28.217, F -13.109)]  [G loss: 4.764] \n",
      "314 [D loss: (-20.911)(R -29.510, F -12.312)]  [G loss: 4.842] \n",
      "314 [D loss: (-21.873)(R -30.880, F -12.866)]  [G loss: 5.757] \n",
      "315 [D loss: (-20.975)(R -29.452, F -12.498)]  [G loss: 5.710] \n",
      "315 [D loss: (-20.994)(R -29.558, F -12.431)]  [G loss: 5.748] \n",
      "316 [D loss: (-21.144)(R -30.136, F -12.151)]  [G loss: 6.215] \n",
      "316 [D loss: (-21.317)(R -29.638, F -12.996)]  [G loss: 6.239] \n",
      "317 [D loss: (-19.371)(R -26.152, F -12.589)]  [G loss: 6.877] \n",
      "317 [D loss: (-20.520)(R -28.562, F -12.477)]  [G loss: 7.007] \n",
      "318 [D loss: (-19.880)(R -27.398, F -12.362)]  [G loss: 7.704] \n",
      "318 [D loss: (-20.867)(R -28.878, F -12.857)]  [G loss: 8.016] \n",
      "319 [D loss: (-20.632)(R -28.066, F -13.199)]  [G loss: 8.471] \n",
      "319 [D loss: (-20.453)(R -27.969, F -12.937)]  [G loss: 9.082] \n",
      "320 [D loss: (-21.114)(R -28.041, F -14.188)]  [G loss: 9.479] \n",
      "320 [D loss: (-21.244)(R -29.343, F -13.144)]  [G loss: 9.740] \n",
      "321 [D loss: (-20.733)(R -27.968, F -13.498)]  [G loss: 10.300] \n",
      "321 [D loss: (-21.472)(R -29.224, F -13.719)]  [G loss: 10.441] \n",
      "322 [D loss: (-20.312)(R -26.548, F -14.075)]  [G loss: 10.661] \n",
      "322 [D loss: (-22.297)(R -29.602, F -14.992)]  [G loss: 11.584] \n",
      "323 [D loss: (-20.763)(R -27.255, F -14.270)]  [G loss: 11.712] \n",
      "323 [D loss: (-21.218)(R -28.000, F -14.437)]  [G loss: 12.402] \n",
      "324 [D loss: (-21.902)(R -29.025, F -14.778)]  [G loss: 12.555] \n",
      "324 [D loss: (-22.372)(R -29.725, F -15.018)]  [G loss: 12.618] \n",
      "325 [D loss: (-22.066)(R -29.037, F -15.095)]  [G loss: 12.431] \n",
      "325 [D loss: (-21.902)(R -28.769, F -15.036)]  [G loss: 13.385] \n",
      "326 [D loss: (-21.047)(R -27.644, F -14.449)]  [G loss: 12.754] \n",
      "326 [D loss: (-23.030)(R -30.809, F -15.251)]  [G loss: 13.089] \n",
      "327 [D loss: (-22.518)(R -29.630, F -15.406)]  [G loss: 13.656] \n",
      "327 [D loss: (-22.388)(R -29.623, F -15.154)]  [G loss: 13.968] \n",
      "328 [D loss: (-23.065)(R -30.285, F -15.846)]  [G loss: 14.471] \n",
      "328 [D loss: (-22.827)(R -29.667, F -15.988)]  [G loss: 14.431] \n",
      "329 [D loss: (-22.036)(R -29.012, F -15.061)]  [G loss: 14.708] \n",
      "329 [D loss: (-23.087)(R -30.434, F -15.740)]  [G loss: 14.691] \n",
      "330 [D loss: (-23.167)(R -30.290, F -16.045)]  [G loss: 15.098] \n",
      "330 [D loss: (-23.889)(R -31.849, F -15.929)]  [G loss: 15.150] \n",
      "331 [D loss: (-24.296)(R -32.441, F -16.151)]  [G loss: 15.787] \n",
      "331 [D loss: (-23.861)(R -32.095, F -15.627)]  [G loss: 16.100] \n",
      "332 [D loss: (-24.568)(R -32.782, F -16.354)]  [G loss: 16.031] \n",
      "332 [D loss: (-24.259)(R -32.066, F -16.452)]  [G loss: 16.365] \n",
      "333 [D loss: (-24.178)(R -31.533, F -16.823)]  [G loss: 16.460] \n",
      "333 [D loss: (-24.142)(R -30.370, F -17.913)]  [G loss: 16.922] \n",
      "334 [D loss: (-24.595)(R -31.893, F -17.298)]  [G loss: 16.637] \n",
      "334 [D loss: (-24.409)(R -32.900, F -15.919)]  [G loss: 16.146] \n",
      "335 [D loss: (-25.037)(R -33.870, F -16.205)]  [G loss: 16.219] \n",
      "335 [D loss: (-24.790)(R -33.488, F -16.092)]  [G loss: 16.043] \n",
      "336 [D loss: (-23.768)(R -31.822, F -15.714)]  [G loss: 15.071] \n",
      "336 [D loss: (-24.266)(R -32.927, F -15.604)]  [G loss: 15.786] \n",
      "337 [D loss: (-23.831)(R -32.146, F -15.515)]  [G loss: 15.542] \n",
      "337 [D loss: (-24.682)(R -33.615, F -15.749)]  [G loss: 15.262] \n",
      "338 [D loss: (-24.540)(R -33.899, F -15.180)]  [G loss: 14.102] \n",
      "338 [D loss: (-24.070)(R -33.443, F -14.698)]  [G loss: 14.383] \n",
      "339 [D loss: (-24.401)(R -33.231, F -15.571)]  [G loss: 13.704] \n",
      "339 [D loss: (-22.082)(R -30.747, F -13.416)]  [G loss: 13.517] \n",
      "340 [D loss: (-22.847)(R -32.648, F -13.045)]  [G loss: 12.705] \n",
      "340 [D loss: (-21.753)(R -30.816, F -12.690)]  [G loss: 12.076] \n",
      "341 [D loss: (-21.931)(R -31.347, F -12.515)]  [G loss: 12.375] \n",
      "341 [D loss: (-20.598)(R -29.371, F -11.826)]  [G loss: 11.971] \n",
      "342 [D loss: (-21.542)(R -30.585, F -12.499)]  [G loss: 11.022] \n",
      "342 [D loss: (-20.771)(R -30.009, F -11.533)]  [G loss: 10.030] \n",
      "343 [D loss: (-20.088)(R -28.415, F -11.762)]  [G loss: 10.770] \n",
      "343 [D loss: (-19.733)(R -29.569, F -9.896)]  [G loss: 9.178] \n",
      "344 [D loss: (-18.803)(R -28.499, F -9.107)]  [G loss: 8.937] \n",
      "344 [D loss: (-17.995)(R -27.350, F -8.641)]  [G loss: 8.263] \n",
      "345 [D loss: (-16.372)(R -25.813, F -6.931)]  [G loss: 7.795] \n",
      "345 [D loss: (-17.264)(R -26.792, F -7.737)]  [G loss: 5.185] \n",
      "346 [D loss: (-16.754)(R -26.267, F -7.241)]  [G loss: 5.099] \n",
      "346 [D loss: (-15.140)(R -24.588, F -5.691)]  [G loss: 4.033] \n",
      "347 [D loss: (-15.476)(R -25.066, F -5.886)]  [G loss: 3.520] \n",
      "347 [D loss: (-14.637)(R -24.179, F -5.096)]  [G loss: 2.951] \n",
      "348 [D loss: (-13.528)(R -22.802, F -4.253)]  [G loss: 1.858] \n",
      "348 [D loss: (-12.606)(R -21.719, F -3.493)]  [G loss: 1.067] \n",
      "349 [D loss: (-12.211)(R -22.256, F -2.166)]  [G loss: 1.766] \n",
      "349 [D loss: (-11.243)(R -20.562, F -1.923)]  [G loss: 1.055] \n",
      "350 [D loss: (-11.513)(R -20.577, F -2.450)]  [G loss: 0.621] \n",
      "350 [D loss: (-11.415)(R -19.205, F -3.625)]  [G loss: 1.849] \n",
      "351 [D loss: (-9.974)(R -17.042, F -2.907)]  [G loss: 1.212] \n",
      "351 [D loss: (-10.863)(R -17.706, F -4.021)]  [G loss: 2.221] \n",
      "352 [D loss: (-9.584)(R -15.659, F -3.509)]  [G loss: 1.588] \n",
      "352 [D loss: (-10.950)(R -17.188, F -4.713)]  [G loss: 1.805] \n",
      "353 [D loss: (-10.280)(R -16.435, F -4.125)]  [G loss: 1.654] \n",
      "353 [D loss: (-9.725)(R -15.846, F -3.604)]  [G loss: 1.711] \n",
      "354 [D loss: (-10.131)(R -14.525, F -5.736)]  [G loss: 2.882] \n",
      "354 [D loss: (-10.218)(R -14.973, F -5.464)]  [G loss: 3.268] \n",
      "355 [D loss: (-9.266)(R -13.409, F -5.124)]  [G loss: 3.064] \n",
      "355 [D loss: (-9.365)(R -12.833, F -5.896)]  [G loss: 3.677] \n",
      "356 [D loss: (-10.767)(R -14.836, F -6.698)]  [G loss: 4.035] \n",
      "356 [D loss: (-8.950)(R -12.937, F -4.963)]  [G loss: 4.048] \n",
      "357 [D loss: (-9.997)(R -14.942, F -5.052)]  [G loss: 3.786] \n",
      "357 [D loss: (-9.820)(R -14.424, F -5.216)]  [G loss: 3.184] \n",
      "358 [D loss: (-9.995)(R -13.787, F -6.203)]  [G loss: 4.185] \n",
      "358 [D loss: (-9.689)(R -12.970, F -6.408)]  [G loss: 4.070] \n",
      "359 [D loss: (-9.936)(R -14.339, F -5.534)]  [G loss: 3.825] \n",
      "359 [D loss: (-10.466)(R -15.521, F -5.412)]  [G loss: 3.727] \n",
      "360 [D loss: (-10.339)(R -14.851, F -5.827)]  [G loss: 3.430] \n",
      "360 [D loss: (-11.009)(R -15.497, F -6.521)]  [G loss: 3.661] \n",
      "361 [D loss: (-10.673)(R -15.619, F -5.727)]  [G loss: 2.535] \n",
      "361 [D loss: (-10.093)(R -15.848, F -4.338)]  [G loss: 1.768] \n",
      "362 [D loss: (-10.110)(R -17.569, F -2.650)]  [G loss: 1.979] \n",
      "362 [D loss: (-9.620)(R -17.543, F -1.698)]  [G loss: 0.957] \n",
      "363 [D loss: (-10.219)(R -18.581, F -1.856)]  [G loss: 1.390] \n",
      "363 [D loss: (-9.963)(R -18.044, F -1.882)]  [G loss: 0.925] \n",
      "364 [D loss: (-10.566)(R -17.960, F -3.172)]  [G loss: 1.137] \n",
      "364 [D loss: (-10.695)(R -20.979, F -0.410)]  [G loss: -0.185] \n",
      "365 [D loss: (-10.390)(R -19.656, F -1.124)]  [G loss: -0.217] \n",
      "365 [D loss: (-9.408)(R -20.202, F 1.386)]  [G loss: -0.260] \n",
      "366 [D loss: (-10.768)(R -20.832, F -0.703)]  [G loss: -0.611] \n",
      "366 [D loss: (-10.203)(R -20.745, F 0.338)]  [G loss: -0.643] \n",
      "367 [D loss: (-11.086)(R -21.331, F -0.841)]  [G loss: -0.879] \n",
      "367 [D loss: (-9.957)(R -20.223, F 0.308)]  [G loss: -0.224] \n",
      "368 [D loss: (-10.351)(R -20.683, F -0.019)]  [G loss: -0.911] \n",
      "368 [D loss: (-10.461)(R -21.058, F 0.136)]  [G loss: -1.175] \n",
      "369 [D loss: (-10.602)(R -20.985, F -0.218)]  [G loss: -0.846] \n",
      "369 [D loss: (-10.302)(R -21.153, F 0.548)]  [G loss: -1.424] \n",
      "370 [D loss: (-10.191)(R -20.927, F 0.546)]  [G loss: -1.461] \n",
      "370 [D loss: (-10.538)(R -21.601, F 0.525)]  [G loss: -1.286] \n",
      "371 [D loss: (-10.986)(R -22.626, F 0.654)]  [G loss: -2.126] \n",
      "371 [D loss: (-11.353)(R -22.730, F 0.024)]  [G loss: -1.731] \n",
      "372 [D loss: (-9.667)(R -22.639, F 3.304)]  [G loss: -1.408] \n",
      "372 [D loss: (-11.408)(R -22.849, F 0.033)]  [G loss: -1.292] \n",
      "373 [D loss: (-11.056)(R -23.222, F 1.109)]  [G loss: -1.446] \n",
      "373 [D loss: (-11.254)(R -24.141, F 1.633)]  [G loss: -2.001] \n",
      "374 [D loss: (-12.388)(R -24.954, F 0.179)]  [G loss: -1.262] \n",
      "374 [D loss: (-12.383)(R -24.846, F 0.079)]  [G loss: -2.423] \n",
      "375 [D loss: (-11.898)(R -24.719, F 0.924)]  [G loss: -2.532] \n",
      "375 [D loss: (-10.996)(R -24.402, F 2.411)]  [G loss: -1.671] \n",
      "376 [D loss: (-12.486)(R -25.788, F 0.816)]  [G loss: -1.793] \n",
      "376 [D loss: (-12.384)(R -25.125, F 0.357)]  [G loss: -0.995] \n",
      "377 [D loss: (-11.690)(R -24.843, F 1.463)]  [G loss: -1.153] \n",
      "377 [D loss: (-12.176)(R -25.257, F 0.904)]  [G loss: -1.612] \n",
      "378 [D loss: (-13.103)(R -25.595, F -0.611)]  [G loss: -2.064] \n",
      "378 [D loss: (-12.535)(R -25.440, F 0.371)]  [G loss: -1.107] \n",
      "379 [D loss: (-12.305)(R -25.554, F 0.944)]  [G loss: -0.888] \n",
      "379 [D loss: (-12.174)(R -25.533, F 1.184)]  [G loss: -1.434] \n",
      "380 [D loss: (-11.815)(R -26.589, F 2.960)]  [G loss: -1.221] \n",
      "380 [D loss: (-12.249)(R -26.455, F 1.958)]  [G loss: -1.764] \n",
      "381 [D loss: (-13.521)(R -27.087, F 0.045)]  [G loss: -1.697] \n",
      "381 [D loss: (-13.910)(R -27.042, F -0.778)]  [G loss: -0.973] \n",
      "382 [D loss: (-11.886)(R -26.921, F 3.150)]  [G loss: -1.204] \n",
      "382 [D loss: (-12.246)(R -26.475, F 1.984)]  [G loss: -0.992] \n",
      "383 [D loss: (-13.476)(R -26.797, F -0.156)]  [G loss: -1.121] \n",
      "383 [D loss: (-12.741)(R -27.200, F 1.718)]  [G loss: -1.517] \n",
      "384 [D loss: (-14.078)(R -29.444, F 1.288)]  [G loss: -2.510] \n",
      "384 [D loss: (-12.021)(R -27.221, F 3.178)]  [G loss: -3.055] \n",
      "385 [D loss: (-12.660)(R -27.255, F 1.934)]  [G loss: -2.332] \n",
      "385 [D loss: (-12.156)(R -28.250, F 3.937)]  [G loss: -2.368] \n",
      "386 [D loss: (-11.953)(R -26.898, F 2.991)]  [G loss: -1.865] \n",
      "386 [D loss: (-12.825)(R -28.969, F 3.320)]  [G loss: -3.059] \n",
      "387 [D loss: (-13.048)(R -27.015, F 0.919)]  [G loss: -2.975] \n",
      "387 [D loss: (-11.433)(R -27.371, F 4.504)]  [G loss: -3.450] \n",
      "388 [D loss: (-12.264)(R -28.414, F 3.887)]  [G loss: -3.610] \n",
      "388 [D loss: (-13.442)(R -28.635, F 1.750)]  [G loss: -3.865] \n",
      "389 [D loss: (-11.153)(R -27.568, F 5.263)]  [G loss: -4.339] \n",
      "389 [D loss: (-13.490)(R -28.583, F 1.602)]  [G loss: -4.477] \n",
      "390 [D loss: (-11.663)(R -28.475, F 5.150)]  [G loss: -5.071] \n",
      "390 [D loss: (-12.506)(R -28.705, F 3.693)]  [G loss: -5.097] \n",
      "391 [D loss: (-13.288)(R -28.960, F 2.385)]  [G loss: -4.995] \n",
      "391 [D loss: (-11.658)(R -27.802, F 4.487)]  [G loss: -6.243] \n",
      "392 [D loss: (-11.365)(R -28.617, F 5.886)]  [G loss: -7.586] \n",
      "392 [D loss: (-11.631)(R -29.495, F 6.234)]  [G loss: -7.669] \n",
      "393 [D loss: (-12.378)(R -30.464, F 5.708)]  [G loss: -8.713] \n",
      "393 [D loss: (-10.080)(R -29.497, F 9.336)]  [G loss: -8.405] \n",
      "394 [D loss: (-10.584)(R -28.907, F 7.739)]  [G loss: -8.580] \n",
      "394 [D loss: (-12.071)(R -30.823, F 6.681)]  [G loss: -9.733] \n",
      "395 [D loss: (-10.315)(R -30.101, F 9.470)]  [G loss: -9.345] \n",
      "395 [D loss: (-10.616)(R -30.120, F 8.888)]  [G loss: -11.402] \n",
      "396 [D loss: (-10.033)(R -30.086, F 10.021)]  [G loss: -10.721] \n",
      "396 [D loss: (-11.676)(R -30.992, F 7.639)]  [G loss: -12.265] \n",
      "397 [D loss: (-8.697)(R -31.470, F 14.075)]  [G loss: -11.852] \n",
      "397 [D loss: (-8.539)(R -31.194, F 14.115)]  [G loss: -12.692] \n",
      "398 [D loss: (-9.385)(R -31.281, F 12.510)]  [G loss: -13.309] \n",
      "398 [D loss: (-9.865)(R -32.000, F 12.271)]  [G loss: -13.682] \n",
      "399 [D loss: (-10.775)(R -32.272, F 10.721)]  [G loss: -14.549] \n",
      "399 [D loss: (-11.082)(R -32.719, F 10.555)]  [G loss: -15.040] \n",
      "400 [D loss: (-8.790)(R -33.068, F 15.488)]  [G loss: -15.797] \n",
      "400 [D loss: (-8.744)(R -33.332, F 15.845)]  [G loss: -15.746] \n",
      "401 [D loss: (-8.785)(R -32.924, F 15.354)]  [G loss: -15.744] \n",
      "401 [D loss: (-7.900)(R -33.003, F 17.202)]  [G loss: -15.625] \n",
      "402 [D loss: (-10.777)(R -33.256, F 11.701)]  [G loss: -15.678] \n",
      "402 [D loss: (-9.042)(R -31.397, F 13.313)]  [G loss: -16.252] \n",
      "403 [D loss: (-10.505)(R -33.330, F 12.321)]  [G loss: -15.903] \n",
      "403 [D loss: (-9.398)(R -33.465, F 14.669)]  [G loss: -16.581] \n",
      "404 [D loss: (-6.811)(R -32.394, F 18.772)]  [G loss: -16.294] \n",
      "404 [D loss: (-9.628)(R -31.916, F 12.659)]  [G loss: -16.762] \n",
      "405 [D loss: (-8.080)(R -32.483, F 16.323)]  [G loss: -16.845] \n",
      "405 [D loss: (-9.784)(R -33.628, F 14.061)]  [G loss: -16.681] \n",
      "406 [D loss: (-5.129)(R -32.293, F 22.034)]  [G loss: -16.063] \n",
      "406 [D loss: (-8.663)(R -32.291, F 14.965)]  [G loss: -17.434] \n",
      "407 [D loss: (-7.560)(R -33.331, F 18.212)]  [G loss: -17.137] \n",
      "407 [D loss: (-9.847)(R -32.785, F 13.092)]  [G loss: -16.032] \n",
      "408 [D loss: (-9.317)(R -34.033, F 15.399)]  [G loss: -16.688] \n",
      "408 [D loss: (-7.851)(R -33.124, F 17.422)]  [G loss: -16.649] \n",
      "409 [D loss: (-8.551)(R -32.536, F 15.434)]  [G loss: -16.842] \n",
      "409 [D loss: (-7.985)(R -32.279, F 16.309)]  [G loss: -16.407] \n",
      "410 [D loss: (-7.898)(R -32.485, F 16.689)]  [G loss: -16.412] \n",
      "410 [D loss: (-8.903)(R -33.407, F 15.601)]  [G loss: -16.843] \n",
      "411 [D loss: (-7.239)(R -32.503, F 18.026)]  [G loss: -16.744] \n",
      "411 [D loss: (-8.997)(R -32.673, F 14.678)]  [G loss: -16.610] \n",
      "412 [D loss: (-7.239)(R -32.484, F 18.006)]  [G loss: -16.031] \n",
      "412 [D loss: (-7.696)(R -31.291, F 15.898)]  [G loss: -17.313] \n",
      "413 [D loss: (-7.911)(R -32.262, F 16.439)]  [G loss: -15.708] \n",
      "413 [D loss: (-11.278)(R -32.444, F 9.887)]  [G loss: -15.590] \n",
      "414 [D loss: (-9.152)(R -31.786, F 13.482)]  [G loss: -15.709] \n",
      "414 [D loss: (-7.921)(R -31.273, F 15.431)]  [G loss: -15.751] \n",
      "415 [D loss: (-7.551)(R -31.145, F 16.044)]  [G loss: -14.537] \n",
      "415 [D loss: (-9.639)(R -30.247, F 10.969)]  [G loss: -14.934] \n",
      "416 [D loss: (-8.581)(R -30.283, F 13.121)]  [G loss: -13.926] \n",
      "416 [D loss: (-7.298)(R -30.678, F 16.081)]  [G loss: -14.418] \n",
      "417 [D loss: (-8.149)(R -30.137, F 13.839)]  [G loss: -13.723] \n",
      "417 [D loss: (-7.689)(R -29.632, F 14.254)]  [G loss: -13.761] \n",
      "418 [D loss: (-5.915)(R -28.787, F 16.956)]  [G loss: -13.038] \n",
      "418 [D loss: (-7.442)(R -28.595, F 13.712)]  [G loss: -12.215] \n",
      "419 [D loss: (-8.316)(R -28.157, F 11.524)]  [G loss: -11.928] \n",
      "419 [D loss: (-7.108)(R -28.694, F 14.478)]  [G loss: -11.901] \n",
      "420 [D loss: (-8.108)(R -27.374, F 11.157)]  [G loss: -12.052] \n",
      "420 [D loss: (-9.582)(R -28.429, F 9.266)]  [G loss: -11.400] \n",
      "421 [D loss: (-8.646)(R -27.772, F 10.481)]  [G loss: -12.229] \n",
      "421 [D loss: (-8.117)(R -27.873, F 11.640)]  [G loss: -12.422] \n",
      "422 [D loss: (-7.228)(R -26.917, F 12.461)]  [G loss: -11.032] \n",
      "422 [D loss: (-7.652)(R -26.854, F 11.551)]  [G loss: -11.105] \n",
      "423 [D loss: (-7.399)(R -26.702, F 11.905)]  [G loss: -9.978] \n",
      "423 [D loss: (-7.190)(R -26.127, F 11.748)]  [G loss: -8.961] \n",
      "424 [D loss: (-7.351)(R -25.193, F 10.491)]  [G loss: -8.555] \n",
      "424 [D loss: (-8.730)(R -25.329, F 7.870)]  [G loss: -8.578] \n",
      "425 [D loss: (-6.623)(R -23.645, F 10.398)]  [G loss: -7.532] \n",
      "425 [D loss: (-7.599)(R -22.443, F 7.244)]  [G loss: -7.281] \n",
      "426 [D loss: (-8.106)(R -22.607, F 6.396)]  [G loss: -6.540] \n",
      "426 [D loss: (-9.639)(R -22.355, F 3.076)]  [G loss: -6.694] \n",
      "427 [D loss: (-8.152)(R -21.951, F 5.648)]  [G loss: -6.233] \n",
      "427 [D loss: (-8.029)(R -22.979, F 6.921)]  [G loss: -5.994] \n",
      "428 [D loss: (-9.677)(R -22.786, F 3.433)]  [G loss: -6.448] \n",
      "428 [D loss: (-7.937)(R -23.228, F 7.353)]  [G loss: -5.800] \n",
      "429 [D loss: (-9.656)(R -22.715, F 3.403)]  [G loss: -7.121] \n",
      "429 [D loss: (-6.857)(R -22.291, F 8.577)]  [G loss: -5.981] \n",
      "430 [D loss: (-8.550)(R -21.509, F 4.409)]  [G loss: -6.129] \n",
      "430 [D loss: (-7.801)(R -22.216, F 6.614)]  [G loss: -5.962] \n",
      "431 [D loss: (-7.818)(R -21.648, F 6.013)]  [G loss: -5.392] \n",
      "431 [D loss: (-8.700)(R -20.502, F 3.102)]  [G loss: -5.370] \n",
      "432 [D loss: (-7.992)(R -21.292, F 5.309)]  [G loss: -5.382] \n",
      "432 [D loss: (-7.955)(R -20.348, F 4.438)]  [G loss: -4.880] \n",
      "433 [D loss: (-8.610)(R -20.649, F 3.428)]  [G loss: -5.027] \n",
      "433 [D loss: (-8.004)(R -21.170, F 5.163)]  [G loss: -5.324] \n",
      "434 [D loss: (-7.823)(R -20.442, F 4.795)]  [G loss: -5.253] \n",
      "434 [D loss: (-8.233)(R -20.412, F 3.947)]  [G loss: -5.152] \n",
      "435 [D loss: (-8.029)(R -20.328, F 4.270)]  [G loss: -4.888] \n",
      "435 [D loss: (-7.853)(R -19.934, F 4.228)]  [G loss: -4.192] \n",
      "436 [D loss: (-7.748)(R -20.211, F 4.715)]  [G loss: -4.844] \n",
      "436 [D loss: (-7.577)(R -19.798, F 4.643)]  [G loss: -4.629] \n",
      "437 [D loss: (-8.782)(R -19.243, F 1.679)]  [G loss: -4.547] \n",
      "437 [D loss: (-7.765)(R -19.951, F 4.422)]  [G loss: -4.975] \n",
      "438 [D loss: (-7.364)(R -18.815, F 4.087)]  [G loss: -4.159] \n",
      "438 [D loss: (-7.770)(R -19.506, F 3.967)]  [G loss: -4.261] \n",
      "439 [D loss: (-5.860)(R -19.473, F 7.754)]  [G loss: -3.793] \n",
      "439 [D loss: (-7.652)(R -19.047, F 3.744)]  [G loss: -5.086] \n",
      "440 [D loss: (-8.722)(R -18.753, F 1.310)]  [G loss: -3.988] \n",
      "440 [D loss: (-6.060)(R -18.356, F 6.237)]  [G loss: -4.007] \n",
      "441 [D loss: (-7.225)(R -18.292, F 3.841)]  [G loss: -4.018] \n",
      "441 [D loss: (-9.164)(R -18.087, F -0.240)]  [G loss: -4.016] \n",
      "442 [D loss: (-7.101)(R -17.850, F 3.649)]  [G loss: -3.299] \n",
      "442 [D loss: (-7.442)(R -17.821, F 2.937)]  [G loss: -2.942] \n",
      "443 [D loss: (-7.532)(R -18.080, F 3.015)]  [G loss: -3.177] \n",
      "443 [D loss: (-6.400)(R -17.476, F 4.676)]  [G loss: -2.961] \n",
      "444 [D loss: (-7.972)(R -16.850, F 0.906)]  [G loss: -3.327] \n",
      "444 [D loss: (-6.738)(R -17.901, F 4.425)]  [G loss: -2.958] \n",
      "445 [D loss: (-6.708)(R -17.985, F 4.569)]  [G loss: -3.816] \n",
      "445 [D loss: (-7.586)(R -17.424, F 2.253)]  [G loss: -3.363] \n",
      "446 [D loss: (-8.237)(R -17.558, F 1.084)]  [G loss: -3.874] \n",
      "446 [D loss: (-6.437)(R -17.669, F 4.795)]  [G loss: -3.891] \n",
      "447 [D loss: (-6.977)(R -17.581, F 3.628)]  [G loss: -2.462] \n",
      "447 [D loss: (-6.545)(R -17.329, F 4.238)]  [G loss: -2.620] \n",
      "448 [D loss: (-8.226)(R -17.077, F 0.625)]  [G loss: -2.697] \n",
      "448 [D loss: (-6.416)(R -16.946, F 4.113)]  [G loss: -3.287] \n",
      "449 [D loss: (-7.418)(R -16.744, F 1.907)]  [G loss: -2.947] \n",
      "449 [D loss: (-6.757)(R -16.334, F 2.820)]  [G loss: -2.470] \n",
      "450 [D loss: (-5.991)(R -15.531, F 3.548)]  [G loss: -1.246] \n",
      "450 [D loss: (-7.794)(R -14.954, F -0.635)]  [G loss: -0.367] \n",
      "451 [D loss: (-7.912)(R -14.785, F -1.039)]  [G loss: 0.217] \n",
      "451 [D loss: (-7.065)(R -14.129, F -0.000)]  [G loss: 0.751] \n",
      "452 [D loss: (-7.641)(R -13.012, F -2.270)]  [G loss: 1.021] \n",
      "452 [D loss: (-7.290)(R -12.934, F -1.646)]  [G loss: 1.062] \n",
      "453 [D loss: (-7.722)(R -13.023, F -2.420)]  [G loss: 1.260] \n",
      "453 [D loss: (-7.122)(R -12.603, F -1.640)]  [G loss: 1.927] \n",
      "454 [D loss: (-7.495)(R -12.107, F -2.882)]  [G loss: 2.159] \n",
      "454 [D loss: (-6.274)(R -12.123, F -0.424)]  [G loss: 2.214] \n",
      "455 [D loss: (-7.043)(R -12.106, F -1.979)]  [G loss: 2.118] \n",
      "455 [D loss: (-6.288)(R -12.052, F -0.525)]  [G loss: 2.835] \n",
      "456 [D loss: (-7.634)(R -12.124, F -3.145)]  [G loss: 2.399] \n",
      "456 [D loss: (-6.588)(R -11.604, F -1.572)]  [G loss: 2.642] \n",
      "457 [D loss: (-7.489)(R -11.092, F -3.886)]  [G loss: 3.651] \n",
      "457 [D loss: (-7.271)(R -11.122, F -3.420)]  [G loss: 3.800] \n",
      "458 [D loss: (-7.573)(R -11.248, F -3.898)]  [G loss: 3.301] \n",
      "458 [D loss: (-7.452)(R -11.603, F -3.302)]  [G loss: 2.986] \n",
      "459 [D loss: (-7.790)(R -11.573, F -4.007)]  [G loss: 3.168] \n",
      "459 [D loss: (-8.026)(R -11.654, F -4.398)]  [G loss: 3.277] \n",
      "460 [D loss: (-7.586)(R -11.734, F -3.437)]  [G loss: 3.597] \n",
      "460 [D loss: (-6.860)(R -12.029, F -1.691)]  [G loss: 3.770] \n",
      "461 [D loss: (-7.218)(R -11.741, F -2.696)]  [G loss: 3.761] \n",
      "461 [D loss: (-8.161)(R -11.438, F -4.884)]  [G loss: 4.017] \n",
      "462 [D loss: (-7.978)(R -11.666, F -4.290)]  [G loss: 3.709] \n",
      "462 [D loss: (-7.983)(R -11.798, F -4.168)]  [G loss: 3.523] \n",
      "463 [D loss: (-8.436)(R -11.894, F -4.977)]  [G loss: 4.273] \n",
      "463 [D loss: (-8.021)(R -10.788, F -5.254)]  [G loss: 5.169] \n",
      "464 [D loss: (-8.041)(R -11.016, F -5.066)]  [G loss: 5.145] \n",
      "464 [D loss: (-8.687)(R -10.576, F -6.799)]  [G loss: 5.971] \n",
      "465 [D loss: (-8.862)(R -10.025, F -7.700)]  [G loss: 6.461] \n",
      "465 [D loss: (-8.033)(R -10.059, F -6.008)]  [G loss: 6.151] \n",
      "466 [D loss: (-8.667)(R -10.280, F -7.054)]  [G loss: 5.859] \n",
      "466 [D loss: (-8.377)(R -9.761, F -6.994)]  [G loss: 7.089] \n",
      "467 [D loss: (-8.586)(R -9.325, F -7.848)]  [G loss: 7.668] \n",
      "467 [D loss: (-8.654)(R -9.248, F -8.059)]  [G loss: 7.387] \n",
      "468 [D loss: (-8.538)(R -8.717, F -8.360)]  [G loss: 8.725] \n",
      "468 [D loss: (-9.039)(R -7.664, F -10.414)]  [G loss: 9.240] \n",
      "469 [D loss: (-8.666)(R -7.861, F -9.471)]  [G loss: 9.480] \n",
      "469 [D loss: (-8.653)(R -7.583, F -9.723)]  [G loss: 9.356] \n",
      "470 [D loss: (-8.651)(R -7.321, F -9.981)]  [G loss: 9.992] \n",
      "470 [D loss: (-8.371)(R -6.950, F -9.792)]  [G loss: 10.213] \n",
      "471 [D loss: (-8.871)(R -5.934, F -11.808)]  [G loss: 10.875] \n",
      "471 [D loss: (-8.604)(R -5.706, F -11.503)]  [G loss: 11.590] \n",
      "472 [D loss: (-8.286)(R -5.614, F -10.958)]  [G loss: 12.111] \n",
      "472 [D loss: (-8.960)(R -5.274, F -12.647)]  [G loss: 11.978] \n",
      "473 [D loss: (-8.806)(R -5.075, F -12.537)]  [G loss: 12.261] \n",
      "473 [D loss: (-8.867)(R -5.541, F -12.193)]  [G loss: 11.845] \n",
      "474 [D loss: (-8.549)(R -5.468, F -11.630)]  [G loss: 11.968] \n",
      "474 [D loss: (-8.821)(R -5.382, F -12.260)]  [G loss: 11.828] \n",
      "475 [D loss: (-8.641)(R -5.342, F -11.939)]  [G loss: 12.174] \n",
      "475 [D loss: (-9.124)(R -4.814, F -13.435)]  [G loss: 12.907] \n",
      "476 [D loss: (-8.889)(R -3.967, F -13.812)]  [G loss: 13.302] \n",
      "476 [D loss: (-9.000)(R -3.485, F -14.515)]  [G loss: 13.439] \n",
      "477 [D loss: (-8.949)(R -3.284, F -14.615)]  [G loss: 13.479] \n",
      "477 [D loss: (-8.207)(R -3.409, F -13.005)]  [G loss: 13.160] \n",
      "478 [D loss: (-8.960)(R -4.314, F -13.607)]  [G loss: 12.952] \n",
      "478 [D loss: (-8.302)(R -3.844, F -12.760)]  [G loss: 12.681] \n",
      "479 [D loss: (-8.606)(R -3.356, F -13.855)]  [G loss: 13.555] \n",
      "479 [D loss: (-9.094)(R -3.403, F -14.784)]  [G loss: 13.651] \n",
      "480 [D loss: (-8.413)(R -2.662, F -14.165)]  [G loss: 13.905] \n",
      "480 [D loss: (-8.379)(R -1.919, F -14.840)]  [G loss: 14.325] \n",
      "481 [D loss: (-8.230)(R -2.015, F -14.446)]  [G loss: 14.013] \n",
      "481 [D loss: (-8.587)(R -2.088, F -15.085)]  [G loss: 14.396] \n",
      "482 [D loss: (-8.114)(R -1.566, F -14.663)]  [G loss: 14.344] \n",
      "482 [D loss: (-8.212)(R -1.161, F -15.264)]  [G loss: 14.608] \n",
      "483 [D loss: (-8.136)(R -0.752, F -15.520)]  [G loss: 15.026] \n",
      "483 [D loss: (-8.341)(R -0.770, F -15.912)]  [G loss: 15.227] \n",
      "484 [D loss: (-8.404)(R -1.194, F -15.615)]  [G loss: 15.145] \n",
      "484 [D loss: (-8.023)(R -0.196, F -15.850)]  [G loss: 15.420] \n",
      "485 [D loss: (-7.741)(R 0.196, F -15.679)]  [G loss: 14.912] \n",
      "485 [D loss: (-7.465)(R 0.411, F -15.340)]  [G loss: 14.925] \n",
      "486 [D loss: (-7.868)(R 0.082, F -15.819)]  [G loss: 14.506] \n",
      "486 [D loss: (-7.889)(R -0.011, F -15.767)]  [G loss: 14.514] \n",
      "487 [D loss: (-7.788)(R -0.236, F -15.339)]  [G loss: 13.749] \n",
      "487 [D loss: (-7.631)(R -0.978, F -14.284)]  [G loss: 13.726] \n",
      "488 [D loss: (-7.877)(R -1.601, F -14.154)]  [G loss: 13.770] \n",
      "488 [D loss: (-7.450)(R -0.441, F -14.459)]  [G loss: 13.912] \n",
      "489 [D loss: (-7.413)(R -0.262, F -14.564)]  [G loss: 14.080] \n",
      "489 [D loss: (-7.179)(R -0.112, F -14.245)]  [G loss: 14.074] \n",
      "490 [D loss: (-7.380)(R -0.946, F -13.815)]  [G loss: 13.584] \n",
      "490 [D loss: (-7.579)(R -0.838, F -14.319)]  [G loss: 13.407] \n",
      "491 [D loss: (-7.443)(R -0.447, F -14.439)]  [G loss: 13.865] \n",
      "491 [D loss: (-7.259)(R -0.019, F -14.499)]  [G loss: 13.626] \n",
      "492 [D loss: (-7.331)(R -0.404, F -14.257)]  [G loss: 14.225] \n",
      "492 [D loss: (-7.441)(R -0.026, F -14.855)]  [G loss: 14.691] \n",
      "493 [D loss: (-7.144)(R -0.141, F -14.148)]  [G loss: 14.157] \n",
      "493 [D loss: (-7.412)(R -0.793, F -14.032)]  [G loss: 13.954] \n",
      "494 [D loss: (-7.605)(R -0.160, F -15.049)]  [G loss: 14.521] \n",
      "494 [D loss: (-7.584)(R -0.949, F -14.220)]  [G loss: 14.091] \n",
      "495 [D loss: (-7.315)(R -0.383, F -14.246)]  [G loss: 13.891] \n",
      "495 [D loss: (-7.187)(R -0.649, F -13.725)]  [G loss: 13.304] \n",
      "496 [D loss: (-7.601)(R -2.049, F -13.154)]  [G loss: 13.413] \n",
      "496 [D loss: (-7.549)(R -2.250, F -12.849)]  [G loss: 12.553] \n",
      "497 [D loss: (-7.628)(R -2.224, F -13.033)]  [G loss: 13.298] \n",
      "497 [D loss: (-7.499)(R -2.565, F -12.432)]  [G loss: 12.927] \n",
      "498 [D loss: (-8.108)(R -3.410, F -12.806)]  [G loss: 12.430] \n",
      "498 [D loss: (-7.976)(R -3.834, F -12.118)]  [G loss: 12.300] \n",
      "499 [D loss: (-8.305)(R -4.498, F -12.113)]  [G loss: 12.364] \n",
      "499 [D loss: (-8.594)(R -4.504, F -12.683)]  [G loss: 12.218] \n",
      "500 [D loss: (-9.213)(R -5.152, F -13.273)]  [G loss: 12.745] \n",
      "500 [D loss: (-9.096)(R -5.896, F -12.295)]  [G loss: 12.169] \n",
      "501 [D loss: (-9.276)(R -6.381, F -12.170)]  [G loss: 12.716] \n",
      "501 [D loss: (-9.380)(R -6.293, F -12.467)]  [G loss: 12.698] \n",
      "502 [D loss: (-9.316)(R -6.194, F -12.437)]  [G loss: 13.385] \n",
      "502 [D loss: (-10.041)(R -5.674, F -14.407)]  [G loss: 14.768] \n",
      "503 [D loss: (-9.640)(R -5.424, F -13.856)]  [G loss: 15.242] \n",
      "503 [D loss: (-10.103)(R -5.616, F -14.590)]  [G loss: 15.625] \n",
      "504 [D loss: (-10.523)(R -6.252, F -14.794)]  [G loss: 14.721] \n",
      "504 [D loss: (-10.346)(R -5.946, F -14.747)]  [G loss: 15.332] \n",
      "505 [D loss: (-10.604)(R -6.448, F -14.760)]  [G loss: 15.651] \n",
      "505 [D loss: (-10.673)(R -6.137, F -15.208)]  [G loss: 16.275] \n",
      "506 [D loss: (-10.992)(R -5.826, F -16.158)]  [G loss: 16.663] \n",
      "506 [D loss: (-11.090)(R -6.013, F -16.166)]  [G loss: 16.853] \n",
      "507 [D loss: (-11.191)(R -6.648, F -15.734)]  [G loss: 15.834] \n",
      "507 [D loss: (-11.453)(R -7.748, F -15.158)]  [G loss: 15.427] \n",
      "508 [D loss: (-11.329)(R -8.139, F -14.520)]  [G loss: 14.996] \n",
      "508 [D loss: (-11.115)(R -7.140, F -15.090)]  [G loss: 15.662] \n",
      "509 [D loss: (-11.516)(R -7.989, F -15.043)]  [G loss: 15.187] \n",
      "509 [D loss: (-11.039)(R -6.780, F -15.297)]  [G loss: 15.398] \n",
      "510 [D loss: (-11.602)(R -7.822, F -15.381)]  [G loss: 15.186] \n",
      "510 [D loss: (-11.405)(R -8.243, F -14.568)]  [G loss: 14.734] \n",
      "511 [D loss: (-11.242)(R -7.884, F -14.600)]  [G loss: 14.916] \n",
      "511 [D loss: (-11.387)(R -7.459, F -15.314)]  [G loss: 15.539] \n",
      "512 [D loss: (-10.927)(R -6.673, F -15.180)]  [G loss: 15.021] \n",
      "512 [D loss: (-11.259)(R -7.197, F -15.321)]  [G loss: 15.001] \n",
      "513 [D loss: (-10.799)(R -6.190, F -15.408)]  [G loss: 15.337] \n",
      "513 [D loss: (-10.820)(R -6.758, F -14.882)]  [G loss: 14.900] \n",
      "514 [D loss: (-10.761)(R -6.924, F -14.598)]  [G loss: 14.100] \n",
      "514 [D loss: (-10.613)(R -6.937, F -14.288)]  [G loss: 13.828] \n",
      "515 [D loss: (-10.644)(R -7.211, F -14.077)]  [G loss: 12.790] \n",
      "515 [D loss: (-10.258)(R -7.115, F -13.402)]  [G loss: 12.254] \n",
      "516 [D loss: (-10.212)(R -7.021, F -13.402)]  [G loss: 12.434] \n",
      "516 [D loss: (-9.956)(R -6.203, F -13.710)]  [G loss: 13.187] \n",
      "517 [D loss: (-10.272)(R -5.242, F -15.302)]  [G loss: 13.352] \n",
      "517 [D loss: (-9.674)(R -5.059, F -14.288)]  [G loss: 13.195] \n",
      "518 [D loss: (-9.536)(R -5.333, F -13.739)]  [G loss: 12.707] \n",
      "518 [D loss: (-9.423)(R -4.843, F -14.003)]  [G loss: 12.654] \n",
      "519 [D loss: (-9.400)(R -4.742, F -14.058)]  [G loss: 11.825] \n",
      "519 [D loss: (-9.176)(R -5.349, F -13.004)]  [G loss: 11.463] \n",
      "520 [D loss: (-8.505)(R -4.931, F -12.079)]  [G loss: 11.205] \n",
      "520 [D loss: (-8.838)(R -4.891, F -12.786)]  [G loss: 11.652] \n",
      "521 [D loss: (-8.336)(R -3.768, F -12.904)]  [G loss: 11.848] \n",
      "521 [D loss: (-7.846)(R -2.915, F -12.777)]  [G loss: 12.396] \n",
      "522 [D loss: (-8.397)(R -2.791, F -14.002)]  [G loss: 12.210] \n",
      "522 [D loss: (-8.120)(R -2.884, F -13.355)]  [G loss: 12.001] \n",
      "523 [D loss: (-7.731)(R -2.783, F -12.678)]  [G loss: 11.769] \n",
      "523 [D loss: (-7.759)(R -2.382, F -13.136)]  [G loss: 12.155] \n",
      "524 [D loss: (-7.485)(R -1.941, F -13.029)]  [G loss: 11.816] \n",
      "524 [D loss: (-7.293)(R -2.843, F -11.743)]  [G loss: 11.562] \n",
      "525 [D loss: (-7.163)(R -1.815, F -12.512)]  [G loss: 11.852] \n",
      "525 [D loss: (-7.450)(R -1.402, F -13.498)]  [G loss: 12.108] \n",
      "526 [D loss: (-7.378)(R -1.413, F -13.344)]  [G loss: 11.921] \n",
      "526 [D loss: (-7.348)(R -0.654, F -14.043)]  [G loss: 12.480] \n",
      "527 [D loss: (-6.468)(R 0.163, F -13.098)]  [G loss: 12.878] \n",
      "527 [D loss: (-6.978)(R 0.346, F -14.302)]  [G loss: 13.070] \n",
      "528 [D loss: (-6.910)(R 0.751, F -14.570)]  [G loss: 14.002] \n",
      "528 [D loss: (-6.807)(R 1.172, F -14.785)]  [G loss: 15.065] \n",
      "529 [D loss: (-6.861)(R 2.866, F -16.589)]  [G loss: 15.633] \n",
      "529 [D loss: (-6.401)(R 3.238, F -16.040)]  [G loss: 15.722] \n",
      "530 [D loss: (-6.774)(R 2.821, F -16.369)]  [G loss: 15.819] \n",
      "530 [D loss: (-6.505)(R 3.420, F -16.430)]  [G loss: 15.144] \n",
      "531 [D loss: (-6.765)(R 2.371, F -15.902)]  [G loss: 15.337] \n",
      "531 [D loss: (-6.329)(R 2.842, F -15.499)]  [G loss: 15.582] \n",
      "532 [D loss: (-6.525)(R 2.655, F -15.706)]  [G loss: 15.466] \n",
      "532 [D loss: (-6.879)(R 1.929, F -15.688)]  [G loss: 15.421] \n",
      "533 [D loss: (-6.784)(R 1.867, F -15.436)]  [G loss: 15.374] \n",
      "533 [D loss: (-6.885)(R 1.555, F -15.325)]  [G loss: 15.956] \n",
      "534 [D loss: (-6.602)(R 3.286, F -16.490)]  [G loss: 16.494] \n",
      "534 [D loss: (-6.572)(R 3.771, F -16.916)]  [G loss: 16.806] \n",
      "535 [D loss: (-6.743)(R 3.848, F -17.335)]  [G loss: 17.564] \n",
      "535 [D loss: (-7.070)(R 3.404, F -17.544)]  [G loss: 17.576] \n",
      "536 [D loss: (-6.830)(R 3.604, F -17.264)]  [G loss: 17.635] \n",
      "536 [D loss: (-7.133)(R 3.161, F -17.427)]  [G loss: 17.550] \n",
      "537 [D loss: (-7.348)(R 2.480, F -17.175)]  [G loss: 17.126] \n",
      "537 [D loss: (-7.314)(R 2.294, F -16.922)]  [G loss: 17.317] \n",
      "538 [D loss: (-7.525)(R 2.299, F -17.349)]  [G loss: 17.720] \n",
      "538 [D loss: (-7.175)(R 1.921, F -16.270)]  [G loss: 16.742] \n",
      "539 [D loss: (-7.954)(R 1.138, F -17.046)]  [G loss: 17.122] \n",
      "539 [D loss: (-7.557)(R 1.475, F -16.590)]  [G loss: 16.747] \n",
      "540 [D loss: (-7.581)(R 1.449, F -16.610)]  [G loss: 17.147] \n",
      "540 [D loss: (-8.267)(R -0.133, F -16.402)]  [G loss: 16.849] \n",
      "541 [D loss: (-8.307)(R -0.268, F -16.346)]  [G loss: 16.914] \n",
      "541 [D loss: (-8.191)(R -0.041, F -16.342)]  [G loss: 17.041] \n",
      "542 [D loss: (-8.648)(R -0.669, F -16.627)]  [G loss: 17.113] \n",
      "542 [D loss: (-8.379)(R -0.846, F -15.912)]  [G loss: 16.710] \n",
      "543 [D loss: (-8.760)(R -1.821, F -15.698)]  [G loss: 16.452] \n",
      "543 [D loss: (-9.110)(R -2.033, F -16.188)]  [G loss: 16.759] \n",
      "544 [D loss: (-8.941)(R -1.587, F -16.295)]  [G loss: 16.201] \n",
      "544 [D loss: (-9.081)(R -1.958, F -16.204)]  [G loss: 16.664] \n",
      "545 [D loss: (-9.197)(R -2.492, F -15.901)]  [G loss: 16.357] \n",
      "545 [D loss: (-9.167)(R -2.518, F -15.815)]  [G loss: 16.299] \n",
      "546 [D loss: (-9.044)(R -2.248, F -15.839)]  [G loss: 16.130] \n",
      "546 [D loss: (-9.328)(R -2.596, F -16.061)]  [G loss: 16.329] \n",
      "547 [D loss: (-9.408)(R -3.269, F -15.548)]  [G loss: 16.309] \n",
      "547 [D loss: (-9.582)(R -3.695, F -15.469)]  [G loss: 15.859] \n",
      "548 [D loss: (-9.628)(R -3.404, F -15.851)]  [G loss: 16.152] \n",
      "548 [D loss: (-9.686)(R -3.659, F -15.713)]  [G loss: 16.115] \n",
      "549 [D loss: (-10.145)(R -4.274, F -16.015)]  [G loss: 16.000] \n",
      "549 [D loss: (-10.244)(R -4.518, F -15.970)]  [G loss: 16.342] \n",
      "550 [D loss: (-9.845)(R -3.977, F -15.713)]  [G loss: 16.007] \n",
      "550 [D loss: (-10.215)(R -4.720, F -15.710)]  [G loss: 15.916] \n",
      "551 [D loss: (-10.404)(R -4.905, F -15.904)]  [G loss: 15.789] \n",
      "551 [D loss: (-10.130)(R -4.609, F -15.651)]  [G loss: 15.581] \n",
      "552 [D loss: (-10.107)(R -4.665, F -15.550)]  [G loss: 15.464] \n",
      "552 [D loss: (-10.136)(R -4.561, F -15.711)]  [G loss: 15.948] \n",
      "553 [D loss: (-10.057)(R -4.761, F -15.354)]  [G loss: 15.231] \n",
      "553 [D loss: (-10.041)(R -4.887, F -15.194)]  [G loss: 15.459] \n",
      "554 [D loss: (-9.984)(R -4.620, F -15.349)]  [G loss: 15.554] \n",
      "554 [D loss: (-10.119)(R -4.957, F -15.282)]  [G loss: 15.457] \n",
      "555 [D loss: (-10.033)(R -4.598, F -15.469)]  [G loss: 15.638] \n",
      "555 [D loss: (-9.963)(R -4.369, F -15.557)]  [G loss: 15.557] \n",
      "556 [D loss: (-9.926)(R -4.737, F -15.116)]  [G loss: 15.342] \n",
      "556 [D loss: (-10.113)(R -4.879, F -15.346)]  [G loss: 15.115] \n",
      "557 [D loss: (-10.025)(R -4.893, F -15.157)]  [G loss: 14.926] \n",
      "557 [D loss: (-10.035)(R -4.485, F -15.585)]  [G loss: 15.225] \n",
      "558 [D loss: (-9.859)(R -4.157, F -15.560)]  [G loss: 15.111] \n",
      "558 [D loss: (-9.963)(R -4.625, F -15.301)]  [G loss: 15.102] \n",
      "559 [D loss: (-9.591)(R -4.289, F -14.894)]  [G loss: 14.661] \n",
      "559 [D loss: (-9.765)(R -4.019, F -15.511)]  [G loss: 14.761] \n",
      "560 [D loss: (-9.715)(R -3.927, F -15.503)]  [G loss: 14.800] \n",
      "560 [D loss: (-9.350)(R -3.378, F -15.322)]  [G loss: 14.725] \n",
      "561 [D loss: (-9.436)(R -3.320, F -15.552)]  [G loss: 14.625] \n",
      "561 [D loss: (-9.627)(R -3.713, F -15.541)]  [G loss: 14.912] \n",
      "562 [D loss: (-9.405)(R -3.207, F -15.604)]  [G loss: 14.990] \n",
      "562 [D loss: (-9.401)(R -3.233, F -15.568)]  [G loss: 14.569] \n",
      "563 [D loss: (-9.402)(R -3.593, F -15.210)]  [G loss: 14.548] \n",
      "563 [D loss: (-9.103)(R -2.921, F -15.284)]  [G loss: 14.206] \n",
      "564 [D loss: (-8.860)(R -2.468, F -15.251)]  [G loss: 14.238] \n",
      "564 [D loss: (-8.779)(R -2.607, F -14.951)]  [G loss: 13.789] \n",
      "565 [D loss: (-8.955)(R -2.556, F -15.354)]  [G loss: 13.724] \n",
      "565 [D loss: (-8.537)(R -1.825, F -15.250)]  [G loss: 13.801] \n",
      "566 [D loss: (-8.784)(R -3.059, F -14.510)]  [G loss: 13.215] \n",
      "566 [D loss: (-8.575)(R -2.925, F -14.225)]  [G loss: 12.389] \n",
      "567 [D loss: (-8.565)(R -3.044, F -14.085)]  [G loss: 12.680] \n",
      "567 [D loss: (-8.400)(R -3.242, F -13.558)]  [G loss: 12.297] \n",
      "568 [D loss: (-8.457)(R -3.145, F -13.769)]  [G loss: 12.256] \n",
      "568 [D loss: (-7.928)(R -3.591, F -12.264)]  [G loss: 10.533] \n",
      "569 [D loss: (-7.705)(R -3.681, F -11.728)]  [G loss: 10.102] \n",
      "569 [D loss: (-7.769)(R -4.206, F -11.333)]  [G loss: 10.538] \n",
      "570 [D loss: (-7.697)(R -3.203, F -12.191)]  [G loss: 10.326] \n",
      "570 [D loss: (-7.380)(R -2.177, F -12.583)]  [G loss: 11.703] \n",
      "571 [D loss: (-7.738)(R -0.926, F -14.550)]  [G loss: 12.318] \n",
      "571 [D loss: (-7.551)(R -1.541, F -13.561)]  [G loss: 12.631] \n",
      "572 [D loss: (-7.248)(R -0.994, F -13.502)]  [G loss: 12.363] \n",
      "572 [D loss: (-7.432)(R -1.032, F -13.833)]  [G loss: 12.327] \n",
      "573 [D loss: (-7.167)(R -1.050, F -13.284)]  [G loss: 12.163] \n",
      "573 [D loss: (-6.578)(R -1.276, F -11.881)]  [G loss: 10.859] \n",
      "574 [D loss: (-6.780)(R -1.048, F -12.512)]  [G loss: 10.882] \n",
      "574 [D loss: (-5.905)(R -1.061, F -10.749)]  [G loss: 10.664] \n",
      "575 [D loss: (-6.883)(R -1.545, F -12.220)]  [G loss: 10.274] \n",
      "575 [D loss: (-6.993)(R -2.656, F -11.330)]  [G loss: 8.950] \n",
      "576 [D loss: (-7.116)(R -3.754, F -10.478)]  [G loss: 9.831] \n",
      "576 [D loss: (-8.291)(R -4.966, F -11.616)]  [G loss: 8.831] \n",
      "577 [D loss: (-7.386)(R -5.075, F -9.697)]  [G loss: 7.996] \n",
      "577 [D loss: (-7.668)(R -5.187, F -10.148)]  [G loss: 8.826] \n",
      "578 [D loss: (-7.765)(R -6.488, F -9.043)]  [G loss: 8.117] \n",
      "578 [D loss: (-7.408)(R -5.702, F -9.113)]  [G loss: 9.420] \n",
      "579 [D loss: (-7.381)(R -5.521, F -9.241)]  [G loss: 7.758] \n",
      "579 [D loss: (-7.627)(R -6.404, F -8.849)]  [G loss: 7.116] \n",
      "580 [D loss: (-7.415)(R -6.412, F -8.417)]  [G loss: 8.042] \n",
      "580 [D loss: (-7.663)(R -6.570, F -8.756)]  [G loss: 7.822] \n",
      "581 [D loss: (-7.825)(R -7.383, F -8.267)]  [G loss: 7.932] \n",
      "581 [D loss: (-7.678)(R -6.733, F -8.624)]  [G loss: 7.667] \n",
      "582 [D loss: (-7.683)(R -6.726, F -8.640)]  [G loss: 8.612] \n",
      "582 [D loss: (-7.892)(R -7.007, F -8.777)]  [G loss: 7.654] \n",
      "583 [D loss: (-6.550)(R -7.241, F -5.858)]  [G loss: 7.366] \n",
      "583 [D loss: (-7.610)(R -6.934, F -8.286)]  [G loss: 8.559] \n",
      "584 [D loss: (-7.628)(R -6.908, F -8.348)]  [G loss: 9.392] \n",
      "584 [D loss: (-8.307)(R -6.950, F -9.664)]  [G loss: 9.488] \n",
      "585 [D loss: (-8.428)(R -7.129, F -9.727)]  [G loss: 9.366] \n",
      "585 [D loss: (-8.669)(R -6.760, F -10.578)]  [G loss: 9.730] \n",
      "586 [D loss: (-8.894)(R -6.682, F -11.106)]  [G loss: 10.640] \n",
      "586 [D loss: (-8.068)(R -6.188, F -9.948)]  [G loss: 10.616] \n",
      "587 [D loss: (-8.456)(R -6.060, F -10.853)]  [G loss: 10.279] \n",
      "587 [D loss: (-8.273)(R -6.198, F -10.348)]  [G loss: 10.255] \n",
      "588 [D loss: (-8.396)(R -6.038, F -10.754)]  [G loss: 11.201] \n",
      "588 [D loss: (-8.178)(R -4.857, F -11.499)]  [G loss: 11.673] \n",
      "589 [D loss: (-8.527)(R -5.431, F -11.623)]  [G loss: 12.021] \n",
      "589 [D loss: (-8.487)(R -4.574, F -12.399)]  [G loss: 12.155] \n",
      "590 [D loss: (-8.685)(R -5.317, F -12.052)]  [G loss: 12.714] \n",
      "590 [D loss: (-8.636)(R -4.798, F -12.475)]  [G loss: 12.390] \n",
      "591 [D loss: (-8.368)(R -4.576, F -12.160)]  [G loss: 12.940] \n",
      "591 [D loss: (-8.870)(R -5.116, F -12.624)]  [G loss: 13.117] \n",
      "592 [D loss: (-9.242)(R -5.073, F -13.412)]  [G loss: 13.028] \n",
      "592 [D loss: (-9.344)(R -5.464, F -13.224)]  [G loss: 13.200] \n",
      "593 [D loss: (-9.397)(R -5.512, F -13.283)]  [G loss: 12.903] \n",
      "593 [D loss: (-9.252)(R -5.585, F -12.919)]  [G loss: 12.539] \n",
      "594 [D loss: (-9.087)(R -5.181, F -12.992)]  [G loss: 12.289] \n",
      "594 [D loss: (-9.308)(R -6.573, F -12.043)]  [G loss: 12.462] \n",
      "595 [D loss: (-9.064)(R -5.445, F -12.683)]  [G loss: 12.942] \n",
      "595 [D loss: (-9.248)(R -5.384, F -13.112)]  [G loss: 13.426] \n",
      "596 [D loss: (-9.064)(R -5.080, F -13.048)]  [G loss: 13.267] \n",
      "596 [D loss: (-9.083)(R -4.798, F -13.367)]  [G loss: 13.660] \n",
      "597 [D loss: (-9.376)(R -5.493, F -13.258)]  [G loss: 13.357] \n",
      "597 [D loss: (-9.173)(R -5.470, F -12.875)]  [G loss: 13.300] \n",
      "598 [D loss: (-9.298)(R -5.408, F -13.188)]  [G loss: 12.832] \n",
      "598 [D loss: (-9.187)(R -5.184, F -13.191)]  [G loss: 13.161] \n",
      "599 [D loss: (-8.983)(R -4.900, F -13.065)]  [G loss: 13.051] \n",
      "599 [D loss: (-9.223)(R -4.921, F -13.524)]  [G loss: 13.344] \n",
      "600 [D loss: (-9.163)(R -4.707, F -13.619)]  [G loss: 13.323] \n",
      "600 [D loss: (-9.119)(R -5.128, F -13.110)]  [G loss: 12.759] \n",
      "601 [D loss: (-9.116)(R -5.245, F -12.987)]  [G loss: 12.907] \n",
      "601 [D loss: (-9.206)(R -5.252, F -13.160)]  [G loss: 12.860] \n",
      "602 [D loss: (-9.446)(R -5.517, F -13.374)]  [G loss: 12.782] \n",
      "602 [D loss: (-9.086)(R -4.977, F -13.195)]  [G loss: 13.047] \n",
      "603 [D loss: (-9.420)(R -5.000, F -13.839)]  [G loss: 13.302] \n",
      "603 [D loss: (-9.182)(R -4.521, F -13.843)]  [G loss: 13.317] \n",
      "604 [D loss: (-9.685)(R -5.279, F -14.092)]  [G loss: 13.124] \n",
      "604 [D loss: (-9.571)(R -5.275, F -13.867)]  [G loss: 13.420] \n",
      "605 [D loss: (-9.368)(R -4.811, F -13.925)]  [G loss: 13.054] \n",
      "605 [D loss: (-9.165)(R -4.804, F -13.527)]  [G loss: 12.705] \n",
      "606 [D loss: (-9.524)(R -5.165, F -13.883)]  [G loss: 12.485] \n",
      "606 [D loss: (-9.358)(R -5.403, F -13.313)]  [G loss: 12.497] \n",
      "607 [D loss: (-9.289)(R -5.475, F -13.102)]  [G loss: 12.078] \n",
      "607 [D loss: (-9.416)(R -5.314, F -13.517)]  [G loss: 12.245] \n",
      "608 [D loss: (-9.264)(R -5.298, F -13.230)]  [G loss: 12.069] \n",
      "608 [D loss: (-8.989)(R -4.844, F -13.133)]  [G loss: 11.446] \n",
      "609 [D loss: (-8.989)(R -5.396, F -12.583)]  [G loss: 11.506] \n",
      "609 [D loss: (-8.833)(R -5.263, F -12.403)]  [G loss: 11.025] \n",
      "610 [D loss: (-8.735)(R -5.243, F -12.227)]  [G loss: 10.809] \n",
      "610 [D loss: (-9.046)(R -6.320, F -11.772)]  [G loss: 9.868] \n",
      "611 [D loss: (-8.682)(R -6.311, F -11.053)]  [G loss: 9.779] \n",
      "611 [D loss: (-8.768)(R -6.206, F -11.331)]  [G loss: 8.757] \n",
      "612 [D loss: (-8.701)(R -6.783, F -10.619)]  [G loss: 8.298] \n",
      "612 [D loss: (-8.686)(R -6.610, F -10.763)]  [G loss: 8.954] \n",
      "613 [D loss: (-8.488)(R -6.098, F -10.878)]  [G loss: 8.952] \n",
      "613 [D loss: (-8.147)(R -6.619, F -9.676)]  [G loss: 7.822] \n",
      "614 [D loss: (-8.344)(R -6.801, F -9.888)]  [G loss: 7.488] \n",
      "614 [D loss: (-8.068)(R -6.442, F -9.695)]  [G loss: 7.741] \n",
      "615 [D loss: (-7.570)(R -6.235, F -8.905)]  [G loss: 7.116] \n",
      "615 [D loss: (-7.510)(R -6.098, F -8.921)]  [G loss: 6.885] \n",
      "616 [D loss: (-7.676)(R -6.287, F -9.066)]  [G loss: 6.744] \n",
      "616 [D loss: (-7.544)(R -6.641, F -8.446)]  [G loss: 5.802] \n",
      "617 [D loss: (-7.419)(R -6.660, F -8.177)]  [G loss: 5.387] \n",
      "617 [D loss: (-7.330)(R -6.399, F -8.261)]  [G loss: 5.681] \n",
      "618 [D loss: (-6.967)(R -6.534, F -7.401)]  [G loss: 5.253] \n",
      "618 [D loss: (-6.644)(R -6.738, F -6.550)]  [G loss: 4.728] \n",
      "619 [D loss: (-6.928)(R -6.724, F -7.133)]  [G loss: 4.435] \n",
      "619 [D loss: (-6.234)(R -6.232, F -6.236)]  [G loss: 4.586] \n",
      "620 [D loss: (-6.273)(R -6.415, F -6.130)]  [G loss: 4.019] \n",
      "620 [D loss: (-5.747)(R -6.360, F -5.133)]  [G loss: 4.404] \n",
      "621 [D loss: (-5.817)(R -6.196, F -5.438)]  [G loss: 3.775] \n",
      "621 [D loss: (-5.579)(R -6.547, F -4.612)]  [G loss: 3.226] \n",
      "622 [D loss: (-5.592)(R -6.643, F -4.541)]  [G loss: 3.140] \n",
      "622 [D loss: (-5.680)(R -6.155, F -5.204)]  [G loss: 2.821] \n",
      "623 [D loss: (-5.683)(R -7.175, F -4.192)]  [G loss: 2.193] \n",
      "623 [D loss: (-5.380)(R -7.454, F -3.305)]  [G loss: 1.909] \n",
      "624 [D loss: (-5.697)(R -7.622, F -3.772)]  [G loss: 1.967] \n",
      "624 [D loss: (-4.934)(R -7.342, F -2.526)]  [G loss: 1.562] \n",
      "625 [D loss: (-4.914)(R -7.622, F -2.207)]  [G loss: 0.868] \n",
      "625 [D loss: (-5.461)(R -7.673, F -3.249)]  [G loss: 0.781] \n",
      "626 [D loss: (-5.095)(R -8.994, F -1.196)]  [G loss: 0.233] \n",
      "626 [D loss: (-5.536)(R -9.140, F -1.931)]  [G loss: 0.787] \n",
      "627 [D loss: (-5.480)(R -8.866, F -2.094)]  [G loss: 0.803] \n",
      "627 [D loss: (-5.324)(R -8.233, F -2.415)]  [G loss: 1.740] \n",
      "628 [D loss: (-5.365)(R -8.391, F -2.338)]  [G loss: 0.844] \n",
      "628 [D loss: (-4.041)(R -7.681, F -0.400)]  [G loss: 1.799] \n",
      "629 [D loss: (-5.280)(R -8.257, F -2.303)]  [G loss: 1.943] \n",
      "629 [D loss: (-6.255)(R -8.116, F -4.394)]  [G loss: 1.518] \n",
      "630 [D loss: (-6.069)(R -8.475, F -3.662)]  [G loss: 2.031] \n",
      "630 [D loss: (-6.442)(R -8.472, F -4.412)]  [G loss: 1.865] \n",
      "631 [D loss: (-5.649)(R -8.424, F -2.873)]  [G loss: 2.335] \n",
      "631 [D loss: (-5.795)(R -8.109, F -3.481)]  [G loss: 2.410] \n",
      "632 [D loss: (-5.827)(R -8.556, F -3.098)]  [G loss: 2.653] \n",
      "632 [D loss: (-6.472)(R -8.576, F -4.368)]  [G loss: 3.798] \n",
      "633 [D loss: (-6.373)(R -8.101, F -4.645)]  [G loss: 3.587] \n",
      "633 [D loss: (-6.222)(R -8.168, F -4.276)]  [G loss: 4.110] \n",
      "634 [D loss: (-6.030)(R -8.670, F -3.389)]  [G loss: 4.593] \n",
      "634 [D loss: (-6.818)(R -8.539, F -5.097)]  [G loss: 4.588] \n",
      "635 [D loss: (-7.402)(R -8.407, F -6.397)]  [G loss: 5.070] \n",
      "635 [D loss: (-7.168)(R -8.497, F -5.839)]  [G loss: 5.301] \n",
      "636 [D loss: (-6.970)(R -8.820, F -5.120)]  [G loss: 6.225] \n",
      "636 [D loss: (-7.552)(R -8.552, F -6.551)]  [G loss: 6.010] \n",
      "637 [D loss: (-7.419)(R -8.497, F -6.341)]  [G loss: 6.000] \n",
      "637 [D loss: (-7.382)(R -8.423, F -6.341)]  [G loss: 6.909] \n",
      "638 [D loss: (-7.927)(R -8.341, F -7.512)]  [G loss: 7.131] \n",
      "638 [D loss: (-8.205)(R -9.076, F -7.335)]  [G loss: 6.928] \n",
      "639 [D loss: (-7.923)(R -8.859, F -6.987)]  [G loss: 6.974] \n",
      "639 [D loss: (-8.375)(R -8.731, F -8.019)]  [G loss: 7.390] \n",
      "640 [D loss: (-8.545)(R -8.287, F -8.803)]  [G loss: 7.363] \n",
      "640 [D loss: (-8.140)(R -8.775, F -7.505)]  [G loss: 6.904] \n",
      "641 [D loss: (-7.865)(R -8.986, F -6.745)]  [G loss: 6.751] \n",
      "641 [D loss: (-7.887)(R -9.179, F -6.595)]  [G loss: 6.425] \n",
      "642 [D loss: (-8.450)(R -9.543, F -7.358)]  [G loss: 7.213] \n",
      "642 [D loss: (-8.299)(R -9.276, F -7.321)]  [G loss: 7.592] \n",
      "643 [D loss: (-8.178)(R -9.065, F -7.291)]  [G loss: 7.999] \n",
      "643 [D loss: (-8.563)(R -9.043, F -8.082)]  [G loss: 7.995] \n",
      "644 [D loss: (-8.948)(R -8.657, F -9.239)]  [G loss: 8.599] \n",
      "644 [D loss: (-8.785)(R -8.999, F -8.571)]  [G loss: 8.628] \n",
      "645 [D loss: (-8.267)(R -9.015, F -7.520)]  [G loss: 8.365] \n",
      "645 [D loss: (-8.312)(R -8.937, F -7.687)]  [G loss: 8.400] \n",
      "646 [D loss: (-8.678)(R -9.238, F -8.118)]  [G loss: 8.397] \n",
      "646 [D loss: (-8.799)(R -9.541, F -8.056)]  [G loss: 8.171] \n",
      "647 [D loss: (-9.106)(R -8.875, F -9.337)]  [G loss: 8.776] \n",
      "647 [D loss: (-9.175)(R -8.921, F -9.428)]  [G loss: 8.601] \n",
      "648 [D loss: (-8.756)(R -8.309, F -9.202)]  [G loss: 8.599] \n",
      "648 [D loss: (-8.788)(R -9.376, F -8.200)]  [G loss: 8.494] \n",
      "649 [D loss: (-8.413)(R -8.737, F -8.089)]  [G loss: 8.677] \n",
      "649 [D loss: (-8.943)(R -8.636, F -9.250)]  [G loss: 8.727] \n",
      "650 [D loss: (-9.024)(R -8.411, F -9.637)]  [G loss: 9.340] \n",
      "650 [D loss: (-8.739)(R -8.037, F -9.441)]  [G loss: 8.609] \n",
      "651 [D loss: (-8.868)(R -8.868, F -8.868)]  [G loss: 8.405] \n",
      "651 [D loss: (-9.426)(R -9.186, F -9.666)]  [G loss: 8.168] \n",
      "652 [D loss: (-9.755)(R -9.932, F -9.578)]  [G loss: 8.115] \n",
      "652 [D loss: (-8.968)(R -9.221, F -8.716)]  [G loss: 8.014] \n",
      "653 [D loss: (-9.050)(R -9.125, F -8.975)]  [G loss: 7.707] \n",
      "653 [D loss: (-9.074)(R -8.616, F -9.533)]  [G loss: 7.765] \n",
      "654 [D loss: (-8.584)(R -8.480, F -8.688)]  [G loss: 7.358] \n",
      "654 [D loss: (-8.312)(R -8.600, F -8.025)]  [G loss: 7.105] \n",
      "655 [D loss: (-8.667)(R -8.738, F -8.595)]  [G loss: 7.127] \n",
      "655 [D loss: (-8.327)(R -8.161, F -8.494)]  [G loss: 6.729] \n",
      "656 [D loss: (-8.784)(R -8.839, F -8.729)]  [G loss: 6.154] \n",
      "656 [D loss: (-8.698)(R -9.046, F -8.349)]  [G loss: 6.072] \n",
      "657 [D loss: (-7.862)(R -8.170, F -7.555)]  [G loss: 6.031] \n",
      "657 [D loss: (-8.412)(R -8.843, F -7.981)]  [G loss: 5.911] \n",
      "658 [D loss: (-7.827)(R -8.680, F -6.973)]  [G loss: 5.338] \n",
      "658 [D loss: (-7.990)(R -8.379, F -7.602)]  [G loss: 5.074] \n",
      "659 [D loss: (-8.023)(R -9.075, F -6.971)]  [G loss: 4.592] \n",
      "659 [D loss: (-7.825)(R -8.734, F -6.915)]  [G loss: 4.661] \n",
      "660 [D loss: (-7.314)(R -8.505, F -6.123)]  [G loss: 4.703] \n",
      "660 [D loss: (-7.730)(R -9.145, F -6.316)]  [G loss: 4.682] \n",
      "661 [D loss: (-7.751)(R -9.062, F -6.441)]  [G loss: 4.414] \n",
      "661 [D loss: (-7.367)(R -9.295, F -5.438)]  [G loss: 3.843] \n",
      "662 [D loss: (-7.646)(R -9.050, F -6.242)]  [G loss: 3.859] \n",
      "662 [D loss: (-7.398)(R -9.446, F -5.351)]  [G loss: 3.795] \n",
      "663 [D loss: (-7.632)(R -8.942, F -6.322)]  [G loss: 4.100] \n",
      "663 [D loss: (-7.177)(R -8.487, F -5.868)]  [G loss: 4.547] \n",
      "664 [D loss: (-7.478)(R -8.687, F -6.270)]  [G loss: 4.063] \n",
      "664 [D loss: (-7.220)(R -8.831, F -5.609)]  [G loss: 4.151] \n",
      "665 [D loss: (-8.020)(R -9.078, F -6.963)]  [G loss: 4.344] \n",
      "665 [D loss: (-7.301)(R -9.209, F -5.392)]  [G loss: 4.391] \n",
      "666 [D loss: (-7.664)(R -9.246, F -6.083)]  [G loss: 4.726] \n",
      "666 [D loss: (-7.554)(R -8.947, F -6.161)]  [G loss: 4.829] \n",
      "667 [D loss: (-7.479)(R -9.579, F -5.378)]  [G loss: 5.164] \n",
      "667 [D loss: (-7.724)(R -9.858, F -5.590)]  [G loss: 4.938] \n",
      "668 [D loss: (-7.938)(R -9.407, F -6.468)]  [G loss: 6.276] \n",
      "668 [D loss: (-8.138)(R -9.387, F -6.888)]  [G loss: 6.479] \n",
      "669 [D loss: (-8.137)(R -9.412, F -6.861)]  [G loss: 6.838] \n",
      "669 [D loss: (-8.748)(R -9.492, F -8.003)]  [G loss: 7.182] \n",
      "670 [D loss: (-8.512)(R -9.617, F -7.406)]  [G loss: 7.224] \n",
      "670 [D loss: (-8.800)(R -9.800, F -7.800)]  [G loss: 7.915] \n",
      "671 [D loss: (-8.761)(R -9.538, F -7.985)]  [G loss: 8.390] \n",
      "671 [D loss: (-8.866)(R -9.446, F -8.286)]  [G loss: 8.687] \n",
      "672 [D loss: (-9.258)(R -9.500, F -9.016)]  [G loss: 8.853] \n",
      "672 [D loss: (-9.331)(R -10.021, F -8.640)]  [G loss: 8.883] \n",
      "673 [D loss: (-9.548)(R -9.945, F -9.151)]  [G loss: 9.330] \n",
      "673 [D loss: (-9.271)(R -9.343, F -9.199)]  [G loss: 9.302] \n",
      "674 [D loss: (-9.683)(R -9.732, F -9.634)]  [G loss: 9.750] \n",
      "674 [D loss: (-9.377)(R -9.445, F -9.310)]  [G loss: 9.838] \n",
      "675 [D loss: (-10.100)(R -10.377, F -9.823)]  [G loss: 9.499] \n",
      "675 [D loss: (-10.236)(R -10.589, F -9.884)]  [G loss: 9.493] \n",
      "676 [D loss: (-10.436)(R -10.400, F -10.472)]  [G loss: 9.880] \n",
      "676 [D loss: (-10.036)(R -10.132, F -9.940)]  [G loss: 10.230] \n",
      "677 [D loss: (-10.198)(R -10.094, F -10.303)]  [G loss: 9.624] \n",
      "677 [D loss: (-10.359)(R -10.317, F -10.401)]  [G loss: 9.631] \n",
      "678 [D loss: (-10.197)(R -10.704, F -9.690)]  [G loss: 9.764] \n",
      "678 [D loss: (-9.974)(R -10.104, F -9.843)]  [G loss: 9.555] \n",
      "679 [D loss: (-10.426)(R -10.291, F -10.561)]  [G loss: 9.566] \n",
      "679 [D loss: (-10.088)(R -9.840, F -10.335)]  [G loss: 10.041] \n",
      "680 [D loss: (-10.280)(R -9.853, F -10.708)]  [G loss: 9.767] \n",
      "680 [D loss: (-10.185)(R -9.331, F -11.039)]  [G loss: 9.492] \n",
      "681 [D loss: (-10.035)(R -9.491, F -10.578)]  [G loss: 9.432] \n",
      "681 [D loss: (-9.895)(R -9.335, F -10.456)]  [G loss: 8.935] \n",
      "682 [D loss: (-9.819)(R -9.512, F -10.126)]  [G loss: 8.791] \n",
      "682 [D loss: (-10.074)(R -9.975, F -10.172)]  [G loss: 9.139] \n",
      "683 [D loss: (-9.757)(R -9.433, F -10.081)]  [G loss: 8.753] \n",
      "683 [D loss: (-9.817)(R -8.810, F -10.823)]  [G loss: 8.753] \n",
      "684 [D loss: (-9.311)(R -9.163, F -9.459)]  [G loss: 8.226] \n",
      "684 [D loss: (-9.235)(R -8.452, F -10.019)]  [G loss: 8.026] \n",
      "685 [D loss: (-9.195)(R -8.979, F -9.411)]  [G loss: 7.785] \n",
      "685 [D loss: (-9.141)(R -8.643, F -9.638)]  [G loss: 7.736] \n",
      "686 [D loss: (-8.799)(R -8.258, F -9.341)]  [G loss: 7.212] \n",
      "686 [D loss: (-8.700)(R -8.383, F -9.017)]  [G loss: 6.879] \n",
      "687 [D loss: (-8.324)(R -8.887, F -7.761)]  [G loss: 5.835] \n",
      "687 [D loss: (-7.994)(R -8.240, F -7.749)]  [G loss: 6.006] \n",
      "688 [D loss: (-8.418)(R -9.026, F -7.810)]  [G loss: 5.839] \n",
      "688 [D loss: (-7.797)(R -7.653, F -7.941)]  [G loss: 5.557] \n",
      "689 [D loss: (-7.453)(R -7.653, F -7.252)]  [G loss: 5.248] \n",
      "689 [D loss: (-7.538)(R -7.252, F -7.825)]  [G loss: 5.593] \n",
      "690 [D loss: (-7.296)(R -7.469, F -7.123)]  [G loss: 4.493] \n",
      "690 [D loss: (-6.714)(R -7.656, F -5.772)]  [G loss: 3.784] \n",
      "691 [D loss: (-6.748)(R -7.705, F -5.792)]  [G loss: 3.511] \n",
      "691 [D loss: (-6.317)(R -7.547, F -5.087)]  [G loss: 3.409] \n",
      "692 [D loss: (-6.084)(R -6.682, F -5.487)]  [G loss: 3.594] \n",
      "692 [D loss: (-5.913)(R -6.815, F -5.012)]  [G loss: 3.405] \n",
      "693 [D loss: (-5.863)(R -6.916, F -4.810)]  [G loss: 2.391] \n",
      "693 [D loss: (-5.178)(R -6.584, F -3.772)]  [G loss: 2.695] \n",
      "694 [D loss: (-5.159)(R -7.342, F -2.977)]  [G loss: 2.030] \n",
      "694 [D loss: (-4.863)(R -7.215, F -2.510)]  [G loss: 1.775] \n",
      "695 [D loss: (-5.142)(R -7.136, F -3.147)]  [G loss: 1.926] \n",
      "695 [D loss: (-4.601)(R -6.480, F -2.723)]  [G loss: 2.150] \n",
      "696 [D loss: (-4.910)(R -6.102, F -3.719)]  [G loss: 2.385] \n",
      "696 [D loss: (-4.825)(R -5.895, F -3.756)]  [G loss: 2.586] \n",
      "697 [D loss: (-4.548)(R -5.731, F -3.365)]  [G loss: 2.305] \n",
      "697 [D loss: (-4.751)(R -5.791, F -3.712)]  [G loss: 2.396] \n",
      "698 [D loss: (-4.388)(R -6.245, F -2.531)]  [G loss: 2.292] \n",
      "698 [D loss: (-4.547)(R -5.427, F -3.667)]  [G loss: 2.655] \n",
      "699 [D loss: (-4.392)(R -5.363, F -3.422)]  [G loss: 2.324] \n",
      "699 [D loss: (-4.154)(R -5.214, F -3.094)]  [G loss: 2.966] \n",
      "700 [D loss: (-4.337)(R -4.796, F -3.879)]  [G loss: 3.558] \n",
      "700 [D loss: (-4.478)(R -4.245, F -4.710)]  [G loss: 3.915] \n",
      "701 [D loss: (-4.254)(R -4.678, F -3.829)]  [G loss: 3.670] \n",
      "701 [D loss: (-4.143)(R -4.553, F -3.732)]  [G loss: 4.065] \n",
      "702 [D loss: (-4.431)(R -4.585, F -4.278)]  [G loss: 4.052] \n",
      "702 [D loss: (-4.613)(R -4.552, F -4.675)]  [G loss: 4.156] \n",
      "703 [D loss: (-4.345)(R -4.693, F -3.996)]  [G loss: 5.125] \n",
      "703 [D loss: (-4.414)(R -4.215, F -4.612)]  [G loss: 4.722] \n",
      "704 [D loss: (-5.130)(R -4.326, F -5.935)]  [G loss: 5.176] \n",
      "704 [D loss: (-5.085)(R -4.618, F -5.552)]  [G loss: 5.056] \n",
      "705 [D loss: (-4.953)(R -4.926, F -4.980)]  [G loss: 5.041] \n",
      "705 [D loss: (-5.090)(R -4.896, F -5.283)]  [G loss: 6.025] \n",
      "706 [D loss: (-5.040)(R -4.987, F -5.094)]  [G loss: 6.272] \n",
      "706 [D loss: (-5.317)(R -4.843, F -5.791)]  [G loss: 6.874] \n",
      "707 [D loss: (-5.916)(R -4.070, F -7.763)]  [G loss: 7.564] \n",
      "707 [D loss: (-6.271)(R -4.360, F -8.182)]  [G loss: 8.068] \n",
      "708 [D loss: (-6.227)(R -4.282, F -8.173)]  [G loss: 8.141] \n",
      "708 [D loss: (-6.135)(R -4.691, F -7.580)]  [G loss: 8.346] \n",
      "709 [D loss: (-6.291)(R -5.065, F -7.518)]  [G loss: 7.844] \n",
      "709 [D loss: (-6.669)(R -5.691, F -7.647)]  [G loss: 8.391] \n",
      "710 [D loss: (-6.856)(R -5.620, F -8.093)]  [G loss: 8.592] \n",
      "710 [D loss: (-7.161)(R -5.731, F -8.590)]  [G loss: 8.706] \n",
      "711 [D loss: (-7.595)(R -6.038, F -9.153)]  [G loss: 9.263] \n",
      "711 [D loss: (-7.910)(R -6.801, F -9.018)]  [G loss: 8.749] \n",
      "712 [D loss: (-7.911)(R -7.360, F -8.462)]  [G loss: 8.882] \n",
      "712 [D loss: (-8.201)(R -7.957, F -8.445)]  [G loss: 8.285] \n",
      "713 [D loss: (-7.966)(R -7.966, F -7.966)]  [G loss: 8.593] \n",
      "713 [D loss: (-8.385)(R -7.593, F -9.177)]  [G loss: 9.208] \n",
      "714 [D loss: (-8.591)(R -8.175, F -9.008)]  [G loss: 9.060] \n",
      "714 [D loss: (-8.940)(R -8.425, F -9.454)]  [G loss: 9.207] \n",
      "715 [D loss: (-8.541)(R -8.394, F -8.688)]  [G loss: 8.798] \n",
      "715 [D loss: (-9.652)(R -9.277, F -10.028)]  [G loss: 8.397] \n",
      "716 [D loss: (-9.242)(R -9.244, F -9.240)]  [G loss: 8.653] \n",
      "716 [D loss: (-9.390)(R -9.043, F -9.737)]  [G loss: 8.826] \n",
      "717 [D loss: (-9.097)(R -9.173, F -9.021)]  [G loss: 8.892] \n",
      "717 [D loss: (-9.414)(R -9.454, F -9.375)]  [G loss: 8.536] \n",
      "718 [D loss: (-9.965)(R -9.512, F -10.418)]  [G loss: 8.550] \n",
      "718 [D loss: (-9.600)(R -9.727, F -9.472)]  [G loss: 8.722] \n",
      "719 [D loss: (-9.076)(R -8.720, F -9.431)]  [G loss: 8.121] \n",
      "719 [D loss: (-9.439)(R -8.947, F -9.932)]  [G loss: 8.026] \n",
      "720 [D loss: (-9.738)(R -9.332, F -10.143)]  [G loss: 8.056] \n",
      "720 [D loss: (-9.449)(R -9.522, F -9.376)]  [G loss: 7.437] \n",
      "721 [D loss: (-9.068)(R -9.461, F -8.674)]  [G loss: 7.004] \n",
      "721 [D loss: (-9.161)(R -9.997, F -8.324)]  [G loss: 6.256] \n",
      "722 [D loss: (-9.295)(R -10.416, F -8.174)]  [G loss: 5.829] \n",
      "722 [D loss: (-8.985)(R -9.901, F -8.069)]  [G loss: 5.772] \n",
      "723 [D loss: (-8.738)(R -10.416, F -7.060)]  [G loss: 5.293] \n",
      "723 [D loss: (-8.767)(R -10.178, F -7.355)]  [G loss: 4.772] \n",
      "724 [D loss: (-8.637)(R -10.076, F -7.199)]  [G loss: 5.120] \n",
      "724 [D loss: (-8.928)(R -10.489, F -7.366)]  [G loss: 5.166] \n",
      "725 [D loss: (-8.442)(R -9.787, F -7.097)]  [G loss: 5.524] \n",
      "725 [D loss: (-8.859)(R -9.638, F -8.080)]  [G loss: 5.641] \n",
      "726 [D loss: (-8.498)(R -9.295, F -7.701)]  [G loss: 5.306] \n",
      "726 [D loss: (-8.651)(R -9.545, F -7.758)]  [G loss: 4.840] \n",
      "727 [D loss: (-7.923)(R -8.909, F -6.937)]  [G loss: 4.605] \n",
      "727 [D loss: (-8.317)(R -9.624, F -7.009)]  [G loss: 4.261] \n",
      "728 [D loss: (-7.457)(R -9.158, F -5.756)]  [G loss: 4.107] \n",
      "728 [D loss: (-7.541)(R -8.858, F -6.225)]  [G loss: 4.246] \n",
      "729 [D loss: (-7.790)(R -9.253, F -6.327)]  [G loss: 3.968] \n",
      "729 [D loss: (-8.014)(R -9.597, F -6.432)]  [G loss: 3.675] \n",
      "730 [D loss: (-7.627)(R -9.747, F -5.507)]  [G loss: 3.798] \n",
      "730 [D loss: (-7.678)(R -9.113, F -6.242)]  [G loss: 3.752] \n",
      "731 [D loss: (-7.483)(R -9.066, F -5.901)]  [G loss: 3.812] \n",
      "731 [D loss: (-7.255)(R -9.051, F -5.459)]  [G loss: 4.088] \n",
      "732 [D loss: (-7.491)(R -9.203, F -5.778)]  [G loss: 3.864] \n",
      "732 [D loss: (-7.220)(R -8.679, F -5.760)]  [G loss: 3.920] \n",
      "733 [D loss: (-7.131)(R -9.129, F -5.134)]  [G loss: 4.055] \n",
      "733 [D loss: (-7.428)(R -8.863, F -5.994)]  [G loss: 4.467] \n",
      "734 [D loss: (-7.020)(R -8.627, F -5.412)]  [G loss: 4.525] \n",
      "734 [D loss: (-6.798)(R -7.826, F -5.771)]  [G loss: 5.140] \n",
      "735 [D loss: (-7.251)(R -7.904, F -6.599)]  [G loss: 5.867] \n",
      "735 [D loss: (-7.060)(R -7.554, F -6.566)]  [G loss: 6.506] \n",
      "736 [D loss: (-6.873)(R -6.462, F -7.284)]  [G loss: 6.918] \n",
      "736 [D loss: (-7.272)(R -7.056, F -7.489)]  [G loss: 7.174] \n",
      "737 [D loss: (-7.409)(R -7.031, F -7.787)]  [G loss: 7.201] \n",
      "737 [D loss: (-7.524)(R -6.979, F -8.069)]  [G loss: 7.609] \n",
      "738 [D loss: (-7.480)(R -6.767, F -8.193)]  [G loss: 8.137] \n",
      "738 [D loss: (-7.282)(R -5.184, F -9.380)]  [G loss: 9.129] \n",
      "739 [D loss: (-7.596)(R -5.076, F -10.115)]  [G loss: 9.432] \n",
      "739 [D loss: (-7.476)(R -4.679, F -10.273)]  [G loss: 9.588] \n",
      "740 [D loss: (-7.240)(R -4.204, F -10.277)]  [G loss: 9.833] \n",
      "740 [D loss: (-7.441)(R -4.059, F -10.824)]  [G loss: 10.323] \n",
      "741 [D loss: (-8.149)(R -4.955, F -11.344)]  [G loss: 10.736] \n",
      "741 [D loss: (-7.620)(R -3.625, F -11.616)]  [G loss: 10.907] \n",
      "742 [D loss: (-7.797)(R -4.402, F -11.192)]  [G loss: 10.414] \n",
      "742 [D loss: (-7.958)(R -4.726, F -11.190)]  [G loss: 10.331] \n",
      "743 [D loss: (-8.158)(R -4.890, F -11.425)]  [G loss: 10.339] \n",
      "743 [D loss: (-7.853)(R -4.662, F -11.044)]  [G loss: 9.842] \n",
      "744 [D loss: (-8.553)(R -6.104, F -11.001)]  [G loss: 9.861] \n",
      "744 [D loss: (-8.460)(R -5.498, F -11.422)]  [G loss: 9.926] \n",
      "745 [D loss: (-8.275)(R -5.276, F -11.274)]  [G loss: 9.644] \n",
      "745 [D loss: (-8.573)(R -5.898, F -11.249)]  [G loss: 9.590] \n",
      "746 [D loss: (-8.301)(R -5.455, F -11.147)]  [G loss: 9.435] \n",
      "746 [D loss: (-8.588)(R -5.517, F -11.659)]  [G loss: 9.620] \n",
      "747 [D loss: (-8.734)(R -5.780, F -11.687)]  [G loss: 9.539] \n",
      "747 [D loss: (-8.515)(R -5.538, F -11.492)]  [G loss: 9.244] \n",
      "748 [D loss: (-8.671)(R -5.819, F -11.524)]  [G loss: 9.170] \n",
      "748 [D loss: (-8.678)(R -5.930, F -11.427)]  [G loss: 8.971] \n",
      "749 [D loss: (-8.781)(R -5.838, F -11.724)]  [G loss: 9.035] \n",
      "749 [D loss: (-8.802)(R -5.699, F -11.905)]  [G loss: 9.079] \n",
      "750 [D loss: (-8.765)(R -5.676, F -11.853)]  [G loss: 8.691] \n",
      "750 [D loss: (-8.687)(R -6.244, F -11.131)]  [G loss: 7.869] \n",
      "751 [D loss: (-8.869)(R -6.707, F -11.032)]  [G loss: 7.768] \n",
      "751 [D loss: (-8.877)(R -6.497, F -11.257)]  [G loss: 7.800] \n",
      "752 [D loss: (-8.329)(R -5.917, F -10.742)]  [G loss: 7.198] \n",
      "752 [D loss: (-8.678)(R -7.321, F -10.034)]  [G loss: 6.239] \n",
      "753 [D loss: (-8.537)(R -7.509, F -9.564)]  [G loss: 6.057] \n",
      "753 [D loss: (-8.076)(R -6.102, F -10.050)]  [G loss: 6.520] \n",
      "754 [D loss: (-8.146)(R -6.179, F -10.112)]  [G loss: 6.793] \n",
      "754 [D loss: (-8.092)(R -6.366, F -9.818)]  [G loss: 6.428] \n",
      "755 [D loss: (-8.102)(R -6.506, F -9.698)]  [G loss: 6.235] \n",
      "755 [D loss: (-7.792)(R -6.858, F -8.725)]  [G loss: 6.270] \n",
      "756 [D loss: (-7.300)(R -6.324, F -8.276)]  [G loss: 6.297] \n",
      "756 [D loss: (-7.827)(R -6.642, F -9.013)]  [G loss: 6.773] \n",
      "757 [D loss: (-7.638)(R -5.975, F -9.301)]  [G loss: 7.764] \n",
      "757 [D loss: (-7.664)(R -5.929, F -9.399)]  [G loss: 8.015] \n",
      "758 [D loss: (-7.853)(R -6.371, F -9.336)]  [G loss: 7.939] \n",
      "758 [D loss: (-7.488)(R -6.050, F -8.926)]  [G loss: 7.512] \n",
      "759 [D loss: (-7.661)(R -5.881, F -9.441)]  [G loss: 7.524] \n",
      "759 [D loss: (-7.286)(R -5.917, F -8.655)]  [G loss: 7.440] \n",
      "760 [D loss: (-7.688)(R -6.013, F -9.362)]  [G loss: 7.812] \n",
      "760 [D loss: (-7.319)(R -6.014, F -8.624)]  [G loss: 7.540] \n",
      "761 [D loss: (-7.843)(R -6.650, F -9.037)]  [G loss: 7.857] \n",
      "761 [D loss: (-7.865)(R -6.335, F -9.395)]  [G loss: 8.452] \n",
      "762 [D loss: (-7.928)(R -5.861, F -9.996)]  [G loss: 9.113] \n",
      "762 [D loss: (-7.815)(R -5.753, F -9.877)]  [G loss: 9.066] \n",
      "763 [D loss: (-7.906)(R -6.150, F -9.661)]  [G loss: 9.137] \n",
      "763 [D loss: (-7.893)(R -6.122, F -9.664)]  [G loss: 9.430] \n",
      "764 [D loss: (-8.181)(R -5.746, F -10.616)]  [G loss: 9.840] \n",
      "764 [D loss: (-8.091)(R -4.669, F -11.514)]  [G loss: 10.732] \n",
      "765 [D loss: (-8.239)(R -4.692, F -11.786)]  [G loss: 11.138] \n",
      "765 [D loss: (-8.483)(R -5.085, F -11.881)]  [G loss: 11.084] \n",
      "766 [D loss: (-8.417)(R -5.364, F -11.470)]  [G loss: 10.693] \n",
      "766 [D loss: (-8.563)(R -5.528, F -11.598)]  [G loss: 10.871] \n",
      "767 [D loss: (-8.725)(R -5.205, F -12.244)]  [G loss: 11.382] \n",
      "767 [D loss: (-8.703)(R -4.897, F -12.510)]  [G loss: 11.559] \n",
      "768 [D loss: (-8.630)(R -5.414, F -11.845)]  [G loss: 11.025] \n",
      "768 [D loss: (-8.980)(R -5.733, F -12.226)]  [G loss: 11.127] \n",
      "769 [D loss: (-8.909)(R -5.779, F -12.040)]  [G loss: 11.227] \n",
      "769 [D loss: (-8.921)(R -5.903, F -11.940)]  [G loss: 10.792] \n",
      "770 [D loss: (-8.986)(R -6.226, F -11.745)]  [G loss: 10.605] \n",
      "770 [D loss: (-8.963)(R -5.740, F -12.187)]  [G loss: 10.864] \n",
      "771 [D loss: (-8.951)(R -5.838, F -12.063)]  [G loss: 10.740] \n",
      "771 [D loss: (-8.799)(R -5.669, F -11.929)]  [G loss: 10.775] \n",
      "772 [D loss: (-9.024)(R -5.817, F -12.232)]  [G loss: 10.682] \n",
      "772 [D loss: (-8.669)(R -5.751, F -11.588)]  [G loss: 9.813] \n",
      "773 [D loss: (-8.811)(R -6.197, F -11.426)]  [G loss: 9.796] \n",
      "773 [D loss: (-8.608)(R -5.114, F -12.102)]  [G loss: 10.432] \n",
      "774 [D loss: (-8.434)(R -4.558, F -12.309)]  [G loss: 10.344] \n",
      "774 [D loss: (-8.460)(R -5.278, F -11.642)]  [G loss: 9.494] \n",
      "775 [D loss: (-8.261)(R -5.118, F -11.405)]  [G loss: 9.372] \n",
      "775 [D loss: (-8.132)(R -4.386, F -11.878)]  [G loss: 9.728] \n",
      "776 [D loss: (-8.166)(R -4.391, F -11.941)]  [G loss: 9.558] \n",
      "776 [D loss: (-7.845)(R -4.307, F -11.382)]  [G loss: 9.227] \n",
      "777 [D loss: (-7.598)(R -3.499, F -11.696)]  [G loss: 9.281] \n",
      "777 [D loss: (-7.756)(R -3.527, F -11.985)]  [G loss: 9.457] \n",
      "778 [D loss: (-7.373)(R -2.884, F -11.862)]  [G loss: 9.123] \n",
      "778 [D loss: (-7.176)(R -2.928, F -11.424)]  [G loss: 8.949] \n",
      "779 [D loss: (-7.095)(R -2.877, F -11.314)]  [G loss: 8.698] \n",
      "779 [D loss: (-6.785)(R -2.501, F -11.070)]  [G loss: 8.653] \n",
      "780 [D loss: (-6.768)(R -2.698, F -10.838)]  [G loss: 8.194] \n",
      "780 [D loss: (-6.628)(R -2.596, F -10.659)]  [G loss: 7.845] \n",
      "781 [D loss: (-6.428)(R -2.930, F -9.927)]  [G loss: 7.469] \n",
      "781 [D loss: (-6.262)(R -3.189, F -9.336)]  [G loss: 7.010] \n",
      "782 [D loss: (-6.333)(R -3.402, F -9.264)]  [G loss: 6.913] \n",
      "782 [D loss: (-6.117)(R -2.629, F -9.605)]  [G loss: 7.500] \n",
      "783 [D loss: (-6.051)(R -2.326, F -9.775)]  [G loss: 7.974] \n",
      "783 [D loss: (-5.732)(R -1.334, F -10.129)]  [G loss: 8.709] \n",
      "784 [D loss: (-5.656)(R -2.133, F -9.179)]  [G loss: 8.243] \n",
      "784 [D loss: (-6.011)(R -2.710, F -9.312)]  [G loss: 7.935] \n",
      "785 [D loss: (-5.958)(R -3.491, F -8.425)]  [G loss: 7.724] \n",
      "785 [D loss: (-6.294)(R -4.115, F -8.474)]  [G loss: 7.912] \n",
      "786 [D loss: (-6.312)(R -3.904, F -8.720)]  [G loss: 8.429] \n",
      "786 [D loss: (-6.471)(R -3.553, F -9.388)]  [G loss: 8.895] \n",
      "787 [D loss: (-6.427)(R -3.160, F -9.695)]  [G loss: 9.440] \n",
      "787 [D loss: (-6.499)(R -3.321, F -9.677)]  [G loss: 9.634] \n",
      "788 [D loss: (-6.724)(R -3.293, F -10.155)]  [G loss: 10.297] \n",
      "788 [D loss: (-6.827)(R -2.472, F -11.182)]  [G loss: 11.269] \n",
      "789 [D loss: (-6.954)(R -2.487, F -11.422)]  [G loss: 11.777] \n",
      "789 [D loss: (-6.977)(R -1.878, F -12.077)]  [G loss: 12.254] \n",
      "790 [D loss: (-7.266)(R -2.230, F -12.301)]  [G loss: 12.459] \n",
      "790 [D loss: (-7.391)(R -2.300, F -12.482)]  [G loss: 12.673] \n",
      "791 [D loss: (-7.493)(R -2.230, F -12.757)]  [G loss: 12.936] \n",
      "791 [D loss: (-7.415)(R -2.163, F -12.667)]  [G loss: 12.744] \n",
      "792 [D loss: (-7.986)(R -3.358, F -12.614)]  [G loss: 12.876] \n",
      "792 [D loss: (-7.920)(R -3.168, F -12.671)]  [G loss: 12.789] \n",
      "793 [D loss: (-7.989)(R -3.255, F -12.723)]  [G loss: 12.832] \n",
      "793 [D loss: (-8.209)(R -4.032, F -12.385)]  [G loss: 12.368] \n",
      "794 [D loss: (-8.148)(R -3.630, F -12.667)]  [G loss: 12.543] \n",
      "794 [D loss: (-8.670)(R -4.787, F -12.553)]  [G loss: 12.543] \n",
      "795 [D loss: (-8.408)(R -4.352, F -12.464)]  [G loss: 12.347] \n",
      "795 [D loss: (-8.580)(R -4.801, F -12.359)]  [G loss: 12.395] \n",
      "796 [D loss: (-8.840)(R -4.869, F -12.810)]  [G loss: 12.642] \n",
      "796 [D loss: (-8.904)(R -4.995, F -12.812)]  [G loss: 12.669] \n",
      "797 [D loss: (-9.020)(R -5.329, F -12.712)]  [G loss: 12.426] \n",
      "797 [D loss: (-9.290)(R -5.785, F -12.794)]  [G loss: 12.565] \n",
      "798 [D loss: (-9.107)(R -5.396, F -12.817)]  [G loss: 12.580] \n",
      "798 [D loss: (-9.372)(R -5.870, F -12.874)]  [G loss: 12.529] \n",
      "799 [D loss: (-9.592)(R -6.282, F -12.901)]  [G loss: 12.608] \n",
      "799 [D loss: (-9.804)(R -6.324, F -13.284)]  [G loss: 12.835] \n",
      "800 [D loss: (-9.546)(R -5.918, F -13.173)]  [G loss: 12.569] \n",
      "800 [D loss: (-9.716)(R -6.306, F -13.126)]  [G loss: 12.509] \n",
      "801 [D loss: (-9.728)(R -6.392, F -13.064)]  [G loss: 12.341] \n",
      "801 [D loss: (-9.609)(R -6.085, F -13.132)]  [G loss: 12.347] \n",
      "802 [D loss: (-9.962)(R -6.765, F -13.160)]  [G loss: 12.190] \n",
      "802 [D loss: (-9.748)(R -6.185, F -13.310)]  [G loss: 12.421] \n",
      "803 [D loss: (-10.038)(R -7.011, F -13.065)]  [G loss: 12.268] \n",
      "803 [D loss: (-9.988)(R -6.255, F -13.722)]  [G loss: 12.680] \n",
      "804 [D loss: (-9.769)(R -6.379, F -13.160)]  [G loss: 12.093] \n",
      "804 [D loss: (-9.979)(R -6.709, F -13.250)]  [G loss: 12.123] \n",
      "805 [D loss: (-9.952)(R -6.277, F -13.627)]  [G loss: 12.511] \n",
      "805 [D loss: (-9.922)(R -6.439, F -13.405)]  [G loss: 12.256] \n",
      "806 [D loss: (-10.137)(R -6.652, F -13.621)]  [G loss: 12.425] \n",
      "806 [D loss: (-10.163)(R -6.806, F -13.519)]  [G loss: 12.279] \n",
      "807 [D loss: (-9.894)(R -6.132, F -13.656)]  [G loss: 12.088] \n",
      "807 [D loss: (-9.950)(R -6.468, F -13.432)]  [G loss: 12.121] \n",
      "808 [D loss: (-10.207)(R -6.574, F -13.840)]  [G loss: 12.094] \n",
      "808 [D loss: (-10.091)(R -6.684, F -13.497)]  [G loss: 11.654] \n",
      "809 [D loss: (-10.042)(R -6.363, F -13.721)]  [G loss: 11.887] \n",
      "809 [D loss: (-10.040)(R -6.135, F -13.946)]  [G loss: 12.031] \n",
      "810 [D loss: (-9.844)(R -6.179, F -13.509)]  [G loss: 11.781] \n",
      "810 [D loss: (-9.918)(R -6.092, F -13.743)]  [G loss: 11.972] \n",
      "811 [D loss: (-9.688)(R -5.321, F -14.055)]  [G loss: 12.325] \n",
      "811 [D loss: (-9.465)(R -5.085, F -13.844)]  [G loss: 12.027] \n",
      "812 [D loss: (-9.403)(R -5.314, F -13.493)]  [G loss: 11.661] \n",
      "812 [D loss: (-9.820)(R -5.754, F -13.886)]  [G loss: 11.842] \n",
      "813 [D loss: (-9.370)(R -4.827, F -13.913)]  [G loss: 11.936] \n",
      "813 [D loss: (-9.384)(R -5.249, F -13.519)]  [G loss: 11.607] \n",
      "814 [D loss: (-9.095)(R -4.723, F -13.468)]  [G loss: 11.774] \n",
      "814 [D loss: (-9.054)(R -4.475, F -13.633)]  [G loss: 11.391] \n",
      "815 [D loss: (-8.861)(R -4.146, F -13.577)]  [G loss: 11.429] \n",
      "815 [D loss: (-8.769)(R -4.000, F -13.537)]  [G loss: 11.514] \n",
      "816 [D loss: (-8.586)(R -4.054, F -13.118)]  [G loss: 11.254] \n",
      "816 [D loss: (-8.914)(R -4.385, F -13.443)]  [G loss: 11.255] \n",
      "817 [D loss: (-8.652)(R -4.037, F -13.267)]  [G loss: 11.320] \n",
      "817 [D loss: (-8.612)(R -3.622, F -13.602)]  [G loss: 11.521] \n",
      "818 [D loss: (-8.249)(R -2.957, F -13.541)]  [G loss: 11.252] \n",
      "818 [D loss: (-8.203)(R -3.104, F -13.303)]  [G loss: 10.895] \n",
      "819 [D loss: (-7.818)(R -2.980, F -12.656)]  [G loss: 10.547] \n",
      "819 [D loss: (-7.679)(R -3.033, F -12.325)]  [G loss: 10.239] \n",
      "820 [D loss: (-7.581)(R -2.859, F -12.303)]  [G loss: 10.674] \n",
      "820 [D loss: (-7.485)(R -2.594, F -12.377)]  [G loss: 10.363] \n",
      "821 [D loss: (-7.564)(R -3.470, F -11.658)]  [G loss: 9.959] \n",
      "821 [D loss: (-7.626)(R -3.395, F -11.856)]  [G loss: 9.951] \n",
      "822 [D loss: (-7.199)(R -2.716, F -11.681)]  [G loss: 10.320] \n",
      "822 [D loss: (-7.177)(R -2.564, F -11.790)]  [G loss: 10.671] \n",
      "823 [D loss: (-7.462)(R -3.447, F -11.477)]  [G loss: 10.816] \n",
      "823 [D loss: (-7.603)(R -4.032, F -11.175)]  [G loss: 10.816] \n",
      "824 [D loss: (-7.421)(R -2.591, F -12.250)]  [G loss: 12.127] \n",
      "824 [D loss: (-7.653)(R -2.376, F -12.929)]  [G loss: 12.494] \n",
      "825 [D loss: (-7.329)(R -1.566, F -13.092)]  [G loss: 12.742] \n",
      "825 [D loss: (-7.469)(R -2.050, F -12.889)]  [G loss: 12.522] \n",
      "826 [D loss: (-7.360)(R -2.104, F -12.615)]  [G loss: 12.257] \n",
      "826 [D loss: (-7.423)(R -1.819, F -13.028)]  [G loss: 12.601] \n",
      "827 [D loss: (-7.478)(R -1.738, F -13.217)]  [G loss: 12.911] \n",
      "827 [D loss: (-7.155)(R -1.448, F -12.862)]  [G loss: 12.554] \n",
      "828 [D loss: (-7.635)(R -2.320, F -12.949)]  [G loss: 12.774] \n",
      "828 [D loss: (-7.527)(R -2.102, F -12.953)]  [G loss: 12.761] \n",
      "829 [D loss: (-7.481)(R -1.861, F -13.102)]  [G loss: 12.783] \n",
      "829 [D loss: (-7.082)(R -1.267, F -12.897)]  [G loss: 12.632] \n",
      "830 [D loss: (-7.411)(R -1.925, F -12.897)]  [G loss: 12.559] \n",
      "830 [D loss: (-7.458)(R -2.103, F -12.814)]  [G loss: 12.389] \n",
      "831 [D loss: (-7.457)(R -1.973, F -12.940)]  [G loss: 12.421] \n",
      "831 [D loss: (-7.046)(R -1.224, F -12.869)]  [G loss: 12.333] \n",
      "832 [D loss: (-7.324)(R -1.842, F -12.807)]  [G loss: 12.273] \n",
      "832 [D loss: (-7.329)(R -1.792, F -12.866)]  [G loss: 12.159] \n",
      "833 [D loss: (-7.208)(R -1.729, F -12.686)]  [G loss: 11.975] \n",
      "833 [D loss: (-7.622)(R -2.615, F -12.628)]  [G loss: 11.953] \n",
      "834 [D loss: (-6.937)(R -0.982, F -12.891)]  [G loss: 12.085] \n",
      "834 [D loss: (-7.060)(R -1.428, F -12.692)]  [G loss: 11.784] \n",
      "835 [D loss: (-7.109)(R -1.545, F -12.674)]  [G loss: 11.629] \n",
      "835 [D loss: (-7.407)(R -2.242, F -12.572)]  [G loss: 11.528] \n",
      "836 [D loss: (-7.068)(R -1.416, F -12.719)]  [G loss: 11.686] \n",
      "836 [D loss: (-6.774)(R -1.066, F -12.481)]  [G loss: 11.238] \n",
      "837 [D loss: (-6.907)(R -1.628, F -12.185)]  [G loss: 10.998] \n",
      "837 [D loss: (-6.884)(R -1.415, F -12.354)]  [G loss: 10.902] \n",
      "838 [D loss: (-6.634)(R -1.055, F -12.212)]  [G loss: 10.748] \n",
      "838 [D loss: (-6.480)(R -0.831, F -12.128)]  [G loss: 10.545] \n",
      "839 [D loss: (-6.513)(R -1.034, F -11.992)]  [G loss: 10.382] \n",
      "839 [D loss: (-6.336)(R -0.947, F -11.724)]  [G loss: 10.080] \n",
      "840 [D loss: (-6.125)(R -0.509, F -11.740)]  [G loss: 9.984] \n",
      "840 [D loss: (-6.321)(R -0.920, F -11.722)]  [G loss: 9.844] \n",
      "841 [D loss: (-6.130)(R -0.668, F -11.593)]  [G loss: 9.652] \n",
      "841 [D loss: (-5.908)(R -0.362, F -11.455)]  [G loss: 9.546] \n",
      "842 [D loss: (-5.846)(R -0.268, F -11.424)]  [G loss: 9.424] \n",
      "842 [D loss: (-6.002)(R -1.021, F -10.982)]  [G loss: 8.885] \n",
      "843 [D loss: (-5.365)(R -0.218, F -10.512)]  [G loss: 8.239] \n",
      "843 [D loss: (-5.226)(R -0.649, F -9.803)]  [G loss: 7.740] \n",
      "844 [D loss: (-5.636)(R -1.406, F -9.866)]  [G loss: 7.817] \n",
      "844 [D loss: (-5.067)(R -0.306, F -9.828)]  [G loss: 7.812] \n",
      "845 [D loss: (-5.569)(R -0.927, F -10.211)]  [G loss: 7.718] \n",
      "845 [D loss: (-4.779)(R -0.114, F -9.444)]  [G loss: 7.600] \n",
      "846 [D loss: (-4.763)(R 0.113, F -9.639)]  [G loss: 7.603] \n",
      "846 [D loss: (-4.734)(R 0.142, F -9.609)]  [G loss: 7.742] \n",
      "847 [D loss: (-4.818)(R -0.055, F -9.580)]  [G loss: 7.434] \n",
      "847 [D loss: (-4.693)(R -0.375, F -9.010)]  [G loss: 7.297] \n",
      "848 [D loss: (-4.552)(R -0.200, F -8.904)]  [G loss: 7.064] \n",
      "848 [D loss: (-4.238)(R 0.302, F -8.778)]  [G loss: 7.213] \n",
      "849 [D loss: (-4.379)(R 0.101, F -8.860)]  [G loss: 7.559] \n",
      "849 [D loss: (-4.727)(R -0.645, F -8.810)]  [G loss: 7.165] \n",
      "850 [D loss: (-4.491)(R -1.103, F -7.879)]  [G loss: 6.915] \n",
      "850 [D loss: (-4.239)(R -0.613, F -7.866)]  [G loss: 6.743] \n",
      "851 [D loss: (-4.726)(R -1.622, F -7.831)]  [G loss: 6.729] \n",
      "851 [D loss: (-4.775)(R -1.565, F -7.985)]  [G loss: 7.057] \n",
      "852 [D loss: (-4.918)(R -1.619, F -8.217)]  [G loss: 7.206] \n",
      "852 [D loss: (-5.147)(R -1.922, F -8.372)]  [G loss: 7.675] \n",
      "853 [D loss: (-5.138)(R -1.522, F -8.754)]  [G loss: 8.132] \n",
      "853 [D loss: (-5.113)(R -1.606, F -8.621)]  [G loss: 8.426] \n",
      "854 [D loss: (-5.609)(R -1.994, F -9.225)]  [G loss: 9.101] \n",
      "854 [D loss: (-6.008)(R -1.960, F -10.057)]  [G loss: 9.854] \n",
      "855 [D loss: (-6.030)(R -1.975, F -10.086)]  [G loss: 10.079] \n",
      "855 [D loss: (-6.269)(R -1.986, F -10.553)]  [G loss: 10.469] \n",
      "856 [D loss: (-6.830)(R -2.820, F -10.841)]  [G loss: 11.167] \n",
      "856 [D loss: (-7.268)(R -2.606, F -11.930)]  [G loss: 12.067] \n",
      "857 [D loss: (-7.454)(R -2.571, F -12.336)]  [G loss: 12.364] \n",
      "857 [D loss: (-7.488)(R -2.898, F -12.078)]  [G loss: 12.255] \n",
      "858 [D loss: (-8.172)(R -4.358, F -11.987)]  [G loss: 12.092] \n",
      "858 [D loss: (-8.140)(R -4.276, F -12.004)]  [G loss: 12.152] \n",
      "859 [D loss: (-8.931)(R -5.800, F -12.062)]  [G loss: 12.257] \n",
      "859 [D loss: (-8.880)(R -5.776, F -11.985)]  [G loss: 12.169] \n",
      "860 [D loss: (-9.435)(R -6.839, F -12.030)]  [G loss: 11.915] \n",
      "860 [D loss: (-9.766)(R -7.351, F -12.181)]  [G loss: 12.282] \n",
      "861 [D loss: (-9.845)(R -7.272, F -12.417)]  [G loss: 12.428] \n",
      "861 [D loss: (-10.172)(R -7.978, F -12.366)]  [G loss: 12.230] \n",
      "862 [D loss: (-10.557)(R -8.623, F -12.491)]  [G loss: 12.285] \n",
      "862 [D loss: (-10.712)(R -8.682, F -12.742)]  [G loss: 12.509] \n",
      "863 [D loss: (-10.989)(R -8.968, F -13.010)]  [G loss: 12.615] \n",
      "863 [D loss: (-11.164)(R -8.935, F -13.393)]  [G loss: 12.865] \n",
      "864 [D loss: (-11.328)(R -9.490, F -13.167)]  [G loss: 12.538] \n",
      "864 [D loss: (-11.620)(R -9.764, F -13.476)]  [G loss: 12.735] \n",
      "865 [D loss: (-11.757)(R -9.669, F -13.845)]  [G loss: 13.270] \n",
      "865 [D loss: (-11.923)(R -9.701, F -14.146)]  [G loss: 13.208] \n",
      "866 [D loss: (-12.095)(R -9.889, F -14.300)]  [G loss: 13.259] \n",
      "866 [D loss: (-12.129)(R -9.698, F -14.560)]  [G loss: 13.426] \n",
      "867 [D loss: (-12.367)(R -10.338, F -14.396)]  [G loss: 13.135] \n",
      "867 [D loss: (-12.500)(R -10.335, F -14.665)]  [G loss: 13.267] \n",
      "868 [D loss: (-12.572)(R -9.966, F -15.178)]  [G loss: 13.970] \n",
      "868 [D loss: (-12.652)(R -9.976, F -15.327)]  [G loss: 13.795] \n",
      "869 [D loss: (-12.753)(R -10.208, F -15.299)]  [G loss: 13.616] \n",
      "869 [D loss: (-13.009)(R -10.597, F -15.422)]  [G loss: 13.451] \n",
      "870 [D loss: (-12.909)(R -10.220, F -15.597)]  [G loss: 13.890] \n",
      "870 [D loss: (-12.857)(R -9.640, F -16.074)]  [G loss: 14.119] \n",
      "871 [D loss: (-12.869)(R -9.870, F -15.869)]  [G loss: 13.779] \n",
      "871 [D loss: (-12.676)(R -9.677, F -15.674)]  [G loss: 13.784] \n",
      "872 [D loss: (-12.864)(R -9.679, F -16.048)]  [G loss: 13.922] \n",
      "872 [D loss: (-12.779)(R -9.246, F -16.312)]  [G loss: 14.007] \n",
      "873 [D loss: (-12.760)(R -9.632, F -15.888)]  [G loss: 13.573] \n",
      "873 [D loss: (-12.838)(R -9.330, F -16.345)]  [G loss: 14.063] \n",
      "874 [D loss: (-12.627)(R -8.994, F -16.261)]  [G loss: 14.065] \n",
      "874 [D loss: (-12.628)(R -9.335, F -15.922)]  [G loss: 13.747] \n",
      "875 [D loss: (-12.467)(R -8.627, F -16.306)]  [G loss: 14.268] \n",
      "875 [D loss: (-12.257)(R -8.199, F -16.315)]  [G loss: 14.392] \n",
      "876 [D loss: (-12.302)(R -8.271, F -16.333)]  [G loss: 14.555] \n",
      "876 [D loss: (-12.555)(R -8.379, F -16.731)]  [G loss: 14.581] \n",
      "877 [D loss: (-12.319)(R -8.156, F -16.482)]  [G loss: 14.574] \n",
      "877 [D loss: (-12.125)(R -7.382, F -16.867)]  [G loss: 14.636] \n",
      "878 [D loss: (-12.023)(R -7.659, F -16.388)]  [G loss: 14.538] \n",
      "878 [D loss: (-12.043)(R -7.883, F -16.203)]  [G loss: 14.152] \n",
      "879 [D loss: (-11.782)(R -7.341, F -16.222)]  [G loss: 14.321] \n",
      "879 [D loss: (-11.809)(R -7.110, F -16.509)]  [G loss: 14.827] \n",
      "880 [D loss: (-11.594)(R -6.995, F -16.192)]  [G loss: 14.283] \n",
      "880 [D loss: (-11.572)(R -7.142, F -16.002)]  [G loss: 14.169] \n",
      "881 [D loss: (-11.656)(R -7.122, F -16.190)]  [G loss: 14.242] \n",
      "881 [D loss: (-11.374)(R -6.625, F -16.124)]  [G loss: 14.166] \n",
      "882 [D loss: (-11.175)(R -6.261, F -16.090)]  [G loss: 14.247] \n",
      "882 [D loss: (-11.080)(R -6.006, F -16.154)]  [G loss: 14.313] \n",
      "883 [D loss: (-10.717)(R -5.435, F -15.999)]  [G loss: 14.134] \n",
      "883 [D loss: (-10.626)(R -5.664, F -15.588)]  [G loss: 13.982] \n",
      "884 [D loss: (-10.545)(R -5.479, F -15.610)]  [G loss: 13.912] \n",
      "884 [D loss: (-10.720)(R -5.430, F -16.010)]  [G loss: 14.252] \n",
      "885 [D loss: (-9.993)(R -4.470, F -15.516)]  [G loss: 14.015] \n",
      "885 [D loss: (-9.965)(R -4.649, F -15.281)]  [G loss: 13.566] \n",
      "886 [D loss: (-9.717)(R -3.776, F -15.658)]  [G loss: 14.172] \n",
      "886 [D loss: (-9.502)(R -3.715, F -15.288)]  [G loss: 14.137] \n",
      "887 [D loss: (-9.485)(R -3.290, F -15.679)]  [G loss: 14.603] \n",
      "887 [D loss: (-9.247)(R -3.353, F -15.142)]  [G loss: 13.907] \n",
      "888 [D loss: (-9.206)(R -3.296, F -15.116)]  [G loss: 13.831] \n",
      "888 [D loss: (-9.394)(R -2.964, F -15.823)]  [G loss: 14.447] \n",
      "889 [D loss: (-8.971)(R -1.747, F -16.194)]  [G loss: 14.727] \n",
      "889 [D loss: (-8.958)(R -2.397, F -15.520)]  [G loss: 14.573] \n",
      "890 [D loss: (-8.762)(R -1.963, F -15.561)]  [G loss: 14.639] \n",
      "890 [D loss: (-8.706)(R -1.727, F -15.685)]  [G loss: 14.784] \n",
      "891 [D loss: (-8.372)(R -0.835, F -15.909)]  [G loss: 14.829] \n",
      "891 [D loss: (-8.362)(R -0.633, F -16.092)]  [G loss: 14.658] \n",
      "892 [D loss: (-8.542)(R -1.417, F -15.667)]  [G loss: 14.769] \n",
      "892 [D loss: (-8.173)(R -0.978, F -15.368)]  [G loss: 14.614] \n",
      "893 [D loss: (-7.983)(R -0.390, F -15.575)]  [G loss: 14.848] \n",
      "893 [D loss: (-7.868)(R -0.333, F -15.402)]  [G loss: 14.625] \n",
      "894 [D loss: (-8.255)(R -0.772, F -15.739)]  [G loss: 14.532] \n",
      "894 [D loss: (-7.671)(R 0.326, F -15.667)]  [G loss: 15.058] \n",
      "895 [D loss: (-7.461)(R 0.813, F -15.736)]  [G loss: 14.923] \n",
      "895 [D loss: (-7.315)(R 0.868, F -15.499)]  [G loss: 15.078] \n",
      "896 [D loss: (-7.040)(R 1.548, F -15.628)]  [G loss: 14.976] \n",
      "896 [D loss: (-7.453)(R 0.667, F -15.574)]  [G loss: 14.976] \n",
      "897 [D loss: (-7.493)(R 1.516, F -16.503)]  [G loss: 15.524] \n",
      "897 [D loss: (-7.093)(R 1.833, F -16.020)]  [G loss: 15.366] \n",
      "898 [D loss: (-7.094)(R 1.298, F -15.485)]  [G loss: 15.044] \n",
      "898 [D loss: (-6.572)(R 2.038, F -15.183)]  [G loss: 15.020] \n",
      "899 [D loss: (-6.937)(R 1.568, F -15.441)]  [G loss: 15.216] \n",
      "899 [D loss: (-6.982)(R 2.064, F -16.029)]  [G loss: 15.613] \n",
      "900 [D loss: (-6.977)(R 2.471, F -16.425)]  [G loss: 15.499] \n",
      "900 [D loss: (-6.841)(R 2.010, F -15.691)]  [G loss: 15.199] \n",
      "901 [D loss: (-6.701)(R 2.606, F -16.007)]  [G loss: 15.675] \n",
      "901 [D loss: (-6.816)(R 2.413, F -16.045)]  [G loss: 15.664] \n",
      "902 [D loss: (-6.922)(R 2.528, F -16.373)]  [G loss: 15.603] \n",
      "902 [D loss: (-7.069)(R 2.678, F -16.816)]  [G loss: 16.010] \n",
      "903 [D loss: (-6.793)(R 2.898, F -16.484)]  [G loss: 15.815] \n",
      "903 [D loss: (-6.169)(R 3.397, F -15.734)]  [G loss: 15.804] \n",
      "904 [D loss: (-6.662)(R 3.293, F -16.618)]  [G loss: 15.919] \n",
      "904 [D loss: (-6.838)(R 3.553, F -17.229)]  [G loss: 16.262] \n",
      "905 [D loss: (-6.515)(R 3.804, F -16.833)]  [G loss: 15.782] \n",
      "905 [D loss: (-6.392)(R 3.853, F -16.636)]  [G loss: 15.930] \n",
      "906 [D loss: (-6.203)(R 4.425, F -16.831)]  [G loss: 15.947] \n",
      "906 [D loss: (-6.605)(R 3.776, F -16.986)]  [G loss: 15.973] \n",
      "907 [D loss: (-6.539)(R 4.548, F -17.625)]  [G loss: 16.292] \n",
      "907 [D loss: (-6.493)(R 4.538, F -17.525)]  [G loss: 16.332] \n",
      "908 [D loss: (-5.975)(R 5.509, F -17.459)]  [G loss: 16.371] \n",
      "908 [D loss: (-6.489)(R 4.565, F -17.543)]  [G loss: 16.309] \n",
      "909 [D loss: (-6.145)(R 5.383, F -17.673)]  [G loss: 16.612] \n",
      "909 [D loss: (-6.189)(R 5.588, F -17.967)]  [G loss: 16.568] \n",
      "910 [D loss: (-6.370)(R 5.401, F -18.141)]  [G loss: 16.847] \n",
      "910 [D loss: (-6.551)(R 5.351, F -18.452)]  [G loss: 16.927] \n",
      "911 [D loss: (-6.147)(R 6.289, F -18.583)]  [G loss: 17.068] \n",
      "911 [D loss: (-6.079)(R 6.508, F -18.666)]  [G loss: 16.968] \n",
      "912 [D loss: (-5.998)(R 6.473, F -18.469)]  [G loss: 16.869] \n",
      "912 [D loss: (-5.741)(R 6.757, F -18.238)]  [G loss: 16.771] \n",
      "913 [D loss: (-5.715)(R 7.389, F -18.819)]  [G loss: 17.087] \n",
      "913 [D loss: (-6.160)(R 6.802, F -19.123)]  [G loss: 17.627] \n",
      "914 [D loss: (-5.890)(R 7.903, F -19.682)]  [G loss: 18.117] \n",
      "914 [D loss: (-5.917)(R 7.935, F -19.770)]  [G loss: 17.794] \n",
      "915 [D loss: (-5.680)(R 8.271, F -19.632)]  [G loss: 17.982] \n",
      "915 [D loss: (-5.614)(R 8.275, F -19.502)]  [G loss: 18.137] \n",
      "916 [D loss: (-5.494)(R 9.089, F -20.078)]  [G loss: 18.358] \n",
      "916 [D loss: (-5.171)(R 9.829, F -20.171)]  [G loss: 18.242] \n",
      "917 [D loss: (-4.711)(R 10.822, F -20.243)]  [G loss: 18.834] \n",
      "917 [D loss: (-5.413)(R 9.803, F -20.628)]  [G loss: 19.063] \n",
      "918 [D loss: (-4.806)(R 11.749, F -21.361)]  [G loss: 20.020] \n",
      "918 [D loss: (-5.359)(R 10.449, F -21.167)]  [G loss: 19.787] \n",
      "919 [D loss: (-5.309)(R 10.657, F -21.275)]  [G loss: 20.163] \n",
      "919 [D loss: (-4.978)(R 11.704, F -21.661)]  [G loss: 20.510] \n",
      "920 [D loss: (-5.232)(R 11.226, F -21.691)]  [G loss: 20.743] \n",
      "920 [D loss: (-5.108)(R 11.715, F -21.930)]  [G loss: 20.519] \n",
      "921 [D loss: (-5.156)(R 11.407, F -21.718)]  [G loss: 20.911] \n",
      "921 [D loss: (-5.005)(R 11.634, F -21.644)]  [G loss: 20.757] \n",
      "922 [D loss: (-5.493)(R 10.930, F -21.916)]  [G loss: 21.150] \n",
      "922 [D loss: (-5.253)(R 11.882, F -22.387)]  [G loss: 21.889] \n",
      "923 [D loss: (-5.803)(R 10.888, F -22.494)]  [G loss: 22.237] \n",
      "923 [D loss: (-6.059)(R 10.511, F -22.629)]  [G loss: 22.294] \n",
      "924 [D loss: (-5.855)(R 11.162, F -22.872)]  [G loss: 22.152] \n",
      "924 [D loss: (-6.023)(R 10.680, F -22.726)]  [G loss: 22.535] \n",
      "925 [D loss: (-6.648)(R 9.232, F -22.527)]  [G loss: 22.303] \n",
      "925 [D loss: (-6.054)(R 10.605, F -22.714)]  [G loss: 22.986] \n",
      "926 [D loss: (-6.239)(R 9.817, F -22.296)]  [G loss: 22.592] \n",
      "926 [D loss: (-7.215)(R 8.110, F -22.540)]  [G loss: 22.664] \n",
      "927 [D loss: (-7.693)(R 7.188, F -22.573)]  [G loss: 22.973] \n",
      "927 [D loss: (-7.469)(R 7.870, F -22.809)]  [G loss: 23.061] \n",
      "928 [D loss: (-8.368)(R 5.858, F -22.595)]  [G loss: 22.716] \n",
      "928 [D loss: (-8.343)(R 5.863, F -22.550)]  [G loss: 23.144] \n",
      "929 [D loss: (-8.555)(R 5.529, F -22.638)]  [G loss: 23.118] \n",
      "929 [D loss: (-8.695)(R 5.230, F -22.621)]  [G loss: 23.300] \n",
      "930 [D loss: (-8.809)(R 5.055, F -22.672)]  [G loss: 22.982] \n",
      "930 [D loss: (-9.063)(R 4.168, F -22.294)]  [G loss: 22.778] \n",
      "931 [D loss: (-9.289)(R 3.637, F -22.215)]  [G loss: 22.717] \n",
      "931 [D loss: (-9.633)(R 3.424, F -22.690)]  [G loss: 23.057] \n",
      "932 [D loss: (-9.526)(R 3.116, F -22.167)]  [G loss: 22.813] \n",
      "932 [D loss: (-9.723)(R 2.481, F -21.926)]  [G loss: 22.561] \n",
      "933 [D loss: (-10.089)(R 1.874, F -22.051)]  [G loss: 22.874] \n",
      "933 [D loss: (-10.099)(R 2.054, F -22.252)]  [G loss: 22.840] \n",
      "934 [D loss: (-10.097)(R 1.873, F -22.068)]  [G loss: 22.828] \n",
      "934 [D loss: (-10.494)(R 1.261, F -22.249)]  [G loss: 22.512] \n",
      "935 [D loss: (-10.507)(R 0.944, F -21.958)]  [G loss: 22.547] \n",
      "935 [D loss: (-11.233)(R -0.413, F -22.053)]  [G loss: 22.383] \n",
      "936 [D loss: (-10.819)(R 0.541, F -22.179)]  [G loss: 22.686] \n",
      "936 [D loss: (-11.071)(R -0.109, F -22.032)]  [G loss: 22.288] \n",
      "937 [D loss: (-11.158)(R -0.772, F -21.544)]  [G loss: 22.140] \n",
      "937 [D loss: (-10.784)(R 0.038, F -21.606)]  [G loss: 21.962] \n",
      "938 [D loss: (-11.374)(R -0.768, F -21.979)]  [G loss: 22.163] \n",
      "938 [D loss: (-11.386)(R -1.168, F -21.605)]  [G loss: 22.177] \n",
      "939 [D loss: (-11.412)(R -1.196, F -21.628)]  [G loss: 21.774] \n",
      "939 [D loss: (-11.649)(R -1.901, F -21.398)]  [G loss: 21.563] \n",
      "940 [D loss: (-11.656)(R -1.578, F -21.733)]  [G loss: 21.568] \n",
      "940 [D loss: (-11.768)(R -1.819, F -21.717)]  [G loss: 21.759] \n",
      "941 [D loss: (-11.525)(R -1.499, F -21.551)]  [G loss: 21.705] \n",
      "941 [D loss: (-12.156)(R -2.243, F -22.070)]  [G loss: 21.838] \n",
      "942 [D loss: (-12.015)(R -2.196, F -21.834)]  [G loss: 21.646] \n",
      "942 [D loss: (-11.922)(R -2.140, F -21.704)]  [G loss: 21.418] \n",
      "943 [D loss: (-11.637)(R -1.856, F -21.418)]  [G loss: 21.453] \n",
      "943 [D loss: (-12.001)(R -2.567, F -21.434)]  [G loss: 21.156] \n",
      "944 [D loss: (-11.947)(R -2.341, F -21.552)]  [G loss: 20.909] \n",
      "944 [D loss: (-12.169)(R -2.878, F -21.459)]  [G loss: 20.977] \n",
      "945 [D loss: (-11.892)(R -2.418, F -21.367)]  [G loss: 20.857] \n",
      "945 [D loss: (-11.424)(R -1.419, F -21.428)]  [G loss: 20.905] \n",
      "946 [D loss: (-11.740)(R -1.927, F -21.553)]  [G loss: 20.985] \n",
      "946 [D loss: (-11.856)(R -2.350, F -21.362)]  [G loss: 20.664] \n",
      "947 [D loss: (-11.970)(R -2.422, F -21.518)]  [G loss: 20.867] \n",
      "947 [D loss: (-11.498)(R -1.413, F -21.583)]  [G loss: 20.971] \n",
      "948 [D loss: (-11.416)(R -1.375, F -21.458)]  [G loss: 20.514] \n",
      "948 [D loss: (-11.638)(R -1.941, F -21.336)]  [G loss: 20.505] \n",
      "949 [D loss: (-11.321)(R -1.281, F -21.361)]  [G loss: 20.631] \n",
      "949 [D loss: (-11.027)(R -0.700, F -21.354)]  [G loss: 20.804] \n",
      "950 [D loss: (-10.582)(R -0.097, F -21.068)]  [G loss: 20.130] \n",
      "950 [D loss: (-10.573)(R -0.429, F -20.717)]  [G loss: 19.932] \n",
      "951 [D loss: (-10.833)(R -1.039, F -20.626)]  [G loss: 19.613] \n",
      "951 [D loss: (-10.806)(R -0.975, F -20.637)]  [G loss: 19.868] \n",
      "952 [D loss: (-10.296)(R 0.589, F -21.180)]  [G loss: 20.084] \n",
      "952 [D loss: (-10.508)(R 0.029, F -21.044)]  [G loss: 20.342] \n",
      "953 [D loss: (-10.250)(R 0.633, F -21.133)]  [G loss: 20.143] \n",
      "953 [D loss: (-9.865)(R 1.225, F -20.955)]  [G loss: 19.859] \n",
      "954 [D loss: (-9.760)(R 1.141, F -20.662)]  [G loss: 19.856] \n",
      "954 [D loss: (-10.049)(R 0.413, F -20.511)]  [G loss: 19.428] \n",
      "955 [D loss: (-9.746)(R 1.052, F -20.544)]  [G loss: 19.375] \n",
      "955 [D loss: (-9.344)(R 1.960, F -20.648)]  [G loss: 19.753] \n",
      "956 [D loss: (-9.247)(R 2.274, F -20.769)]  [G loss: 19.677] \n",
      "956 [D loss: (-9.366)(R 2.352, F -21.084)]  [G loss: 19.626] \n",
      "957 [D loss: (-9.101)(R 2.551, F -20.753)]  [G loss: 19.600] \n",
      "957 [D loss: (-8.894)(R 2.567, F -20.355)]  [G loss: 19.473] \n",
      "958 [D loss: (-8.267)(R 3.776, F -20.311)]  [G loss: 19.433] \n",
      "958 [D loss: (-8.389)(R 3.622, F -20.399)]  [G loss: 19.495] \n",
      "959 [D loss: (-8.268)(R 4.252, F -20.787)]  [G loss: 19.644] \n",
      "959 [D loss: (-7.966)(R 5.545, F -21.476)]  [G loss: 20.267] \n",
      "960 [D loss: (-7.711)(R 5.929, F -21.351)]  [G loss: 20.381] \n",
      "960 [D loss: (-7.359)(R 6.033, F -20.750)]  [G loss: 20.004] \n",
      "961 [D loss: (-7.789)(R 5.075, F -20.653)]  [G loss: 19.702] \n",
      "961 [D loss: (-7.409)(R 6.366, F -21.185)]  [G loss: 20.088] \n",
      "962 [D loss: (-7.056)(R 6.905, F -21.016)]  [G loss: 20.001] \n",
      "962 [D loss: (-6.436)(R 8.035, F -20.907)]  [G loss: 19.884] \n",
      "963 [D loss: (-6.620)(R 7.496, F -20.735)]  [G loss: 19.540] \n",
      "963 [D loss: (-6.492)(R 7.811, F -20.794)]  [G loss: 19.753] \n",
      "964 [D loss: (-6.142)(R 8.700, F -20.983)]  [G loss: 19.905] \n",
      "964 [D loss: (-6.637)(R 7.742, F -21.016)]  [G loss: 20.094] \n",
      "965 [D loss: (-6.416)(R 8.491, F -21.323)]  [G loss: 20.594] \n",
      "965 [D loss: (-5.900)(R 9.498, F -21.299)]  [G loss: 20.461] \n",
      "966 [D loss: (-6.089)(R 8.806, F -20.983)]  [G loss: 20.387] \n",
      "966 [D loss: (-5.659)(R 9.847, F -21.164)]  [G loss: 20.237] \n",
      "967 [D loss: (-5.189)(R 11.041, F -21.419)]  [G loss: 20.499] \n",
      "967 [D loss: (-5.542)(R 10.327, F -21.411)]  [G loss: 20.098] \n",
      "968 [D loss: (-5.021)(R 11.284, F -21.326)]  [G loss: 20.477] \n",
      "968 [D loss: (-5.581)(R 10.287, F -21.450)]  [G loss: 20.947] \n",
      "969 [D loss: (-4.735)(R 12.273, F -21.744)]  [G loss: 20.814] \n",
      "969 [D loss: (-5.062)(R 11.912, F -22.036)]  [G loss: 21.329] \n",
      "970 [D loss: (-4.763)(R 12.458, F -21.985)]  [G loss: 21.459] \n",
      "970 [D loss: (-4.552)(R 12.924, F -22.028)]  [G loss: 21.285] \n",
      "971 [D loss: (-4.279)(R 13.602, F -22.159)]  [G loss: 21.483] \n",
      "971 [D loss: (-4.453)(R 13.010, F -21.916)]  [G loss: 21.105] \n",
      "972 [D loss: (-4.040)(R 13.834, F -21.915)]  [G loss: 21.199] \n",
      "972 [D loss: (-4.423)(R 13.274, F -22.119)]  [G loss: 21.554] \n",
      "973 [D loss: (-3.797)(R 14.852, F -22.445)]  [G loss: 21.620] \n",
      "973 [D loss: (-4.306)(R 13.943, F -22.555)]  [G loss: 22.006] \n",
      "974 [D loss: (-4.213)(R 14.039, F -22.466)]  [G loss: 22.086] \n",
      "974 [D loss: (-4.392)(R 13.358, F -22.143)]  [G loss: 21.738] \n",
      "975 [D loss: (-3.837)(R 14.245, F -21.919)]  [G loss: 21.506] \n",
      "975 [D loss: (-4.574)(R 12.559, F -21.708)]  [G loss: 21.561] \n",
      "976 [D loss: (-4.472)(R 12.948, F -21.892)]  [G loss: 21.664] \n",
      "976 [D loss: (-4.527)(R 12.895, F -21.949)]  [G loss: 21.815] \n",
      "977 [D loss: (-4.737)(R 12.529, F -22.004)]  [G loss: 21.887] \n",
      "977 [D loss: (-4.788)(R 12.448, F -22.024)]  [G loss: 21.876] \n",
      "978 [D loss: (-5.134)(R 11.829, F -22.098)]  [G loss: 21.901] \n",
      "978 [D loss: (-4.910)(R 12.297, F -22.116)]  [G loss: 21.653] \n",
      "979 [D loss: (-5.082)(R 11.892, F -22.056)]  [G loss: 21.673] \n",
      "979 [D loss: (-4.486)(R 13.147, F -22.119)]  [G loss: 21.687] \n",
      "980 [D loss: (-4.893)(R 12.100, F -21.885)]  [G loss: 21.526] \n",
      "980 [D loss: (-4.867)(R 12.049, F -21.782)]  [G loss: 21.268] \n",
      "981 [D loss: (-4.479)(R 12.750, F -21.707)]  [G loss: 21.133] \n",
      "981 [D loss: (-4.160)(R 13.486, F -21.806)]  [G loss: 21.294] \n",
      "982 [D loss: (-4.379)(R 12.833, F -21.591)]  [G loss: 21.043] \n",
      "982 [D loss: (-4.511)(R 12.492, F -21.514)]  [G loss: 21.151] \n",
      "983 [D loss: (-4.732)(R 12.090, F -21.554)]  [G loss: 20.727] \n",
      "983 [D loss: (-4.794)(R 11.957, F -21.546)]  [G loss: 21.050] \n",
      "984 [D loss: (-4.954)(R 11.670, F -21.578)]  [G loss: 20.988] \n",
      "984 [D loss: (-4.478)(R 12.745, F -21.701)]  [G loss: 21.044] \n",
      "985 [D loss: (-4.971)(R 11.753, F -21.695)]  [G loss: 20.977] \n",
      "985 [D loss: (-4.969)(R 11.736, F -21.673)]  [G loss: 20.919] \n",
      "986 [D loss: (-4.317)(R 12.812, F -21.446)]  [G loss: 20.423] \n",
      "986 [D loss: (-5.174)(R 11.068, F -21.416)]  [G loss: 20.601] \n",
      "987 [D loss: (-4.588)(R 11.936, F -21.113)]  [G loss: 20.243] \n",
      "987 [D loss: (-4.769)(R 11.593, F -21.131)]  [G loss: 20.189] \n",
      "988 [D loss: (-5.180)(R 10.721, F -21.081)]  [G loss: 20.166] \n",
      "988 [D loss: (-4.841)(R 11.993, F -21.675)]  [G loss: 20.375] \n",
      "989 [D loss: (-5.230)(R 10.822, F -21.282)]  [G loss: 20.044] \n",
      "989 [D loss: (-4.975)(R 10.977, F -20.928)]  [G loss: 19.831] \n",
      "990 [D loss: (-4.713)(R 11.279, F -20.705)]  [G loss: 19.345] \n",
      "990 [D loss: (-4.970)(R 10.387, F -20.327)]  [G loss: 19.389] \n",
      "991 [D loss: (-4.917)(R 10.342, F -20.177)]  [G loss: 18.832] \n",
      "991 [D loss: (-4.971)(R 9.474, F -19.416)]  [G loss: 18.466] \n",
      "992 [D loss: (-4.571)(R 10.212, F -19.353)]  [G loss: 18.433] \n",
      "992 [D loss: (-5.085)(R 9.347, F -19.518)]  [G loss: 18.378] \n",
      "993 [D loss: (-5.018)(R 9.421, F -19.456)]  [G loss: 18.428] \n",
      "993 [D loss: (-4.674)(R 10.055, F -19.403)]  [G loss: 18.081] \n",
      "994 [D loss: (-5.263)(R 7.909, F -18.435)]  [G loss: 17.712] \n",
      "994 [D loss: (-5.453)(R 7.227, F -18.132)]  [G loss: 16.823] \n",
      "995 [D loss: (-5.276)(R 7.222, F -17.774)]  [G loss: 16.566] \n",
      "995 [D loss: (-5.465)(R 6.286, F -17.217)]  [G loss: 15.865] \n",
      "996 [D loss: (-5.428)(R 5.949, F -16.805)]  [G loss: 15.575] \n",
      "996 [D loss: (-5.597)(R 5.234, F -16.428)]  [G loss: 15.504] \n",
      "997 [D loss: (-5.499)(R 5.199, F -16.197)]  [G loss: 15.470] \n",
      "997 [D loss: (-6.264)(R 3.427, F -15.954)]  [G loss: 15.199] \n",
      "998 [D loss: (-5.961)(R 3.390, F -15.312)]  [G loss: 14.673] \n",
      "998 [D loss: (-5.696)(R 3.343, F -14.736)]  [G loss: 14.428] \n",
      "999 [D loss: (-6.326)(R 2.290, F -14.942)]  [G loss: 14.116] \n",
      "999 [D loss: (-6.262)(R 1.984, F -14.508)]  [G loss: 13.954] \n",
      "1000 [D loss: (-6.463)(R 1.500, F -14.426)]  [G loss: 13.916] \n",
      "1000 [D loss: (-6.662)(R 0.861, F -14.185)]  [G loss: 13.936] \n",
      "1001 [D loss: (-6.781)(R 1.127, F -14.689)]  [G loss: 14.498] \n",
      "1001 [D loss: (-6.975)(R 1.025, F -14.976)]  [G loss: 14.321] \n",
      "1002 [D loss: (-7.111)(R 0.422, F -14.644)]  [G loss: 14.217] \n",
      "1002 [D loss: (-7.101)(R -0.114, F -14.089)]  [G loss: 14.235] \n",
      "1003 [D loss: (-7.012)(R 0.066, F -14.090)]  [G loss: 14.167] \n",
      "1003 [D loss: (-7.597)(R -0.652, F -14.542)]  [G loss: 14.149] \n",
      "1004 [D loss: (-7.513)(R -1.236, F -13.790)]  [G loss: 14.287] \n",
      "1004 [D loss: (-8.044)(R -1.791, F -14.297)]  [G loss: 14.294] \n",
      "1005 [D loss: (-8.466)(R -2.442, F -14.490)]  [G loss: 14.146] \n",
      "1005 [D loss: (-8.043)(R -1.936, F -14.150)]  [G loss: 14.657] \n",
      "1006 [D loss: (-8.055)(R -2.264, F -13.847)]  [G loss: 14.482] \n",
      "1006 [D loss: (-8.996)(R -3.105, F -14.887)]  [G loss: 14.854] \n",
      "1007 [D loss: (-8.621)(R -2.215, F -15.027)]  [G loss: 15.276] \n",
      "1007 [D loss: (-8.794)(R -2.790, F -14.798)]  [G loss: 15.452] \n",
      "1008 [D loss: (-9.504)(R -3.217, F -15.790)]  [G loss: 15.900] \n",
      "1008 [D loss: (-9.369)(R -2.660, F -16.077)]  [G loss: 16.055] \n",
      "1009 [D loss: (-9.539)(R -3.287, F -15.792)]  [G loss: 16.000] \n",
      "1009 [D loss: (-9.812)(R -3.483, F -16.140)]  [G loss: 16.445] \n",
      "1010 [D loss: (-9.801)(R -3.251, F -16.351)]  [G loss: 16.602] \n",
      "1010 [D loss: (-10.149)(R -4.348, F -15.950)]  [G loss: 16.310] \n",
      "1011 [D loss: (-10.180)(R -4.196, F -16.164)]  [G loss: 15.842] \n",
      "1011 [D loss: (-10.286)(R -4.650, F -15.922)]  [G loss: 15.847] \n",
      "1012 [D loss: (-10.436)(R -4.580, F -16.291)]  [G loss: 16.062] \n",
      "1012 [D loss: (-10.661)(R -5.082, F -16.239)]  [G loss: 16.038] \n",
      "1013 [D loss: (-10.743)(R -4.830, F -16.655)]  [G loss: 16.290] \n",
      "1013 [D loss: (-10.598)(R -4.363, F -16.833)]  [G loss: 16.556] \n",
      "1014 [D loss: (-10.778)(R -5.070, F -16.486)]  [G loss: 15.842] \n",
      "1014 [D loss: (-10.762)(R -5.497, F -16.027)]  [G loss: 15.699] \n",
      "1015 [D loss: (-10.966)(R -5.619, F -16.312)]  [G loss: 15.888] \n",
      "1015 [D loss: (-10.994)(R -5.598, F -16.390)]  [G loss: 16.119] \n",
      "1016 [D loss: (-11.375)(R -6.049, F -16.700)]  [G loss: 16.129] \n",
      "1016 [D loss: (-10.853)(R -5.023, F -16.684)]  [G loss: 15.909] \n",
      "1017 [D loss: (-11.320)(R -6.310, F -16.331)]  [G loss: 15.370] \n",
      "1017 [D loss: (-11.058)(R -6.221, F -15.895)]  [G loss: 15.119] \n",
      "1018 [D loss: (-11.269)(R -6.766, F -15.772)]  [G loss: 14.754] \n",
      "1018 [D loss: (-11.253)(R -6.445, F -16.060)]  [G loss: 15.031] \n",
      "1019 [D loss: (-11.084)(R -6.171, F -15.997)]  [G loss: 14.820] \n",
      "1019 [D loss: (-11.086)(R -6.282, F -15.891)]  [G loss: 14.682] \n",
      "1020 [D loss: (-10.675)(R -5.468, F -15.882)]  [G loss: 14.613] \n",
      "1020 [D loss: (-10.863)(R -6.033, F -15.693)]  [G loss: 14.741] \n",
      "1021 [D loss: (-10.696)(R -5.503, F -15.889)]  [G loss: 14.421] \n",
      "1021 [D loss: (-10.663)(R -5.595, F -15.731)]  [G loss: 14.278] \n",
      "1022 [D loss: (-10.492)(R -5.607, F -15.377)]  [G loss: 13.734] \n",
      "1022 [D loss: (-10.424)(R -5.869, F -14.979)]  [G loss: 13.537] \n",
      "1023 [D loss: (-10.767)(R -6.122, F -15.412)]  [G loss: 13.603] \n",
      "1023 [D loss: (-10.458)(R -5.554, F -15.362)]  [G loss: 13.931] \n",
      "1024 [D loss: (-10.203)(R -4.972, F -15.434)]  [G loss: 13.947] \n",
      "1024 [D loss: (-9.928)(R -4.813, F -15.044)]  [G loss: 13.582] \n",
      "1025 [D loss: (-10.058)(R -5.345, F -14.772)]  [G loss: 12.863] \n",
      "1025 [D loss: (-9.882)(R -5.061, F -14.704)]  [G loss: 12.993] \n",
      "1026 [D loss: (-9.755)(R -4.820, F -14.690)]  [G loss: 12.982] \n",
      "1026 [D loss: (-9.681)(R -4.937, F -14.424)]  [G loss: 12.574] \n",
      "1027 [D loss: (-9.480)(R -4.479, F -14.480)]  [G loss: 12.690] \n",
      "1027 [D loss: (-9.276)(R -4.449, F -14.102)]  [G loss: 12.351] \n",
      "1028 [D loss: (-9.006)(R -4.045, F -13.967)]  [G loss: 12.172] \n",
      "1028 [D loss: (-8.968)(R -4.055, F -13.880)]  [G loss: 12.007] \n",
      "1029 [D loss: (-8.668)(R -3.579, F -13.758)]  [G loss: 11.695] \n",
      "1029 [D loss: (-8.673)(R -3.973, F -13.373)]  [G loss: 11.462] \n",
      "1030 [D loss: (-8.434)(R -4.198, F -12.669)]  [G loss: 10.741] \n",
      "1030 [D loss: (-7.987)(R -3.932, F -12.042)]  [G loss: 10.588] \n",
      "1031 [D loss: (-8.246)(R -4.689, F -11.803)]  [G loss: 10.260] \n",
      "1031 [D loss: (-7.832)(R -3.993, F -11.671)]  [G loss: 10.278] \n",
      "1032 [D loss: (-7.841)(R -3.755, F -11.928)]  [G loss: 10.316] \n",
      "1032 [D loss: (-7.837)(R -3.185, F -12.490)]  [G loss: 10.668] \n",
      "1033 [D loss: (-7.074)(R -1.825, F -12.324)]  [G loss: 10.735] \n",
      "1033 [D loss: (-7.124)(R -2.038, F -12.210)]  [G loss: 10.659] \n",
      "1034 [D loss: (-7.123)(R -2.313, F -11.932)]  [G loss: 10.329] \n",
      "1034 [D loss: (-6.876)(R -2.823, F -10.930)]  [G loss: 9.364] \n",
      "1035 [D loss: (-6.655)(R -2.677, F -10.633)]  [G loss: 9.460] \n",
      "1035 [D loss: (-6.222)(R -2.517, F -9.927)]  [G loss: 9.215] \n",
      "1036 [D loss: (-6.426)(R -3.071, F -9.782)]  [G loss: 8.931] \n",
      "1036 [D loss: (-6.893)(R -4.407, F -9.379)]  [G loss: 8.760] \n",
      "1037 [D loss: (-6.932)(R -4.040, F -9.823)]  [G loss: 8.843] \n",
      "1037 [D loss: (-6.208)(R -2.652, F -9.763)]  [G loss: 9.085] \n",
      "1038 [D loss: (-6.319)(R -2.237, F -10.401)]  [G loss: 9.685] \n",
      "1038 [D loss: (-6.493)(R -2.435, F -10.551)]  [G loss: 9.547] \n",
      "1039 [D loss: (-6.101)(R -1.470, F -10.733)]  [G loss: 9.806] \n",
      "1039 [D loss: (-5.996)(R -1.680, F -10.313)]  [G loss: 9.683] \n",
      "1040 [D loss: (-6.043)(R -1.617, F -10.469)]  [G loss: 9.703] \n",
      "1040 [D loss: (-5.973)(R -1.262, F -10.684)]  [G loss: 9.787] \n",
      "1041 [D loss: (-5.478)(R -1.100, F -9.857)]  [G loss: 9.353] \n",
      "1041 [D loss: (-5.773)(R -1.588, F -9.958)]  [G loss: 8.753] \n",
      "1042 [D loss: (-5.519)(R -1.934, F -9.104)]  [G loss: 8.546] \n",
      "1042 [D loss: (-5.265)(R -1.458, F -9.072)]  [G loss: 8.263] \n",
      "1043 [D loss: (-5.292)(R -1.729, F -8.854)]  [G loss: 8.282] \n",
      "1043 [D loss: (-4.967)(R -0.974, F -8.961)]  [G loss: 8.216] \n",
      "1044 [D loss: (-4.964)(R -1.199, F -8.729)]  [G loss: 8.116] \n",
      "1044 [D loss: (-5.244)(R -1.832, F -8.657)]  [G loss: 7.749] \n",
      "1045 [D loss: (-4.879)(R -1.210, F -8.549)]  [G loss: 8.154] \n",
      "1045 [D loss: (-4.957)(R -1.345, F -8.568)]  [G loss: 8.396] \n",
      "1046 [D loss: (-4.998)(R -0.993, F -9.002)]  [G loss: 8.336] \n",
      "1046 [D loss: (-4.567)(R -0.149, F -8.984)]  [G loss: 8.310] \n",
      "1047 [D loss: (-4.568)(R -0.444, F -8.693)]  [G loss: 8.205] \n",
      "1047 [D loss: (-4.332)(R -0.204, F -8.460)]  [G loss: 7.595] \n",
      "1048 [D loss: (-4.707)(R -1.015, F -8.400)]  [G loss: 7.657] \n",
      "1048 [D loss: (-4.422)(R -0.087, F -8.757)]  [G loss: 7.977] \n",
      "1049 [D loss: (-4.311)(R -0.097, F -8.525)]  [G loss: 7.953] \n",
      "1049 [D loss: (-4.315)(R -0.028, F -8.601)]  [G loss: 7.997] \n",
      "1050 [D loss: (-4.226)(R 0.318, F -8.771)]  [G loss: 8.130] \n",
      "1050 [D loss: (-4.330)(R 0.253, F -8.912)]  [G loss: 8.316] \n",
      "1051 [D loss: (-4.064)(R 0.978, F -9.107)]  [G loss: 8.536] \n",
      "1051 [D loss: (-3.815)(R 1.404, F -9.033)]  [G loss: 8.627] \n",
      "1052 [D loss: (-3.783)(R 1.693, F -9.259)]  [G loss: 8.543] \n",
      "1052 [D loss: (-3.811)(R 1.459, F -9.081)]  [G loss: 8.457] \n",
      "1053 [D loss: (-3.611)(R 1.206, F -8.428)]  [G loss: 8.122] \n",
      "1053 [D loss: (-3.683)(R 1.033, F -8.399)]  [G loss: 7.839] \n",
      "1054 [D loss: (-3.894)(R 0.879, F -8.667)]  [G loss: 8.134] \n",
      "1054 [D loss: (-4.184)(R 0.279, F -8.647)]  [G loss: 8.332] \n",
      "1055 [D loss: (-3.485)(R 2.112, F -9.083)]  [G loss: 8.567] \n",
      "1055 [D loss: (-3.480)(R 2.054, F -9.014)]  [G loss: 8.490] \n",
      "1056 [D loss: (-3.588)(R 1.730, F -8.907)]  [G loss: 8.287] \n",
      "1056 [D loss: (-3.720)(R 1.185, F -8.625)]  [G loss: 8.163] \n",
      "1057 [D loss: (-4.209)(R -0.060, F -8.359)]  [G loss: 7.956] \n",
      "1057 [D loss: (-3.562)(R 0.920, F -8.045)]  [G loss: 7.895] \n",
      "1058 [D loss: (-3.666)(R 0.648, F -7.980)]  [G loss: 7.701] \n",
      "1058 [D loss: (-3.887)(R 0.210, F -7.984)]  [G loss: 7.714] \n",
      "1059 [D loss: (-4.082)(R 0.270, F -8.433)]  [G loss: 8.095] \n",
      "1059 [D loss: (-4.196)(R 0.743, F -9.135)]  [G loss: 8.634] \n",
      "1060 [D loss: (-4.328)(R 1.033, F -9.690)]  [G loss: 9.619] \n",
      "1060 [D loss: (-4.054)(R 2.113, F -10.220)]  [G loss: 10.202] \n",
      "1061 [D loss: (-4.041)(R 2.315, F -10.398)]  [G loss: 10.310] \n",
      "1061 [D loss: (-4.044)(R 2.393, F -10.480)]  [G loss: 10.572] \n",
      "1062 [D loss: (-4.179)(R 2.625, F -10.982)]  [G loss: 10.817] \n",
      "1062 [D loss: (-4.271)(R 2.793, F -11.336)]  [G loss: 11.084] \n",
      "1063 [D loss: (-4.341)(R 2.623, F -11.305)]  [G loss: 11.261] \n",
      "1063 [D loss: (-4.582)(R 2.257, F -11.421)]  [G loss: 11.501] \n",
      "1064 [D loss: (-4.918)(R 1.878, F -11.713)]  [G loss: 11.694] \n",
      "1064 [D loss: (-5.148)(R 1.815, F -12.111)]  [G loss: 11.941] \n",
      "1065 [D loss: (-4.678)(R 2.791, F -12.147)]  [G loss: 12.078] \n",
      "1065 [D loss: (-5.085)(R 2.037, F -12.208)]  [G loss: 11.914] \n",
      "1066 [D loss: (-5.219)(R 1.323, F -11.761)]  [G loss: 11.626] \n",
      "1066 [D loss: (-5.163)(R 1.511, F -11.838)]  [G loss: 11.759] \n",
      "1067 [D loss: (-5.207)(R 1.677, F -12.091)]  [G loss: 11.801] \n",
      "1067 [D loss: (-5.063)(R 1.760, F -11.886)]  [G loss: 12.009] \n",
      "1068 [D loss: (-5.829)(R 0.626, F -12.284)]  [G loss: 11.919] \n",
      "1068 [D loss: (-5.326)(R 0.676, F -11.327)]  [G loss: 11.429] \n",
      "1069 [D loss: (-5.901)(R -0.982, F -10.820)]  [G loss: 10.979] \n",
      "1069 [D loss: (-5.295)(R 0.305, F -10.895)]  [G loss: 11.011] \n",
      "1070 [D loss: (-5.499)(R 0.097, F -11.094)]  [G loss: 10.911] \n",
      "1070 [D loss: (-6.185)(R -1.201, F -11.169)]  [G loss: 10.731] \n",
      "1071 [D loss: (-6.000)(R -1.214, F -10.785)]  [G loss: 10.692] \n",
      "1071 [D loss: (-6.222)(R -1.330, F -11.115)]  [G loss: 10.914] \n",
      "1072 [D loss: (-6.487)(R -1.954, F -11.021)]  [G loss: 10.955] \n",
      "1072 [D loss: (-6.191)(R -1.507, F -10.874)]  [G loss: 10.815] \n",
      "1073 [D loss: (-6.809)(R -2.507, F -11.111)]  [G loss: 10.657] \n",
      "1073 [D loss: (-6.339)(R -1.980, F -10.698)]  [G loss: 10.571] \n",
      "1074 [D loss: (-6.265)(R -2.793, F -9.738)]  [G loss: 10.438] \n",
      "1074 [D loss: (-6.261)(R -2.845, F -9.676)]  [G loss: 10.102] \n",
      "1075 [D loss: (-6.197)(R -2.927, F -9.467)]  [G loss: 10.085] \n",
      "1075 [D loss: (-6.875)(R -3.445, F -10.305)]  [G loss: 10.610] \n",
      "1076 [D loss: (-6.685)(R -2.731, F -10.640)]  [G loss: 10.863] \n",
      "1076 [D loss: (-6.914)(R -3.087, F -10.740)]  [G loss: 10.774] \n",
      "1077 [D loss: (-6.909)(R -2.824, F -10.994)]  [G loss: 11.063] \n",
      "1077 [D loss: (-7.378)(R -3.011, F -11.745)]  [G loss: 11.202] \n",
      "1078 [D loss: (-7.234)(R -3.053, F -11.415)]  [G loss: 11.252] \n",
      "1078 [D loss: (-6.943)(R -2.996, F -10.890)]  [G loss: 10.968] \n",
      "1079 [D loss: (-6.860)(R -2.918, F -10.802)]  [G loss: 11.048] \n",
      "1079 [D loss: (-7.645)(R -4.272, F -11.018)]  [G loss: 10.919] \n",
      "1080 [D loss: (-7.498)(R -3.661, F -11.335)]  [G loss: 10.683] \n",
      "1080 [D loss: (-7.385)(R -3.757, F -11.012)]  [G loss: 10.624] \n",
      "1081 [D loss: (-7.374)(R -3.781, F -10.968)]  [G loss: 10.893] \n",
      "1081 [D loss: (-7.332)(R -3.532, F -11.131)]  [G loss: 10.808] \n",
      "1082 [D loss: (-7.569)(R -4.503, F -10.634)]  [G loss: 10.407] \n",
      "1082 [D loss: (-7.933)(R -5.034, F -10.833)]  [G loss: 10.581] \n",
      "1083 [D loss: (-7.676)(R -4.493, F -10.859)]  [G loss: 10.834] \n",
      "1083 [D loss: (-8.022)(R -4.926, F -11.117)]  [G loss: 10.720] \n",
      "1084 [D loss: (-7.882)(R -5.096, F -10.669)]  [G loss: 10.869] \n",
      "1084 [D loss: (-7.589)(R -4.532, F -10.646)]  [G loss: 10.886] \n",
      "1085 [D loss: (-8.007)(R -5.111, F -10.903)]  [G loss: 11.224] \n",
      "1085 [D loss: (-7.988)(R -4.374, F -11.602)]  [G loss: 11.615] \n",
      "1086 [D loss: (-8.211)(R -4.640, F -11.781)]  [G loss: 11.379] \n",
      "1086 [D loss: (-7.978)(R -4.148, F -11.808)]  [G loss: 11.535] \n",
      "1087 [D loss: (-8.182)(R -4.904, F -11.461)]  [G loss: 11.417] \n",
      "1087 [D loss: (-8.050)(R -4.436, F -11.663)]  [G loss: 11.880] \n",
      "1088 [D loss: (-8.437)(R -4.447, F -12.428)]  [G loss: 12.192] \n",
      "1088 [D loss: (-7.886)(R -3.852, F -11.920)]  [G loss: 11.875] \n",
      "1089 [D loss: (-7.676)(R -4.657, F -10.695)]  [G loss: 11.268] \n",
      "1089 [D loss: (-8.010)(R -5.023, F -10.998)]  [G loss: 11.062] \n",
      "1090 [D loss: (-8.409)(R -5.630, F -11.188)]  [G loss: 11.538] \n",
      "1090 [D loss: (-8.016)(R -4.607, F -11.424)]  [G loss: 11.671] \n",
      "1091 [D loss: (-8.305)(R -4.923, F -11.688)]  [G loss: 11.537] \n",
      "1091 [D loss: (-8.528)(R -5.022, F -12.034)]  [G loss: 12.218] \n",
      "1092 [D loss: (-8.597)(R -5.352, F -11.842)]  [G loss: 10.999] \n",
      "1092 [D loss: (-8.345)(R -5.434, F -11.257)]  [G loss: 11.093] \n",
      "1093 [D loss: (-8.076)(R -5.719, F -10.432)]  [G loss: 11.536] \n",
      "1093 [D loss: (-8.403)(R -5.956, F -10.849)]  [G loss: 11.142] \n",
      "1094 [D loss: (-8.253)(R -5.512, F -10.993)]  [G loss: 10.766] \n",
      "1094 [D loss: (-8.274)(R -6.249, F -10.300)]  [G loss: 10.949] \n",
      "1095 [D loss: (-8.176)(R -5.858, F -10.494)]  [G loss: 11.193] \n",
      "1095 [D loss: (-8.461)(R -5.647, F -11.276)]  [G loss: 11.488] \n",
      "1096 [D loss: (-8.278)(R -5.316, F -11.239)]  [G loss: 11.714] \n",
      "1096 [D loss: (-8.578)(R -5.278, F -11.879)]  [G loss: 11.489] \n",
      "1097 [D loss: (-8.997)(R -5.996, F -11.999)]  [G loss: 11.211] \n",
      "1097 [D loss: (-8.468)(R -5.843, F -11.093)]  [G loss: 11.868] \n",
      "1098 [D loss: (-8.382)(R -5.583, F -11.181)]  [G loss: 11.490] \n",
      "1098 [D loss: (-8.472)(R -5.712, F -11.232)]  [G loss: 11.501] \n",
      "1099 [D loss: (-8.452)(R -6.198, F -10.705)]  [G loss: 10.858] \n",
      "1099 [D loss: (-8.611)(R -5.836, F -11.386)]  [G loss: 11.142] \n",
      "1100 [D loss: (-8.177)(R -5.878, F -10.475)]  [G loss: 11.142] \n",
      "1100 [D loss: (-8.376)(R -6.273, F -10.478)]  [G loss: 11.206] \n",
      "1101 [D loss: (-9.020)(R -5.880, F -12.160)]  [G loss: 11.624] \n",
      "1101 [D loss: (-8.462)(R -5.546, F -11.377)]  [G loss: 11.475] \n",
      "1102 [D loss: (-8.529)(R -5.945, F -11.112)]  [G loss: 11.286] \n",
      "1102 [D loss: (-8.574)(R -5.536, F -11.611)]  [G loss: 11.115] \n",
      "1103 [D loss: (-8.498)(R -5.637, F -11.358)]  [G loss: 11.231] \n",
      "1103 [D loss: (-8.818)(R -5.504, F -12.132)]  [G loss: 11.476] \n",
      "1104 [D loss: (-8.705)(R -5.109, F -12.302)]  [G loss: 12.215] \n",
      "1104 [D loss: (-8.926)(R -5.265, F -12.587)]  [G loss: 11.401] \n",
      "1105 [D loss: (-8.179)(R -4.796, F -11.561)]  [G loss: 11.417] \n",
      "1105 [D loss: (-8.258)(R -4.900, F -11.617)]  [G loss: 11.887] \n",
      "1106 [D loss: (-8.215)(R -5.005, F -11.424)]  [G loss: 11.962] \n",
      "1106 [D loss: (-8.360)(R -4.372, F -12.349)]  [G loss: 12.042] \n",
      "1107 [D loss: (-8.286)(R -4.652, F -11.921)]  [G loss: 11.856] \n",
      "1107 [D loss: (-8.852)(R -4.770, F -12.933)]  [G loss: 11.840] \n",
      "1108 [D loss: (-8.749)(R -4.405, F -13.094)]  [G loss: 12.517] \n",
      "1108 [D loss: (-8.592)(R -3.979, F -13.206)]  [G loss: 12.564] \n",
      "1109 [D loss: (-8.342)(R -3.326, F -13.357)]  [G loss: 12.830] \n",
      "1109 [D loss: (-8.015)(R -2.884, F -13.147)]  [G loss: 12.805] \n",
      "1110 [D loss: (-8.311)(R -3.379, F -13.243)]  [G loss: 12.877] \n",
      "1110 [D loss: (-8.175)(R -2.898, F -13.452)]  [G loss: 12.968] \n",
      "1111 [D loss: (-8.347)(R -3.403, F -13.290)]  [G loss: 12.682] \n",
      "1111 [D loss: (-8.017)(R -2.718, F -13.317)]  [G loss: 13.044] \n",
      "1112 [D loss: (-8.078)(R -2.312, F -13.845)]  [G loss: 13.359] \n",
      "1112 [D loss: (-8.140)(R -2.427, F -13.853)]  [G loss: 13.613] \n",
      "1113 [D loss: (-7.961)(R -2.170, F -13.752)]  [G loss: 13.265] \n",
      "1113 [D loss: (-7.911)(R -2.250, F -13.571)]  [G loss: 13.220] \n",
      "1114 [D loss: (-7.797)(R -1.917, F -13.676)]  [G loss: 13.344] \n",
      "1114 [D loss: (-7.971)(R -2.206, F -13.735)]  [G loss: 12.990] \n",
      "1115 [D loss: (-7.623)(R -1.861, F -13.384)]  [G loss: 12.707] \n",
      "1115 [D loss: (-7.753)(R -2.437, F -13.068)]  [G loss: 12.855] \n",
      "1116 [D loss: (-7.447)(R -1.958, F -12.935)]  [G loss: 12.655] \n",
      "1116 [D loss: (-7.656)(R -2.245, F -13.067)]  [G loss: 12.766] \n",
      "1117 [D loss: (-7.338)(R -1.380, F -13.296)]  [G loss: 13.039] \n",
      "1117 [D loss: (-7.310)(R -1.250, F -13.370)]  [G loss: 12.905] \n",
      "1118 [D loss: (-7.386)(R -1.332, F -13.440)]  [G loss: 12.950] \n",
      "1118 [D loss: (-7.398)(R -1.423, F -13.373)]  [G loss: 13.080] \n",
      "1119 [D loss: (-7.006)(R -0.527, F -13.484)]  [G loss: 13.158] \n",
      "1119 [D loss: (-7.087)(R 0.057, F -14.231)]  [G loss: 13.747] \n",
      "1120 [D loss: (-6.755)(R 0.812, F -14.322)]  [G loss: 13.880] \n",
      "1120 [D loss: (-6.879)(R 0.272, F -14.030)]  [G loss: 13.415] \n",
      "1121 [D loss: (-7.055)(R -0.042, F -14.068)]  [G loss: 13.646] \n",
      "1121 [D loss: (-6.722)(R 1.132, F -14.575)]  [G loss: 14.065] \n",
      "1122 [D loss: (-6.654)(R 1.338, F -14.645)]  [G loss: 14.033] \n",
      "1122 [D loss: (-6.644)(R 1.006, F -14.293)]  [G loss: 13.812] \n",
      "1123 [D loss: (-6.420)(R 1.352, F -14.191)]  [G loss: 13.783] \n",
      "1123 [D loss: (-6.200)(R 2.151, F -14.550)]  [G loss: 13.949] \n",
      "1124 [D loss: (-6.104)(R 2.294, F -14.502)]  [G loss: 14.224] \n",
      "1124 [D loss: (-6.046)(R 2.704, F -14.796)]  [G loss: 14.305] \n",
      "1125 [D loss: (-5.843)(R 3.078, F -14.764)]  [G loss: 14.417] \n",
      "1125 [D loss: (-5.881)(R 2.994, F -14.756)]  [G loss: 14.367] \n",
      "1126 [D loss: (-5.596)(R 3.272, F -14.463)]  [G loss: 14.050] \n",
      "1126 [D loss: (-5.635)(R 3.279, F -14.549)]  [G loss: 14.099] \n",
      "1127 [D loss: (-5.285)(R 4.175, F -14.744)]  [G loss: 14.243] \n",
      "1127 [D loss: (-5.417)(R 4.351, F -15.184)]  [G loss: 14.707] \n",
      "1128 [D loss: (-5.516)(R 4.718, F -15.750)]  [G loss: 15.182] \n",
      "1128 [D loss: (-5.074)(R 5.202, F -15.349)]  [G loss: 15.009] \n",
      "1129 [D loss: (-5.139)(R 4.951, F -15.229)]  [G loss: 14.818] \n",
      "1129 [D loss: (-4.916)(R 5.399, F -15.232)]  [G loss: 14.791] \n",
      "1130 [D loss: (-5.133)(R 4.979, F -15.244)]  [G loss: 14.859] \n",
      "1130 [D loss: (-4.809)(R 5.690, F -15.308)]  [G loss: 14.806] \n",
      "1131 [D loss: (-4.660)(R 6.088, F -15.408)]  [G loss: 14.942] \n",
      "1131 [D loss: (-4.695)(R 6.489, F -15.880)]  [G loss: 15.606] \n",
      "1132 [D loss: (-4.236)(R 7.647, F -16.120)]  [G loss: 15.624] \n",
      "1132 [D loss: (-4.484)(R 6.989, F -15.956)]  [G loss: 15.422] \n",
      "1133 [D loss: (-4.261)(R 7.458, F -15.980)]  [G loss: 15.332] \n",
      "1133 [D loss: (-3.944)(R 7.865, F -15.753)]  [G loss: 15.402] \n",
      "1134 [D loss: (-4.398)(R 7.102, F -15.897)]  [G loss: 15.331] \n",
      "1134 [D loss: (-4.658)(R 6.711, F -16.026)]  [G loss: 15.638] \n",
      "1135 [D loss: (-4.385)(R 7.924, F -16.693)]  [G loss: 16.455] \n",
      "1135 [D loss: (-4.175)(R 8.518, F -16.867)]  [G loss: 16.701] \n",
      "1136 [D loss: (-4.225)(R 8.793, F -17.242)]  [G loss: 17.002] \n",
      "1136 [D loss: (-4.216)(R 9.371, F -17.803)]  [G loss: 17.461] \n",
      "1137 [D loss: (-4.185)(R 9.889, F -18.259)]  [G loss: 18.263] \n",
      "1137 [D loss: (-3.885)(R 11.379, F -19.149)]  [G loss: 19.127] \n",
      "1138 [D loss: (-4.284)(R 11.450, F -20.019)]  [G loss: 19.901] \n",
      "1138 [D loss: (-4.540)(R 10.835, F -19.914)]  [G loss: 19.857] \n",
      "1139 [D loss: (-4.087)(R 11.053, F -19.228)]  [G loss: 19.257] \n",
      "1139 [D loss: (-4.356)(R 10.598, F -19.310)]  [G loss: 19.233] \n",
      "1140 [D loss: (-3.703)(R 12.015, F -19.421)]  [G loss: 19.574] \n",
      "1140 [D loss: (-4.377)(R 10.659, F -19.413)]  [G loss: 19.494] \n",
      "1141 [D loss: (-4.898)(R 9.693, F -19.488)]  [G loss: 19.571] \n",
      "1141 [D loss: (-4.378)(R 10.862, F -19.617)]  [G loss: 19.627] \n",
      "1142 [D loss: (-4.366)(R 11.114, F -19.845)]  [G loss: 19.870] \n",
      "1142 [D loss: (-4.320)(R 10.845, F -19.486)]  [G loss: 19.627] \n",
      "1143 [D loss: (-3.780)(R 12.277, F -19.837)]  [G loss: 20.053] \n",
      "1143 [D loss: (-4.402)(R 11.389, F -20.192)]  [G loss: 20.287] \n",
      "1144 [D loss: (-4.309)(R 11.427, F -20.046)]  [G loss: 20.221] \n",
      "1144 [D loss: (-4.341)(R 11.304, F -19.986)]  [G loss: 20.213] \n",
      "1145 [D loss: (-4.482)(R 11.034, F -19.999)]  [G loss: 20.154] \n",
      "1145 [D loss: (-4.422)(R 11.395, F -20.239)]  [G loss: 20.343] \n",
      "1146 [D loss: (-3.988)(R 12.113, F -20.089)]  [G loss: 20.321] \n",
      "1146 [D loss: (-4.239)(R 11.559, F -20.036)]  [G loss: 20.346] \n",
      "1147 [D loss: (-4.201)(R 11.943, F -20.346)]  [G loss: 20.651] \n",
      "1147 [D loss: (-4.153)(R 11.915, F -20.221)]  [G loss: 20.359] \n",
      "1148 [D loss: (-4.330)(R 10.955, F -19.614)]  [G loss: 19.928] \n",
      "1148 [D loss: (-4.048)(R 11.337, F -19.433)]  [G loss: 19.811] \n",
      "1149 [D loss: (-4.308)(R 10.896, F -19.512)]  [G loss: 19.961] \n",
      "1149 [D loss: (-4.147)(R 11.468, F -19.761)]  [G loss: 19.890] \n",
      "1150 [D loss: (-4.539)(R 10.448, F -19.525)]  [G loss: 19.649] \n",
      "1150 [D loss: (-4.755)(R 9.912, F -19.422)]  [G loss: 19.777] \n",
      "1151 [D loss: (-4.654)(R 10.134, F -19.441)]  [G loss: 19.952] \n",
      "1151 [D loss: (-4.588)(R 10.839, F -20.016)]  [G loss: 20.306] \n",
      "1152 [D loss: (-4.447)(R 11.578, F -20.473)]  [G loss: 20.782] \n",
      "1152 [D loss: (-4.645)(R 11.417, F -20.706)]  [G loss: 20.808] \n",
      "1153 [D loss: (-4.603)(R 11.105, F -20.310)]  [G loss: 20.581] \n",
      "1153 [D loss: (-4.686)(R 10.841, F -20.213)]  [G loss: 20.379] \n",
      "1154 [D loss: (-4.574)(R 11.194, F -20.341)]  [G loss: 20.495] \n",
      "1154 [D loss: (-4.746)(R 11.151, F -20.642)]  [G loss: 20.884] \n",
      "1155 [D loss: (-4.761)(R 11.242, F -20.765)]  [G loss: 21.106] \n",
      "1155 [D loss: (-5.215)(R 10.412, F -20.841)]  [G loss: 21.120] \n",
      "1156 [D loss: (-4.915)(R 11.189, F -21.018)]  [G loss: 21.046] \n",
      "1156 [D loss: (-4.981)(R 10.642, F -20.605)]  [G loss: 20.987] \n",
      "1157 [D loss: (-4.690)(R 10.735, F -20.114)]  [G loss: 20.469] \n",
      "1157 [D loss: (-4.807)(R 10.391, F -20.006)]  [G loss: 20.304] \n",
      "1158 [D loss: (-4.777)(R 10.188, F -19.743)]  [G loss: 20.018] \n",
      "1158 [D loss: (-4.713)(R 9.727, F -19.152)]  [G loss: 19.460] \n",
      "1159 [D loss: (-4.449)(R 9.622, F -18.521)]  [G loss: 19.154] \n",
      "1159 [D loss: (-4.487)(R 9.532, F -18.506)]  [G loss: 18.764] \n",
      "1160 [D loss: (-4.731)(R 8.287, F -17.749)]  [G loss: 18.307] \n",
      "1160 [D loss: (-4.813)(R 7.577, F -17.204)]  [G loss: 17.791] \n",
      "1161 [D loss: (-5.019)(R 7.247, F -17.284)]  [G loss: 17.818] \n",
      "1161 [D loss: (-4.984)(R 7.382, F -17.349)]  [G loss: 17.645] \n",
      "1162 [D loss: (-4.916)(R 7.306, F -17.139)]  [G loss: 17.876] \n",
      "1162 [D loss: (-5.020)(R 7.328, F -17.367)]  [G loss: 17.757] \n",
      "1163 [D loss: (-5.387)(R 6.950, F -17.724)]  [G loss: 17.802] \n",
      "1163 [D loss: (-5.340)(R 6.869, F -17.550)]  [G loss: 17.685] \n",
      "1164 [D loss: (-4.945)(R 7.139, F -17.029)]  [G loss: 17.361] \n",
      "1164 [D loss: (-5.351)(R 6.058, F -16.761)]  [G loss: 17.191] \n",
      "1165 [D loss: (-5.132)(R 6.572, F -16.837)]  [G loss: 17.250] \n",
      "1165 [D loss: (-5.392)(R 6.493, F -17.277)]  [G loss: 17.542] \n",
      "1166 [D loss: (-5.318)(R 6.098, F -16.734)]  [G loss: 17.263] \n",
      "1166 [D loss: (-5.100)(R 6.477, F -16.678)]  [G loss: 17.061] \n",
      "1167 [D loss: (-5.246)(R 6.367, F -16.859)]  [G loss: 17.334] \n",
      "1167 [D loss: (-5.321)(R 6.843, F -17.485)]  [G loss: 17.763] \n",
      "1168 [D loss: (-5.262)(R 6.816, F -17.340)]  [G loss: 17.726] \n",
      "1168 [D loss: (-5.042)(R 7.506, F -17.589)]  [G loss: 17.810] \n",
      "1169 [D loss: (-5.728)(R 5.930, F -17.386)]  [G loss: 17.754] \n",
      "1169 [D loss: (-5.305)(R 6.697, F -17.308)]  [G loss: 17.608] \n",
      "1170 [D loss: (-5.377)(R 6.043, F -16.798)]  [G loss: 17.273] \n",
      "1170 [D loss: (-5.318)(R 6.225, F -16.860)]  [G loss: 17.338] \n",
      "1171 [D loss: (-5.602)(R 5.465, F -16.670)]  [G loss: 17.228] \n",
      "1171 [D loss: (-5.962)(R 4.870, F -16.795)]  [G loss: 17.026] \n",
      "1172 [D loss: (-5.632)(R 5.516, F -16.780)]  [G loss: 16.978] \n",
      "1172 [D loss: (-5.580)(R 5.611, F -16.772)]  [G loss: 16.843] \n",
      "1173 [D loss: (-5.400)(R 5.527, F -16.328)]  [G loss: 16.853] \n",
      "1173 [D loss: (-5.852)(R 4.908, F -16.612)]  [G loss: 16.854] \n",
      "1174 [D loss: (-5.648)(R 5.265, F -16.562)]  [G loss: 16.861] \n",
      "1174 [D loss: (-5.897)(R 4.793, F -16.587)]  [G loss: 16.868] \n",
      "1175 [D loss: (-5.770)(R 4.961, F -16.500)]  [G loss: 16.574] \n",
      "1175 [D loss: (-5.702)(R 4.628, F -16.033)]  [G loss: 16.255] \n",
      "1176 [D loss: (-5.945)(R 3.690, F -15.581)]  [G loss: 16.163] \n",
      "1176 [D loss: (-5.708)(R 4.947, F -16.363)]  [G loss: 16.395] \n",
      "1177 [D loss: (-5.544)(R 4.612, F -15.700)]  [G loss: 16.015] \n",
      "1177 [D loss: (-5.644)(R 4.793, F -16.080)]  [G loss: 16.023] \n",
      "1178 [D loss: (-5.592)(R 3.862, F -15.046)]  [G loss: 15.038] \n",
      "1178 [D loss: (-6.033)(R 2.391, F -14.458)]  [G loss: 14.668] \n",
      "1179 [D loss: (-5.791)(R 2.755, F -14.337)]  [G loss: 14.510] \n",
      "1179 [D loss: (-5.437)(R 3.120, F -13.993)]  [G loss: 14.261] \n",
      "1180 [D loss: (-5.792)(R 2.803, F -14.387)]  [G loss: 14.375] \n",
      "1180 [D loss: (-5.763)(R 3.021, F -14.547)]  [G loss: 14.355] \n",
      "1181 [D loss: (-5.820)(R 1.987, F -13.627)]  [G loss: 13.869] \n",
      "1181 [D loss: (-5.688)(R 1.868, F -13.243)]  [G loss: 13.501] \n",
      "1182 [D loss: (-5.668)(R 1.686, F -13.021)]  [G loss: 13.436] \n",
      "1182 [D loss: (-5.730)(R 2.012, F -13.472)]  [G loss: 13.428] \n",
      "1183 [D loss: (-5.676)(R 1.919, F -13.271)]  [G loss: 13.245] \n",
      "1183 [D loss: (-5.412)(R 2.045, F -12.868)]  [G loss: 13.183] \n",
      "1184 [D loss: (-5.523)(R 1.829, F -12.876)]  [G loss: 13.130] \n",
      "1184 [D loss: (-5.387)(R 1.060, F -11.834)]  [G loss: 12.583] \n",
      "1185 [D loss: (-5.750)(R 0.984, F -12.484)]  [G loss: 12.257] \n",
      "1185 [D loss: (-5.546)(R 0.752, F -11.843)]  [G loss: 11.976] \n",
      "1186 [D loss: (-5.679)(R 0.376, F -11.734)]  [G loss: 11.832] \n",
      "1186 [D loss: (-5.657)(R 0.753, F -12.067)]  [G loss: 11.937] \n",
      "1187 [D loss: (-5.496)(R 0.534, F -11.526)]  [G loss: 11.883] \n",
      "1187 [D loss: (-5.712)(R 0.357, F -11.780)]  [G loss: 11.725] \n",
      "1188 [D loss: (-5.488)(R 0.557, F -11.534)]  [G loss: 12.012] \n",
      "1188 [D loss: (-5.508)(R 0.816, F -11.832)]  [G loss: 12.230] \n",
      "1189 [D loss: (-5.290)(R 1.404, F -11.984)]  [G loss: 12.463] \n",
      "1189 [D loss: (-5.622)(R 1.273, F -12.518)]  [G loss: 12.362] \n",
      "1190 [D loss: (-5.768)(R 0.528, F -12.064)]  [G loss: 12.205] \n",
      "1190 [D loss: (-5.552)(R 0.856, F -11.960)]  [G loss: 12.047] \n",
      "1191 [D loss: (-5.519)(R 0.846, F -11.884)]  [G loss: 11.997] \n",
      "1191 [D loss: (-5.366)(R 0.449, F -11.181)]  [G loss: 11.715] \n",
      "1192 [D loss: (-5.884)(R -0.087, F -11.681)]  [G loss: 11.758] \n",
      "1192 [D loss: (-5.446)(R 0.780, F -11.673)]  [G loss: 11.869] \n",
      "1193 [D loss: (-5.352)(R 0.602, F -11.305)]  [G loss: 11.777] \n",
      "1193 [D loss: (-5.757)(R 0.560, F -12.073)]  [G loss: 11.960] \n",
      "1194 [D loss: (-5.585)(R 0.964, F -12.133)]  [G loss: 12.258] \n",
      "1194 [D loss: (-5.206)(R 1.312, F -11.724)]  [G loss: 12.294] \n",
      "1195 [D loss: (-5.725)(R 0.616, F -12.067)]  [G loss: 12.431] \n",
      "1195 [D loss: (-5.865)(R 0.706, F -12.436)]  [G loss: 12.731] \n",
      "1196 [D loss: (-5.577)(R 1.609, F -12.762)]  [G loss: 13.028] \n",
      "1196 [D loss: (-5.296)(R 1.866, F -12.457)]  [G loss: 12.523] \n",
      "1197 [D loss: (-5.672)(R 0.221, F -11.565)]  [G loss: 11.785] \n",
      "1197 [D loss: (-5.200)(R 0.114, F -10.514)]  [G loss: 11.108] \n",
      "1198 [D loss: (-5.694)(R -0.845, F -10.543)]  [G loss: 10.680] \n",
      "1198 [D loss: (-5.518)(R -1.063, F -9.973)]  [G loss: 10.491] \n",
      "1199 [D loss: (-5.582)(R -1.654, F -9.510)]  [G loss: 10.319] \n",
      "1199 [D loss: (-5.699)(R -1.373, F -10.026)]  [G loss: 10.223] \n",
      "1200 [D loss: (-5.812)(R -1.663, F -9.960)]  [G loss: 9.941] \n",
      "1200 [D loss: (-5.572)(R -1.427, F -9.716)]  [G loss: 10.035] \n",
      "1201 [D loss: (-5.731)(R -1.619, F -9.843)]  [G loss: 9.896] \n",
      "1201 [D loss: (-5.852)(R -1.959, F -9.744)]  [G loss: 10.166] \n",
      "1202 [D loss: (-5.592)(R -1.229, F -9.954)]  [G loss: 10.079] \n",
      "1202 [D loss: (-5.979)(R -2.300, F -9.657)]  [G loss: 9.732] \n",
      "1203 [D loss: (-5.786)(R -1.849, F -9.724)]  [G loss: 9.803] \n",
      "1203 [D loss: (-5.873)(R -2.025, F -9.721)]  [G loss: 9.867] \n",
      "1204 [D loss: (-6.017)(R -1.821, F -10.213)]  [G loss: 10.066] \n",
      "1204 [D loss: (-5.736)(R -1.505, F -9.967)]  [G loss: 10.348] \n",
      "1205 [D loss: (-6.027)(R -1.432, F -10.621)]  [G loss: 10.410] \n",
      "1205 [D loss: (-5.969)(R -2.099, F -9.839)]  [G loss: 10.375] \n",
      "1206 [D loss: (-6.041)(R -1.717, F -10.365)]  [G loss: 10.336] \n",
      "1206 [D loss: (-5.927)(R -1.748, F -10.106)]  [G loss: 10.344] \n",
      "1207 [D loss: (-6.112)(R -1.882, F -10.342)]  [G loss: 10.769] \n",
      "1207 [D loss: (-6.449)(R -2.040, F -10.859)]  [G loss: 11.014] \n",
      "1208 [D loss: (-6.301)(R -1.167, F -11.436)]  [G loss: 11.548] \n",
      "1208 [D loss: (-5.933)(R -1.005, F -10.861)]  [G loss: 11.366] \n",
      "1209 [D loss: (-6.238)(R -1.310, F -11.166)]  [G loss: 11.138] \n",
      "1209 [D loss: (-5.968)(R -1.658, F -10.278)]  [G loss: 10.891] \n",
      "1210 [D loss: (-6.298)(R -1.758, F -10.839)]  [G loss: 11.209] \n",
      "1210 [D loss: (-6.662)(R -1.746, F -11.579)]  [G loss: 11.514] \n",
      "1211 [D loss: (-6.349)(R -1.355, F -11.344)]  [G loss: 11.266] \n",
      "1211 [D loss: (-6.392)(R -1.940, F -10.845)]  [G loss: 11.119] \n",
      "1212 [D loss: (-6.386)(R -1.650, F -11.123)]  [G loss: 11.085] \n",
      "1212 [D loss: (-6.360)(R -2.352, F -10.368)]  [G loss: 10.507] \n",
      "1213 [D loss: (-6.315)(R -2.171, F -10.458)]  [G loss: 10.406] \n",
      "1213 [D loss: (-6.128)(R -2.303, F -9.954)]  [G loss: 10.343] \n",
      "1214 [D loss: (-6.586)(R -3.756, F -9.416)]  [G loss: 9.758] \n",
      "1214 [D loss: (-6.393)(R -3.695, F -9.090)]  [G loss: 9.424] \n",
      "1215 [D loss: (-6.631)(R -4.261, F -9.001)]  [G loss: 9.453] \n",
      "1215 [D loss: (-6.385)(R -3.266, F -9.504)]  [G loss: 9.894] \n",
      "1216 [D loss: (-6.430)(R -3.426, F -9.433)]  [G loss: 9.873] \n",
      "1216 [D loss: (-6.730)(R -3.873, F -9.587)]  [G loss: 9.790] \n",
      "1217 [D loss: (-6.607)(R -3.456, F -9.757)]  [G loss: 10.317] \n",
      "1217 [D loss: (-6.640)(R -2.895, F -10.386)]  [G loss: 10.499] \n",
      "1218 [D loss: (-6.646)(R -3.231, F -10.061)]  [G loss: 10.317] \n",
      "1218 [D loss: (-6.775)(R -3.432, F -10.118)]  [G loss: 10.549] \n",
      "1219 [D loss: (-6.993)(R -3.852, F -10.134)]  [G loss: 10.626] \n",
      "1219 [D loss: (-6.982)(R -3.160, F -10.804)]  [G loss: 10.856] \n",
      "1220 [D loss: (-7.062)(R -2.779, F -11.346)]  [G loss: 11.298] \n",
      "1220 [D loss: (-6.777)(R -2.400, F -11.154)]  [G loss: 11.276] \n",
      "1221 [D loss: (-6.667)(R -2.485, F -10.850)]  [G loss: 11.399] \n",
      "1221 [D loss: (-7.132)(R -3.366, F -10.898)]  [G loss: 11.237] \n",
      "1222 [D loss: (-7.338)(R -3.480, F -11.196)]  [G loss: 11.296] \n",
      "1222 [D loss: (-6.835)(R -2.489, F -11.182)]  [G loss: 11.648] \n",
      "1223 [D loss: (-6.910)(R -2.642, F -11.178)]  [G loss: 11.503] \n",
      "1223 [D loss: (-6.783)(R -2.418, F -11.148)]  [G loss: 11.538] \n",
      "1224 [D loss: (-6.967)(R -3.048, F -10.885)]  [G loss: 11.127] \n",
      "1224 [D loss: (-7.029)(R -2.998, F -11.061)]  [G loss: 11.323] \n",
      "1225 [D loss: (-6.915)(R -2.441, F -11.390)]  [G loss: 11.543] \n",
      "1225 [D loss: (-6.955)(R -2.295, F -11.616)]  [G loss: 11.926] \n",
      "1226 [D loss: (-6.886)(R -2.052, F -11.720)]  [G loss: 12.028] \n",
      "1226 [D loss: (-6.994)(R -2.319, F -11.669)]  [G loss: 12.005] \n",
      "1227 [D loss: (-7.105)(R -2.571, F -11.638)]  [G loss: 11.868] \n",
      "1227 [D loss: (-6.956)(R -2.123, F -11.790)]  [G loss: 12.038] \n",
      "1228 [D loss: (-7.109)(R -2.242, F -11.975)]  [G loss: 12.187] \n",
      "1228 [D loss: (-6.835)(R -1.264, F -12.406)]  [G loss: 12.709] \n",
      "1229 [D loss: (-7.181)(R -1.575, F -12.787)]  [G loss: 13.204] \n",
      "1229 [D loss: (-7.105)(R -1.190, F -13.020)]  [G loss: 13.217] \n",
      "1230 [D loss: (-6.928)(R -0.624, F -13.233)]  [G loss: 13.522] \n",
      "1230 [D loss: (-7.001)(R -0.393, F -13.609)]  [G loss: 13.872] \n",
      "1231 [D loss: (-6.941)(R 0.142, F -14.024)]  [G loss: 14.128] \n",
      "1231 [D loss: (-7.071)(R -0.250, F -13.891)]  [G loss: 14.261] \n",
      "1232 [D loss: (-7.109)(R -0.272, F -13.946)]  [G loss: 14.256] \n",
      "1232 [D loss: (-7.258)(R -0.439, F -14.076)]  [G loss: 14.029] \n",
      "1233 [D loss: (-6.785)(R 0.038, F -13.608)]  [G loss: 14.068] \n",
      "1233 [D loss: (-6.991)(R -0.505, F -13.478)]  [G loss: 13.898] \n",
      "1234 [D loss: (-7.206)(R -0.272, F -14.140)]  [G loss: 14.042] \n",
      "1234 [D loss: (-7.463)(R -0.274, F -14.651)]  [G loss: 14.484] \n",
      "1235 [D loss: (-7.076)(R 0.461, F -14.612)]  [G loss: 14.945] \n",
      "1235 [D loss: (-7.331)(R 0.480, F -15.142)]  [G loss: 14.996] \n",
      "1236 [D loss: (-7.204)(R 0.992, F -15.401)]  [G loss: 15.067] \n",
      "1236 [D loss: (-6.944)(R 0.909, F -14.797)]  [G loss: 15.197] \n",
      "1237 [D loss: (-7.271)(R 0.722, F -15.265)]  [G loss: 15.071] \n",
      "1237 [D loss: (-6.920)(R 1.167, F -15.007)]  [G loss: 15.455] \n",
      "1238 [D loss: (-6.635)(R 1.608, F -14.877)]  [G loss: 15.503] \n",
      "1238 [D loss: (-6.896)(R 0.991, F -14.783)]  [G loss: 15.221] \n",
      "1239 [D loss: (-7.099)(R 0.970, F -15.169)]  [G loss: 15.150] \n",
      "1239 [D loss: (-6.912)(R 1.528, F -15.351)]  [G loss: 15.193] \n",
      "1240 [D loss: (-6.908)(R 1.049, F -14.866)]  [G loss: 15.080] \n",
      "1240 [D loss: (-6.491)(R 1.933, F -14.914)]  [G loss: 15.190] \n",
      "1241 [D loss: (-6.852)(R 0.936, F -14.641)]  [G loss: 15.190] \n",
      "1241 [D loss: (-6.877)(R 0.760, F -14.514)]  [G loss: 15.029] \n",
      "1242 [D loss: (-6.202)(R 2.017, F -14.421)]  [G loss: 14.937] \n",
      "1242 [D loss: (-6.398)(R 1.934, F -14.730)]  [G loss: 14.941] \n",
      "1243 [D loss: (-6.562)(R 1.669, F -14.793)]  [G loss: 15.111] \n",
      "1243 [D loss: (-6.148)(R 1.806, F -14.102)]  [G loss: 15.007] \n",
      "1244 [D loss: (-7.462)(R -0.235, F -14.688)]  [G loss: 14.303] \n",
      "1244 [D loss: (-6.162)(R 1.244, F -13.567)]  [G loss: 14.536] \n",
      "1245 [D loss: (-6.854)(R 0.763, F -14.472)]  [G loss: 14.594] \n",
      "1245 [D loss: (-6.717)(R 1.183, F -14.617)]  [G loss: 14.778] \n",
      "1246 [D loss: (-6.460)(R 1.739, F -14.659)]  [G loss: 14.955] \n",
      "1246 [D loss: (-6.510)(R 1.660, F -14.679)]  [G loss: 14.767] \n",
      "1247 [D loss: (-6.415)(R 1.724, F -14.554)]  [G loss: 14.457] \n",
      "1247 [D loss: (-6.110)(R 1.630, F -13.851)]  [G loss: 14.098] \n",
      "1248 [D loss: (-6.169)(R 1.213, F -13.551)]  [G loss: 13.675] \n",
      "1248 [D loss: (-5.941)(R 1.037, F -12.919)]  [G loss: 13.369] \n",
      "1249 [D loss: (-6.651)(R 0.372, F -13.674)]  [G loss: 13.506] \n",
      "1249 [D loss: (-6.448)(R 0.765, F -13.660)]  [G loss: 13.679] \n",
      "1250 [D loss: (-6.348)(R 0.698, F -13.394)]  [G loss: 13.680] \n",
      "1250 [D loss: (-6.313)(R 1.035, F -13.662)]  [G loss: 13.632] \n",
      "1251 [D loss: (-6.116)(R 0.655, F -12.886)]  [G loss: 13.754] \n",
      "1251 [D loss: (-5.849)(R 1.248, F -12.945)]  [G loss: 13.639] \n",
      "1252 [D loss: (-6.005)(R 1.751, F -13.761)]  [G loss: 13.813] \n",
      "1252 [D loss: (-6.204)(R 0.896, F -13.304)]  [G loss: 13.729] \n",
      "1253 [D loss: (-5.678)(R 1.233, F -12.589)]  [G loss: 13.314] \n",
      "1253 [D loss: (-5.936)(R 1.159, F -13.030)]  [G loss: 13.120] \n",
      "1254 [D loss: (-6.115)(R 1.115, F -13.346)]  [G loss: 13.203] \n",
      "1254 [D loss: (-5.471)(R 1.570, F -12.512)]  [G loss: 13.382] \n",
      "1255 [D loss: (-5.796)(R 1.870, F -13.461)]  [G loss: 13.373] \n",
      "1255 [D loss: (-5.631)(R 1.814, F -13.075)]  [G loss: 13.636] \n",
      "1256 [D loss: (-5.342)(R 1.629, F -12.313)]  [G loss: 13.444] \n",
      "1256 [D loss: (-5.805)(R 1.597, F -13.207)]  [G loss: 13.587] \n",
      "1257 [D loss: (-6.021)(R 1.470, F -13.513)]  [G loss: 13.297] \n",
      "1257 [D loss: (-5.697)(R 1.754, F -13.148)]  [G loss: 13.143] \n",
      "1258 [D loss: (-6.183)(R 0.992, F -13.358)]  [G loss: 13.437] \n",
      "1258 [D loss: (-6.146)(R 1.726, F -14.018)]  [G loss: 13.666] \n",
      "1259 [D loss: (-6.131)(R 1.773, F -14.034)]  [G loss: 13.852] \n",
      "1259 [D loss: (-5.430)(R 2.286, F -13.145)]  [G loss: 13.705] \n",
      "1260 [D loss: (-5.786)(R 1.592, F -13.164)]  [G loss: 13.550] \n",
      "1260 [D loss: (-5.941)(R 1.624, F -13.506)]  [G loss: 13.603] \n",
      "1261 [D loss: (-5.985)(R 1.896, F -13.866)]  [G loss: 14.045] \n",
      "1261 [D loss: (-5.674)(R 2.150, F -13.498)]  [G loss: 14.057] \n",
      "1262 [D loss: (-5.407)(R 2.375, F -13.188)]  [G loss: 13.512] \n",
      "1262 [D loss: (-5.584)(R 2.069, F -13.238)]  [G loss: 13.273] \n",
      "1263 [D loss: (-5.310)(R 2.099, F -12.720)]  [G loss: 13.415] \n",
      "1263 [D loss: (-6.183)(R 1.715, F -14.080)]  [G loss: 13.705] \n",
      "1264 [D loss: (-5.696)(R 2.013, F -13.404)]  [G loss: 13.840] \n",
      "1264 [D loss: (-5.774)(R 1.800, F -13.348)]  [G loss: 13.414] \n",
      "1265 [D loss: (-6.068)(R 1.470, F -13.605)]  [G loss: 13.360] \n",
      "1265 [D loss: (-6.455)(R 0.512, F -13.423)]  [G loss: 13.726] \n",
      "1266 [D loss: (-5.409)(R 2.286, F -13.104)]  [G loss: 13.571] \n",
      "1266 [D loss: (-5.989)(R 1.199, F -13.178)]  [G loss: 13.405] \n",
      "1267 [D loss: (-5.310)(R 2.062, F -12.682)]  [G loss: 13.476] \n",
      "1267 [D loss: (-5.874)(R 1.878, F -13.627)]  [G loss: 13.433] \n",
      "1268 [D loss: (-5.795)(R 1.460, F -13.051)]  [G loss: 13.655] \n",
      "1268 [D loss: (-5.930)(R 2.128, F -13.989)]  [G loss: 13.554] \n",
      "1269 [D loss: (-5.578)(R 2.172, F -13.328)]  [G loss: 13.636] \n",
      "1269 [D loss: (-5.688)(R 2.067, F -13.444)]  [G loss: 13.645] \n",
      "1270 [D loss: (-5.883)(R 1.993, F -13.759)]  [G loss: 13.815] \n",
      "1270 [D loss: (-5.797)(R 2.527, F -14.121)]  [G loss: 13.822] \n",
      "1271 [D loss: (-6.100)(R 2.227, F -14.427)]  [G loss: 14.093] \n",
      "1271 [D loss: (-5.689)(R 2.378, F -13.756)]  [G loss: 13.864] \n",
      "1272 [D loss: (-5.643)(R 2.329, F -13.616)]  [G loss: 13.614] \n",
      "1272 [D loss: (-5.667)(R 2.294, F -13.629)]  [G loss: 13.689] \n",
      "1273 [D loss: (-6.002)(R 2.095, F -14.099)]  [G loss: 14.200] \n",
      "1273 [D loss: (-5.482)(R 2.711, F -13.674)]  [G loss: 14.035] \n",
      "1274 [D loss: (-5.721)(R 2.258, F -13.700)]  [G loss: 14.114] \n",
      "1274 [D loss: (-5.811)(R 2.494, F -14.116)]  [G loss: 14.031] \n",
      "1275 [D loss: (-5.624)(R 2.818, F -14.066)]  [G loss: 14.029] \n",
      "1275 [D loss: (-6.076)(R 1.898, F -14.051)]  [G loss: 13.920] \n",
      "1276 [D loss: (-5.731)(R 2.232, F -13.694)]  [G loss: 13.704] \n",
      "1276 [D loss: (-5.475)(R 2.834, F -13.784)]  [G loss: 13.806] \n",
      "1277 [D loss: (-5.767)(R 1.732, F -13.266)]  [G loss: 13.383] \n",
      "1277 [D loss: (-5.602)(R 2.202, F -13.406)]  [G loss: 13.447] \n",
      "1278 [D loss: (-5.879)(R 1.626, F -13.384)]  [G loss: 13.354] \n",
      "1278 [D loss: (-5.930)(R 1.555, F -13.416)]  [G loss: 13.444] \n",
      "1279 [D loss: (-5.704)(R 1.978, F -13.386)]  [G loss: 13.640] \n",
      "1279 [D loss: (-5.756)(R 1.777, F -13.289)]  [G loss: 13.380] \n",
      "1280 [D loss: (-5.612)(R 1.742, F -12.967)]  [G loss: 13.212] \n",
      "1280 [D loss: (-5.721)(R 1.590, F -13.032)]  [G loss: 13.126] \n",
      "1281 [D loss: (-5.653)(R 1.605, F -12.911)]  [G loss: 13.113] \n",
      "1281 [D loss: (-5.845)(R 1.362, F -13.052)]  [G loss: 13.259] \n",
      "1282 [D loss: (-5.310)(R 2.395, F -13.016)]  [G loss: 13.593] \n",
      "1282 [D loss: (-5.312)(R 2.782, F -13.406)]  [G loss: 13.447] \n",
      "1283 [D loss: (-5.804)(R 1.609, F -13.218)]  [G loss: 13.199] \n",
      "1283 [D loss: (-5.301)(R 2.660, F -13.262)]  [G loss: 13.525] \n",
      "1284 [D loss: (-6.069)(R 1.250, F -13.388)]  [G loss: 13.405] \n",
      "1284 [D loss: (-5.565)(R 2.108, F -13.238)]  [G loss: 13.480] \n",
      "1285 [D loss: (-5.760)(R 1.899, F -13.419)]  [G loss: 13.563] \n",
      "1285 [D loss: (-5.656)(R 1.724, F -13.037)]  [G loss: 13.289] \n",
      "1286 [D loss: (-5.752)(R 1.109, F -12.613)]  [G loss: 12.943] \n",
      "1286 [D loss: (-5.473)(R 1.761, F -12.707)]  [G loss: 12.964] \n",
      "1287 [D loss: (-5.652)(R 1.329, F -12.634)]  [G loss: 12.882] \n",
      "1287 [D loss: (-5.580)(R 1.888, F -13.048)]  [G loss: 13.289] \n",
      "1288 [D loss: (-5.737)(R 1.916, F -13.391)]  [G loss: 13.364] \n",
      "1288 [D loss: (-5.486)(R 2.319, F -13.290)]  [G loss: 13.450] \n",
      "1289 [D loss: (-5.603)(R 1.963, F -13.168)]  [G loss: 13.428] \n",
      "1289 [D loss: (-5.441)(R 2.401, F -13.284)]  [G loss: 13.471] \n",
      "1290 [D loss: (-5.431)(R 2.313, F -13.175)]  [G loss: 13.459] \n",
      "1290 [D loss: (-5.723)(R 1.918, F -13.365)]  [G loss: 13.757] \n",
      "1291 [D loss: (-5.680)(R 2.393, F -13.752)]  [G loss: 14.047] \n",
      "1291 [D loss: (-5.435)(R 2.646, F -13.516)]  [G loss: 13.702] \n",
      "1292 [D loss: (-5.719)(R 1.684, F -13.123)]  [G loss: 13.313] \n",
      "1292 [D loss: (-5.675)(R 1.830, F -13.179)]  [G loss: 13.244] \n",
      "1293 [D loss: (-5.274)(R 2.340, F -12.887)]  [G loss: 13.005] \n",
      "1293 [D loss: (-5.585)(R 1.633, F -12.803)]  [G loss: 13.025] \n",
      "1294 [D loss: (-5.728)(R 1.300, F -12.756)]  [G loss: 13.064] \n",
      "1294 [D loss: (-5.258)(R 2.639, F -13.156)]  [G loss: 13.519] \n",
      "1295 [D loss: (-5.426)(R 2.578, F -13.429)]  [G loss: 13.584] \n",
      "1295 [D loss: (-5.246)(R 2.721, F -13.213)]  [G loss: 13.441] \n",
      "1296 [D loss: (-5.323)(R 2.743, F -13.390)]  [G loss: 13.523] \n",
      "1296 [D loss: (-5.202)(R 3.153, F -13.558)]  [G loss: 13.747] \n",
      "1297 [D loss: (-5.544)(R 2.110, F -13.197)]  [G loss: 13.322] \n",
      "1297 [D loss: (-5.383)(R 1.885, F -12.652)]  [G loss: 12.915] \n",
      "1298 [D loss: (-5.344)(R 2.003, F -12.692)]  [G loss: 12.879] \n",
      "1298 [D loss: (-5.574)(R 1.939, F -13.086)]  [G loss: 13.261] \n",
      "1299 [D loss: (-5.543)(R 2.082, F -13.168)]  [G loss: 13.654] \n",
      "1299 [D loss: (-5.270)(R 2.665, F -13.206)]  [G loss: 13.532] \n",
      "1300 [D loss: (-5.175)(R 2.972, F -13.321)]  [G loss: 13.583] \n",
      "1300 [D loss: (-4.744)(R 3.640, F -13.127)]  [G loss: 13.554] \n",
      "1301 [D loss: (-5.109)(R 2.867, F -13.085)]  [G loss: 13.235] \n",
      "1301 [D loss: (-4.883)(R 3.162, F -12.929)]  [G loss: 13.112] \n",
      "1302 [D loss: (-5.340)(R 2.301, F -12.981)]  [G loss: 13.240] \n",
      "1302 [D loss: (-5.138)(R 2.488, F -12.763)]  [G loss: 13.130] \n",
      "1303 [D loss: (-5.135)(R 2.885, F -13.155)]  [G loss: 13.558] \n",
      "1303 [D loss: (-5.223)(R 2.778, F -13.225)]  [G loss: 13.539] \n",
      "1304 [D loss: (-5.457)(R 2.418, F -13.333)]  [G loss: 13.454] \n",
      "1304 [D loss: (-5.455)(R 2.399, F -13.310)]  [G loss: 13.606] \n",
      "1305 [D loss: (-5.330)(R 2.665, F -13.324)]  [G loss: 13.625] \n",
      "1305 [D loss: (-5.284)(R 3.294, F -13.863)]  [G loss: 13.962] \n",
      "1306 [D loss: (-5.235)(R 3.343, F -13.813)]  [G loss: 14.026] \n",
      "1306 [D loss: (-4.894)(R 3.742, F -13.529)]  [G loss: 13.830] \n",
      "1307 [D loss: (-5.397)(R 2.667, F -13.461)]  [G loss: 13.788] \n",
      "1307 [D loss: (-5.183)(R 3.161, F -13.528)]  [G loss: 13.732] \n",
      "1308 [D loss: (-4.976)(R 3.121, F -13.073)]  [G loss: 13.540] \n",
      "1308 [D loss: (-4.941)(R 3.238, F -13.120)]  [G loss: 13.431] \n",
      "1309 [D loss: (-5.113)(R 2.993, F -13.219)]  [G loss: 13.518] \n",
      "1309 [D loss: (-5.203)(R 3.155, F -13.561)]  [G loss: 13.945] \n",
      "1310 [D loss: (-5.177)(R 3.442, F -13.797)]  [G loss: 14.238] \n",
      "1310 [D loss: (-4.826)(R 4.022, F -13.673)]  [G loss: 14.105] \n",
      "1311 [D loss: (-5.231)(R 3.279, F -13.741)]  [G loss: 14.169] \n",
      "1311 [D loss: (-5.297)(R 3.482, F -14.076)]  [G loss: 14.290] \n",
      "1312 [D loss: (-5.026)(R 3.861, F -13.914)]  [G loss: 14.578] \n",
      "1312 [D loss: (-5.166)(R 3.855, F -14.187)]  [G loss: 14.391] \n",
      "1313 [D loss: (-5.208)(R 3.882, F -14.297)]  [G loss: 14.516] \n",
      "1313 [D loss: (-4.949)(R 4.397, F -14.294)]  [G loss: 14.728] \n",
      "1314 [D loss: (-4.742)(R 4.710, F -14.193)]  [G loss: 14.479] \n",
      "1314 [D loss: (-5.090)(R 3.915, F -14.094)]  [G loss: 14.420] \n",
      "1315 [D loss: (-4.858)(R 4.167, F -13.883)]  [G loss: 14.171] \n",
      "1315 [D loss: (-5.073)(R 3.410, F -13.555)]  [G loss: 14.001] \n",
      "1316 [D loss: (-5.231)(R 3.217, F -13.679)]  [G loss: 14.064] \n",
      "1316 [D loss: (-5.141)(R 3.487, F -13.769)]  [G loss: 14.134] \n",
      "1317 [D loss: (-4.794)(R 4.305, F -13.893)]  [G loss: 14.162] \n",
      "1317 [D loss: (-5.124)(R 3.734, F -13.981)]  [G loss: 14.314] \n",
      "1318 [D loss: (-4.822)(R 4.439, F -14.083)]  [G loss: 14.616] \n",
      "1318 [D loss: (-4.977)(R 4.162, F -14.116)]  [G loss: 14.473] \n",
      "1319 [D loss: (-5.105)(R 3.705, F -13.915)]  [G loss: 14.246] \n",
      "1319 [D loss: (-4.712)(R 4.100, F -13.524)]  [G loss: 14.161] \n",
      "1320 [D loss: (-4.788)(R 3.822, F -13.398)]  [G loss: 13.924] \n",
      "1320 [D loss: (-4.873)(R 3.571, F -13.318)]  [G loss: 13.750] \n",
      "1321 [D loss: (-4.922)(R 3.889, F -13.733)]  [G loss: 14.018] \n",
      "1321 [D loss: (-5.141)(R 3.470, F -13.752)]  [G loss: 14.033] \n",
      "1322 [D loss: (-4.684)(R 4.239, F -13.607)]  [G loss: 14.161] \n",
      "1322 [D loss: (-4.726)(R 4.310, F -13.761)]  [G loss: 14.082] \n",
      "1323 [D loss: (-4.911)(R 3.990, F -13.812)]  [G loss: 14.131] \n",
      "1323 [D loss: (-4.827)(R 4.172, F -13.825)]  [G loss: 14.269] \n",
      "1324 [D loss: (-4.815)(R 4.294, F -13.924)]  [G loss: 14.362] \n",
      "1324 [D loss: (-5.283)(R 3.753, F -14.318)]  [G loss: 14.564] \n",
      "1325 [D loss: (-5.303)(R 4.260, F -14.865)]  [G loss: 15.239] \n",
      "1325 [D loss: (-5.012)(R 5.259, F -15.284)]  [G loss: 15.536] \n",
      "1326 [D loss: (-4.731)(R 5.787, F -15.248)]  [G loss: 15.676] \n",
      "1326 [D loss: (-4.995)(R 5.291, F -15.280)]  [G loss: 15.516] \n",
      "1327 [D loss: (-5.203)(R 4.831, F -15.238)]  [G loss: 15.320] \n",
      "1327 [D loss: (-4.974)(R 4.984, F -14.932)]  [G loss: 15.264] \n",
      "1328 [D loss: (-5.192)(R 4.626, F -15.010)]  [G loss: 15.458] \n",
      "1328 [D loss: (-5.119)(R 5.137, F -15.375)]  [G loss: 15.685] \n",
      "1329 [D loss: (-5.158)(R 5.286, F -15.601)]  [G loss: 15.963] \n",
      "1329 [D loss: (-5.146)(R 5.418, F -15.711)]  [G loss: 15.954] \n",
      "1330 [D loss: (-5.135)(R 5.573, F -15.843)]  [G loss: 15.961] \n",
      "1330 [D loss: (-5.185)(R 5.403, F -15.773)]  [G loss: 16.026] \n",
      "1331 [D loss: (-5.076)(R 5.504, F -15.656)]  [G loss: 16.018] \n",
      "1331 [D loss: (-5.252)(R 5.086, F -15.590)]  [G loss: 15.760] \n",
      "1332 [D loss: (-4.709)(R 5.498, F -14.916)]  [G loss: 15.706] \n",
      "1332 [D loss: (-5.041)(R 4.976, F -15.058)]  [G loss: 15.342] \n",
      "1333 [D loss: (-5.008)(R 4.799, F -14.815)]  [G loss: 15.167] \n",
      "1333 [D loss: (-4.666)(R 5.312, F -14.645)]  [G loss: 15.028] \n",
      "1334 [D loss: (-4.862)(R 4.519, F -14.243)]  [G loss: 14.693] \n",
      "1334 [D loss: (-4.995)(R 3.923, F -13.913)]  [G loss: 14.566] \n",
      "1335 [D loss: (-5.181)(R 3.712, F -14.073)]  [G loss: 14.627] \n",
      "1335 [D loss: (-4.874)(R 4.324, F -14.073)]  [G loss: 14.647] \n",
      "1336 [D loss: (-5.058)(R 3.854, F -13.969)]  [G loss: 14.559] \n",
      "1336 [D loss: (-5.389)(R 3.410, F -14.188)]  [G loss: 14.465] \n",
      "1337 [D loss: (-5.006)(R 4.079, F -14.091)]  [G loss: 14.407] \n",
      "1337 [D loss: (-5.262)(R 3.614, F -14.138)]  [G loss: 14.640] \n",
      "1338 [D loss: (-5.067)(R 3.861, F -13.995)]  [G loss: 14.568] \n",
      "1338 [D loss: (-5.441)(R 3.444, F -14.325)]  [G loss: 14.589] \n",
      "1339 [D loss: (-5.603)(R 3.103, F -14.308)]  [G loss: 14.884] \n",
      "1339 [D loss: (-5.149)(R 4.121, F -14.419)]  [G loss: 14.801] \n",
      "1340 [D loss: (-4.823)(R 4.420, F -14.067)]  [G loss: 14.579] \n",
      "1340 [D loss: (-5.086)(R 3.869, F -14.041)]  [G loss: 14.455] \n",
      "1341 [D loss: (-4.955)(R 3.751, F -13.660)]  [G loss: 14.430] \n",
      "1341 [D loss: (-5.397)(R 3.136, F -13.929)]  [G loss: 14.307] \n",
      "1342 [D loss: (-4.814)(R 4.097, F -13.726)]  [G loss: 14.328] \n",
      "1342 [D loss: (-5.383)(R 2.996, F -13.762)]  [G loss: 14.111] \n",
      "1343 [D loss: (-5.308)(R 3.201, F -13.817)]  [G loss: 14.204] \n",
      "1343 [D loss: (-5.257)(R 3.251, F -13.764)]  [G loss: 14.407] \n",
      "1344 [D loss: (-5.246)(R 2.931, F -13.423)]  [G loss: 14.122] \n",
      "1344 [D loss: (-5.376)(R 2.513, F -13.264)]  [G loss: 13.754] \n",
      "1345 [D loss: (-5.507)(R 2.261, F -13.275)]  [G loss: 13.588] \n",
      "1345 [D loss: (-5.328)(R 2.340, F -12.995)]  [G loss: 13.652] \n",
      "1346 [D loss: (-5.432)(R 2.424, F -13.288)]  [G loss: 13.700] \n",
      "1346 [D loss: (-5.492)(R 2.615, F -13.600)]  [G loss: 13.864] \n",
      "1347 [D loss: (-5.309)(R 3.248, F -13.865)]  [G loss: 14.212] \n",
      "1347 [D loss: (-5.377)(R 3.131, F -13.885)]  [G loss: 14.197] \n",
      "1348 [D loss: (-5.327)(R 3.069, F -13.722)]  [G loss: 14.351] \n",
      "1348 [D loss: (-5.844)(R 2.543, F -14.232)]  [G loss: 14.481] \n",
      "1349 [D loss: (-5.585)(R 3.115, F -14.285)]  [G loss: 14.580] \n",
      "1349 [D loss: (-5.401)(R 3.875, F -14.677)]  [G loss: 15.085] \n",
      "1350 [D loss: (-5.480)(R 3.752, F -14.711)]  [G loss: 15.335] \n",
      "1350 [D loss: (-5.390)(R 4.095, F -14.875)]  [G loss: 15.251] \n",
      "1351 [D loss: (-5.219)(R 4.233, F -14.671)]  [G loss: 15.164] \n",
      "1351 [D loss: (-5.292)(R 3.959, F -14.542)]  [G loss: 15.198] \n",
      "1352 [D loss: (-5.183)(R 4.040, F -14.405)]  [G loss: 15.059] \n",
      "1352 [D loss: (-5.564)(R 3.423, F -14.552)]  [G loss: 15.009] \n",
      "1353 [D loss: (-5.039)(R 4.470, F -14.548)]  [G loss: 14.773] \n",
      "1353 [D loss: (-5.357)(R 3.538, F -14.251)]  [G loss: 14.897] \n",
      "1354 [D loss: (-5.298)(R 3.704, F -14.301)]  [G loss: 14.639] \n",
      "1354 [D loss: (-5.428)(R 3.357, F -14.213)]  [G loss: 14.620] \n",
      "1355 [D loss: (-5.601)(R 3.582, F -14.783)]  [G loss: 14.835] \n",
      "1355 [D loss: (-5.445)(R 3.824, F -14.714)]  [G loss: 14.922] \n",
      "1356 [D loss: (-5.286)(R 3.922, F -14.495)]  [G loss: 14.925] \n",
      "1356 [D loss: (-5.229)(R 3.525, F -13.984)]  [G loss: 14.479] \n",
      "1357 [D loss: (-5.779)(R 2.478, F -14.036)]  [G loss: 14.393] \n",
      "1357 [D loss: (-5.275)(R 3.303, F -13.854)]  [G loss: 14.432] \n",
      "1358 [D loss: (-5.560)(R 3.219, F -14.340)]  [G loss: 14.603] \n",
      "1358 [D loss: (-5.659)(R 3.148, F -14.467)]  [G loss: 14.827] \n",
      "1359 [D loss: (-5.566)(R 3.126, F -14.259)]  [G loss: 14.771] \n",
      "1359 [D loss: (-5.629)(R 3.125, F -14.383)]  [G loss: 14.418] \n",
      "1360 [D loss: (-5.419)(R 2.917, F -13.755)]  [G loss: 14.256] \n",
      "1360 [D loss: (-5.586)(R 3.036, F -14.208)]  [G loss: 14.456] \n",
      "1361 [D loss: (-5.107)(R 3.903, F -14.117)]  [G loss: 14.704] \n",
      "1361 [D loss: (-5.380)(R 3.510, F -14.270)]  [G loss: 14.759] \n",
      "1362 [D loss: (-5.729)(R 3.198, F -14.655)]  [G loss: 14.506] \n",
      "1362 [D loss: (-5.583)(R 3.287, F -14.452)]  [G loss: 14.818] \n",
      "1363 [D loss: (-5.475)(R 3.288, F -14.237)]  [G loss: 14.834] \n",
      "1363 [D loss: (-5.234)(R 3.724, F -14.193)]  [G loss: 14.697] \n",
      "1364 [D loss: (-5.353)(R 3.771, F -14.478)]  [G loss: 14.502] \n",
      "1364 [D loss: (-5.313)(R 3.407, F -14.033)]  [G loss: 14.251] \n",
      "1365 [D loss: (-5.071)(R 3.673, F -13.815)]  [G loss: 14.265] \n",
      "1365 [D loss: (-5.806)(R 2.247, F -13.859)]  [G loss: 14.353] \n",
      "1366 [D loss: (-5.372)(R 3.180, F -13.923)]  [G loss: 14.517] \n",
      "1366 [D loss: (-5.275)(R 3.630, F -14.180)]  [G loss: 14.384] \n",
      "1367 [D loss: (-5.102)(R 3.918, F -14.123)]  [G loss: 14.517] \n",
      "1367 [D loss: (-5.349)(R 3.367, F -14.066)]  [G loss: 14.310] \n",
      "1368 [D loss: (-5.178)(R 3.670, F -14.026)]  [G loss: 14.244] \n",
      "1368 [D loss: (-5.459)(R 2.863, F -13.780)]  [G loss: 14.113] \n",
      "1369 [D loss: (-5.364)(R 2.666, F -13.394)]  [G loss: 14.130] \n",
      "1369 [D loss: (-5.161)(R 3.295, F -13.618)]  [G loss: 14.201] \n",
      "1370 [D loss: (-5.338)(R 2.790, F -13.466)]  [G loss: 14.082] \n",
      "1370 [D loss: (-5.108)(R 3.395, F -13.612)]  [G loss: 14.103] \n",
      "1371 [D loss: (-4.903)(R 3.443, F -13.250)]  [G loss: 14.145] \n",
      "1371 [D loss: (-5.519)(R 2.613, F -13.651)]  [G loss: 13.881] \n",
      "1372 [D loss: (-5.419)(R 2.933, F -13.770)]  [G loss: 14.340] \n",
      "1372 [D loss: (-4.979)(R 4.228, F -14.186)]  [G loss: 14.275] \n",
      "1373 [D loss: (-5.064)(R 3.480, F -13.609)]  [G loss: 13.901] \n",
      "1373 [D loss: (-5.671)(R 1.989, F -13.332)]  [G loss: 13.510] \n",
      "1374 [D loss: (-5.273)(R 2.484, F -13.030)]  [G loss: 13.576] \n",
      "1374 [D loss: (-5.149)(R 2.461, F -12.758)]  [G loss: 13.561] \n",
      "1375 [D loss: (-5.216)(R 2.884, F -13.317)]  [G loss: 13.674] \n",
      "1375 [D loss: (-5.733)(R 2.771, F -14.237)]  [G loss: 13.994] \n",
      "1376 [D loss: (-5.321)(R 3.179, F -13.822)]  [G loss: 14.026] \n",
      "1376 [D loss: (-5.049)(R 3.379, F -13.476)]  [G loss: 13.904] \n",
      "1377 [D loss: (-5.336)(R 3.017, F -13.689)]  [G loss: 13.935] \n",
      "1377 [D loss: (-5.202)(R 3.127, F -13.532)]  [G loss: 13.805] \n",
      "1378 [D loss: (-5.156)(R 3.298, F -13.611)]  [G loss: 13.949] \n",
      "1378 [D loss: (-5.223)(R 3.205, F -13.652)]  [G loss: 13.967] \n",
      "1379 [D loss: (-5.083)(R 3.580, F -13.746)]  [G loss: 14.116] \n",
      "1379 [D loss: (-4.932)(R 3.273, F -13.137)]  [G loss: 14.008] \n",
      "1380 [D loss: (-4.833)(R 3.052, F -12.718)]  [G loss: 13.660] \n",
      "1380 [D loss: (-4.645)(R 3.030, F -12.320)]  [G loss: 13.235] \n",
      "1381 [D loss: (-4.832)(R 2.519, F -12.184)]  [G loss: 12.788] \n",
      "1381 [D loss: (-4.971)(R 2.133, F -12.074)]  [G loss: 12.490] \n",
      "1382 [D loss: (-5.029)(R 1.852, F -11.909)]  [G loss: 12.750] \n",
      "1382 [D loss: (-5.253)(R 2.314, F -12.820)]  [G loss: 13.006] \n",
      "1383 [D loss: (-4.791)(R 2.874, F -12.455)]  [G loss: 13.167] \n",
      "1383 [D loss: (-4.867)(R 3.014, F -12.748)]  [G loss: 13.127] \n",
      "1384 [D loss: (-4.920)(R 2.831, F -12.671)]  [G loss: 13.169] \n",
      "1384 [D loss: (-4.857)(R 3.066, F -12.780)]  [G loss: 13.340] \n",
      "1385 [D loss: (-4.536)(R 3.494, F -12.565)]  [G loss: 13.445] \n",
      "1385 [D loss: (-4.855)(R 4.039, F -13.748)]  [G loss: 13.871] \n",
      "1386 [D loss: (-4.936)(R 3.850, F -13.722)]  [G loss: 13.975] \n",
      "1386 [D loss: (-4.851)(R 4.167, F -13.870)]  [G loss: 14.163] \n",
      "1387 [D loss: (-4.740)(R 3.859, F -13.338)]  [G loss: 14.175] \n",
      "1387 [D loss: (-4.655)(R 3.630, F -12.940)]  [G loss: 14.032] \n",
      "1388 [D loss: (-4.935)(R 3.371, F -13.242)]  [G loss: 13.856] \n",
      "1388 [D loss: (-4.213)(R 4.637, F -13.063)]  [G loss: 13.780] \n",
      "1389 [D loss: (-4.934)(R 3.253, F -13.121)]  [G loss: 13.826] \n",
      "1389 [D loss: (-4.846)(R 3.594, F -13.286)]  [G loss: 13.890] \n",
      "1390 [D loss: (-4.808)(R 4.419, F -14.034)]  [G loss: 14.070] \n",
      "1390 [D loss: (-4.915)(R 3.918, F -13.748)]  [G loss: 14.199] \n",
      "1391 [D loss: (-4.755)(R 4.275, F -13.784)]  [G loss: 14.092] \n",
      "1391 [D loss: (-4.693)(R 3.644, F -13.030)]  [G loss: 13.921] \n",
      "1392 [D loss: (-4.924)(R 3.970, F -13.817)]  [G loss: 13.950] \n",
      "1392 [D loss: (-4.866)(R 3.724, F -13.457)]  [G loss: 14.105] \n",
      "1393 [D loss: (-4.809)(R 3.192, F -12.810)]  [G loss: 13.650] \n",
      "1393 [D loss: (-5.002)(R 3.395, F -13.399)]  [G loss: 13.625] \n",
      "1394 [D loss: (-4.866)(R 3.421, F -13.154)]  [G loss: 13.397] \n",
      "1394 [D loss: (-4.810)(R 3.895, F -13.515)]  [G loss: 13.747] \n",
      "1395 [D loss: (-4.520)(R 4.148, F -13.188)]  [G loss: 13.714] \n",
      "1395 [D loss: (-4.792)(R 3.279, F -12.863)]  [G loss: 13.470] \n",
      "1396 [D loss: (-4.525)(R 3.254, F -12.304)]  [G loss: 13.230] \n",
      "1396 [D loss: (-5.067)(R 2.966, F -13.100)]  [G loss: 12.881] \n",
      "1397 [D loss: (-4.963)(R 3.259, F -13.184)]  [G loss: 13.048] \n",
      "1397 [D loss: (-4.957)(R 3.686, F -13.599)]  [G loss: 13.051] \n",
      "1398 [D loss: (-4.170)(R 3.957, F -12.298)]  [G loss: 13.265] \n",
      "1398 [D loss: (-3.804)(R 4.409, F -12.018)]  [G loss: 13.137] \n",
      "1399 [D loss: (-4.814)(R 2.764, F -12.392)]  [G loss: 12.818] \n",
      "1399 [D loss: (-4.659)(R 3.105, F -12.423)]  [G loss: 12.610] \n",
      "1400 [D loss: (-4.714)(R 2.989, F -12.417)]  [G loss: 12.476] \n",
      "1400 [D loss: (-4.892)(R 1.740, F -11.524)]  [G loss: 12.525] \n",
      "1401 [D loss: (-5.457)(R 1.340, F -12.255)]  [G loss: 12.038] \n",
      "1401 [D loss: (-5.228)(R 2.067, F -12.524)]  [G loss: 12.568] \n",
      "1402 [D loss: (-5.037)(R 2.820, F -12.893)]  [G loss: 13.051] \n",
      "1402 [D loss: (-4.525)(R 3.511, F -12.562)]  [G loss: 13.125] \n",
      "1403 [D loss: (-4.666)(R 2.938, F -12.270)]  [G loss: 13.267] \n",
      "1403 [D loss: (-4.902)(R 3.003, F -12.807)]  [G loss: 12.859] \n",
      "1404 [D loss: (-4.760)(R 2.287, F -11.806)]  [G loss: 12.369] \n",
      "1404 [D loss: (-4.646)(R 1.409, F -10.701)]  [G loss: 11.710] \n",
      "1405 [D loss: (-4.765)(R 1.347, F -10.876)]  [G loss: 11.305] \n",
      "1405 [D loss: (-4.670)(R 2.069, F -11.409)]  [G loss: 11.318] \n",
      "1406 [D loss: (-4.717)(R 1.639, F -11.073)]  [G loss: 11.603] \n",
      "1406 [D loss: (-4.505)(R 1.476, F -10.486)]  [G loss: 11.372] \n",
      "1407 [D loss: (-5.217)(R 0.698, F -11.132)]  [G loss: 11.049] \n",
      "1407 [D loss: (-5.005)(R 0.766, F -10.775)]  [G loss: 11.134] \n",
      "1408 [D loss: (-4.888)(R 0.927, F -10.703)]  [G loss: 11.246] \n",
      "1408 [D loss: (-5.036)(R 1.437, F -11.508)]  [G loss: 11.869] \n",
      "1409 [D loss: (-4.405)(R 1.665, F -10.475)]  [G loss: 11.774] \n",
      "1409 [D loss: (-4.752)(R 1.498, F -11.002)]  [G loss: 11.609] \n",
      "1410 [D loss: (-4.930)(R 1.573, F -11.433)]  [G loss: 11.498] \n",
      "1410 [D loss: (-4.557)(R 1.726, F -10.839)]  [G loss: 11.204] \n",
      "1411 [D loss: (-5.104)(R 1.017, F -11.224)]  [G loss: 11.168] \n",
      "1411 [D loss: (-4.905)(R 0.432, F -10.242)]  [G loss: 10.932] \n",
      "1412 [D loss: (-5.251)(R 0.613, F -11.115)]  [G loss: 11.088] \n",
      "1412 [D loss: (-4.289)(R 1.549, F -10.127)]  [G loss: 10.844] \n",
      "1413 [D loss: (-4.595)(R 1.307, F -10.496)]  [G loss: 11.332] \n",
      "1413 [D loss: (-4.867)(R 0.911, F -10.645)]  [G loss: 11.261] \n",
      "1414 [D loss: (-4.827)(R 0.918, F -10.573)]  [G loss: 11.663] \n",
      "1414 [D loss: (-5.148)(R 0.890, F -11.185)]  [G loss: 11.452] \n",
      "1415 [D loss: (-4.551)(R 1.460, F -10.561)]  [G loss: 10.992] \n",
      "1415 [D loss: (-4.781)(R 0.934, F -10.496)]  [G loss: 10.736] \n",
      "1416 [D loss: (-4.337)(R 0.963, F -9.637)]  [G loss: 10.763] \n",
      "1416 [D loss: (-5.275)(R 0.251, F -10.802)]  [G loss: 10.433] \n",
      "1417 [D loss: (-5.159)(R 0.768, F -11.086)]  [G loss: 10.510] \n",
      "1417 [D loss: (-5.172)(R 0.312, F -10.657)]  [G loss: 10.871] \n",
      "1418 [D loss: (-5.373)(R 0.872, F -11.617)]  [G loss: 11.241] \n",
      "1418 [D loss: (-4.290)(R 1.200, F -9.780)]  [G loss: 11.536] \n",
      "1419 [D loss: (-4.372)(R 1.987, F -10.730)]  [G loss: 11.944] \n",
      "1419 [D loss: (-4.968)(R 1.294, F -11.231)]  [G loss: 11.640] \n",
      "1420 [D loss: (-4.935)(R 1.390, F -11.260)]  [G loss: 11.461] \n",
      "1420 [D loss: (-5.284)(R 0.536, F -11.104)]  [G loss: 11.562] \n",
      "1421 [D loss: (-4.747)(R 1.376, F -10.870)]  [G loss: 11.131] \n",
      "1421 [D loss: (-4.549)(R 1.460, F -10.558)]  [G loss: 11.471] \n",
      "1422 [D loss: (-5.137)(R 1.250, F -11.524)]  [G loss: 11.570] \n",
      "1422 [D loss: (-4.793)(R 0.684, F -10.269)]  [G loss: 10.551] \n",
      "1423 [D loss: (-4.662)(R 0.706, F -10.030)]  [G loss: 9.903] \n",
      "1423 [D loss: (-4.844)(R -0.100, F -9.589)]  [G loss: 10.293] \n",
      "1424 [D loss: (-5.468)(R 0.465, F -11.401)]  [G loss: 11.168] \n",
      "1424 [D loss: (-5.531)(R 1.208, F -12.271)]  [G loss: 11.543] \n",
      "1425 [D loss: (-5.184)(R 2.328, F -12.695)]  [G loss: 12.075] \n",
      "1425 [D loss: (-4.789)(R 2.294, F -11.873)]  [G loss: 11.639] \n",
      "1426 [D loss: (-4.951)(R 1.287, F -11.189)]  [G loss: 11.614] \n",
      "1426 [D loss: (-4.559)(R 1.664, F -10.781)]  [G loss: 11.214] \n",
      "1427 [D loss: (-4.422)(R 2.036, F -10.881)]  [G loss: 10.792] \n",
      "1427 [D loss: (-4.999)(R 0.542, F -10.540)]  [G loss: 11.008] \n",
      "1428 [D loss: (-5.324)(R 1.363, F -12.011)]  [G loss: 11.401] \n",
      "1428 [D loss: (-4.456)(R 1.648, F -10.560)]  [G loss: 10.933] \n",
      "1429 [D loss: (-4.666)(R 1.065, F -10.397)]  [G loss: 11.044] \n",
      "1429 [D loss: (-4.922)(R 1.246, F -11.090)]  [G loss: 11.002] \n",
      "1430 [D loss: (-4.470)(R 1.243, F -10.183)]  [G loss: 11.395] \n",
      "1430 [D loss: (-4.630)(R 1.017, F -10.277)]  [G loss: 10.575] \n",
      "1431 [D loss: (-5.734)(R 0.468, F -11.936)]  [G loss: 10.539] \n",
      "1431 [D loss: (-4.899)(R 1.194, F -10.992)]  [G loss: 11.063] \n",
      "1432 [D loss: (-5.341)(R 0.880, F -11.561)]  [G loss: 11.068] \n",
      "1432 [D loss: (-4.628)(R 1.770, F -11.026)]  [G loss: 11.318] \n",
      "1433 [D loss: (-5.063)(R 1.011, F -11.138)]  [G loss: 11.059] \n",
      "1433 [D loss: (-4.762)(R 1.245, F -10.769)]  [G loss: 10.675] \n",
      "1434 [D loss: (-4.699)(R 1.017, F -10.416)]  [G loss: 10.863] \n",
      "1434 [D loss: (-4.967)(R 0.023, F -9.958)]  [G loss: 9.963] \n",
      "1435 [D loss: (-4.672)(R -0.121, F -9.222)]  [G loss: 9.546] \n",
      "1435 [D loss: (-5.416)(R -0.343, F -10.489)]  [G loss: 9.957] \n",
      "1436 [D loss: (-4.144)(R 1.278, F -9.567)]  [G loss: 10.550] \n",
      "1436 [D loss: (-4.977)(R 0.784, F -10.739)]  [G loss: 10.560] \n",
      "1437 [D loss: (-4.945)(R 0.729, F -10.620)]  [G loss: 10.060] \n",
      "1437 [D loss: (-5.114)(R 0.628, F -10.857)]  [G loss: 10.508] \n",
      "1438 [D loss: (-4.861)(R -0.252, F -9.469)]  [G loss: 10.475] \n",
      "1438 [D loss: (-4.953)(R 1.185, F -11.092)]  [G loss: 9.995] \n",
      "1439 [D loss: (-4.633)(R 0.203, F -9.469)]  [G loss: 10.299] \n",
      "1439 [D loss: (-4.697)(R 0.680, F -10.073)]  [G loss: 10.601] \n",
      "1440 [D loss: (-5.285)(R 0.118, F -10.687)]  [G loss: 10.626] \n",
      "1440 [D loss: (-4.637)(R 0.560, F -9.834)]  [G loss: 10.158] \n",
      "1441 [D loss: (-5.204)(R -0.264, F -10.143)]  [G loss: 10.301] \n",
      "1441 [D loss: (-4.824)(R 0.194, F -9.843)]  [G loss: 10.124] \n",
      "1442 [D loss: (-5.236)(R 0.147, F -10.618)]  [G loss: 10.397] \n",
      "1442 [D loss: (-4.677)(R -0.155, F -9.199)]  [G loss: 9.828] \n",
      "1443 [D loss: (-5.035)(R -0.706, F -9.365)]  [G loss: 9.994] \n",
      "1443 [D loss: (-5.046)(R -0.701, F -9.392)]  [G loss: 9.450] \n",
      "1444 [D loss: (-4.597)(R 0.030, F -9.224)]  [G loss: 9.390] \n",
      "1444 [D loss: (-5.641)(R -0.830, F -10.451)]  [G loss: 9.826] \n",
      "1445 [D loss: (-5.299)(R -1.203, F -9.395)]  [G loss: 9.886] \n",
      "1445 [D loss: (-4.049)(R 0.523, F -8.621)]  [G loss: 9.569] \n",
      "1446 [D loss: (-4.496)(R -0.717, F -8.275)]  [G loss: 9.749] \n",
      "1446 [D loss: (-5.293)(R -0.251, F -10.335)]  [G loss: 9.725] \n",
      "1447 [D loss: (-4.687)(R 0.114, F -9.488)]  [G loss: 9.998] \n",
      "1447 [D loss: (-4.965)(R -0.235, F -9.695)]  [G loss: 9.547] \n",
      "1448 [D loss: (-5.048)(R -0.604, F -9.493)]  [G loss: 9.085] \n",
      "1448 [D loss: (-4.953)(R -0.863, F -9.043)]  [G loss: 8.759] \n",
      "1449 [D loss: (-3.826)(R 0.154, F -7.805)]  [G loss: 9.757] \n",
      "1449 [D loss: (-4.846)(R 0.078, F -9.771)]  [G loss: 8.945] \n",
      "1450 [D loss: (-4.511)(R -0.541, F -8.481)]  [G loss: 9.417] \n",
      "1450 [D loss: (-4.795)(R -0.157, F -9.434)]  [G loss: 8.804] \n",
      "1451 [D loss: (-4.871)(R -0.987, F -8.755)]  [G loss: 9.082] \n",
      "1451 [D loss: (-5.165)(R -0.050, F -10.280)]  [G loss: 9.292] \n",
      "1452 [D loss: (-5.200)(R -0.188, F -10.211)]  [G loss: 9.002] \n",
      "1452 [D loss: (-4.448)(R 0.016, F -8.911)]  [G loss: 9.679] \n",
      "1453 [D loss: (-4.932)(R -0.239, F -9.626)]  [G loss: 9.773] \n",
      "1453 [D loss: (-5.430)(R 0.072, F -10.932)]  [G loss: 9.731] \n",
      "1454 [D loss: (-4.341)(R 0.644, F -9.326)]  [G loss: 10.024] \n",
      "1454 [D loss: (-5.505)(R 0.267, F -11.277)]  [G loss: 9.453] \n",
      "1455 [D loss: (-4.860)(R 0.382, F -10.102)]  [G loss: 9.995] \n",
      "1455 [D loss: (-4.903)(R 0.428, F -10.234)]  [G loss: 9.680] \n",
      "1456 [D loss: (-4.514)(R -0.523, F -8.506)]  [G loss: 8.863] \n",
      "1456 [D loss: (-4.609)(R -1.200, F -8.019)]  [G loss: 8.377] \n",
      "1457 [D loss: (-4.713)(R -1.329, F -8.097)]  [G loss: 8.200] \n",
      "1457 [D loss: (-4.626)(R -0.924, F -8.329)]  [G loss: 8.449] \n",
      "1458 [D loss: (-3.992)(R -0.313, F -7.671)]  [G loss: 8.268] \n",
      "1458 [D loss: (-5.033)(R -1.701, F -8.365)]  [G loss: 7.915] \n",
      "1459 [D loss: (-4.336)(R -1.184, F -7.488)]  [G loss: 7.606] \n",
      "1459 [D loss: (-4.674)(R -1.214, F -8.134)]  [G loss: 7.881] \n",
      "1460 [D loss: (-4.352)(R -1.624, F -7.079)]  [G loss: 7.738] \n",
      "1460 [D loss: (-4.748)(R -1.660, F -7.835)]  [G loss: 7.630] \n",
      "1461 [D loss: (-4.012)(R -2.045, F -5.979)]  [G loss: 7.070] \n",
      "1461 [D loss: (-5.294)(R -2.766, F -7.823)]  [G loss: 7.122] \n",
      "1462 [D loss: (-4.265)(R -1.292, F -7.238)]  [G loss: 7.615] \n",
      "1462 [D loss: (-4.833)(R -1.610, F -8.055)]  [G loss: 7.434] \n",
      "1463 [D loss: (-4.631)(R -1.101, F -8.162)]  [G loss: 7.485] \n",
      "1463 [D loss: (-4.556)(R -1.634, F -7.477)]  [G loss: 7.917] \n",
      "1464 [D loss: (-4.533)(R -1.848, F -7.217)]  [G loss: 7.474] \n",
      "1464 [D loss: (-3.419)(R -1.370, F -5.468)]  [G loss: 7.689] \n",
      "1465 [D loss: (-4.580)(R -2.270, F -6.889)]  [G loss: 6.757] \n",
      "1465 [D loss: (-4.978)(R -2.296, F -7.660)]  [G loss: 7.355] \n",
      "1466 [D loss: (-4.233)(R -0.519, F -7.948)]  [G loss: 8.031] \n",
      "1466 [D loss: (-4.610)(R -1.680, F -7.540)]  [G loss: 7.405] \n",
      "1467 [D loss: (-4.494)(R -1.405, F -7.583)]  [G loss: 7.950] \n",
      "1467 [D loss: (-4.226)(R -0.572, F -7.880)]  [G loss: 7.949] \n",
      "1468 [D loss: (-4.593)(R -1.051, F -8.136)]  [G loss: 8.137] \n",
      "1468 [D loss: (-4.251)(R -0.989, F -7.513)]  [G loss: 8.128] \n",
      "1469 [D loss: (-4.095)(R 0.186, F -8.377)]  [G loss: 7.836] \n",
      "1469 [D loss: (-5.001)(R -0.937, F -9.064)]  [G loss: 8.226] \n",
      "1470 [D loss: (-5.072)(R -1.047, F -9.097)]  [G loss: 9.027] \n",
      "1470 [D loss: (-4.226)(R 0.984, F -9.436)]  [G loss: 8.929] \n",
      "1471 [D loss: (-4.693)(R 0.083, F -9.469)]  [G loss: 8.427] \n",
      "1471 [D loss: (-4.866)(R -0.451, F -9.281)]  [G loss: 8.641] \n",
      "1472 [D loss: (-3.369)(R 0.352, F -7.090)]  [G loss: 8.444] \n",
      "1472 [D loss: (-4.474)(R -1.090, F -7.858)]  [G loss: 7.717] \n",
      "1473 [D loss: (-4.930)(R -1.316, F -8.545)]  [G loss: 8.270] \n",
      "1473 [D loss: (-3.969)(R -0.765, F -7.173)]  [G loss: 7.666] \n",
      "1474 [D loss: (-4.255)(R -0.629, F -7.880)]  [G loss: 8.305] \n",
      "1474 [D loss: (-4.382)(R -0.984, F -7.779)]  [G loss: 8.246] \n",
      "1475 [D loss: (-4.568)(R -0.230, F -8.906)]  [G loss: 8.584] \n",
      "1475 [D loss: (-4.193)(R -0.368, F -8.019)]  [G loss: 8.446] \n",
      "1476 [D loss: (-4.135)(R 0.019, F -8.288)]  [G loss: 8.133] \n",
      "1476 [D loss: (-4.572)(R -0.208, F -8.937)]  [G loss: 8.275] \n",
      "1477 [D loss: (-4.999)(R -1.459, F -8.539)]  [G loss: 7.630] \n",
      "1477 [D loss: (-4.033)(R -1.393, F -6.672)]  [G loss: 7.464] \n",
      "1478 [D loss: (-4.134)(R -1.849, F -6.419)]  [G loss: 7.103] \n",
      "1478 [D loss: (-5.050)(R -2.460, F -7.641)]  [G loss: 7.212] \n",
      "1479 [D loss: (-4.403)(R -2.106, F -6.701)]  [G loss: 6.992] \n",
      "1479 [D loss: (-3.583)(R -1.763, F -5.402)]  [G loss: 6.932] \n",
      "1480 [D loss: (-4.239)(R -2.039, F -6.439)]  [G loss: 6.640] \n",
      "1480 [D loss: (-4.662)(R -2.248, F -7.077)]  [G loss: 7.412] \n",
      "1481 [D loss: (-4.384)(R -1.412, F -7.356)]  [G loss: 6.815] \n",
      "1481 [D loss: (-3.761)(R -1.124, F -6.397)]  [G loss: 7.114] \n",
      "1482 [D loss: (-4.102)(R -1.215, F -6.988)]  [G loss: 7.274] \n",
      "1482 [D loss: (-4.210)(R -1.861, F -6.560)]  [G loss: 7.024] \n",
      "1483 [D loss: (-3.397)(R -1.060, F -5.734)]  [G loss: 6.182] \n",
      "1483 [D loss: (-4.107)(R -2.571, F -5.643)]  [G loss: 6.620] \n",
      "1484 [D loss: (-4.515)(R -1.650, F -7.380)]  [G loss: 6.964] \n",
      "1484 [D loss: (-4.258)(R -2.046, F -6.470)]  [G loss: 6.490] \n",
      "1485 [D loss: (-4.037)(R -1.792, F -6.281)]  [G loss: 6.818] \n",
      "1485 [D loss: (-3.171)(R -0.797, F -5.546)]  [G loss: 6.639] \n",
      "1486 [D loss: (-4.374)(R -2.016, F -6.732)]  [G loss: 6.214] \n",
      "1486 [D loss: (-3.196)(R -1.059, F -5.334)]  [G loss: 6.436] \n",
      "1487 [D loss: (-4.258)(R -3.435, F -5.081)]  [G loss: 5.767] \n",
      "1487 [D loss: (-4.268)(R -2.819, F -5.717)]  [G loss: 5.769] \n",
      "1488 [D loss: (-4.305)(R -2.819, F -5.792)]  [G loss: 6.297] \n",
      "1488 [D loss: (-4.715)(R -3.103, F -6.327)]  [G loss: 6.694] \n",
      "1489 [D loss: (-4.473)(R -2.478, F -6.468)]  [G loss: 6.683] \n",
      "1489 [D loss: (-4.161)(R -2.267, F -6.055)]  [G loss: 6.178] \n",
      "1490 [D loss: (-5.050)(R -2.802, F -7.298)]  [G loss: 6.689] \n",
      "1490 [D loss: (-3.753)(R -1.034, F -6.472)]  [G loss: 7.098] \n",
      "1491 [D loss: (-4.496)(R -1.563, F -7.428)]  [G loss: 6.774] \n",
      "1491 [D loss: (-4.144)(R -2.049, F -6.238)]  [G loss: 7.116] \n",
      "1492 [D loss: (-4.533)(R -2.069, F -6.996)]  [G loss: 7.339] \n",
      "1492 [D loss: (-4.380)(R -1.923, F -6.836)]  [G loss: 7.778] \n",
      "1493 [D loss: (-4.754)(R -1.444, F -8.064)]  [G loss: 7.875] \n",
      "1493 [D loss: (-5.045)(R -1.991, F -8.099)]  [G loss: 7.824] \n",
      "1494 [D loss: (-4.681)(R -1.806, F -7.555)]  [G loss: 7.868] \n",
      "1494 [D loss: (-4.528)(R -1.529, F -7.526)]  [G loss: 7.424] \n",
      "1495 [D loss: (-4.408)(R -2.178, F -6.639)]  [G loss: 7.284] \n",
      "1495 [D loss: (-4.629)(R -2.615, F -6.644)]  [G loss: 7.564] \n",
      "1496 [D loss: (-4.595)(R -2.238, F -6.953)]  [G loss: 7.685] \n",
      "1496 [D loss: (-4.737)(R -2.474, F -6.999)]  [G loss: 7.539] \n",
      "1497 [D loss: (-4.898)(R -2.583, F -7.213)]  [G loss: 7.516] \n",
      "1497 [D loss: (-5.104)(R -2.341, F -7.867)]  [G loss: 7.629] \n",
      "1498 [D loss: (-4.925)(R -1.981, F -7.869)]  [G loss: 7.718] \n",
      "1498 [D loss: (-4.804)(R -2.173, F -7.435)]  [G loss: 8.163] \n",
      "1499 [D loss: (-4.085)(R -1.845, F -6.324)]  [G loss: 8.025] \n",
      "1499 [D loss: (-4.772)(R -2.668, F -6.876)]  [G loss: 7.530] \n",
      "1500 [D loss: (-4.845)(R -2.731, F -6.958)]  [G loss: 7.266] \n",
      "1500 [D loss: (-5.189)(R -2.712, F -7.665)]  [G loss: 7.253] \n",
      "1501 [D loss: (-5.091)(R -2.001, F -8.181)]  [G loss: 7.955] \n",
      "1501 [D loss: (-5.181)(R -2.325, F -8.038)]  [G loss: 8.096] \n",
      "1502 [D loss: (-4.753)(R -2.312, F -7.194)]  [G loss: 7.554] \n",
      "1502 [D loss: (-4.924)(R -2.769, F -7.078)]  [G loss: 7.789] \n",
      "1503 [D loss: (-4.729)(R -2.602, F -6.855)]  [G loss: 7.170] \n",
      "1503 [D loss: (-4.874)(R -2.854, F -6.893)]  [G loss: 7.353] \n",
      "1504 [D loss: (-5.566)(R -2.987, F -8.145)]  [G loss: 7.878] \n",
      "1504 [D loss: (-4.747)(R -2.713, F -6.781)]  [G loss: 7.800] \n",
      "1505 [D loss: (-5.053)(R -2.839, F -7.267)]  [G loss: 7.742] \n",
      "1505 [D loss: (-5.673)(R -2.962, F -8.384)]  [G loss: 7.991] \n",
      "1506 [D loss: (-5.084)(R -2.440, F -7.728)]  [G loss: 8.446] \n",
      "1506 [D loss: (-5.236)(R -2.645, F -7.826)]  [G loss: 8.575] \n",
      "1507 [D loss: (-5.448)(R -2.536, F -8.361)]  [G loss: 8.550] \n",
      "1507 [D loss: (-4.787)(R -1.502, F -8.071)]  [G loss: 9.108] \n",
      "1508 [D loss: (-5.232)(R -2.468, F -7.996)]  [G loss: 8.747] \n",
      "1508 [D loss: (-5.910)(R -2.417, F -9.403)]  [G loss: 8.969] \n",
      "1509 [D loss: (-5.445)(R -2.662, F -8.228)]  [G loss: 8.903] \n",
      "1509 [D loss: (-5.190)(R -2.180, F -8.200)]  [G loss: 8.751] \n",
      "1510 [D loss: (-5.422)(R -2.649, F -8.195)]  [G loss: 8.965] \n",
      "1510 [D loss: (-5.994)(R -2.641, F -9.346)]  [G loss: 9.040] \n",
      "1511 [D loss: (-5.679)(R -2.190, F -9.168)]  [G loss: 9.233] \n",
      "1511 [D loss: (-6.119)(R -2.734, F -9.505)]  [G loss: 9.478] \n",
      "1512 [D loss: (-5.690)(R -2.322, F -9.059)]  [G loss: 9.380] \n",
      "1512 [D loss: (-5.694)(R -2.170, F -9.218)]  [G loss: 9.420] \n",
      "1513 [D loss: (-5.815)(R -1.671, F -9.960)]  [G loss: 9.457] \n",
      "1513 [D loss: (-5.772)(R -2.384, F -9.161)]  [G loss: 9.685] \n",
      "1514 [D loss: (-5.796)(R -2.155, F -9.438)]  [G loss: 9.754] \n",
      "1514 [D loss: (-5.707)(R -1.924, F -9.490)]  [G loss: 9.679] \n",
      "1515 [D loss: (-5.982)(R -2.176, F -9.788)]  [G loss: 9.582] \n",
      "1515 [D loss: (-6.106)(R -2.423, F -9.789)]  [G loss: 9.507] \n",
      "1516 [D loss: (-5.905)(R -2.613, F -9.198)]  [G loss: 9.611] \n",
      "1516 [D loss: (-5.791)(R -2.235, F -9.348)]  [G loss: 9.357] \n",
      "1517 [D loss: (-6.259)(R -3.283, F -9.236)]  [G loss: 9.500] \n",
      "1517 [D loss: (-5.927)(R -2.833, F -9.021)]  [G loss: 9.418] \n",
      "1518 [D loss: (-5.907)(R -2.113, F -9.702)]  [G loss: 9.656] \n",
      "1518 [D loss: (-5.811)(R -2.339, F -9.282)]  [G loss: 9.478] \n",
      "1519 [D loss: (-5.429)(R -2.576, F -8.281)]  [G loss: 9.091] \n",
      "1519 [D loss: (-6.230)(R -3.519, F -8.941)]  [G loss: 9.188] \n",
      "1520 [D loss: (-6.130)(R -3.218, F -9.043)]  [G loss: 9.056] \n",
      "1520 [D loss: (-5.259)(R -2.489, F -8.029)]  [G loss: 8.909] \n",
      "1521 [D loss: (-6.205)(R -3.892, F -8.517)]  [G loss: 8.652] \n",
      "1521 [D loss: (-6.206)(R -3.422, F -8.990)]  [G loss: 8.723] \n",
      "1522 [D loss: (-5.908)(R -3.591, F -8.226)]  [G loss: 8.816] \n",
      "1522 [D loss: (-5.756)(R -2.844, F -8.668)]  [G loss: 8.798] \n",
      "1523 [D loss: (-5.826)(R -2.978, F -8.675)]  [G loss: 8.748] \n",
      "1523 [D loss: (-5.621)(R -3.457, F -7.786)]  [G loss: 8.515] \n",
      "1524 [D loss: (-5.615)(R -3.467, F -7.763)]  [G loss: 8.410] \n",
      "1524 [D loss: (-5.974)(R -3.592, F -8.355)]  [G loss: 8.571] \n",
      "1525 [D loss: (-5.598)(R -3.244, F -7.952)]  [G loss: 8.348] \n",
      "1525 [D loss: (-5.815)(R -3.179, F -8.451)]  [G loss: 8.473] \n",
      "1526 [D loss: (-5.489)(R -3.376, F -7.601)]  [G loss: 8.451] \n",
      "1526 [D loss: (-5.616)(R -3.510, F -7.722)]  [G loss: 8.112] \n",
      "1527 [D loss: (-5.516)(R -3.733, F -7.299)]  [G loss: 8.206] \n",
      "1527 [D loss: (-5.776)(R -3.443, F -8.110)]  [G loss: 8.424] \n",
      "1528 [D loss: (-5.433)(R -2.661, F -8.205)]  [G loss: 8.544] \n",
      "1528 [D loss: (-5.544)(R -2.682, F -8.407)]  [G loss: 8.492] \n",
      "1529 [D loss: (-5.311)(R -2.837, F -7.785)]  [G loss: 8.274] \n",
      "1529 [D loss: (-5.277)(R -3.108, F -7.445)]  [G loss: 8.023] \n",
      "1530 [D loss: (-5.501)(R -3.300, F -7.702)]  [G loss: 7.713] \n",
      "1530 [D loss: (-5.584)(R -3.902, F -7.266)]  [G loss: 7.601] \n",
      "1531 [D loss: (-5.145)(R -3.590, F -6.700)]  [G loss: 7.388] \n",
      "1531 [D loss: (-5.429)(R -4.401, F -6.458)]  [G loss: 6.992] \n",
      "1532 [D loss: (-5.448)(R -4.259, F -6.638)]  [G loss: 6.954] \n",
      "1532 [D loss: (-5.294)(R -3.850, F -6.737)]  [G loss: 7.018] \n",
      "1533 [D loss: (-5.444)(R -3.732, F -7.157)]  [G loss: 7.098] \n",
      "1533 [D loss: (-5.326)(R -3.981, F -6.670)]  [G loss: 6.894] \n",
      "1534 [D loss: (-5.202)(R -4.044, F -6.360)]  [G loss: 6.743] \n",
      "1534 [D loss: (-5.151)(R -4.241, F -6.062)]  [G loss: 6.612] \n",
      "1535 [D loss: (-5.169)(R -4.167, F -6.172)]  [G loss: 6.366] \n",
      "1535 [D loss: (-5.340)(R -4.672, F -6.008)]  [G loss: 6.112] \n",
      "1536 [D loss: (-5.160)(R -4.154, F -6.166)]  [G loss: 6.511] \n",
      "1536 [D loss: (-5.226)(R -3.916, F -6.537)]  [G loss: 6.812] \n",
      "1537 [D loss: (-4.935)(R -3.564, F -6.306)]  [G loss: 6.819] \n",
      "1537 [D loss: (-4.952)(R -3.517, F -6.387)]  [G loss: 6.737] \n",
      "1538 [D loss: (-4.859)(R -3.413, F -6.305)]  [G loss: 6.580] \n",
      "1538 [D loss: (-5.039)(R -3.759, F -6.319)]  [G loss: 6.534] \n",
      "1539 [D loss: (-4.992)(R -3.816, F -6.167)]  [G loss: 6.584] \n",
      "1539 [D loss: (-4.803)(R -3.212, F -6.394)]  [G loss: 6.769] \n",
      "1540 [D loss: (-4.797)(R -3.118, F -6.475)]  [G loss: 6.780] \n",
      "1540 [D loss: (-4.722)(R -3.168, F -6.277)]  [G loss: 6.815] \n",
      "1541 [D loss: (-4.682)(R -3.086, F -6.278)]  [G loss: 6.848] \n",
      "1541 [D loss: (-4.712)(R -3.123, F -6.300)]  [G loss: 6.772] \n",
      "1542 [D loss: (-4.668)(R -3.048, F -6.288)]  [G loss: 6.510] \n",
      "1542 [D loss: (-4.844)(R -3.233, F -6.455)]  [G loss: 6.946] \n",
      "1543 [D loss: (-4.958)(R -3.327, F -6.589)]  [G loss: 6.842] \n",
      "1543 [D loss: (-4.571)(R -2.871, F -6.271)]  [G loss: 6.797] \n",
      "1544 [D loss: (-4.588)(R -2.492, F -6.685)]  [G loss: 6.906] \n",
      "1544 [D loss: (-4.551)(R -2.599, F -6.504)]  [G loss: 6.969] \n",
      "1545 [D loss: (-4.806)(R -3.014, F -6.598)]  [G loss: 6.848] \n",
      "1545 [D loss: (-4.529)(R -2.695, F -6.363)]  [G loss: 6.867] \n",
      "1546 [D loss: (-4.347)(R -2.130, F -6.564)]  [G loss: 7.006] \n",
      "1546 [D loss: (-4.814)(R -2.760, F -6.868)]  [G loss: 7.130] \n",
      "1547 [D loss: (-4.713)(R -2.561, F -6.866)]  [G loss: 7.022] \n",
      "1547 [D loss: (-4.635)(R -2.508, F -6.763)]  [G loss: 7.091] \n",
      "1548 [D loss: (-4.497)(R -2.251, F -6.744)]  [G loss: 7.120] \n",
      "1548 [D loss: (-4.646)(R -2.464, F -6.828)]  [G loss: 7.183] \n",
      "1549 [D loss: (-4.300)(R -1.945, F -6.656)]  [G loss: 7.055] \n",
      "1549 [D loss: (-4.306)(R -2.012, F -6.601)]  [G loss: 7.011] \n",
      "1550 [D loss: (-4.251)(R -1.875, F -6.627)]  [G loss: 6.981] \n",
      "1550 [D loss: (-4.402)(R -2.004, F -6.801)]  [G loss: 7.001] \n",
      "1551 [D loss: (-4.542)(R -2.391, F -6.692)]  [G loss: 7.043] \n",
      "1551 [D loss: (-4.246)(R -1.717, F -6.774)]  [G loss: 7.105] \n",
      "1552 [D loss: (-4.416)(R -2.020, F -6.812)]  [G loss: 7.063] \n",
      "1552 [D loss: (-4.258)(R -1.676, F -6.840)]  [G loss: 7.169] \n",
      "1553 [D loss: (-4.456)(R -1.909, F -7.002)]  [G loss: 7.293] \n",
      "1553 [D loss: (-4.691)(R -2.023, F -7.360)]  [G loss: 7.587] \n",
      "1554 [D loss: (-4.629)(R -1.509, F -7.750)]  [G loss: 7.828] \n",
      "1554 [D loss: (-4.524)(R -1.534, F -7.515)]  [G loss: 7.904] \n",
      "1555 [D loss: (-4.424)(R -1.000, F -7.847)]  [G loss: 8.115] \n",
      "1555 [D loss: (-4.545)(R -0.953, F -8.136)]  [G loss: 8.366] \n",
      "1556 [D loss: (-4.568)(R -0.748, F -8.388)]  [G loss: 8.705] \n",
      "1556 [D loss: (-4.557)(R -0.762, F -8.352)]  [G loss: 8.663] \n",
      "1557 [D loss: (-4.564)(R -0.604, F -8.524)]  [G loss: 8.761] \n",
      "1557 [D loss: (-4.328)(R -0.137, F -8.519)]  [G loss: 8.887] \n",
      "1558 [D loss: (-4.455)(R -0.152, F -8.758)]  [G loss: 9.045] \n",
      "1558 [D loss: (-4.384)(R -0.137, F -8.631)]  [G loss: 8.889] \n",
      "1559 [D loss: (-4.305)(R -0.122, F -8.487)]  [G loss: 8.649] \n",
      "1559 [D loss: (-4.215)(R -0.115, F -8.315)]  [G loss: 8.541] \n",
      "1560 [D loss: (-4.351)(R -0.743, F -7.959)]  [G loss: 8.324] \n",
      "1560 [D loss: (-4.488)(R -0.719, F -8.258)]  [G loss: 8.458] \n",
      "1561 [D loss: (-4.358)(R -0.848, F -7.869)]  [G loss: 8.329] \n",
      "1561 [D loss: (-4.447)(R -1.146, F -7.748)]  [G loss: 8.090] \n",
      "1562 [D loss: (-4.314)(R -1.054, F -7.573)]  [G loss: 7.835] \n",
      "1562 [D loss: (-4.271)(R -1.290, F -7.253)]  [G loss: 7.414] \n",
      "1563 [D loss: (-4.428)(R -1.731, F -7.124)]  [G loss: 7.324] \n",
      "1563 [D loss: (-4.409)(R -1.839, F -6.980)]  [G loss: 7.259] \n",
      "1564 [D loss: (-4.162)(R -1.410, F -6.913)]  [G loss: 7.296] \n",
      "1564 [D loss: (-4.428)(R -1.708, F -7.147)]  [G loss: 7.346] \n",
      "1565 [D loss: (-4.600)(R -1.994, F -7.206)]  [G loss: 7.416] \n",
      "1565 [D loss: (-4.590)(R -1.786, F -7.394)]  [G loss: 7.668] \n",
      "1566 [D loss: (-4.363)(R -1.332, F -7.395)]  [G loss: 7.716] \n",
      "1566 [D loss: (-4.247)(R -1.250, F -7.243)]  [G loss: 7.367] \n",
      "1567 [D loss: (-4.581)(R -2.010, F -7.152)]  [G loss: 7.474] \n",
      "1567 [D loss: (-4.387)(R -1.649, F -7.125)]  [G loss: 7.528] \n",
      "1568 [D loss: (-4.477)(R -1.896, F -7.058)]  [G loss: 7.236] \n",
      "1568 [D loss: (-4.310)(R -2.022, F -6.599)]  [G loss: 6.764] \n",
      "1569 [D loss: (-4.631)(R -2.803, F -6.459)]  [G loss: 6.580] \n",
      "1569 [D loss: (-4.311)(R -2.532, F -6.090)]  [G loss: 6.210] \n",
      "1570 [D loss: (-4.287)(R -3.105, F -5.469)]  [G loss: 5.905] \n",
      "1570 [D loss: (-4.232)(R -2.806, F -5.657)]  [G loss: 5.773] \n",
      "1571 [D loss: (-4.647)(R -3.694, F -5.600)]  [G loss: 5.855] \n",
      "1571 [D loss: (-4.396)(R -3.084, F -5.707)]  [G loss: 5.895] \n",
      "1572 [D loss: (-4.304)(R -2.864, F -5.744)]  [G loss: 5.978] \n",
      "1572 [D loss: (-4.488)(R -3.299, F -5.677)]  [G loss: 6.024] \n",
      "1573 [D loss: (-4.425)(R -2.907, F -5.942)]  [G loss: 6.301] \n",
      "1573 [D loss: (-4.451)(R -2.645, F -6.256)]  [G loss: 6.632] \n",
      "1574 [D loss: (-4.242)(R -2.228, F -6.257)]  [G loss: 6.460] \n",
      "1574 [D loss: (-4.266)(R -2.270, F -6.262)]  [G loss: 6.463] \n",
      "1575 [D loss: (-4.239)(R -2.412, F -6.066)]  [G loss: 6.332] \n",
      "1575 [D loss: (-4.380)(R -2.608, F -6.153)]  [G loss: 6.441] \n",
      "1576 [D loss: (-4.499)(R -2.960, F -6.038)]  [G loss: 6.378] \n",
      "1576 [D loss: (-4.371)(R -2.699, F -6.043)]  [G loss: 6.260] \n",
      "1577 [D loss: (-4.134)(R -2.606, F -5.663)]  [G loss: 5.890] \n",
      "1577 [D loss: (-4.378)(R -3.560, F -5.195)]  [G loss: 5.568] \n",
      "1578 [D loss: (-4.321)(R -3.494, F -5.147)]  [G loss: 5.435] \n",
      "1578 [D loss: (-4.263)(R -3.582, F -4.944)]  [G loss: 5.322] \n",
      "1579 [D loss: (-4.225)(R -3.395, F -5.054)]  [G loss: 5.322] \n",
      "1579 [D loss: (-4.306)(R -3.452, F -5.160)]  [G loss: 5.392] \n",
      "1580 [D loss: (-4.357)(R -3.650, F -5.063)]  [G loss: 5.165] \n",
      "1580 [D loss: (-4.131)(R -3.292, F -4.970)]  [G loss: 5.354] \n",
      "1581 [D loss: (-4.390)(R -3.238, F -5.542)]  [G loss: 5.711] \n",
      "1581 [D loss: (-4.326)(R -2.956, F -5.695)]  [G loss: 5.968] \n",
      "1582 [D loss: (-4.211)(R -2.734, F -5.689)]  [G loss: 5.937] \n",
      "1582 [D loss: (-4.058)(R -2.416, F -5.699)]  [G loss: 6.072] \n",
      "1583 [D loss: (-4.249)(R -3.054, F -5.445)]  [G loss: 5.542] \n",
      "1583 [D loss: (-4.188)(R -3.496, F -4.880)]  [G loss: 5.143] \n",
      "1584 [D loss: (-4.209)(R -3.756, F -4.661)]  [G loss: 5.021] \n",
      "1584 [D loss: (-4.213)(R -3.697, F -4.729)]  [G loss: 5.136] \n",
      "1585 [D loss: (-4.242)(R -3.577, F -4.906)]  [G loss: 5.093] \n",
      "1585 [D loss: (-4.183)(R -3.439, F -4.926)]  [G loss: 5.141] \n",
      "1586 [D loss: (-4.211)(R -3.432, F -4.991)]  [G loss: 5.198] \n",
      "1586 [D loss: (-4.027)(R -2.839, F -5.215)]  [G loss: 5.474] \n",
      "1587 [D loss: (-4.194)(R -3.098, F -5.290)]  [G loss: 5.579] \n",
      "1587 [D loss: (-4.006)(R -2.783, F -5.228)]  [G loss: 5.588] \n",
      "1588 [D loss: (-3.825)(R -2.299, F -5.351)]  [G loss: 5.728] \n",
      "1588 [D loss: (-4.010)(R -2.584, F -5.436)]  [G loss: 5.801] \n",
      "1589 [D loss: (-4.094)(R -2.697, F -5.491)]  [G loss: 5.778] \n",
      "1589 [D loss: (-4.105)(R -2.422, F -5.787)]  [G loss: 6.060] \n",
      "1590 [D loss: (-3.967)(R -1.943, F -5.992)]  [G loss: 6.235] \n",
      "1590 [D loss: (-3.816)(R -1.433, F -6.199)]  [G loss: 6.503] \n",
      "1591 [D loss: (-3.977)(R -1.845, F -6.109)]  [G loss: 6.440] \n",
      "1591 [D loss: (-4.017)(R -1.881, F -6.153)]  [G loss: 6.488] \n",
      "1592 [D loss: (-3.754)(R -1.532, F -5.977)]  [G loss: 6.253] \n",
      "1592 [D loss: (-3.940)(R -1.918, F -5.961)]  [G loss: 6.311] \n",
      "1593 [D loss: (-4.060)(R -2.063, F -6.056)]  [G loss: 6.346] \n",
      "1593 [D loss: (-3.928)(R -1.905, F -5.952)]  [G loss: 6.392] \n",
      "1594 [D loss: (-3.815)(R -1.412, F -6.219)]  [G loss: 6.582] \n",
      "1594 [D loss: (-4.153)(R -2.039, F -6.266)]  [G loss: 6.616] \n",
      "1595 [D loss: (-3.966)(R -1.861, F -6.071)]  [G loss: 6.402] \n",
      "1595 [D loss: (-3.970)(R -2.188, F -5.752)]  [G loss: 6.096] \n",
      "1596 [D loss: (-3.966)(R -2.149, F -5.783)]  [G loss: 6.158] \n",
      "1596 [D loss: (-4.011)(R -1.969, F -6.053)]  [G loss: 6.238] \n",
      "1597 [D loss: (-4.098)(R -2.249, F -5.948)]  [G loss: 6.193] \n",
      "1597 [D loss: (-3.968)(R -1.984, F -5.952)]  [G loss: 6.244] \n",
      "1598 [D loss: (-3.882)(R -2.126, F -5.638)]  [G loss: 6.052] \n",
      "1598 [D loss: (-3.726)(R -1.739, F -5.713)]  [G loss: 6.105] \n",
      "1599 [D loss: (-3.839)(R -2.118, F -5.560)]  [G loss: 5.961] \n",
      "1599 [D loss: (-3.959)(R -2.234, F -5.683)]  [G loss: 5.884] \n",
      "1600 [D loss: (-3.729)(R -1.977, F -5.480)]  [G loss: 5.777] \n",
      "1600 [D loss: (-3.724)(R -1.862, F -5.586)]  [G loss: 5.820] \n",
      "1601 [D loss: (-3.821)(R -2.063, F -5.578)]  [G loss: 5.908] \n",
      "1601 [D loss: (-3.860)(R -2.013, F -5.708)]  [G loss: 5.895] \n",
      "1602 [D loss: (-3.653)(R -1.913, F -5.393)]  [G loss: 5.786] \n",
      "1602 [D loss: (-4.096)(R -2.631, F -5.560)]  [G loss: 5.799] \n",
      "1603 [D loss: (-3.860)(R -1.971, F -5.749)]  [G loss: 6.024] \n",
      "1603 [D loss: (-4.001)(R -1.701, F -6.301)]  [G loss: 6.449] \n",
      "1604 [D loss: (-3.827)(R -1.322, F -6.332)]  [G loss: 6.617] \n",
      "1604 [D loss: (-3.783)(R -1.343, F -6.222)]  [G loss: 6.668] \n",
      "1605 [D loss: (-3.844)(R -1.490, F -6.199)]  [G loss: 6.502] \n",
      "1605 [D loss: (-3.832)(R -1.359, F -6.306)]  [G loss: 6.688] \n",
      "1606 [D loss: (-3.875)(R -1.262, F -6.487)]  [G loss: 6.743] \n",
      "1606 [D loss: (-3.667)(R -1.057, F -6.277)]  [G loss: 6.672] \n",
      "1607 [D loss: (-3.993)(R -1.569, F -6.417)]  [G loss: 6.652] \n",
      "1607 [D loss: (-3.886)(R -1.547, F -6.225)]  [G loss: 6.623] \n",
      "1608 [D loss: (-3.882)(R -1.190, F -6.575)]  [G loss: 6.635] \n",
      "1608 [D loss: (-3.974)(R -1.463, F -6.485)]  [G loss: 6.811] \n",
      "1609 [D loss: (-3.971)(R -1.717, F -6.224)]  [G loss: 6.519] \n",
      "1609 [D loss: (-3.943)(R -1.691, F -6.196)]  [G loss: 6.420] \n",
      "1610 [D loss: (-3.895)(R -1.781, F -6.010)]  [G loss: 6.361] \n",
      "1610 [D loss: (-3.748)(R -1.877, F -5.620)]  [G loss: 5.900] \n",
      "1611 [D loss: (-3.705)(R -2.082, F -5.328)]  [G loss: 5.718] \n",
      "1611 [D loss: (-3.975)(R -2.444, F -5.506)]  [G loss: 5.747] \n",
      "1612 [D loss: (-3.834)(R -2.177, F -5.492)]  [G loss: 5.700] \n",
      "1612 [D loss: (-3.802)(R -2.192, F -5.412)]  [G loss: 5.688] \n",
      "1613 [D loss: (-3.637)(R -1.865, F -5.409)]  [G loss: 5.699] \n",
      "1613 [D loss: (-3.832)(R -2.349, F -5.315)]  [G loss: 5.760] \n",
      "1614 [D loss: (-3.876)(R -2.082, F -5.671)]  [G loss: 5.951] \n",
      "1614 [D loss: (-3.864)(R -2.200, F -5.529)]  [G loss: 5.734] \n",
      "1615 [D loss: (-3.774)(R -2.267, F -5.281)]  [G loss: 5.528] \n",
      "1615 [D loss: (-3.861)(R -2.410, F -5.311)]  [G loss: 5.604] \n",
      "1616 [D loss: (-3.774)(R -2.381, F -5.166)]  [G loss: 5.441] \n",
      "1616 [D loss: (-4.059)(R -3.082, F -5.035)]  [G loss: 5.291] \n",
      "1617 [D loss: (-3.831)(R -2.783, F -4.878)]  [G loss: 5.134] \n",
      "1617 [D loss: (-3.813)(R -2.977, F -4.650)]  [G loss: 4.858] \n",
      "1618 [D loss: (-3.926)(R -3.272, F -4.580)]  [G loss: 4.816] \n",
      "1618 [D loss: (-3.977)(R -3.610, F -4.344)]  [G loss: 4.665] \n",
      "1619 [D loss: (-3.791)(R -3.275, F -4.308)]  [G loss: 4.722] \n",
      "1619 [D loss: (-3.787)(R -3.146, F -4.428)]  [G loss: 4.726] \n",
      "1620 [D loss: (-3.988)(R -3.444, F -4.533)]  [G loss: 4.860] \n",
      "1620 [D loss: (-3.706)(R -2.841, F -4.570)]  [G loss: 4.790] \n",
      "1621 [D loss: (-3.897)(R -3.118, F -4.676)]  [G loss: 4.966] \n",
      "1621 [D loss: (-4.089)(R -3.571, F -4.606)]  [G loss: 4.907] \n",
      "1622 [D loss: (-3.867)(R -3.124, F -4.611)]  [G loss: 5.044] \n",
      "1622 [D loss: (-3.986)(R -3.317, F -4.656)]  [G loss: 4.971] \n",
      "1623 [D loss: (-3.825)(R -2.688, F -4.962)]  [G loss: 5.292] \n",
      "1623 [D loss: (-3.968)(R -2.763, F -5.174)]  [G loss: 5.411] \n",
      "1624 [D loss: (-3.547)(R -2.040, F -5.055)]  [G loss: 5.449] \n",
      "1624 [D loss: (-3.976)(R -2.772, F -5.180)]  [G loss: 5.346] \n",
      "1625 [D loss: (-3.928)(R -3.073, F -4.783)]  [G loss: 5.236] \n",
      "1625 [D loss: (-4.101)(R -3.245, F -4.958)]  [G loss: 5.261] \n",
      "1626 [D loss: (-3.927)(R -2.588, F -5.267)]  [G loss: 5.557] \n",
      "1626 [D loss: (-3.866)(R -2.469, F -5.262)]  [G loss: 5.598] \n",
      "1627 [D loss: (-4.165)(R -2.829, F -5.501)]  [G loss: 5.733] \n",
      "1627 [D loss: (-4.002)(R -2.477, F -5.526)]  [G loss: 5.791] \n",
      "1628 [D loss: (-4.191)(R -2.815, F -5.567)]  [G loss: 5.893] \n",
      "1628 [D loss: (-3.933)(R -2.215, F -5.651)]  [G loss: 6.002] \n",
      "1629 [D loss: (-3.918)(R -2.028, F -5.809)]  [G loss: 6.057] \n",
      "1629 [D loss: (-3.879)(R -1.976, F -5.782)]  [G loss: 6.182] \n",
      "1630 [D loss: (-4.116)(R -2.106, F -6.127)]  [G loss: 6.420] \n",
      "1630 [D loss: (-3.886)(R -1.447, F -6.325)]  [G loss: 6.395] \n",
      "1631 [D loss: (-4.063)(R -1.660, F -6.466)]  [G loss: 6.655] \n",
      "1631 [D loss: (-4.097)(R -1.537, F -6.658)]  [G loss: 6.782] \n",
      "1632 [D loss: (-3.974)(R -1.295, F -6.654)]  [G loss: 6.917] \n",
      "1632 [D loss: (-3.940)(R -1.467, F -6.413)]  [G loss: 6.957] \n",
      "1633 [D loss: (-4.039)(R -1.638, F -6.440)]  [G loss: 6.847] \n",
      "1633 [D loss: (-3.901)(R -1.590, F -6.212)]  [G loss: 6.470] \n",
      "1634 [D loss: (-4.077)(R -2.329, F -5.825)]  [G loss: 6.160] \n",
      "1634 [D loss: (-3.992)(R -2.209, F -5.775)]  [G loss: 6.039] \n",
      "1635 [D loss: (-3.854)(R -2.339, F -5.369)]  [G loss: 5.793] \n",
      "1635 [D loss: (-4.030)(R -2.546, F -5.514)]  [G loss: 5.748] \n",
      "1636 [D loss: (-3.909)(R -2.414, F -5.404)]  [G loss: 5.678] \n",
      "1636 [D loss: (-3.898)(R -2.471, F -5.325)]  [G loss: 5.765] \n",
      "1637 [D loss: (-3.836)(R -2.396, F -5.276)]  [G loss: 5.603] \n",
      "1637 [D loss: (-4.027)(R -2.951, F -5.102)]  [G loss: 5.416] \n",
      "1638 [D loss: (-4.230)(R -3.466, F -4.994)]  [G loss: 5.352] \n",
      "1638 [D loss: (-4.162)(R -3.163, F -5.162)]  [G loss: 5.328] \n",
      "1639 [D loss: (-4.160)(R -3.166, F -5.155)]  [G loss: 5.474] \n",
      "1639 [D loss: (-4.101)(R -2.894, F -5.308)]  [G loss: 5.530] \n",
      "1640 [D loss: (-4.074)(R -2.672, F -5.475)]  [G loss: 5.698] \n",
      "1640 [D loss: (-4.210)(R -2.683, F -5.736)]  [G loss: 5.964] \n",
      "1641 [D loss: (-4.314)(R -2.732, F -5.897)]  [G loss: 6.108] \n",
      "1641 [D loss: (-4.204)(R -2.455, F -5.952)]  [G loss: 6.144] \n",
      "1642 [D loss: (-3.936)(R -2.007, F -5.864)]  [G loss: 6.345] \n",
      "1642 [D loss: (-4.026)(R -2.154, F -5.897)]  [G loss: 6.279] \n",
      "1643 [D loss: (-4.048)(R -2.206, F -5.891)]  [G loss: 6.111] \n",
      "1643 [D loss: (-4.257)(R -2.671, F -5.843)]  [G loss: 6.184] \n",
      "1644 [D loss: (-4.110)(R -2.201, F -6.019)]  [G loss: 6.286] \n",
      "1644 [D loss: (-4.043)(R -2.125, F -5.962)]  [G loss: 6.307] \n",
      "1645 [D loss: (-4.123)(R -2.389, F -5.858)]  [G loss: 6.301] \n",
      "1645 [D loss: (-4.195)(R -2.369, F -6.020)]  [G loss: 6.292] \n",
      "1646 [D loss: (-4.075)(R -2.112, F -6.039)]  [G loss: 6.329] \n",
      "1646 [D loss: (-4.223)(R -2.234, F -6.212)]  [G loss: 6.435] \n",
      "1647 [D loss: (-4.253)(R -2.212, F -6.294)]  [G loss: 6.407] \n",
      "1647 [D loss: (-4.110)(R -2.126, F -6.095)]  [G loss: 6.329] \n",
      "1648 [D loss: (-4.284)(R -2.339, F -6.229)]  [G loss: 6.448] \n",
      "1648 [D loss: (-4.132)(R -2.056, F -6.209)]  [G loss: 6.440] \n",
      "1649 [D loss: (-4.098)(R -2.193, F -6.002)]  [G loss: 6.351] \n",
      "1649 [D loss: (-4.072)(R -1.868, F -6.276)]  [G loss: 6.654] \n",
      "1650 [D loss: (-4.093)(R -1.996, F -6.189)]  [G loss: 6.684] \n",
      "1650 [D loss: (-4.165)(R -2.136, F -6.194)]  [G loss: 6.489] \n",
      "1651 [D loss: (-3.998)(R -1.861, F -6.135)]  [G loss: 6.487] \n",
      "1651 [D loss: (-4.039)(R -2.114, F -5.964)]  [G loss: 6.389] \n",
      "1652 [D loss: (-4.347)(R -2.612, F -6.083)]  [G loss: 6.331] \n",
      "1652 [D loss: (-4.248)(R -2.437, F -6.058)]  [G loss: 6.172] \n",
      "1653 [D loss: (-4.405)(R -2.690, F -6.119)]  [G loss: 6.533] \n",
      "1653 [D loss: (-4.170)(R -1.992, F -6.348)]  [G loss: 6.814] \n",
      "1654 [D loss: (-4.199)(R -1.906, F -6.491)]  [G loss: 6.586] \n",
      "1654 [D loss: (-4.184)(R -2.154, F -6.213)]  [G loss: 6.390] \n",
      "1655 [D loss: (-4.197)(R -2.266, F -6.128)]  [G loss: 6.467] \n",
      "1655 [D loss: (-4.140)(R -2.122, F -6.157)]  [G loss: 6.520] \n",
      "1656 [D loss: (-4.232)(R -2.340, F -6.123)]  [G loss: 6.676] \n",
      "1656 [D loss: (-4.004)(R -1.978, F -6.030)]  [G loss: 6.552] \n",
      "1657 [D loss: (-4.297)(R -2.533, F -6.062)]  [G loss: 6.299] \n",
      "1657 [D loss: (-4.377)(R -2.618, F -6.137)]  [G loss: 6.383] \n",
      "1658 [D loss: (-4.279)(R -2.305, F -6.253)]  [G loss: 6.467] \n",
      "1658 [D loss: (-4.220)(R -2.218, F -6.222)]  [G loss: 6.541] \n",
      "1659 [D loss: (-4.566)(R -2.700, F -6.432)]  [G loss: 6.745] \n",
      "1659 [D loss: (-4.167)(R -1.767, F -6.566)]  [G loss: 6.879] \n",
      "1660 [D loss: (-4.420)(R -2.191, F -6.650)]  [G loss: 6.728] \n",
      "1660 [D loss: (-4.554)(R -2.566, F -6.543)]  [G loss: 6.776] \n",
      "1661 [D loss: (-4.246)(R -2.096, F -6.396)]  [G loss: 6.617] \n",
      "1661 [D loss: (-4.213)(R -1.964, F -6.462)]  [G loss: 6.689] \n",
      "1662 [D loss: (-4.163)(R -1.911, F -6.415)]  [G loss: 6.859] \n",
      "1662 [D loss: (-4.218)(R -2.018, F -6.419)]  [G loss: 6.739] \n",
      "1663 [D loss: (-4.043)(R -1.685, F -6.401)]  [G loss: 6.791] \n",
      "1663 [D loss: (-4.455)(R -2.671, F -6.238)]  [G loss: 6.539] \n",
      "1664 [D loss: (-4.362)(R -2.054, F -6.670)]  [G loss: 6.856] \n",
      "1664 [D loss: (-4.137)(R -1.579, F -6.695)]  [G loss: 7.103] \n",
      "1665 [D loss: (-4.295)(R -1.524, F -7.065)]  [G loss: 7.175] \n",
      "1665 [D loss: (-4.591)(R -1.843, F -7.338)]  [G loss: 7.503] \n",
      "1666 [D loss: (-4.444)(R -1.320, F -7.568)]  [G loss: 7.829] \n",
      "1666 [D loss: (-4.512)(R -1.212, F -7.812)]  [G loss: 7.837] \n",
      "1667 [D loss: (-4.214)(R -0.934, F -7.493)]  [G loss: 7.832] \n",
      "1667 [D loss: (-4.416)(R -1.248, F -7.583)]  [G loss: 7.853] \n",
      "1668 [D loss: (-4.213)(R -1.306, F -7.121)]  [G loss: 7.551] \n",
      "1668 [D loss: (-4.201)(R -1.500, F -6.902)]  [G loss: 7.271] \n",
      "1669 [D loss: (-4.373)(R -2.128, F -6.618)]  [G loss: 7.157] \n",
      "1669 [D loss: (-4.153)(R -1.693, F -6.613)]  [G loss: 6.835] \n",
      "1670 [D loss: (-4.410)(R -2.324, F -6.496)]  [G loss: 6.762] \n",
      "1670 [D loss: (-4.561)(R -2.440, F -6.682)]  [G loss: 6.808] \n",
      "1671 [D loss: (-4.230)(R -2.021, F -6.438)]  [G loss: 6.951] \n",
      "1671 [D loss: (-4.344)(R -2.289, F -6.400)]  [G loss: 6.770] \n",
      "1672 [D loss: (-4.657)(R -2.477, F -6.836)]  [G loss: 6.906] \n",
      "1672 [D loss: (-4.306)(R -1.890, F -6.722)]  [G loss: 7.055] \n",
      "1673 [D loss: (-4.604)(R -2.159, F -7.049)]  [G loss: 7.177] \n",
      "1673 [D loss: (-4.479)(R -1.715, F -7.243)]  [G loss: 7.395] \n",
      "1674 [D loss: (-4.556)(R -1.975, F -7.137)]  [G loss: 7.218] \n",
      "1674 [D loss: (-4.249)(R -1.906, F -6.593)]  [G loss: 7.184] \n",
      "1675 [D loss: (-4.222)(R -1.936, F -6.508)]  [G loss: 6.864] \n",
      "1675 [D loss: (-4.525)(R -2.527, F -6.524)]  [G loss: 6.930] \n",
      "1676 [D loss: (-4.503)(R -2.430, F -6.575)]  [G loss: 6.776] \n",
      "1676 [D loss: (-4.477)(R -2.389, F -6.566)]  [G loss: 6.664] \n",
      "1677 [D loss: (-4.456)(R -2.641, F -6.272)]  [G loss: 6.432] \n",
      "1677 [D loss: (-4.332)(R -2.688, F -5.977)]  [G loss: 6.325] \n",
      "1678 [D loss: (-4.605)(R -2.978, F -6.233)]  [G loss: 6.450] \n",
      "1678 [D loss: (-4.524)(R -2.463, F -6.585)]  [G loss: 6.614] \n",
      "1679 [D loss: (-4.408)(R -2.184, F -6.632)]  [G loss: 6.828] \n",
      "1679 [D loss: (-4.326)(R -2.430, F -6.222)]  [G loss: 6.740] \n",
      "1680 [D loss: (-4.452)(R -2.609, F -6.295)]  [G loss: 6.587] \n",
      "1680 [D loss: (-4.608)(R -2.785, F -6.431)]  [G loss: 6.732] \n",
      "1681 [D loss: (-4.531)(R -2.250, F -6.813)]  [G loss: 6.927] \n",
      "1681 [D loss: (-4.404)(R -1.891, F -6.917)]  [G loss: 7.247] \n",
      "1682 [D loss: (-4.406)(R -1.865, F -6.948)]  [G loss: 7.497] \n",
      "1682 [D loss: (-4.418)(R -1.819, F -7.017)]  [G loss: 7.240] \n",
      "1683 [D loss: (-4.596)(R -2.289, F -6.903)]  [G loss: 7.350] \n",
      "1683 [D loss: (-4.501)(R -2.152, F -6.851)]  [G loss: 7.272] \n",
      "1684 [D loss: (-4.559)(R -1.863, F -7.255)]  [G loss: 7.376] \n",
      "1684 [D loss: (-4.149)(R -1.190, F -7.107)]  [G loss: 7.631] \n",
      "1685 [D loss: (-4.344)(R -1.423, F -7.265)]  [G loss: 7.479] \n",
      "1685 [D loss: (-4.252)(R -1.257, F -7.248)]  [G loss: 7.398] \n",
      "1686 [D loss: (-4.724)(R -2.172, F -7.276)]  [G loss: 7.371] \n",
      "1686 [D loss: (-4.515)(R -1.846, F -7.183)]  [G loss: 7.535] \n",
      "1687 [D loss: (-4.386)(R -1.723, F -7.050)]  [G loss: 7.418] \n",
      "1687 [D loss: (-4.534)(R -1.566, F -7.502)]  [G loss: 7.467] \n",
      "1688 [D loss: (-4.459)(R -1.486, F -7.432)]  [G loss: 7.608] \n",
      "1688 [D loss: (-4.259)(R -1.123, F -7.396)]  [G loss: 7.387] \n",
      "1689 [D loss: (-4.280)(R -1.224, F -7.336)]  [G loss: 7.525] \n",
      "1689 [D loss: (-4.368)(R -1.670, F -7.065)]  [G loss: 7.208] \n",
      "1690 [D loss: (-4.411)(R -1.840, F -6.981)]  [G loss: 7.237] \n",
      "1690 [D loss: (-4.399)(R -1.723, F -7.075)]  [G loss: 7.316] \n",
      "1691 [D loss: (-4.264)(R -1.853, F -6.675)]  [G loss: 7.302] \n",
      "1691 [D loss: (-4.659)(R -1.745, F -7.573)]  [G loss: 7.554] \n",
      "1692 [D loss: (-4.323)(R -0.886, F -7.761)]  [G loss: 7.938] \n",
      "1692 [D loss: (-4.449)(R -0.854, F -8.044)]  [G loss: 7.873] \n",
      "1693 [D loss: (-4.332)(R -0.682, F -7.982)]  [G loss: 8.308] \n",
      "1693 [D loss: (-4.313)(R -0.636, F -7.990)]  [G loss: 7.922] \n",
      "1694 [D loss: (-4.283)(R -1.000, F -7.567)]  [G loss: 7.944] \n",
      "1694 [D loss: (-4.132)(R -0.990, F -7.274)]  [G loss: 7.677] \n",
      "1695 [D loss: (-4.297)(R -1.701, F -6.892)]  [G loss: 7.062] \n",
      "1695 [D loss: (-4.327)(R -1.774, F -6.879)]  [G loss: 6.974] \n",
      "1696 [D loss: (-4.353)(R -1.717, F -6.989)]  [G loss: 7.483] \n",
      "1696 [D loss: (-4.232)(R -1.885, F -6.580)]  [G loss: 6.960] \n",
      "1697 [D loss: (-4.330)(R -1.894, F -6.766)]  [G loss: 7.071] \n",
      "1697 [D loss: (-4.329)(R -1.983, F -6.675)]  [G loss: 7.133] \n",
      "1698 [D loss: (-4.322)(R -1.807, F -6.836)]  [G loss: 7.050] \n",
      "1698 [D loss: (-4.315)(R -1.626, F -7.005)]  [G loss: 6.961] \n",
      "1699 [D loss: (-4.401)(R -1.908, F -6.895)]  [G loss: 7.381] \n",
      "1699 [D loss: (-4.218)(R -1.559, F -6.877)]  [G loss: 7.401] \n",
      "1700 [D loss: (-4.402)(R -1.625, F -7.180)]  [G loss: 7.480] \n",
      "1700 [D loss: (-4.404)(R -1.373, F -7.435)]  [G loss: 7.621] \n",
      "1701 [D loss: (-4.132)(R -1.172, F -7.092)]  [G loss: 7.529] \n",
      "1701 [D loss: (-4.310)(R -1.197, F -7.423)]  [G loss: 7.385] \n",
      "1702 [D loss: (-4.375)(R -1.718, F -7.031)]  [G loss: 7.241] \n",
      "1702 [D loss: (-4.352)(R -1.513, F -7.191)]  [G loss: 7.363] \n",
      "1703 [D loss: (-4.476)(R -1.324, F -7.627)]  [G loss: 7.519] \n",
      "1703 [D loss: (-3.960)(R -1.039, F -6.880)]  [G loss: 7.781] \n",
      "1704 [D loss: (-4.279)(R -1.382, F -7.177)]  [G loss: 7.377] \n",
      "1704 [D loss: (-4.358)(R -1.151, F -7.565)]  [G loss: 7.552] \n",
      "1705 [D loss: (-4.280)(R -1.044, F -7.515)]  [G loss: 7.417] \n",
      "1705 [D loss: (-3.986)(R -0.884, F -7.089)]  [G loss: 7.447] \n",
      "1706 [D loss: (-4.124)(R -1.091, F -7.158)]  [G loss: 7.612] \n",
      "1706 [D loss: (-4.244)(R -1.349, F -7.138)]  [G loss: 7.620] \n",
      "1707 [D loss: (-4.299)(R -1.099, F -7.499)]  [G loss: 7.658] \n",
      "1707 [D loss: (-4.129)(R -1.336, F -6.922)]  [G loss: 7.505] \n",
      "1708 [D loss: (-4.560)(R -1.842, F -7.279)]  [G loss: 7.142] \n",
      "1708 [D loss: (-4.299)(R -1.616, F -6.981)]  [G loss: 7.222] \n",
      "1709 [D loss: (-4.512)(R -1.759, F -7.265)]  [G loss: 7.412] \n",
      "1709 [D loss: (-4.160)(R -1.604, F -6.717)]  [G loss: 7.249] \n",
      "1710 [D loss: (-4.161)(R -1.249, F -7.073)]  [G loss: 7.119] \n",
      "1710 [D loss: (-4.205)(R -1.542, F -6.869)]  [G loss: 7.282] \n",
      "1711 [D loss: (-3.992)(R -1.570, F -6.413)]  [G loss: 7.037] \n",
      "1711 [D loss: (-4.140)(R -1.856, F -6.425)]  [G loss: 6.634] \n",
      "1712 [D loss: (-4.403)(R -2.349, F -6.458)]  [G loss: 6.565] \n",
      "1712 [D loss: (-4.189)(R -1.934, F -6.444)]  [G loss: 6.592] \n",
      "1713 [D loss: (-4.222)(R -2.160, F -6.285)]  [G loss: 6.591] \n",
      "1713 [D loss: (-4.494)(R -2.520, F -6.469)]  [G loss: 6.557] \n",
      "1714 [D loss: (-4.176)(R -2.045, F -6.306)]  [G loss: 6.955] \n",
      "1714 [D loss: (-4.277)(R -1.783, F -6.771)]  [G loss: 6.738] \n",
      "1715 [D loss: (-4.222)(R -1.849, F -6.594)]  [G loss: 7.050] \n",
      "1715 [D loss: (-4.038)(R -1.501, F -6.575)]  [G loss: 6.776] \n",
      "1716 [D loss: (-4.347)(R -2.042, F -6.652)]  [G loss: 6.897] \n",
      "1716 [D loss: (-4.300)(R -1.745, F -6.855)]  [G loss: 6.923] \n",
      "1717 [D loss: (-4.404)(R -1.943, F -6.865)]  [G loss: 6.838] \n",
      "1717 [D loss: (-4.094)(R -1.850, F -6.338)]  [G loss: 7.260] \n",
      "1718 [D loss: (-4.505)(R -1.865, F -7.144)]  [G loss: 7.182] \n",
      "1718 [D loss: (-4.183)(R -1.702, F -6.663)]  [G loss: 7.127] \n",
      "1719 [D loss: (-3.911)(R -1.278, F -6.544)]  [G loss: 7.110] \n",
      "1719 [D loss: (-3.898)(R -1.742, F -6.054)]  [G loss: 6.729] \n",
      "1720 [D loss: (-3.837)(R -1.862, F -5.812)]  [G loss: 6.243] \n",
      "1720 [D loss: (-4.169)(R -2.078, F -6.261)]  [G loss: 6.634] \n",
      "1721 [D loss: (-4.093)(R -1.778, F -6.408)]  [G loss: 6.745] \n",
      "1721 [D loss: (-4.407)(R -1.654, F -7.160)]  [G loss: 6.986] \n",
      "1722 [D loss: (-4.376)(R -1.653, F -7.098)]  [G loss: 6.930] \n",
      "1722 [D loss: (-4.183)(R -1.468, F -6.897)]  [G loss: 6.898] \n",
      "1723 [D loss: (-4.181)(R -1.541, F -6.821)]  [G loss: 6.681] \n",
      "1723 [D loss: (-4.162)(R -1.776, F -6.548)]  [G loss: 6.927] \n",
      "1724 [D loss: (-3.978)(R -1.803, F -6.154)]  [G loss: 6.574] \n",
      "1724 [D loss: (-4.561)(R -2.703, F -6.419)]  [G loss: 6.256] \n",
      "1725 [D loss: (-4.333)(R -1.873, F -6.792)]  [G loss: 6.329] \n",
      "1725 [D loss: (-3.933)(R -1.789, F -6.078)]  [G loss: 6.551] \n",
      "1726 [D loss: (-4.092)(R -2.114, F -6.071)]  [G loss: 6.940] \n",
      "1726 [D loss: (-4.171)(R -1.597, F -6.745)]  [G loss: 6.560] \n",
      "1727 [D loss: (-4.348)(R -1.616, F -7.080)]  [G loss: 6.950] \n",
      "1727 [D loss: (-4.181)(R -1.782, F -6.580)]  [G loss: 6.881] \n",
      "1728 [D loss: (-4.013)(R -1.849, F -6.176)]  [G loss: 6.440] \n",
      "1728 [D loss: (-4.278)(R -1.771, F -6.784)]  [G loss: 6.741] \n",
      "1729 [D loss: (-4.582)(R -1.752, F -7.412)]  [G loss: 6.600] \n",
      "1729 [D loss: (-4.255)(R -1.435, F -7.076)]  [G loss: 7.342] \n",
      "1730 [D loss: (-4.275)(R -1.168, F -7.383)]  [G loss: 7.282] \n",
      "1730 [D loss: (-4.125)(R -0.982, F -7.269)]  [G loss: 7.086] \n",
      "1731 [D loss: (-4.183)(R -1.215, F -7.151)]  [G loss: 7.206] \n",
      "1731 [D loss: (-4.132)(R -1.588, F -6.676)]  [G loss: 7.136] \n",
      "1732 [D loss: (-3.777)(R -1.360, F -6.194)]  [G loss: 7.089] \n",
      "1732 [D loss: (-4.210)(R -1.937, F -6.482)]  [G loss: 6.884] \n",
      "1733 [D loss: (-3.760)(R -1.859, F -5.661)]  [G loss: 6.481] \n",
      "1733 [D loss: (-4.441)(R -2.403, F -6.479)]  [G loss: 6.406] \n",
      "1734 [D loss: (-4.415)(R -2.420, F -6.410)]  [G loss: 6.226] \n",
      "1734 [D loss: (-4.148)(R -2.438, F -5.859)]  [G loss: 6.064] \n",
      "1735 [D loss: (-4.079)(R -2.149, F -6.010)]  [G loss: 6.356] \n",
      "1735 [D loss: (-4.353)(R -2.226, F -6.479)]  [G loss: 6.521] \n",
      "1736 [D loss: (-4.500)(R -2.548, F -6.452)]  [G loss: 6.247] \n",
      "1736 [D loss: (-4.775)(R -2.963, F -6.587)]  [G loss: 6.410] \n",
      "1737 [D loss: (-4.516)(R -2.835, F -6.197)]  [G loss: 6.307] \n",
      "1737 [D loss: (-4.369)(R -2.072, F -6.666)]  [G loss: 6.572] \n",
      "1738 [D loss: (-3.659)(R -1.968, F -5.350)]  [G loss: 6.580] \n",
      "1738 [D loss: (-4.435)(R -2.583, F -6.287)]  [G loss: 6.091] \n",
      "1739 [D loss: (-4.337)(R -2.661, F -6.012)]  [G loss: 6.339] \n",
      "1739 [D loss: (-4.122)(R -2.352, F -5.892)]  [G loss: 6.198] \n",
      "1740 [D loss: (-3.577)(R -2.409, F -4.745)]  [G loss: 6.499] \n",
      "1740 [D loss: (-4.273)(R -2.527, F -6.020)]  [G loss: 6.031] \n",
      "1741 [D loss: (-3.799)(R -2.124, F -5.474)]  [G loss: 5.869] \n",
      "1741 [D loss: (-4.189)(R -2.535, F -5.843)]  [G loss: 6.145] \n",
      "1742 [D loss: (-4.413)(R -2.614, F -6.213)]  [G loss: 5.942] \n",
      "1742 [D loss: (-4.177)(R -2.414, F -5.940)]  [G loss: 5.456] \n",
      "1743 [D loss: (-4.072)(R -2.870, F -5.274)]  [G loss: 5.555] \n",
      "1743 [D loss: (-4.780)(R -2.879, F -6.681)]  [G loss: 5.877] \n",
      "1744 [D loss: (-4.479)(R -2.970, F -5.989)]  [G loss: 5.271] \n",
      "1744 [D loss: (-3.906)(R -2.742, F -5.071)]  [G loss: 5.822] \n",
      "1745 [D loss: (-4.147)(R -2.908, F -5.385)]  [G loss: 5.768] \n",
      "1745 [D loss: (-4.478)(R -3.184, F -5.772)]  [G loss: 5.264] \n",
      "1746 [D loss: (-4.413)(R -3.022, F -5.805)]  [G loss: 5.824] \n",
      "1746 [D loss: (-4.451)(R -2.767, F -6.135)]  [G loss: 5.420] \n",
      "1747 [D loss: (-4.434)(R -2.923, F -5.945)]  [G loss: 5.762] \n",
      "1747 [D loss: (-4.149)(R -2.584, F -5.715)]  [G loss: 6.122] \n",
      "1748 [D loss: (-4.309)(R -2.719, F -5.898)]  [G loss: 5.952] \n",
      "1748 [D loss: (-4.018)(R -2.789, F -5.248)]  [G loss: 5.656] \n",
      "1749 [D loss: (-3.686)(R -2.677, F -4.695)]  [G loss: 5.413] \n",
      "1749 [D loss: (-4.224)(R -3.219, F -5.229)]  [G loss: 4.927] \n",
      "1750 [D loss: (-4.467)(R -3.292, F -5.643)]  [G loss: 4.916] \n",
      "1750 [D loss: (-3.957)(R -2.790, F -5.124)]  [G loss: 5.095] \n",
      "1751 [D loss: (-3.880)(R -2.922, F -4.838)]  [G loss: 4.822] \n",
      "1751 [D loss: (-4.025)(R -3.135, F -4.914)]  [G loss: 5.152] \n",
      "1752 [D loss: (-4.164)(R -3.467, F -4.861)]  [G loss: 5.183] \n",
      "1752 [D loss: (-3.804)(R -3.152, F -4.456)]  [G loss: 5.590] \n",
      "1753 [D loss: (-3.849)(R -3.184, F -4.514)]  [G loss: 5.049] \n",
      "1753 [D loss: (-4.167)(R -3.426, F -4.908)]  [G loss: 4.715] \n",
      "1754 [D loss: (-4.070)(R -3.552, F -4.588)]  [G loss: 4.493] \n",
      "1754 [D loss: (-3.743)(R -3.840, F -3.646)]  [G loss: 4.807] \n",
      "1755 [D loss: (-4.521)(R -3.828, F -5.214)]  [G loss: 4.821] \n",
      "1755 [D loss: (-4.131)(R -3.372, F -4.889)]  [G loss: 5.241] \n",
      "1756 [D loss: (-4.252)(R -3.181, F -5.322)]  [G loss: 4.925] \n",
      "1756 [D loss: (-4.594)(R -3.282, F -5.907)]  [G loss: 5.212] \n",
      "1757 [D loss: (-4.234)(R -3.262, F -5.207)]  [G loss: 5.433] \n",
      "1757 [D loss: (-4.076)(R -3.123, F -5.029)]  [G loss: 5.066] \n",
      "1758 [D loss: (-3.884)(R -3.058, F -4.710)]  [G loss: 5.473] \n",
      "1758 [D loss: (-4.124)(R -3.818, F -4.431)]  [G loss: 4.906] \n",
      "1759 [D loss: (-4.223)(R -4.122, F -4.323)]  [G loss: 4.696] \n",
      "1759 [D loss: (-3.758)(R -2.988, F -4.529)]  [G loss: 5.246] \n",
      "1760 [D loss: (-3.861)(R -3.414, F -4.308)]  [G loss: 4.610] \n",
      "1760 [D loss: (-4.120)(R -2.901, F -5.339)]  [G loss: 4.927] \n",
      "1761 [D loss: (-3.504)(R -3.215, F -3.793)]  [G loss: 4.837] \n",
      "1761 [D loss: (-3.983)(R -3.218, F -4.748)]  [G loss: 5.071] \n",
      "1762 [D loss: (-4.109)(R -3.360, F -4.859)]  [G loss: 5.241] \n",
      "1762 [D loss: (-4.173)(R -3.252, F -5.093)]  [G loss: 4.745] \n",
      "1763 [D loss: (-4.034)(R -3.313, F -4.756)]  [G loss: 4.816] \n",
      "1763 [D loss: (-4.131)(R -3.149, F -5.113)]  [G loss: 5.262] \n",
      "1764 [D loss: (-3.776)(R -3.044, F -4.508)]  [G loss: 4.893] \n",
      "1764 [D loss: (-3.860)(R -3.019, F -4.702)]  [G loss: 5.400] \n",
      "1765 [D loss: (-4.662)(R -3.872, F -5.452)]  [G loss: 4.813] \n",
      "1765 [D loss: (-4.094)(R -3.704, F -4.484)]  [G loss: 5.192] \n",
      "1766 [D loss: (-4.260)(R -3.535, F -4.986)]  [G loss: 4.338] \n",
      "1766 [D loss: (-3.673)(R -3.017, F -4.329)]  [G loss: 4.907] \n",
      "1767 [D loss: (-3.734)(R -3.363, F -4.106)]  [G loss: 4.624] \n",
      "1767 [D loss: (-4.087)(R -3.765, F -4.408)]  [G loss: 4.448] \n",
      "1768 [D loss: (-3.755)(R -4.070, F -3.441)]  [G loss: 4.644] \n",
      "1768 [D loss: (-4.617)(R -3.702, F -5.532)]  [G loss: 4.488] \n",
      "1769 [D loss: (-3.604)(R -3.085, F -4.122)]  [G loss: 4.509] \n",
      "1769 [D loss: (-4.333)(R -3.149, F -5.518)]  [G loss: 4.737] \n",
      "1770 [D loss: (-4.450)(R -4.012, F -4.888)]  [G loss: 4.413] \n",
      "1770 [D loss: (-3.794)(R -3.274, F -4.314)]  [G loss: 4.897] \n",
      "1771 [D loss: (-3.913)(R -3.547, F -4.279)]  [G loss: 5.265] \n",
      "1771 [D loss: (-4.270)(R -3.920, F -4.620)]  [G loss: 4.834] \n",
      "1772 [D loss: (-4.042)(R -3.373, F -4.712)]  [G loss: 4.480] \n",
      "1772 [D loss: (-3.938)(R -3.986, F -3.889)]  [G loss: 4.632] \n",
      "1773 [D loss: (-4.428)(R -3.618, F -5.239)]  [G loss: 4.380] \n",
      "1773 [D loss: (-4.057)(R -3.446, F -4.668)]  [G loss: 4.726] \n",
      "1774 [D loss: (-4.614)(R -4.043, F -5.186)]  [G loss: 4.982] \n",
      "1774 [D loss: (-3.640)(R -3.292, F -3.989)]  [G loss: 4.309] \n",
      "1775 [D loss: (-3.615)(R -3.959, F -3.271)]  [G loss: 4.110] \n",
      "1775 [D loss: (-3.832)(R -3.867, F -3.797)]  [G loss: 4.530] \n",
      "1776 [D loss: (-3.925)(R -3.759, F -4.090)]  [G loss: 4.319] \n",
      "1776 [D loss: (-3.772)(R -4.103, F -3.441)]  [G loss: 4.434] \n",
      "1777 [D loss: (-3.939)(R -4.295, F -3.584)]  [G loss: 4.446] \n",
      "1777 [D loss: (-3.874)(R -3.718, F -4.030)]  [G loss: 4.396] \n",
      "1778 [D loss: (-4.576)(R -4.321, F -4.831)]  [G loss: 4.365] \n",
      "1778 [D loss: (-3.662)(R -3.923, F -3.401)]  [G loss: 3.922] \n",
      "1779 [D loss: (-3.777)(R -3.817, F -3.738)]  [G loss: 4.288] \n",
      "1779 [D loss: (-4.063)(R -4.129, F -3.997)]  [G loss: 4.296] \n",
      "1780 [D loss: (-3.598)(R -3.962, F -3.234)]  [G loss: 4.745] \n",
      "1780 [D loss: (-4.258)(R -4.097, F -4.419)]  [G loss: 4.384] \n",
      "1781 [D loss: (-4.090)(R -3.596, F -4.584)]  [G loss: 4.002] \n",
      "1781 [D loss: (-3.562)(R -3.763, F -3.361)]  [G loss: 4.063] \n",
      "1782 [D loss: (-3.750)(R -4.446, F -3.054)]  [G loss: 4.214] \n",
      "1782 [D loss: (-3.106)(R -3.393, F -2.819)]  [G loss: 3.638] \n",
      "1783 [D loss: (-3.839)(R -3.422, F -4.256)]  [G loss: 3.561] \n",
      "1783 [D loss: (-4.111)(R -4.102, F -4.121)]  [G loss: 3.940] \n",
      "1784 [D loss: (-3.516)(R -3.481, F -3.551)]  [G loss: 4.966] \n",
      "1784 [D loss: (-4.029)(R -3.857, F -4.201)]  [G loss: 3.690] \n",
      "1785 [D loss: (-3.592)(R -4.223, F -2.961)]  [G loss: 4.166] \n",
      "1785 [D loss: (-3.895)(R -3.645, F -4.146)]  [G loss: 3.730] \n",
      "1786 [D loss: (-3.270)(R -3.553, F -2.988)]  [G loss: 4.508] \n",
      "1786 [D loss: (-4.074)(R -3.936, F -4.212)]  [G loss: 4.093] \n",
      "1787 [D loss: (-3.437)(R -3.237, F -3.637)]  [G loss: 4.671] \n",
      "1787 [D loss: (-3.750)(R -3.650, F -3.850)]  [G loss: 4.209] \n",
      "1788 [D loss: (-3.908)(R -3.969, F -3.847)]  [G loss: 4.155] \n",
      "1788 [D loss: (-4.148)(R -4.087, F -4.209)]  [G loss: 4.088] \n",
      "1789 [D loss: (-4.786)(R -4.118, F -5.455)]  [G loss: 3.886] \n",
      "1789 [D loss: (-3.846)(R -4.036, F -3.657)]  [G loss: 4.388] \n",
      "1790 [D loss: (-3.517)(R -3.695, F -3.338)]  [G loss: 4.128] \n",
      "1790 [D loss: (-3.647)(R -3.857, F -3.436)]  [G loss: 4.215] \n",
      "1791 [D loss: (-4.037)(R -3.932, F -4.142)]  [G loss: 2.934] \n",
      "1791 [D loss: (-4.277)(R -3.886, F -4.668)]  [G loss: 3.717] \n",
      "1792 [D loss: (-3.497)(R -3.867, F -3.128)]  [G loss: 4.538] \n",
      "1792 [D loss: (-3.716)(R -3.559, F -3.873)]  [G loss: 4.086] \n",
      "1793 [D loss: (-4.479)(R -3.806, F -5.151)]  [G loss: 3.439] \n",
      "1793 [D loss: (-4.061)(R -4.467, F -3.654)]  [G loss: 3.916] \n",
      "1794 [D loss: (-3.503)(R -3.862, F -3.145)]  [G loss: 3.911] \n",
      "1794 [D loss: (-4.103)(R -3.553, F -4.653)]  [G loss: 3.868] \n",
      "1795 [D loss: (-4.692)(R -4.338, F -5.045)]  [G loss: 3.703] \n",
      "1795 [D loss: (-4.530)(R -4.217, F -4.844)]  [G loss: 4.440] \n",
      "1796 [D loss: (-3.641)(R -3.683, F -3.598)]  [G loss: 3.723] \n",
      "1796 [D loss: (-4.092)(R -3.808, F -4.375)]  [G loss: 4.202] \n",
      "1797 [D loss: (-4.108)(R -3.633, F -4.584)]  [G loss: 3.560] \n",
      "1797 [D loss: (-3.904)(R -3.591, F -4.216)]  [G loss: 3.761] \n",
      "1798 [D loss: (-3.741)(R -3.295, F -4.187)]  [G loss: 4.006] \n",
      "1798 [D loss: (-4.069)(R -4.088, F -4.049)]  [G loss: 3.549] \n",
      "1799 [D loss: (-3.444)(R -3.709, F -3.178)]  [G loss: 3.095] \n",
      "1799 [D loss: (-3.318)(R -4.084, F -2.552)]  [G loss: 3.314] \n",
      "1800 [D loss: (-3.421)(R -4.528, F -2.314)]  [G loss: 3.968] \n",
      "1800 [D loss: (-4.291)(R -4.521, F -4.062)]  [G loss: 2.879] \n",
      "1801 [D loss: (-3.226)(R -4.758, F -1.693)]  [G loss: 3.458] \n",
      "1801 [D loss: (-4.369)(R -4.885, F -3.852)]  [G loss: 3.393] \n",
      "1802 [D loss: (-4.075)(R -4.736, F -3.414)]  [G loss: 3.282] \n",
      "1802 [D loss: (-3.486)(R -4.150, F -2.822)]  [G loss: 3.067] \n",
      "1803 [D loss: (-3.515)(R -4.146, F -2.884)]  [G loss: 3.046] \n",
      "1803 [D loss: (-4.365)(R -4.499, F -4.230)]  [G loss: 3.169] \n",
      "1804 [D loss: (-4.023)(R -4.087, F -3.958)]  [G loss: 2.992] \n",
      "1804 [D loss: (-3.748)(R -3.962, F -3.535)]  [G loss: 4.155] \n",
      "1805 [D loss: (-3.199)(R -4.025, F -2.373)]  [G loss: 3.854] \n",
      "1805 [D loss: (-3.118)(R -3.825, F -2.411)]  [G loss: 3.705] \n",
      "1806 [D loss: (-4.040)(R -4.266, F -3.815)]  [G loss: 3.470] \n",
      "1806 [D loss: (-3.261)(R -4.256, F -2.266)]  [G loss: 3.216] \n",
      "1807 [D loss: (-3.751)(R -4.821, F -2.680)]  [G loss: 2.649] \n",
      "1807 [D loss: (-3.495)(R -4.385, F -2.605)]  [G loss: 3.101] \n",
      "1808 [D loss: (-3.323)(R -3.810, F -2.836)]  [G loss: 3.464] \n",
      "1808 [D loss: (-3.846)(R -4.553, F -3.140)]  [G loss: 2.918] \n",
      "1809 [D loss: (-3.720)(R -4.311, F -3.128)]  [G loss: 3.126] \n",
      "1809 [D loss: (-3.728)(R -4.295, F -3.160)]  [G loss: 3.099] \n",
      "1810 [D loss: (-3.419)(R -4.135, F -2.702)]  [G loss: 3.211] \n",
      "1810 [D loss: (-3.254)(R -4.445, F -2.063)]  [G loss: 3.832] \n",
      "1811 [D loss: (-3.192)(R -4.123, F -2.262)]  [G loss: 3.166] \n",
      "1811 [D loss: (-4.266)(R -4.496, F -4.035)]  [G loss: 2.699] \n",
      "1812 [D loss: (-3.577)(R -4.387, F -2.766)]  [G loss: 3.160] \n",
      "1812 [D loss: (-3.524)(R -4.698, F -2.351)]  [G loss: 3.557] \n",
      "1813 [D loss: (-3.873)(R -4.225, F -3.520)]  [G loss: 3.059] \n",
      "1813 [D loss: (-3.145)(R -4.277, F -2.013)]  [G loss: 3.170] \n",
      "1814 [D loss: (-3.851)(R -4.174, F -3.528)]  [G loss: 2.635] \n",
      "1814 [D loss: (-3.675)(R -4.589, F -2.760)]  [G loss: 2.837] \n",
      "1815 [D loss: (-3.965)(R -4.791, F -3.139)]  [G loss: 2.585] \n",
      "1815 [D loss: (-4.201)(R -4.660, F -3.741)]  [G loss: 3.067] \n",
      "1816 [D loss: (-3.914)(R -4.300, F -3.528)]  [G loss: 3.198] \n",
      "1816 [D loss: (-3.493)(R -4.217, F -2.769)]  [G loss: 3.399] \n",
      "1817 [D loss: (-3.232)(R -4.280, F -2.185)]  [G loss: 2.814] \n",
      "1817 [D loss: (-4.151)(R -4.134, F -4.168)]  [G loss: 3.682] \n",
      "1818 [D loss: (-3.168)(R -3.987, F -2.350)]  [G loss: 2.806] \n",
      "1818 [D loss: (-3.517)(R -4.311, F -2.723)]  [G loss: 2.814] \n",
      "1819 [D loss: (-3.330)(R -4.702, F -1.958)]  [G loss: 3.101] \n",
      "1819 [D loss: (-3.611)(R -4.345, F -2.877)]  [G loss: 2.304] \n",
      "1820 [D loss: (-4.089)(R -4.566, F -3.612)]  [G loss: 3.407] \n",
      "1820 [D loss: (-3.739)(R -3.865, F -3.613)]  [G loss: 2.621] \n",
      "1821 [D loss: (-3.897)(R -4.261, F -3.533)]  [G loss: 3.071] \n",
      "1821 [D loss: (-3.368)(R -4.248, F -2.488)]  [G loss: 3.208] \n",
      "1822 [D loss: (-3.278)(R -3.687, F -2.868)]  [G loss: 2.725] \n",
      "1822 [D loss: (-3.067)(R -3.887, F -2.248)]  [G loss: 3.456] \n",
      "1823 [D loss: (-3.738)(R -4.864, F -2.611)]  [G loss: 2.848] \n",
      "1823 [D loss: (-3.319)(R -4.104, F -2.535)]  [G loss: 2.988] \n",
      "1824 [D loss: (-3.258)(R -4.382, F -2.134)]  [G loss: 2.482] \n",
      "1824 [D loss: (-3.286)(R -4.217, F -2.354)]  [G loss: 2.266] \n",
      "1825 [D loss: (-3.686)(R -4.719, F -2.653)]  [G loss: 2.865] \n",
      "1825 [D loss: (-4.109)(R -4.361, F -3.857)]  [G loss: 3.100] \n",
      "1826 [D loss: (-3.272)(R -4.160, F -2.385)]  [G loss: 3.160] \n",
      "1826 [D loss: (-3.528)(R -4.172, F -2.885)]  [G loss: 3.104] \n",
      "1827 [D loss: (-3.532)(R -4.273, F -2.792)]  [G loss: 2.983] \n",
      "1827 [D loss: (-3.544)(R -3.887, F -3.201)]  [G loss: 2.646] \n",
      "1828 [D loss: (-3.472)(R -4.493, F -2.452)]  [G loss: 3.392] \n",
      "1828 [D loss: (-3.218)(R -3.868, F -2.568)]  [G loss: 3.565] \n",
      "1829 [D loss: (-3.524)(R -4.113, F -2.935)]  [G loss: 3.037] \n",
      "1829 [D loss: (-3.398)(R -4.086, F -2.709)]  [G loss: 3.099] \n",
      "1830 [D loss: (-3.284)(R -4.071, F -2.496)]  [G loss: 3.136] \n",
      "1830 [D loss: (-3.569)(R -3.863, F -3.274)]  [G loss: 3.383] \n",
      "1831 [D loss: (-3.476)(R -3.877, F -3.075)]  [G loss: 2.780] \n",
      "1831 [D loss: (-3.567)(R -3.288, F -3.847)]  [G loss: 3.035] \n",
      "1832 [D loss: (-4.410)(R -4.239, F -4.582)]  [G loss: 3.011] \n",
      "1832 [D loss: (-3.310)(R -3.386, F -3.233)]  [G loss: 2.601] \n",
      "1833 [D loss: (-3.486)(R -3.304, F -3.668)]  [G loss: 3.383] \n",
      "1833 [D loss: (-3.048)(R -3.417, F -2.680)]  [G loss: 3.299] \n",
      "1834 [D loss: (-4.118)(R -4.640, F -3.596)]  [G loss: 3.134] \n",
      "1834 [D loss: (-3.581)(R -4.237, F -2.925)]  [G loss: 3.118] \n",
      "1835 [D loss: (-3.669)(R -4.286, F -3.052)]  [G loss: 2.731] \n",
      "1835 [D loss: (-2.975)(R -3.498, F -2.453)]  [G loss: 2.618] \n",
      "1836 [D loss: (-3.682)(R -3.988, F -3.377)]  [G loss: 3.154] \n",
      "1836 [D loss: (-3.478)(R -3.774, F -3.182)]  [G loss: 3.468] \n",
      "1837 [D loss: (-3.717)(R -3.497, F -3.936)]  [G loss: 3.870] \n",
      "1837 [D loss: (-3.914)(R -3.789, F -4.040)]  [G loss: 3.920] \n",
      "1838 [D loss: (-3.933)(R -3.636, F -4.229)]  [G loss: 3.962] \n",
      "1838 [D loss: (-3.363)(R -3.585, F -3.140)]  [G loss: 4.324] \n",
      "1839 [D loss: (-3.442)(R -3.111, F -3.774)]  [G loss: 3.959] \n",
      "1839 [D loss: (-3.162)(R -2.959, F -3.365)]  [G loss: 3.474] \n",
      "1840 [D loss: (-4.185)(R -4.016, F -4.354)]  [G loss: 3.605] \n",
      "1840 [D loss: (-3.104)(R -3.644, F -2.565)]  [G loss: 3.411] \n",
      "1841 [D loss: (-3.468)(R -4.192, F -2.744)]  [G loss: 3.143] \n",
      "1841 [D loss: (-3.218)(R -3.853, F -2.583)]  [G loss: 2.958] \n",
      "1842 [D loss: (-3.194)(R -4.074, F -2.313)]  [G loss: 3.093] \n",
      "1842 [D loss: (-3.765)(R -4.489, F -3.042)]  [G loss: 3.052] \n",
      "1843 [D loss: (-3.525)(R -4.240, F -2.811)]  [G loss: 3.076] \n",
      "1843 [D loss: (-3.517)(R -3.703, F -3.331)]  [G loss: 3.089] \n",
      "1844 [D loss: (-3.965)(R -3.827, F -4.103)]  [G loss: 3.643] \n",
      "1844 [D loss: (-3.613)(R -3.758, F -3.469)]  [G loss: 3.948] \n",
      "1845 [D loss: (-3.875)(R -3.884, F -3.867)]  [G loss: 3.699] \n",
      "1845 [D loss: (-3.772)(R -3.087, F -4.457)]  [G loss: 3.755] \n",
      "1846 [D loss: (-3.929)(R -3.513, F -4.345)]  [G loss: 3.495] \n",
      "1846 [D loss: (-3.887)(R -3.286, F -4.488)]  [G loss: 4.170] \n",
      "1847 [D loss: (-3.430)(R -3.185, F -3.675)]  [G loss: 3.680] \n",
      "1847 [D loss: (-3.382)(R -3.559, F -3.204)]  [G loss: 3.757] \n",
      "1848 [D loss: (-3.691)(R -3.818, F -3.565)]  [G loss: 3.743] \n",
      "1848 [D loss: (-3.569)(R -3.389, F -3.749)]  [G loss: 4.152] \n",
      "1849 [D loss: (-3.665)(R -3.637, F -3.692)]  [G loss: 3.669] \n",
      "1849 [D loss: (-3.807)(R -3.619, F -3.995)]  [G loss: 3.708] \n",
      "1850 [D loss: (-3.469)(R -3.479, F -3.459)]  [G loss: 3.789] \n",
      "1850 [D loss: (-4.188)(R -3.625, F -4.752)]  [G loss: 3.874] \n",
      "1851 [D loss: (-3.955)(R -3.788, F -4.122)]  [G loss: 3.872] \n",
      "1851 [D loss: (-3.656)(R -3.064, F -4.248)]  [G loss: 4.313] \n",
      "1852 [D loss: (-3.427)(R -3.175, F -3.678)]  [G loss: 4.456] \n",
      "1852 [D loss: (-3.572)(R -3.217, F -3.927)]  [G loss: 4.543] \n",
      "1853 [D loss: (-3.577)(R -2.770, F -4.384)]  [G loss: 4.543] \n",
      "1853 [D loss: (-3.784)(R -3.463, F -4.105)]  [G loss: 4.374] \n",
      "1854 [D loss: (-3.802)(R -3.273, F -4.330)]  [G loss: 4.358] \n",
      "1854 [D loss: (-3.279)(R -2.927, F -3.631)]  [G loss: 4.471] \n",
      "1855 [D loss: (-3.791)(R -3.022, F -4.559)]  [G loss: 4.513] \n",
      "1855 [D loss: (-4.152)(R -3.709, F -4.594)]  [G loss: 4.351] \n",
      "1856 [D loss: (-3.569)(R -2.952, F -4.187)]  [G loss: 4.696] \n",
      "1856 [D loss: (-3.836)(R -3.097, F -4.574)]  [G loss: 4.871] \n",
      "1857 [D loss: (-3.423)(R -2.649, F -4.198)]  [G loss: 4.839] \n",
      "1857 [D loss: (-3.701)(R -3.146, F -4.257)]  [G loss: 4.980] \n",
      "1858 [D loss: (-3.892)(R -3.456, F -4.328)]  [G loss: 4.767] \n",
      "1858 [D loss: (-3.848)(R -3.290, F -4.406)]  [G loss: 4.439] \n",
      "1859 [D loss: (-3.662)(R -2.662, F -4.662)]  [G loss: 4.740] \n",
      "1859 [D loss: (-3.989)(R -3.034, F -4.944)]  [G loss: 4.841] \n",
      "1860 [D loss: (-3.841)(R -2.798, F -4.884)]  [G loss: 5.066] \n",
      "1860 [D loss: (-3.853)(R -2.611, F -5.095)]  [G loss: 5.438] \n",
      "1861 [D loss: (-3.817)(R -2.536, F -5.099)]  [G loss: 5.577] \n",
      "1861 [D loss: (-3.932)(R -2.261, F -5.603)]  [G loss: 5.731] \n",
      "1862 [D loss: (-3.870)(R -2.111, F -5.630)]  [G loss: 6.043] \n",
      "1862 [D loss: (-4.065)(R -1.695, F -6.434)]  [G loss: 6.038] \n",
      "1863 [D loss: (-3.602)(R -1.492, F -5.712)]  [G loss: 6.355] \n",
      "1863 [D loss: (-3.791)(R -1.512, F -6.070)]  [G loss: 6.656] \n",
      "1864 [D loss: (-4.066)(R -1.471, F -6.662)]  [G loss: 6.602] \n",
      "1864 [D loss: (-4.265)(R -1.915, F -6.615)]  [G loss: 6.805] \n",
      "1865 [D loss: (-3.926)(R -1.021, F -6.831)]  [G loss: 7.020] \n",
      "1865 [D loss: (-4.075)(R -1.234, F -6.916)]  [G loss: 7.158] \n",
      "1866 [D loss: (-4.246)(R -1.309, F -7.183)]  [G loss: 7.278] \n",
      "1866 [D loss: (-4.405)(R -1.642, F -7.167)]  [G loss: 7.285] \n",
      "1867 [D loss: (-4.376)(R -1.355, F -7.397)]  [G loss: 7.238] \n",
      "1867 [D loss: (-4.414)(R -1.598, F -7.229)]  [G loss: 7.496] \n",
      "1868 [D loss: (-4.650)(R -1.917, F -7.383)]  [G loss: 7.427] \n",
      "1868 [D loss: (-4.303)(R -1.440, F -7.167)]  [G loss: 7.487] \n",
      "1869 [D loss: (-4.203)(R -1.301, F -7.106)]  [G loss: 7.285] \n",
      "1869 [D loss: (-4.411)(R -1.882, F -6.940)]  [G loss: 7.196] \n",
      "1870 [D loss: (-4.573)(R -2.272, F -6.873)]  [G loss: 7.012] \n",
      "1870 [D loss: (-4.384)(R -1.950, F -6.817)]  [G loss: 6.977] \n",
      "1871 [D loss: (-4.691)(R -2.472, F -6.910)]  [G loss: 7.165] \n",
      "1871 [D loss: (-4.518)(R -2.055, F -6.982)]  [G loss: 7.144] \n",
      "1872 [D loss: (-4.347)(R -1.607, F -7.088)]  [G loss: 7.289] \n",
      "1872 [D loss: (-4.612)(R -2.069, F -7.155)]  [G loss: 7.318] \n",
      "1873 [D loss: (-4.657)(R -2.101, F -7.213)]  [G loss: 7.389] \n",
      "1873 [D loss: (-4.398)(R -1.935, F -6.860)]  [G loss: 7.242] \n",
      "1874 [D loss: (-4.466)(R -1.973, F -6.959)]  [G loss: 7.152] \n",
      "1874 [D loss: (-4.344)(R -1.768, F -6.919)]  [G loss: 7.186] \n",
      "1875 [D loss: (-4.211)(R -1.694, F -6.727)]  [G loss: 7.083] \n",
      "1875 [D loss: (-4.331)(R -1.974, F -6.688)]  [G loss: 6.958] \n",
      "1876 [D loss: (-4.337)(R -2.181, F -6.492)]  [G loss: 6.703] \n",
      "1876 [D loss: (-4.247)(R -2.195, F -6.299)]  [G loss: 6.678] \n",
      "1877 [D loss: (-4.536)(R -2.775, F -6.296)]  [G loss: 6.455] \n",
      "1877 [D loss: (-4.513)(R -2.824, F -6.201)]  [G loss: 6.374] \n",
      "1878 [D loss: (-4.237)(R -2.396, F -6.078)]  [G loss: 6.337] \n",
      "1878 [D loss: (-4.286)(R -2.319, F -6.252)]  [G loss: 6.345] \n",
      "1879 [D loss: (-4.325)(R -2.367, F -6.283)]  [G loss: 6.309] \n",
      "1879 [D loss: (-4.411)(R -2.790, F -6.032)]  [G loss: 6.230] \n",
      "1880 [D loss: (-4.391)(R -3.078, F -5.703)]  [G loss: 5.966] \n",
      "1880 [D loss: (-4.351)(R -2.902, F -5.800)]  [G loss: 5.839] \n",
      "1881 [D loss: (-4.414)(R -3.166, F -5.662)]  [G loss: 5.853] \n",
      "1881 [D loss: (-4.253)(R -3.043, F -5.463)]  [G loss: 5.723] \n",
      "1882 [D loss: (-4.287)(R -3.136, F -5.438)]  [G loss: 5.814] \n",
      "1882 [D loss: (-4.271)(R -3.105, F -5.437)]  [G loss: 5.567] \n",
      "1883 [D loss: (-4.364)(R -3.168, F -5.560)]  [G loss: 5.677] \n",
      "1883 [D loss: (-4.660)(R -3.507, F -5.813)]  [G loss: 5.801] \n",
      "1884 [D loss: (-4.294)(R -2.833, F -5.754)]  [G loss: 5.800] \n",
      "1884 [D loss: (-4.154)(R -2.702, F -5.606)]  [G loss: 5.735] \n",
      "1885 [D loss: (-4.315)(R -3.042, F -5.589)]  [G loss: 5.903] \n",
      "1885 [D loss: (-4.243)(R -2.795, F -5.691)]  [G loss: 6.006] \n",
      "1886 [D loss: (-4.598)(R -3.310, F -5.887)]  [G loss: 6.034] \n",
      "1886 [D loss: (-4.343)(R -2.692, F -5.995)]  [G loss: 6.180] \n",
      "1887 [D loss: (-4.283)(R -2.560, F -6.007)]  [G loss: 6.122] \n",
      "1887 [D loss: (-4.195)(R -2.440, F -5.950)]  [G loss: 6.195] \n",
      "1888 [D loss: (-4.280)(R -2.757, F -5.802)]  [G loss: 6.020] \n",
      "1888 [D loss: (-4.412)(R -3.167, F -5.657)]  [G loss: 6.294] \n",
      "1889 [D loss: (-4.467)(R -2.873, F -6.061)]  [G loss: 6.453] \n",
      "1889 [D loss: (-4.135)(R -2.246, F -6.023)]  [G loss: 6.190] \n",
      "1890 [D loss: (-4.192)(R -2.507, F -5.878)]  [G loss: 6.060] \n",
      "1890 [D loss: (-4.301)(R -3.030, F -5.572)]  [G loss: 5.734] \n",
      "1891 [D loss: (-4.473)(R -3.437, F -5.510)]  [G loss: 5.769] \n",
      "1891 [D loss: (-4.280)(R -3.037, F -5.522)]  [G loss: 5.738] \n",
      "1892 [D loss: (-4.136)(R -2.699, F -5.573)]  [G loss: 5.767] \n",
      "1892 [D loss: (-4.305)(R -3.133, F -5.476)]  [G loss: 5.623] \n",
      "1893 [D loss: (-4.348)(R -3.394, F -5.302)]  [G loss: 5.550] \n",
      "1893 [D loss: (-4.208)(R -3.066, F -5.350)]  [G loss: 5.372] \n",
      "1894 [D loss: (-4.203)(R -2.984, F -5.423)]  [G loss: 5.580] \n",
      "1894 [D loss: (-4.375)(R -3.232, F -5.517)]  [G loss: 5.549] \n",
      "1895 [D loss: (-4.212)(R -3.115, F -5.309)]  [G loss: 5.632] \n",
      "1895 [D loss: (-4.045)(R -2.740, F -5.349)]  [G loss: 5.358] \n",
      "1896 [D loss: (-4.287)(R -3.399, F -5.175)]  [G loss: 5.492] \n",
      "1896 [D loss: (-4.296)(R -2.814, F -5.777)]  [G loss: 5.897] \n",
      "1897 [D loss: (-4.430)(R -3.021, F -5.840)]  [G loss: 6.124] \n",
      "1897 [D loss: (-4.218)(R -2.502, F -5.934)]  [G loss: 6.280] \n",
      "1898 [D loss: (-4.278)(R -2.536, F -6.020)]  [G loss: 6.287] \n",
      "1898 [D loss: (-4.371)(R -2.715, F -6.026)]  [G loss: 6.313] \n",
      "1899 [D loss: (-4.357)(R -2.512, F -6.202)]  [G loss: 6.472] \n",
      "1899 [D loss: (-3.991)(R -1.675, F -6.306)]  [G loss: 6.484] \n",
      "1900 [D loss: (-4.173)(R -1.969, F -6.377)]  [G loss: 6.602] \n",
      "1900 [D loss: (-4.412)(R -2.471, F -6.353)]  [G loss: 6.502] \n",
      "1901 [D loss: (-4.330)(R -2.532, F -6.128)]  [G loss: 6.338] \n",
      "1901 [D loss: (-3.979)(R -1.871, F -6.087)]  [G loss: 6.318] \n",
      "1902 [D loss: (-4.180)(R -2.312, F -6.047)]  [G loss: 6.378] \n",
      "1902 [D loss: (-3.946)(R -1.916, F -5.977)]  [G loss: 6.233] \n",
      "1903 [D loss: (-4.261)(R -2.551, F -5.971)]  [G loss: 6.252] \n",
      "1903 [D loss: (-4.136)(R -2.249, F -6.023)]  [G loss: 6.273] \n",
      "1904 [D loss: (-4.048)(R -1.976, F -6.119)]  [G loss: 6.415] \n",
      "1904 [D loss: (-4.093)(R -1.981, F -6.205)]  [G loss: 6.432] \n",
      "1905 [D loss: (-4.038)(R -1.881, F -6.194)]  [G loss: 6.461] \n",
      "1905 [D loss: (-4.226)(R -2.229, F -6.224)]  [G loss: 6.322] \n",
      "1906 [D loss: (-4.154)(R -2.183, F -6.126)]  [G loss: 6.295] \n",
      "1906 [D loss: (-4.070)(R -2.027, F -6.114)]  [G loss: 6.378] \n",
      "1907 [D loss: (-4.031)(R -1.781, F -6.281)]  [G loss: 6.491] \n",
      "1907 [D loss: (-4.115)(R -1.875, F -6.355)]  [G loss: 6.436] \n",
      "1908 [D loss: (-4.374)(R -2.161, F -6.587)]  [G loss: 6.653] \n",
      "1908 [D loss: (-4.095)(R -1.354, F -6.836)]  [G loss: 6.978] \n",
      "1909 [D loss: (-3.964)(R -1.442, F -6.487)]  [G loss: 6.880] \n",
      "1909 [D loss: (-4.168)(R -1.697, F -6.639)]  [G loss: 6.801] \n",
      "1910 [D loss: (-4.133)(R -1.579, F -6.687)]  [G loss: 6.897] \n",
      "1910 [D loss: (-3.997)(R -1.423, F -6.571)]  [G loss: 6.838] \n",
      "1911 [D loss: (-3.912)(R -1.243, F -6.582)]  [G loss: 6.923] \n",
      "1911 [D loss: (-3.928)(R -1.157, F -6.700)]  [G loss: 6.765] \n",
      "1912 [D loss: (-3.893)(R -1.333, F -6.454)]  [G loss: 6.956] \n",
      "1912 [D loss: (-4.097)(R -1.508, F -6.686)]  [G loss: 6.933] \n",
      "1913 [D loss: (-4.015)(R -1.396, F -6.634)]  [G loss: 6.919] \n",
      "1913 [D loss: (-4.055)(R -1.368, F -6.743)]  [G loss: 7.116] \n",
      "1914 [D loss: (-4.404)(R -1.724, F -7.084)]  [G loss: 7.141] \n",
      "1914 [D loss: (-3.883)(R -0.617, F -7.149)]  [G loss: 7.510] \n",
      "1915 [D loss: (-4.107)(R -0.698, F -7.516)]  [G loss: 7.753] \n",
      "1915 [D loss: (-3.921)(R -0.157, F -7.684)]  [G loss: 7.669] \n",
      "1916 [D loss: (-3.808)(R -0.341, F -7.274)]  [G loss: 7.632] \n",
      "1916 [D loss: (-3.930)(R -0.576, F -7.284)]  [G loss: 7.441] \n",
      "1917 [D loss: (-3.892)(R -0.697, F -7.087)]  [G loss: 7.213] \n",
      "1917 [D loss: (-3.790)(R -0.397, F -7.184)]  [G loss: 7.228] \n",
      "1918 [D loss: (-4.020)(R -1.017, F -7.023)]  [G loss: 7.152] \n",
      "1918 [D loss: (-3.936)(R -0.694, F -7.178)]  [G loss: 7.384] \n",
      "1919 [D loss: (-3.894)(R -0.799, F -6.989)]  [G loss: 7.412] \n",
      "1919 [D loss: (-3.926)(R -0.824, F -7.028)]  [G loss: 7.215] \n",
      "1920 [D loss: (-4.041)(R -1.125, F -6.957)]  [G loss: 7.319] \n",
      "1920 [D loss: (-3.549)(R -0.269, F -6.830)]  [G loss: 7.158] \n",
      "1921 [D loss: (-3.991)(R -0.920, F -7.063)]  [G loss: 7.068] \n",
      "1921 [D loss: (-3.889)(R -0.968, F -6.811)]  [G loss: 6.961] \n",
      "1922 [D loss: (-4.299)(R -1.755, F -6.842)]  [G loss: 6.939] \n",
      "1922 [D loss: (-3.866)(R -0.955, F -6.777)]  [G loss: 7.121] \n",
      "1923 [D loss: (-3.894)(R -0.958, F -6.830)]  [G loss: 7.132] \n",
      "1923 [D loss: (-4.001)(R -1.100, F -6.902)]  [G loss: 6.838] \n",
      "1924 [D loss: (-3.774)(R -0.771, F -6.778)]  [G loss: 7.071] \n",
      "1924 [D loss: (-3.822)(R -0.647, F -6.997)]  [G loss: 7.235] \n",
      "1925 [D loss: (-3.969)(R -1.024, F -6.914)]  [G loss: 7.269] \n",
      "1925 [D loss: (-4.093)(R -0.682, F -7.505)]  [G loss: 7.437] \n",
      "1926 [D loss: (-3.874)(R -0.643, F -7.104)]  [G loss: 7.373] \n",
      "1926 [D loss: (-3.923)(R -1.013, F -6.833)]  [G loss: 6.942] \n",
      "1927 [D loss: (-4.047)(R -1.209, F -6.885)]  [G loss: 6.792] \n",
      "1927 [D loss: (-4.002)(R -1.506, F -6.498)]  [G loss: 6.754] \n",
      "1928 [D loss: (-3.936)(R -1.527, F -6.345)]  [G loss: 6.486] \n",
      "1928 [D loss: (-3.934)(R -1.581, F -6.287)]  [G loss: 6.622] \n",
      "1929 [D loss: (-3.812)(R -1.298, F -6.326)]  [G loss: 6.592] \n",
      "1929 [D loss: (-3.920)(R -1.244, F -6.597)]  [G loss: 6.855] \n",
      "1930 [D loss: (-3.937)(R -1.005, F -6.870)]  [G loss: 7.183] \n",
      "1930 [D loss: (-3.630)(R -0.130, F -7.130)]  [G loss: 7.460] \n",
      "1931 [D loss: (-3.848)(R -0.470, F -7.225)]  [G loss: 7.675] \n",
      "1931 [D loss: (-3.486)(R -0.161, F -6.810)]  [G loss: 7.459] \n",
      "1932 [D loss: (-3.763)(R -0.551, F -6.976)]  [G loss: 7.231] \n",
      "1932 [D loss: (-3.697)(R -0.494, F -6.900)]  [G loss: 7.077] \n",
      "1933 [D loss: (-3.814)(R -1.006, F -6.622)]  [G loss: 6.895] \n",
      "1933 [D loss: (-3.950)(R -1.382, F -6.518)]  [G loss: 6.752] \n",
      "1934 [D loss: (-3.950)(R -0.955, F -6.944)]  [G loss: 6.928] \n",
      "1934 [D loss: (-3.878)(R -0.787, F -6.970)]  [G loss: 7.036] \n",
      "1935 [D loss: (-3.792)(R -0.774, F -6.810)]  [G loss: 7.118] \n",
      "1935 [D loss: (-3.562)(R -0.298, F -6.826)]  [G loss: 7.161] \n",
      "1936 [D loss: (-4.096)(R -1.351, F -6.841)]  [G loss: 7.169] \n",
      "1936 [D loss: (-3.617)(R -0.209, F -7.025)]  [G loss: 7.101] \n",
      "1937 [D loss: (-3.662)(R -0.590, F -6.734)]  [G loss: 7.075] \n",
      "1937 [D loss: (-3.931)(R -1.008, F -6.854)]  [G loss: 7.042] \n",
      "1938 [D loss: (-3.580)(R -0.621, F -6.539)]  [G loss: 7.050] \n",
      "1938 [D loss: (-3.827)(R -0.584, F -7.069)]  [G loss: 6.979] \n",
      "1939 [D loss: (-3.513)(R -0.529, F -6.498)]  [G loss: 6.779] \n",
      "1939 [D loss: (-3.692)(R -0.728, F -6.655)]  [G loss: 6.980] \n",
      "1940 [D loss: (-4.175)(R -1.597, F -6.753)]  [G loss: 6.831] \n",
      "1940 [D loss: (-3.636)(R -0.938, F -6.334)]  [G loss: 6.860] \n",
      "1941 [D loss: (-3.710)(R -0.632, F -6.788)]  [G loss: 6.955] \n",
      "1941 [D loss: (-3.553)(R -0.464, F -6.642)]  [G loss: 7.011] \n",
      "1942 [D loss: (-3.486)(R -0.380, F -6.591)]  [G loss: 6.662] \n",
      "1942 [D loss: (-3.724)(R -0.776, F -6.673)]  [G loss: 6.871] \n",
      "1943 [D loss: (-3.755)(R -0.760, F -6.749)]  [G loss: 6.712] \n",
      "1943 [D loss: (-4.134)(R -1.382, F -6.885)]  [G loss: 6.987] \n",
      "1944 [D loss: (-3.787)(R -0.288, F -7.287)]  [G loss: 7.294] \n",
      "1944 [D loss: (-3.367)(R -0.198, F -6.535)]  [G loss: 7.148] \n",
      "1945 [D loss: (-3.956)(R -0.868, F -7.045)]  [G loss: 7.149] \n",
      "1945 [D loss: (-3.671)(R -0.227, F -7.115)]  [G loss: 7.066] \n",
      "1946 [D loss: (-3.514)(R -0.040, F -6.989)]  [G loss: 7.191] \n",
      "1946 [D loss: (-4.045)(R -0.467, F -7.623)]  [G loss: 7.418] \n",
      "1947 [D loss: (-3.817)(R -0.110, F -7.524)]  [G loss: 7.345] \n",
      "1947 [D loss: (-3.496)(R -0.083, F -6.908)]  [G loss: 7.337] \n",
      "1948 [D loss: (-3.734)(R -0.340, F -7.128)]  [G loss: 7.205] \n",
      "1948 [D loss: (-3.732)(R -0.454, F -7.011)]  [G loss: 7.146] \n",
      "1949 [D loss: (-3.604)(R -0.360, F -6.848)]  [G loss: 7.355] \n",
      "1949 [D loss: (-3.690)(R -0.221, F -7.160)]  [G loss: 7.330] \n",
      "1950 [D loss: (-3.918)(R -0.589, F -7.246)]  [G loss: 7.163] \n",
      "1950 [D loss: (-3.619)(R -0.584, F -6.654)]  [G loss: 7.161] \n",
      "1951 [D loss: (-3.745)(R -0.206, F -7.285)]  [G loss: 7.344] \n",
      "1951 [D loss: (-3.562)(R 0.035, F -7.159)]  [G loss: 7.339] \n",
      "1952 [D loss: (-3.572)(R -0.222, F -6.923)]  [G loss: 6.844] \n",
      "1952 [D loss: (-3.493)(R -0.674, F -6.312)]  [G loss: 6.660] \n",
      "1953 [D loss: (-3.487)(R -0.275, F -6.698)]  [G loss: 6.618] \n",
      "1953 [D loss: (-3.895)(R -1.161, F -6.630)]  [G loss: 6.712] \n",
      "1954 [D loss: (-3.234)(R -0.707, F -5.761)]  [G loss: 6.592] \n",
      "1954 [D loss: (-3.802)(R -1.328, F -6.276)]  [G loss: 6.423] \n",
      "1955 [D loss: (-3.512)(R -1.071, F -5.954)]  [G loss: 6.278] \n",
      "1955 [D loss: (-3.654)(R -0.779, F -6.529)]  [G loss: 6.438] \n",
      "1956 [D loss: (-3.804)(R -1.245, F -6.364)]  [G loss: 6.562] \n",
      "1956 [D loss: (-3.777)(R -0.877, F -6.676)]  [G loss: 6.696] \n",
      "1957 [D loss: (-3.647)(R -0.576, F -6.717)]  [G loss: 6.759] \n",
      "1957 [D loss: (-3.366)(R -0.191, F -6.542)]  [G loss: 6.983] \n",
      "1958 [D loss: (-3.552)(R -0.632, F -6.471)]  [G loss: 7.193] \n",
      "1958 [D loss: (-3.178)(R 0.045, F -6.400)]  [G loss: 6.992] \n",
      "1959 [D loss: (-3.460)(R -0.130, F -6.790)]  [G loss: 6.957] \n",
      "1959 [D loss: (-3.549)(R -0.065, F -7.034)]  [G loss: 6.991] \n",
      "1960 [D loss: (-3.403)(R 0.005, F -6.811)]  [G loss: 7.219] \n",
      "1960 [D loss: (-3.769)(R -0.420, F -7.119)]  [G loss: 7.036] \n",
      "1961 [D loss: (-3.792)(R -0.430, F -7.155)]  [G loss: 7.170] \n",
      "1961 [D loss: (-3.801)(R -0.305, F -7.297)]  [G loss: 7.153] \n",
      "1962 [D loss: (-3.879)(R -0.397, F -7.360)]  [G loss: 7.092] \n",
      "1962 [D loss: (-3.710)(R -0.553, F -6.866)]  [G loss: 6.799] \n",
      "1963 [D loss: (-3.728)(R -0.900, F -6.556)]  [G loss: 6.937] \n",
      "1963 [D loss: (-3.419)(R -0.767, F -6.070)]  [G loss: 6.725] \n",
      "1964 [D loss: (-3.935)(R -0.653, F -7.216)]  [G loss: 6.857] \n",
      "1964 [D loss: (-3.247)(R -0.566, F -5.928)]  [G loss: 6.941] \n",
      "1965 [D loss: (-3.903)(R -1.191, F -6.616)]  [G loss: 6.609] \n",
      "1965 [D loss: (-3.309)(R -0.498, F -6.120)]  [G loss: 6.975] \n",
      "1966 [D loss: (-3.632)(R -1.048, F -6.217)]  [G loss: 6.414] \n",
      "1966 [D loss: (-3.520)(R -0.933, F -6.108)]  [G loss: 6.320] \n",
      "1967 [D loss: (-3.784)(R -1.077, F -6.491)]  [G loss: 6.353] \n",
      "1967 [D loss: (-3.514)(R -0.892, F -6.137)]  [G loss: 6.595] \n",
      "1968 [D loss: (-3.500)(R -0.974, F -6.026)]  [G loss: 6.577] \n",
      "1968 [D loss: (-3.705)(R -0.863, F -6.548)]  [G loss: 6.544] \n",
      "1969 [D loss: (-3.678)(R -0.719, F -6.637)]  [G loss: 6.664] \n",
      "1969 [D loss: (-3.673)(R -1.176, F -6.169)]  [G loss: 6.549] \n",
      "1970 [D loss: (-3.774)(R -0.892, F -6.656)]  [G loss: 6.567] \n",
      "1970 [D loss: (-3.610)(R -0.805, F -6.414)]  [G loss: 6.573] \n",
      "1971 [D loss: (-3.609)(R -0.733, F -6.486)]  [G loss: 6.806] \n",
      "1971 [D loss: (-3.352)(R -0.626, F -6.078)]  [G loss: 6.658] \n",
      "1972 [D loss: (-3.752)(R -0.885, F -6.619)]  [G loss: 6.853] \n",
      "1972 [D loss: (-3.382)(R -0.530, F -6.234)]  [G loss: 6.698] \n",
      "1973 [D loss: (-3.700)(R -1.059, F -6.341)]  [G loss: 6.497] \n",
      "1973 [D loss: (-3.828)(R -1.187, F -6.469)]  [G loss: 6.433] \n",
      "1974 [D loss: (-3.522)(R -0.764, F -6.281)]  [G loss: 6.463] \n",
      "1974 [D loss: (-3.470)(R -0.740, F -6.201)]  [G loss: 6.510] \n",
      "1975 [D loss: (-3.918)(R -1.541, F -6.294)]  [G loss: 6.314] \n",
      "1975 [D loss: (-3.733)(R -1.278, F -6.188)]  [G loss: 6.805] \n",
      "1976 [D loss: (-3.296)(R -1.087, F -5.505)]  [G loss: 6.092] \n",
      "1976 [D loss: (-3.471)(R -1.056, F -5.887)]  [G loss: 6.118] \n",
      "1977 [D loss: (-3.395)(R -0.689, F -6.102)]  [G loss: 6.274] \n",
      "1977 [D loss: (-3.370)(R -0.927, F -5.813)]  [G loss: 6.003] \n",
      "1978 [D loss: (-3.916)(R -1.748, F -6.083)]  [G loss: 5.870] \n",
      "1978 [D loss: (-3.825)(R -1.506, F -6.145)]  [G loss: 6.136] \n",
      "1979 [D loss: (-3.758)(R -1.275, F -6.240)]  [G loss: 6.455] \n",
      "1979 [D loss: (-3.811)(R -1.199, F -6.423)]  [G loss: 6.016] \n",
      "1980 [D loss: (-3.771)(R -0.864, F -6.678)]  [G loss: 6.534] \n",
      "1980 [D loss: (-3.214)(R -0.483, F -5.945)]  [G loss: 6.415] \n",
      "1981 [D loss: (-3.385)(R -0.801, F -5.968)]  [G loss: 6.233] \n",
      "1981 [D loss: (-3.528)(R -1.396, F -5.659)]  [G loss: 6.100] \n",
      "1982 [D loss: (-3.618)(R -1.533, F -5.703)]  [G loss: 6.069] \n",
      "1982 [D loss: (-3.502)(R -1.390, F -5.614)]  [G loss: 5.741] \n",
      "1983 [D loss: (-3.994)(R -2.027, F -5.961)]  [G loss: 5.883] \n",
      "1983 [D loss: (-3.299)(R -1.028, F -5.570)]  [G loss: 5.912] \n",
      "1984 [D loss: (-3.631)(R -1.442, F -5.820)]  [G loss: 6.164] \n",
      "1984 [D loss: (-3.934)(R -1.563, F -6.305)]  [G loss: 6.022] \n",
      "1985 [D loss: (-3.677)(R -1.392, F -5.962)]  [G loss: 6.144] \n",
      "1985 [D loss: (-3.518)(R -0.686, F -6.349)]  [G loss: 6.412] \n",
      "1986 [D loss: (-3.702)(R -1.150, F -6.254)]  [G loss: 6.182] \n",
      "1986 [D loss: (-3.964)(R -1.242, F -6.686)]  [G loss: 6.537] \n",
      "1987 [D loss: (-3.672)(R -1.416, F -5.928)]  [G loss: 6.138] \n",
      "1987 [D loss: (-3.367)(R -0.875, F -5.858)]  [G loss: 6.277] \n",
      "1988 [D loss: (-3.073)(R -0.966, F -5.180)]  [G loss: 5.918] \n",
      "1988 [D loss: (-3.522)(R -1.112, F -5.931)]  [G loss: 5.842] \n",
      "1989 [D loss: (-3.596)(R -1.276, F -5.917)]  [G loss: 5.967] \n",
      "1989 [D loss: (-3.131)(R -0.680, F -5.582)]  [G loss: 5.806] \n",
      "1990 [D loss: (-3.447)(R -1.890, F -5.004)]  [G loss: 5.754] \n",
      "1990 [D loss: (-3.743)(R -2.101, F -5.386)]  [G loss: 6.000] \n",
      "1991 [D loss: (-3.581)(R -1.381, F -5.781)]  [G loss: 5.391] \n",
      "1991 [D loss: (-3.547)(R -1.535, F -5.560)]  [G loss: 5.991] \n",
      "1992 [D loss: (-3.444)(R -1.383, F -5.504)]  [G loss: 5.913] \n",
      "1992 [D loss: (-3.297)(R -1.289, F -5.305)]  [G loss: 5.963] \n",
      "1993 [D loss: (-3.426)(R -1.112, F -5.740)]  [G loss: 5.745] \n",
      "1993 [D loss: (-3.384)(R -1.888, F -4.881)]  [G loss: 5.824] \n",
      "1994 [D loss: (-3.522)(R -1.528, F -5.516)]  [G loss: 5.522] \n",
      "1994 [D loss: (-3.458)(R -1.821, F -5.096)]  [G loss: 5.713] \n",
      "1995 [D loss: (-3.716)(R -2.073, F -5.359)]  [G loss: 5.744] \n",
      "1995 [D loss: (-3.608)(R -1.699, F -5.517)]  [G loss: 5.873] \n",
      "1996 [D loss: (-3.727)(R -1.877, F -5.576)]  [G loss: 5.523] \n",
      "1996 [D loss: (-3.229)(R -1.752, F -4.706)]  [G loss: 5.765] \n",
      "1997 [D loss: (-3.248)(R -1.350, F -5.147)]  [G loss: 5.321] \n",
      "1997 [D loss: (-3.606)(R -1.051, F -6.161)]  [G loss: 5.671] \n",
      "1998 [D loss: (-3.740)(R -1.495, F -5.984)]  [G loss: 5.384] \n",
      "1998 [D loss: (-3.597)(R -1.921, F -5.273)]  [G loss: 5.808] \n",
      "1999 [D loss: (-3.780)(R -1.842, F -5.717)]  [G loss: 5.776] \n",
      "1999 [D loss: (-3.872)(R -1.772, F -5.973)]  [G loss: 5.955] \n",
      "2000 [D loss: (-3.409)(R -1.508, F -5.310)]  [G loss: 5.631] \n",
      "2000 [D loss: (-3.699)(R -1.943, F -5.454)]  [G loss: 5.850] \n",
      "2001 [D loss: (-3.631)(R -1.542, F -5.719)]  [G loss: 5.706] \n",
      "2001 [D loss: (-3.702)(R -1.961, F -5.443)]  [G loss: 5.476] \n",
      "2002 [D loss: (-3.735)(R -1.910, F -5.560)]  [G loss: 5.863] \n",
      "2002 [D loss: (-3.231)(R -1.717, F -4.744)]  [G loss: 5.361] \n",
      "2003 [D loss: (-3.520)(R -1.907, F -5.134)]  [G loss: 5.234] \n",
      "2003 [D loss: (-3.763)(R -2.246, F -5.280)]  [G loss: 5.583] \n",
      "2004 [D loss: (-3.516)(R -2.128, F -4.904)]  [G loss: 5.256] \n",
      "2004 [D loss: (-3.687)(R -1.838, F -5.537)]  [G loss: 5.504] \n",
      "2005 [D loss: (-3.560)(R -1.256, F -5.865)]  [G loss: 5.961] \n",
      "2005 [D loss: (-3.417)(R -1.591, F -5.242)]  [G loss: 5.821] \n",
      "2006 [D loss: (-3.519)(R -1.055, F -5.982)]  [G loss: 5.977] \n",
      "2006 [D loss: (-3.621)(R -1.600, F -5.643)]  [G loss: 5.874] \n",
      "2007 [D loss: (-3.659)(R -1.670, F -5.649)]  [G loss: 5.537] \n",
      "2007 [D loss: (-3.449)(R -1.690, F -5.209)]  [G loss: 5.490] \n",
      "2008 [D loss: (-3.776)(R -1.856, F -5.695)]  [G loss: 5.645] \n",
      "2008 [D loss: (-3.421)(R -1.523, F -5.318)]  [G loss: 5.554] \n",
      "2009 [D loss: (-4.060)(R -2.077, F -6.043)]  [G loss: 5.861] \n",
      "2009 [D loss: (-3.632)(R -1.792, F -5.473)]  [G loss: 5.422] \n",
      "2010 [D loss: (-3.494)(R -1.838, F -5.151)]  [G loss: 5.921] \n",
      "2010 [D loss: (-3.799)(R -1.936, F -5.661)]  [G loss: 5.405] \n",
      "2011 [D loss: (-3.417)(R -1.565, F -5.270)]  [G loss: 5.625] \n",
      "2011 [D loss: (-3.460)(R -1.594, F -5.327)]  [G loss: 5.427] \n",
      "2012 [D loss: (-3.587)(R -1.470, F -5.705)]  [G loss: 5.757] \n",
      "2012 [D loss: (-3.854)(R -1.832, F -5.875)]  [G loss: 5.674] \n",
      "2013 [D loss: (-3.633)(R -1.748, F -5.518)]  [G loss: 5.659] \n",
      "2013 [D loss: (-3.587)(R -1.390, F -5.783)]  [G loss: 5.234] \n",
      "2014 [D loss: (-3.850)(R -1.907, F -5.794)]  [G loss: 5.553] \n",
      "2014 [D loss: (-3.651)(R -1.844, F -5.458)]  [G loss: 5.425] \n",
      "2015 [D loss: (-3.697)(R -1.795, F -5.600)]  [G loss: 5.413] \n",
      "2015 [D loss: (-3.670)(R -2.307, F -5.033)]  [G loss: 5.377] \n",
      "2016 [D loss: (-3.782)(R -2.337, F -5.227)]  [G loss: 5.185] \n",
      "2016 [D loss: (-3.153)(R -1.630, F -4.676)]  [G loss: 5.131] \n",
      "2017 [D loss: (-3.505)(R -2.252, F -4.759)]  [G loss: 5.062] \n",
      "2017 [D loss: (-3.393)(R -1.995, F -4.792)]  [G loss: 5.104] \n",
      "2018 [D loss: (-3.467)(R -1.893, F -5.041)]  [G loss: 5.144] \n",
      "2018 [D loss: (-3.860)(R -1.805, F -5.914)]  [G loss: 5.102] \n",
      "2019 [D loss: (-3.431)(R -2.258, F -4.603)]  [G loss: 5.416] \n",
      "2019 [D loss: (-3.761)(R -2.114, F -5.407)]  [G loss: 5.413] \n",
      "2020 [D loss: (-4.044)(R -2.121, F -5.967)]  [G loss: 5.867] \n",
      "2020 [D loss: (-3.686)(R -1.854, F -5.518)]  [G loss: 5.327] \n",
      "2021 [D loss: (-3.849)(R -2.194, F -5.504)]  [G loss: 5.135] \n",
      "2021 [D loss: (-3.459)(R -1.847, F -5.071)]  [G loss: 4.942] \n",
      "2022 [D loss: (-3.851)(R -2.370, F -5.331)]  [G loss: 5.050] \n",
      "2022 [D loss: (-3.965)(R -2.005, F -5.925)]  [G loss: 5.361] \n",
      "2023 [D loss: (-4.079)(R -1.754, F -6.404)]  [G loss: 5.876] \n",
      "2023 [D loss: (-3.510)(R -2.037, F -4.982)]  [G loss: 5.617] \n",
      "2024 [D loss: (-3.581)(R -1.932, F -5.229)]  [G loss: 5.331] \n",
      "2024 [D loss: (-3.580)(R -2.203, F -4.956)]  [G loss: 5.103] \n",
      "2025 [D loss: (-3.760)(R -1.840, F -5.679)]  [G loss: 5.530] \n",
      "2025 [D loss: (-3.493)(R -1.849, F -5.137)]  [G loss: 5.226] \n",
      "2026 [D loss: (-3.271)(R -1.749, F -4.793)]  [G loss: 5.310] \n",
      "2026 [D loss: (-3.348)(R -1.879, F -4.816)]  [G loss: 5.263] \n",
      "2027 [D loss: (-3.355)(R -2.116, F -4.594)]  [G loss: 5.608] \n",
      "2027 [D loss: (-3.855)(R -2.425, F -5.284)]  [G loss: 5.484] \n",
      "2028 [D loss: (-3.793)(R -2.349, F -5.238)]  [G loss: 5.477] \n",
      "2028 [D loss: (-3.469)(R -1.426, F -5.512)]  [G loss: 5.770] \n",
      "2029 [D loss: (-3.901)(R -1.887, F -5.916)]  [G loss: 5.950] \n",
      "2029 [D loss: (-4.142)(R -2.375, F -5.909)]  [G loss: 5.451] \n",
      "2030 [D loss: (-3.380)(R -1.621, F -5.139)]  [G loss: 5.108] \n",
      "2030 [D loss: (-3.369)(R -1.960, F -4.779)]  [G loss: 4.879] \n",
      "2031 [D loss: (-3.338)(R -2.001, F -4.675)]  [G loss: 4.877] \n",
      "2031 [D loss: (-3.462)(R -2.111, F -4.814)]  [G loss: 4.624] \n",
      "2032 [D loss: (-3.691)(R -3.079, F -4.302)]  [G loss: 4.848] \n",
      "2032 [D loss: (-3.577)(R -2.911, F -4.243)]  [G loss: 4.745] \n",
      "2033 [D loss: (-3.617)(R -2.415, F -4.820)]  [G loss: 4.995] \n",
      "2033 [D loss: (-3.823)(R -2.072, F -5.574)]  [G loss: 5.144] \n",
      "2034 [D loss: (-3.572)(R -1.788, F -5.357)]  [G loss: 5.159] \n",
      "2034 [D loss: (-3.663)(R -2.006, F -5.320)]  [G loss: 4.915] \n",
      "2035 [D loss: (-3.889)(R -2.401, F -5.378)]  [G loss: 5.182] \n",
      "2035 [D loss: (-3.251)(R -2.098, F -4.405)]  [G loss: 4.834] \n",
      "2036 [D loss: (-3.716)(R -2.662, F -4.770)]  [G loss: 5.148] \n",
      "2036 [D loss: (-3.374)(R -2.246, F -4.502)]  [G loss: 4.474] \n",
      "2037 [D loss: (-3.260)(R -2.320, F -4.201)]  [G loss: 4.842] \n",
      "2037 [D loss: (-3.438)(R -2.781, F -4.096)]  [G loss: 5.074] \n",
      "2038 [D loss: (-3.769)(R -2.727, F -4.811)]  [G loss: 4.912] \n",
      "2038 [D loss: (-3.387)(R -1.612, F -5.162)]  [G loss: 4.763] \n",
      "2039 [D loss: (-3.897)(R -2.750, F -5.044)]  [G loss: 4.929] \n",
      "2039 [D loss: (-3.358)(R -2.341, F -4.375)]  [G loss: 4.976] \n",
      "2040 [D loss: (-3.490)(R -2.277, F -4.703)]  [G loss: 4.518] \n",
      "2040 [D loss: (-3.693)(R -2.756, F -4.630)]  [G loss: 4.345] \n",
      "2041 [D loss: (-3.349)(R -2.324, F -4.375)]  [G loss: 4.630] \n",
      "2041 [D loss: (-3.274)(R -1.838, F -4.710)]  [G loss: 5.014] \n",
      "2042 [D loss: (-3.847)(R -2.667, F -5.027)]  [G loss: 4.995] \n",
      "2042 [D loss: (-3.913)(R -2.621, F -5.206)]  [G loss: 4.740] \n",
      "2043 [D loss: (-3.332)(R -2.337, F -4.326)]  [G loss: 4.771] \n",
      "2043 [D loss: (-3.447)(R -2.250, F -4.644)]  [G loss: 4.648] \n",
      "2044 [D loss: (-3.855)(R -3.162, F -4.549)]  [G loss: 4.590] \n",
      "2044 [D loss: (-3.908)(R -2.974, F -4.842)]  [G loss: 4.401] \n",
      "2045 [D loss: (-4.093)(R -2.622, F -5.563)]  [G loss: 5.328] \n",
      "2045 [D loss: (-3.631)(R -1.961, F -5.302)]  [G loss: 5.367] \n",
      "2046 [D loss: (-3.387)(R -2.266, F -4.508)]  [G loss: 4.891] \n",
      "2046 [D loss: (-3.798)(R -2.707, F -4.889)]  [G loss: 4.954] \n",
      "2047 [D loss: (-3.249)(R -1.948, F -4.549)]  [G loss: 4.652] \n",
      "2047 [D loss: (-3.281)(R -2.770, F -3.793)]  [G loss: 4.745] \n",
      "2048 [D loss: (-3.650)(R -2.133, F -5.167)]  [G loss: 4.547] \n",
      "2048 [D loss: (-3.719)(R -2.778, F -4.661)]  [G loss: 4.202] \n",
      "2049 [D loss: (-3.239)(R -2.572, F -3.906)]  [G loss: 4.762] \n",
      "2049 [D loss: (-3.506)(R -2.550, F -4.462)]  [G loss: 4.710] \n",
      "2050 [D loss: (-3.350)(R -2.799, F -3.901)]  [G loss: 5.261] \n",
      "2050 [D loss: (-3.490)(R -2.363, F -4.617)]  [G loss: 4.798] \n",
      "2051 [D loss: (-3.418)(R -2.531, F -4.306)]  [G loss: 4.495] \n",
      "2051 [D loss: (-3.709)(R -2.601, F -4.817)]  [G loss: 4.476] \n",
      "2052 [D loss: (-3.376)(R -2.279, F -4.472)]  [G loss: 4.632] \n",
      "2052 [D loss: (-3.649)(R -2.851, F -4.446)]  [G loss: 4.548] \n",
      "2053 [D loss: (-3.971)(R -2.911, F -5.031)]  [G loss: 4.963] \n",
      "2053 [D loss: (-3.616)(R -2.735, F -4.497)]  [G loss: 4.648] \n",
      "2054 [D loss: (-3.681)(R -2.376, F -4.985)]  [G loss: 4.567] \n",
      "2054 [D loss: (-3.336)(R -1.923, F -4.749)]  [G loss: 4.959] \n",
      "2055 [D loss: (-3.465)(R -2.402, F -4.527)]  [G loss: 4.961] \n",
      "2055 [D loss: (-3.400)(R -2.732, F -4.068)]  [G loss: 4.660] \n",
      "2056 [D loss: (-3.594)(R -2.775, F -4.412)]  [G loss: 4.074] \n",
      "2056 [D loss: (-3.618)(R -2.836, F -4.400)]  [G loss: 4.525] \n",
      "2057 [D loss: (-3.162)(R -2.165, F -4.158)]  [G loss: 4.555] \n",
      "2057 [D loss: (-3.270)(R -2.853, F -3.688)]  [G loss: 4.856] \n",
      "2058 [D loss: (-3.465)(R -2.932, F -3.997)]  [G loss: 3.896] \n",
      "2058 [D loss: (-3.061)(R -2.747, F -3.375)]  [G loss: 4.291] \n",
      "2059 [D loss: (-4.212)(R -3.460, F -4.964)]  [G loss: 4.116] \n",
      "2059 [D loss: (-3.664)(R -2.921, F -4.407)]  [G loss: 4.411] \n",
      "2060 [D loss: (-3.613)(R -3.160, F -4.066)]  [G loss: 4.639] \n",
      "2060 [D loss: (-3.457)(R -2.790, F -4.123)]  [G loss: 4.784] \n",
      "2061 [D loss: (-3.642)(R -3.035, F -4.248)]  [G loss: 4.579] \n",
      "2061 [D loss: (-3.474)(R -2.705, F -4.243)]  [G loss: 4.534] \n",
      "2062 [D loss: (-3.498)(R -2.854, F -4.143)]  [G loss: 4.463] \n",
      "2062 [D loss: (-3.653)(R -3.124, F -4.182)]  [G loss: 4.588] \n",
      "2063 [D loss: (-3.555)(R -2.952, F -4.159)]  [G loss: 4.220] \n",
      "2063 [D loss: (-3.364)(R -2.884, F -3.844)]  [G loss: 4.097] \n",
      "2064 [D loss: (-3.364)(R -2.827, F -3.901)]  [G loss: 4.639] \n",
      "2064 [D loss: (-3.913)(R -2.624, F -5.202)]  [G loss: 4.191] \n",
      "2065 [D loss: (-3.586)(R -2.702, F -4.469)]  [G loss: 4.692] \n",
      "2065 [D loss: (-4.124)(R -3.189, F -5.059)]  [G loss: 4.430] \n",
      "2066 [D loss: (-2.756)(R -2.026, F -3.487)]  [G loss: 4.242] \n",
      "2066 [D loss: (-3.663)(R -2.901, F -4.425)]  [G loss: 4.795] \n",
      "2067 [D loss: (-3.463)(R -2.940, F -3.987)]  [G loss: 4.722] \n",
      "2067 [D loss: (-3.212)(R -2.612, F -3.811)]  [G loss: 4.710] \n",
      "2068 [D loss: (-4.022)(R -3.630, F -4.415)]  [G loss: 3.988] \n",
      "2068 [D loss: (-3.059)(R -2.650, F -3.468)]  [G loss: 4.408] \n",
      "2069 [D loss: (-3.826)(R -3.304, F -4.347)]  [G loss: 4.304] \n",
      "2069 [D loss: (-3.707)(R -3.094, F -4.320)]  [G loss: 4.096] \n",
      "2070 [D loss: (-3.368)(R -2.673, F -4.064)]  [G loss: 4.006] \n",
      "2070 [D loss: (-3.441)(R -2.924, F -3.957)]  [G loss: 4.457] \n",
      "2071 [D loss: (-3.681)(R -3.066, F -4.296)]  [G loss: 4.265] \n",
      "2071 [D loss: (-3.751)(R -2.704, F -4.799)]  [G loss: 4.442] \n",
      "2072 [D loss: (-3.462)(R -3.007, F -3.918)]  [G loss: 4.183] \n",
      "2072 [D loss: (-3.108)(R -2.285, F -3.931)]  [G loss: 4.480] \n",
      "2073 [D loss: (-3.571)(R -2.874, F -4.268)]  [G loss: 4.424] \n",
      "2073 [D loss: (-3.684)(R -2.497, F -4.871)]  [G loss: 4.591] \n",
      "2074 [D loss: (-3.966)(R -3.234, F -4.698)]  [G loss: 4.798] \n",
      "2074 [D loss: (-3.674)(R -2.996, F -4.352)]  [G loss: 4.852] \n",
      "2075 [D loss: (-3.243)(R -2.603, F -3.883)]  [G loss: 4.241] \n",
      "2075 [D loss: (-3.727)(R -2.570, F -4.884)]  [G loss: 4.288] \n",
      "2076 [D loss: (-4.015)(R -3.173, F -4.857)]  [G loss: 4.352] \n",
      "2076 [D loss: (-3.501)(R -2.565, F -4.436)]  [G loss: 4.548] \n",
      "2077 [D loss: (-3.753)(R -3.107, F -4.398)]  [G loss: 4.398] \n",
      "2077 [D loss: (-3.556)(R -3.167, F -3.944)]  [G loss: 4.477] \n",
      "2078 [D loss: (-3.379)(R -2.704, F -4.054)]  [G loss: 4.237] \n",
      "2078 [D loss: (-3.190)(R -1.899, F -4.482)]  [G loss: 4.217] \n",
      "2079 [D loss: (-3.493)(R -3.096, F -3.890)]  [G loss: 4.309] \n",
      "2079 [D loss: (-3.008)(R -2.179, F -3.837)]  [G loss: 4.298] \n",
      "2080 [D loss: (-3.958)(R -3.085, F -4.831)]  [G loss: 4.493] \n",
      "2080 [D loss: (-3.959)(R -3.045, F -4.874)]  [G loss: 3.925] \n",
      "2081 [D loss: (-3.545)(R -2.560, F -4.530)]  [G loss: 4.589] \n",
      "2081 [D loss: (-3.586)(R -2.730, F -4.442)]  [G loss: 4.418] \n",
      "2082 [D loss: (-3.843)(R -2.930, F -4.757)]  [G loss: 4.340] \n",
      "2082 [D loss: (-3.791)(R -3.420, F -4.162)]  [G loss: 4.375] \n",
      "2083 [D loss: (-3.594)(R -2.749, F -4.439)]  [G loss: 4.831] \n",
      "2083 [D loss: (-3.305)(R -2.479, F -4.132)]  [G loss: 4.014] \n",
      "2084 [D loss: (-4.055)(R -3.493, F -4.617)]  [G loss: 4.441] \n",
      "2084 [D loss: (-4.065)(R -3.215, F -4.915)]  [G loss: 4.728] \n",
      "2085 [D loss: (-3.382)(R -2.546, F -4.219)]  [G loss: 4.898] \n",
      "2085 [D loss: (-3.549)(R -2.754, F -4.345)]  [G loss: 4.588] \n",
      "2086 [D loss: (-3.613)(R -2.269, F -4.956)]  [G loss: 4.662] \n",
      "2086 [D loss: (-3.849)(R -3.078, F -4.620)]  [G loss: 4.596] \n",
      "2087 [D loss: (-3.473)(R -2.522, F -4.424)]  [G loss: 4.590] \n",
      "2087 [D loss: (-3.641)(R -2.809, F -4.473)]  [G loss: 4.379] \n",
      "2088 [D loss: (-3.503)(R -3.015, F -3.992)]  [G loss: 3.957] \n",
      "2088 [D loss: (-3.616)(R -2.792, F -4.441)]  [G loss: 4.543] \n",
      "2089 [D loss: (-4.129)(R -3.382, F -4.876)]  [G loss: 4.585] \n",
      "2089 [D loss: (-3.766)(R -2.463, F -5.068)]  [G loss: 4.770] \n",
      "2090 [D loss: (-4.082)(R -3.010, F -5.154)]  [G loss: 4.460] \n",
      "2090 [D loss: (-3.786)(R -3.173, F -4.399)]  [G loss: 4.557] \n",
      "2091 [D loss: (-3.995)(R -2.828, F -5.162)]  [G loss: 4.672] \n",
      "2091 [D loss: (-3.279)(R -2.898, F -3.660)]  [G loss: 4.581] \n",
      "2092 [D loss: (-3.521)(R -2.228, F -4.814)]  [G loss: 4.878] \n",
      "2092 [D loss: (-3.715)(R -2.584, F -4.847)]  [G loss: 4.108] \n",
      "2093 [D loss: (-3.517)(R -2.976, F -4.059)]  [G loss: 4.464] \n",
      "2093 [D loss: (-3.921)(R -3.074, F -4.769)]  [G loss: 4.155] \n",
      "2094 [D loss: (-3.765)(R -2.568, F -4.961)]  [G loss: 4.649] \n",
      "2094 [D loss: (-3.478)(R -2.789, F -4.166)]  [G loss: 4.295] \n",
      "2095 [D loss: (-3.515)(R -2.628, F -4.402)]  [G loss: 4.709] \n",
      "2095 [D loss: (-3.745)(R -3.039, F -4.451)]  [G loss: 4.187] \n",
      "2096 [D loss: (-3.884)(R -3.291, F -4.478)]  [G loss: 4.397] \n",
      "2096 [D loss: (-3.442)(R -2.364, F -4.521)]  [G loss: 4.305] \n",
      "2097 [D loss: (-4.169)(R -3.032, F -5.306)]  [G loss: 4.351] \n",
      "2097 [D loss: (-3.620)(R -2.798, F -4.441)]  [G loss: 4.481] \n",
      "2098 [D loss: (-3.724)(R -2.954, F -4.494)]  [G loss: 4.584] \n",
      "2098 [D loss: (-3.579)(R -2.796, F -4.362)]  [G loss: 4.257] \n",
      "2099 [D loss: (-3.596)(R -2.600, F -4.593)]  [G loss: 4.561] \n",
      "2099 [D loss: (-3.691)(R -2.418, F -4.964)]  [G loss: 4.794] \n",
      "2100 [D loss: (-3.381)(R -2.345, F -4.417)]  [G loss: 4.841] \n",
      "2100 [D loss: (-3.454)(R -3.068, F -3.841)]  [G loss: 4.922] \n",
      "2101 [D loss: (-3.137)(R -2.669, F -3.605)]  [G loss: 4.678] \n",
      "2101 [D loss: (-3.733)(R -3.090, F -4.375)]  [G loss: 4.735] \n",
      "2102 [D loss: (-3.418)(R -2.681, F -4.154)]  [G loss: 4.576] \n",
      "2102 [D loss: (-3.708)(R -3.031, F -4.386)]  [G loss: 4.621] \n",
      "2103 [D loss: (-3.566)(R -2.949, F -4.183)]  [G loss: 4.347] \n",
      "2103 [D loss: (-3.234)(R -2.949, F -3.519)]  [G loss: 4.201] \n",
      "2104 [D loss: (-3.432)(R -3.133, F -3.731)]  [G loss: 4.475] \n",
      "2104 [D loss: (-3.764)(R -2.885, F -4.642)]  [G loss: 4.363] \n",
      "2105 [D loss: (-3.618)(R -3.201, F -4.036)]  [G loss: 4.303] \n",
      "2105 [D loss: (-3.833)(R -3.056, F -4.609)]  [G loss: 4.607] \n",
      "2106 [D loss: (-3.765)(R -2.899, F -4.630)]  [G loss: 4.250] \n",
      "2106 [D loss: (-3.699)(R -3.347, F -4.051)]  [G loss: 4.436] \n",
      "2107 [D loss: (-3.723)(R -3.139, F -4.307)]  [G loss: 4.614] \n",
      "2107 [D loss: (-3.430)(R -2.716, F -4.143)]  [G loss: 4.698] \n",
      "2108 [D loss: (-3.793)(R -3.267, F -4.319)]  [G loss: 4.571] \n",
      "2108 [D loss: (-3.629)(R -3.077, F -4.181)]  [G loss: 4.233] \n",
      "2109 [D loss: (-3.868)(R -2.928, F -4.809)]  [G loss: 4.398] \n",
      "2109 [D loss: (-3.617)(R -2.232, F -5.001)]  [G loss: 4.333] \n",
      "2110 [D loss: (-3.419)(R -2.721, F -4.118)]  [G loss: 4.724] \n",
      "2110 [D loss: (-3.927)(R -2.961, F -4.894)]  [G loss: 4.428] \n",
      "2111 [D loss: (-3.519)(R -2.781, F -4.258)]  [G loss: 4.251] \n",
      "2111 [D loss: (-3.898)(R -2.961, F -4.836)]  [G loss: 4.689] \n",
      "2112 [D loss: (-3.867)(R -2.307, F -5.427)]  [G loss: 4.935] \n",
      "2112 [D loss: (-3.261)(R -2.696, F -3.826)]  [G loss: 4.977] \n",
      "2113 [D loss: (-3.710)(R -3.162, F -4.259)]  [G loss: 4.571] \n",
      "2113 [D loss: (-3.373)(R -2.745, F -4.001)]  [G loss: 4.478] \n",
      "2114 [D loss: (-3.573)(R -2.499, F -4.647)]  [G loss: 4.587] \n",
      "2114 [D loss: (-3.619)(R -2.811, F -4.426)]  [G loss: 4.499] \n",
      "2115 [D loss: (-3.852)(R -3.038, F -4.666)]  [G loss: 4.405] \n",
      "2115 [D loss: (-3.914)(R -2.691, F -5.138)]  [G loss: 4.704] \n",
      "2116 [D loss: (-3.856)(R -2.501, F -5.211)]  [G loss: 4.766] \n",
      "2116 [D loss: (-3.381)(R -1.998, F -4.763)]  [G loss: 4.924] \n",
      "2117 [D loss: (-3.474)(R -2.664, F -4.284)]  [G loss: 5.036] \n",
      "2117 [D loss: (-3.578)(R -2.210, F -4.947)]  [G loss: 5.027] \n",
      "2118 [D loss: (-3.038)(R -2.200, F -3.876)]  [G loss: 4.586] \n",
      "2118 [D loss: (-3.532)(R -2.910, F -4.154)]  [G loss: 4.762] \n",
      "2119 [D loss: (-3.869)(R -2.506, F -5.232)]  [G loss: 4.469] \n",
      "2119 [D loss: (-3.633)(R -2.342, F -4.924)]  [G loss: 4.789] \n",
      "2120 [D loss: (-3.544)(R -2.713, F -4.376)]  [G loss: 4.909] \n",
      "2120 [D loss: (-3.515)(R -2.197, F -4.833)]  [G loss: 4.701] \n",
      "2121 [D loss: (-3.807)(R -2.758, F -4.856)]  [G loss: 4.402] \n",
      "2121 [D loss: (-3.314)(R -2.383, F -4.245)]  [G loss: 4.743] \n",
      "2122 [D loss: (-3.599)(R -3.190, F -4.009)]  [G loss: 4.651] \n",
      "2122 [D loss: (-3.714)(R -2.956, F -4.472)]  [G loss: 4.510] \n",
      "2123 [D loss: (-3.480)(R -2.634, F -4.326)]  [G loss: 4.807] \n",
      "2123 [D loss: (-3.641)(R -3.072, F -4.210)]  [G loss: 4.285] \n",
      "2124 [D loss: (-3.201)(R -2.727, F -3.674)]  [G loss: 4.463] \n",
      "2124 [D loss: (-3.386)(R -2.621, F -4.150)]  [G loss: 4.168] \n",
      "2125 [D loss: (-3.560)(R -2.499, F -4.622)]  [G loss: 4.045] \n",
      "2125 [D loss: (-3.872)(R -3.130, F -4.613)]  [G loss: 4.328] \n",
      "2126 [D loss: (-3.422)(R -2.982, F -3.862)]  [G loss: 3.923] \n",
      "2126 [D loss: (-3.247)(R -2.565, F -3.929)]  [G loss: 4.017] \n",
      "2127 [D loss: (-3.838)(R -3.225, F -4.452)]  [G loss: 4.248] \n",
      "2127 [D loss: (-3.257)(R -2.802, F -3.712)]  [G loss: 4.427] \n",
      "2128 [D loss: (-3.470)(R -2.840, F -4.099)]  [G loss: 4.406] \n",
      "2128 [D loss: (-3.394)(R -3.105, F -3.682)]  [G loss: 4.281] \n",
      "2129 [D loss: (-3.572)(R -2.730, F -4.413)]  [G loss: 4.386] \n",
      "2129 [D loss: (-3.575)(R -2.837, F -4.312)]  [G loss: 4.338] \n",
      "2130 [D loss: (-3.321)(R -2.654, F -3.988)]  [G loss: 4.075] \n",
      "2130 [D loss: (-3.486)(R -3.093, F -3.879)]  [G loss: 4.275] \n",
      "2131 [D loss: (-3.453)(R -2.362, F -4.544)]  [G loss: 4.176] \n",
      "2131 [D loss: (-3.736)(R -2.992, F -4.480)]  [G loss: 4.671] \n",
      "2132 [D loss: (-3.456)(R -1.864, F -5.048)]  [G loss: 4.530] \n",
      "2132 [D loss: (-3.386)(R -2.611, F -4.162)]  [G loss: 4.448] \n",
      "2133 [D loss: (-3.676)(R -2.501, F -4.850)]  [G loss: 4.365] \n",
      "2133 [D loss: (-3.250)(R -2.463, F -4.037)]  [G loss: 4.237] \n",
      "2134 [D loss: (-3.509)(R -2.586, F -4.433)]  [G loss: 4.546] \n",
      "2134 [D loss: (-3.591)(R -2.667, F -4.514)]  [G loss: 4.300] \n",
      "2135 [D loss: (-3.832)(R -2.841, F -4.822)]  [G loss: 4.204] \n",
      "2135 [D loss: (-3.414)(R -2.656, F -4.173)]  [G loss: 4.076] \n",
      "2136 [D loss: (-3.270)(R -2.433, F -4.107)]  [G loss: 4.390] \n",
      "2136 [D loss: (-3.419)(R -3.069, F -3.770)]  [G loss: 4.454] \n",
      "2137 [D loss: (-3.638)(R -2.525, F -4.750)]  [G loss: 4.556] \n",
      "2137 [D loss: (-3.671)(R -2.480, F -4.862)]  [G loss: 4.372] \n",
      "2138 [D loss: (-3.684)(R -2.890, F -4.478)]  [G loss: 4.565] \n",
      "2138 [D loss: (-3.616)(R -2.472, F -4.760)]  [G loss: 4.600] \n",
      "2139 [D loss: (-3.694)(R -2.398, F -4.990)]  [G loss: 4.287] \n",
      "2139 [D loss: (-2.862)(R -2.299, F -3.426)]  [G loss: 4.420] \n",
      "2140 [D loss: (-3.267)(R -2.688, F -3.846)]  [G loss: 4.134] \n",
      "2140 [D loss: (-3.288)(R -2.855, F -3.722)]  [G loss: 4.164] \n",
      "2141 [D loss: (-2.965)(R -2.523, F -3.408)]  [G loss: 4.334] \n",
      "2141 [D loss: (-3.627)(R -2.902, F -4.353)]  [G loss: 4.393] \n",
      "2142 [D loss: (-3.420)(R -2.848, F -3.991)]  [G loss: 4.172] \n",
      "2142 [D loss: (-3.051)(R -2.470, F -3.632)]  [G loss: 4.118] \n",
      "2143 [D loss: (-3.566)(R -2.881, F -4.251)]  [G loss: 4.675] \n",
      "2143 [D loss: (-3.557)(R -2.835, F -4.280)]  [G loss: 4.241] \n",
      "2144 [D loss: (-3.196)(R -2.564, F -3.827)]  [G loss: 4.102] \n",
      "2144 [D loss: (-3.208)(R -2.724, F -3.692)]  [G loss: 4.212] \n",
      "2145 [D loss: (-3.368)(R -3.118, F -3.619)]  [G loss: 3.730] \n",
      "2145 [D loss: (-3.686)(R -3.343, F -4.030)]  [G loss: 3.807] \n",
      "2146 [D loss: (-3.351)(R -3.069, F -3.633)]  [G loss: 3.872] \n",
      "2146 [D loss: (-3.046)(R -2.789, F -3.302)]  [G loss: 3.970] \n",
      "2147 [D loss: (-3.536)(R -3.297, F -3.775)]  [G loss: 3.486] \n",
      "2147 [D loss: (-3.505)(R -2.816, F -4.194)]  [G loss: 3.664] \n",
      "2148 [D loss: (-3.517)(R -2.982, F -4.053)]  [G loss: 3.581] \n",
      "2148 [D loss: (-3.858)(R -3.507, F -4.209)]  [G loss: 3.602] \n",
      "2149 [D loss: (-3.497)(R -3.264, F -3.730)]  [G loss: 3.670] \n",
      "2149 [D loss: (-3.385)(R -2.965, F -3.805)]  [G loss: 4.065] \n",
      "2150 [D loss: (-3.230)(R -2.481, F -3.979)]  [G loss: 4.265] \n",
      "2150 [D loss: (-3.707)(R -3.144, F -4.270)]  [G loss: 4.169] \n",
      "2151 [D loss: (-3.622)(R -2.501, F -4.743)]  [G loss: 4.132] \n",
      "2151 [D loss: (-2.968)(R -2.398, F -3.538)]  [G loss: 4.446] \n",
      "2152 [D loss: (-3.454)(R -2.863, F -4.044)]  [G loss: 4.376] \n",
      "2152 [D loss: (-3.353)(R -2.457, F -4.250)]  [G loss: 4.433] \n",
      "2153 [D loss: (-3.268)(R -2.379, F -4.157)]  [G loss: 4.214] \n",
      "2153 [D loss: (-3.480)(R -2.414, F -4.545)]  [G loss: 4.298] \n",
      "2154 [D loss: (-3.036)(R -1.869, F -4.204)]  [G loss: 4.154] \n",
      "2154 [D loss: (-3.353)(R -2.884, F -3.822)]  [G loss: 4.305] \n",
      "2155 [D loss: (-3.126)(R -2.153, F -4.099)]  [G loss: 4.228] \n",
      "2155 [D loss: (-3.333)(R -2.517, F -4.149)]  [G loss: 4.272] \n",
      "2156 [D loss: (-3.322)(R -2.530, F -4.115)]  [G loss: 4.087] \n",
      "2156 [D loss: (-2.881)(R -1.942, F -3.821)]  [G loss: 4.288] \n",
      "2157 [D loss: (-3.270)(R -2.819, F -3.722)]  [G loss: 4.003] \n",
      "2157 [D loss: (-3.145)(R -2.608, F -3.682)]  [G loss: 4.286] \n",
      "2158 [D loss: (-3.209)(R -2.665, F -3.753)]  [G loss: 3.917] \n",
      "2158 [D loss: (-3.312)(R -2.819, F -3.804)]  [G loss: 4.009] \n",
      "2159 [D loss: (-3.141)(R -2.720, F -3.562)]  [G loss: 3.760] \n",
      "2159 [D loss: (-3.083)(R -2.753, F -3.414)]  [G loss: 3.926] \n",
      "2160 [D loss: (-2.873)(R -2.800, F -2.945)]  [G loss: 3.425] \n",
      "2160 [D loss: (-3.442)(R -3.017, F -3.866)]  [G loss: 3.913] \n",
      "2161 [D loss: (-3.426)(R -3.162, F -3.689)]  [G loss: 3.769] \n",
      "2161 [D loss: (-3.328)(R -3.256, F -3.400)]  [G loss: 3.553] \n",
      "2162 [D loss: (-3.220)(R -2.944, F -3.497)]  [G loss: 4.089] \n",
      "2162 [D loss: (-3.367)(R -2.573, F -4.160)]  [G loss: 3.860] \n",
      "2163 [D loss: (-3.320)(R -3.236, F -3.405)]  [G loss: 3.864] \n",
      "2163 [D loss: (-3.368)(R -2.877, F -3.858)]  [G loss: 3.966] \n",
      "2164 [D loss: (-3.222)(R -3.043, F -3.400)]  [G loss: 3.674] \n",
      "2164 [D loss: (-3.429)(R -3.310, F -3.548)]  [G loss: 3.916] \n",
      "2165 [D loss: (-3.451)(R -3.033, F -3.870)]  [G loss: 3.679] \n",
      "2165 [D loss: (-3.161)(R -2.916, F -3.406)]  [G loss: 3.711] \n",
      "2166 [D loss: (-3.518)(R -3.251, F -3.785)]  [G loss: 3.426] \n",
      "2166 [D loss: (-2.920)(R -2.737, F -3.102)]  [G loss: 3.457] \n",
      "2167 [D loss: (-3.288)(R -2.995, F -3.581)]  [G loss: 3.582] \n",
      "2167 [D loss: (-3.233)(R -2.772, F -3.694)]  [G loss: 3.793] \n",
      "2168 [D loss: (-3.374)(R -3.148, F -3.600)]  [G loss: 3.567] \n",
      "2168 [D loss: (-3.025)(R -2.809, F -3.241)]  [G loss: 3.564] \n",
      "2169 [D loss: (-3.599)(R -3.358, F -3.839)]  [G loss: 3.726] \n",
      "2169 [D loss: (-3.285)(R -2.977, F -3.594)]  [G loss: 3.574] \n",
      "2170 [D loss: (-3.452)(R -3.204, F -3.699)]  [G loss: 3.617] \n",
      "2170 [D loss: (-3.233)(R -3.009, F -3.456)]  [G loss: 3.859] \n",
      "2171 [D loss: (-3.364)(R -2.631, F -4.096)]  [G loss: 3.881] \n",
      "2171 [D loss: (-3.364)(R -3.454, F -3.275)]  [G loss: 4.004] \n",
      "2172 [D loss: (-3.298)(R -2.545, F -4.050)]  [G loss: 3.887] \n",
      "2172 [D loss: (-3.203)(R -2.876, F -3.529)]  [G loss: 4.028] \n",
      "2173 [D loss: (-3.400)(R -2.863, F -3.937)]  [G loss: 3.739] \n",
      "2173 [D loss: (-3.416)(R -2.994, F -3.839)]  [G loss: 3.944] \n",
      "2174 [D loss: (-3.322)(R -2.984, F -3.660)]  [G loss: 4.033] \n",
      "2174 [D loss: (-3.431)(R -2.651, F -4.211)]  [G loss: 4.120] \n",
      "2175 [D loss: (-3.465)(R -3.080, F -3.851)]  [G loss: 3.765] \n",
      "2175 [D loss: (-3.342)(R -2.564, F -4.120)]  [G loss: 3.901] \n",
      "2176 [D loss: (-3.583)(R -2.794, F -4.373)]  [G loss: 3.828] \n",
      "2176 [D loss: (-3.447)(R -2.920, F -3.974)]  [G loss: 4.000] \n",
      "2177 [D loss: (-3.475)(R -2.999, F -3.951)]  [G loss: 3.816] \n",
      "2177 [D loss: (-3.427)(R -3.173, F -3.682)]  [G loss: 3.610] \n",
      "2178 [D loss: (-3.370)(R -3.085, F -3.655)]  [G loss: 3.624] \n",
      "2178 [D loss: (-3.358)(R -3.037, F -3.679)]  [G loss: 3.516] \n",
      "2179 [D loss: (-3.219)(R -3.445, F -2.993)]  [G loss: 3.586] \n",
      "2179 [D loss: (-3.366)(R -3.430, F -3.301)]  [G loss: 3.174] \n",
      "2180 [D loss: (-3.341)(R -3.771, F -2.910)]  [G loss: 3.474] \n",
      "2180 [D loss: (-3.213)(R -3.500, F -2.926)]  [G loss: 3.151] \n",
      "2181 [D loss: (-3.410)(R -3.523, F -3.297)]  [G loss: 3.218] \n",
      "2181 [D loss: (-3.122)(R -3.436, F -2.809)]  [G loss: 3.189] \n",
      "2182 [D loss: (-3.575)(R -3.632, F -3.519)]  [G loss: 3.358] \n",
      "2182 [D loss: (-3.487)(R -3.519, F -3.454)]  [G loss: 3.218] \n",
      "2183 [D loss: (-3.315)(R -3.207, F -3.423)]  [G loss: 3.304] \n",
      "2183 [D loss: (-3.020)(R -3.325, F -2.716)]  [G loss: 3.149] \n",
      "2184 [D loss: (-3.690)(R -4.045, F -3.335)]  [G loss: 3.172] \n",
      "2184 [D loss: (-3.545)(R -3.559, F -3.531)]  [G loss: 3.309] \n",
      "2185 [D loss: (-3.440)(R -3.453, F -3.427)]  [G loss: 3.521] \n",
      "2185 [D loss: (-3.543)(R -3.511, F -3.574)]  [G loss: 3.524] \n",
      "2186 [D loss: (-3.411)(R -3.374, F -3.449)]  [G loss: 3.186] \n",
      "2186 [D loss: (-3.650)(R -3.479, F -3.821)]  [G loss: 3.391] \n",
      "2187 [D loss: (-3.240)(R -3.442, F -3.038)]  [G loss: 3.258] \n",
      "2187 [D loss: (-3.412)(R -3.696, F -3.129)]  [G loss: 3.287] \n",
      "2188 [D loss: (-3.376)(R -3.591, F -3.160)]  [G loss: 3.333] \n",
      "2188 [D loss: (-3.325)(R -3.750, F -2.899)]  [G loss: 3.027] \n",
      "2189 [D loss: (-3.664)(R -4.105, F -3.224)]  [G loss: 2.735] \n",
      "2189 [D loss: (-3.367)(R -3.857, F -2.878)]  [G loss: 2.977] \n",
      "2190 [D loss: (-3.406)(R -3.388, F -3.424)]  [G loss: 3.147] \n",
      "2190 [D loss: (-3.180)(R -3.522, F -2.838)]  [G loss: 3.199] \n",
      "2191 [D loss: (-3.544)(R -3.969, F -3.118)]  [G loss: 2.948] \n",
      "2191 [D loss: (-3.322)(R -3.957, F -2.686)]  [G loss: 3.220] \n",
      "2192 [D loss: (-3.044)(R -3.654, F -2.434)]  [G loss: 2.890] \n",
      "2192 [D loss: (-3.255)(R -4.054, F -2.456)]  [G loss: 3.246] \n",
      "2193 [D loss: (-3.114)(R -3.733, F -2.496)]  [G loss: 2.919] \n",
      "2193 [D loss: (-3.187)(R -3.694, F -2.680)]  [G loss: 2.876] \n",
      "2194 [D loss: (-3.578)(R -3.672, F -3.483)]  [G loss: 3.021] \n",
      "2194 [D loss: (-3.102)(R -3.374, F -2.831)]  [G loss: 2.907] \n",
      "2195 [D loss: (-2.968)(R -3.321, F -2.615)]  [G loss: 2.981] \n",
      "2195 [D loss: (-3.232)(R -3.753, F -2.711)]  [G loss: 2.943] \n",
      "2196 [D loss: (-3.603)(R -4.134, F -3.073)]  [G loss: 2.864] \n",
      "2196 [D loss: (-3.314)(R -3.918, F -2.710)]  [G loss: 2.727] \n",
      "2197 [D loss: (-3.321)(R -3.953, F -2.690)]  [G loss: 2.790] \n",
      "2197 [D loss: (-3.248)(R -3.691, F -2.804)]  [G loss: 2.816] \n",
      "2198 [D loss: (-3.263)(R -3.871, F -2.655)]  [G loss: 2.943] \n",
      "2198 [D loss: (-3.237)(R -3.454, F -3.021)]  [G loss: 2.860] \n",
      "2199 [D loss: (-3.458)(R -3.901, F -3.015)]  [G loss: 2.889] \n",
      "2199 [D loss: (-3.290)(R -3.928, F -2.652)]  [G loss: 2.910] \n",
      "2200 [D loss: (-3.303)(R -3.779, F -2.828)]  [G loss: 2.822] \n",
      "2200 [D loss: (-3.557)(R -3.866, F -3.248)]  [G loss: 2.987] \n",
      "2201 [D loss: (-3.089)(R -3.581, F -2.596)]  [G loss: 2.648] \n",
      "2201 [D loss: (-3.115)(R -3.820, F -2.409)]  [G loss: 2.689] \n",
      "2202 [D loss: (-3.076)(R -4.138, F -2.013)]  [G loss: 2.605] \n",
      "2202 [D loss: (-3.328)(R -4.223, F -2.434)]  [G loss: 2.740] \n",
      "2203 [D loss: (-2.936)(R -3.843, F -2.030)]  [G loss: 2.733] \n",
      "2203 [D loss: (-3.174)(R -3.962, F -2.386)]  [G loss: 2.809] \n",
      "2204 [D loss: (-3.250)(R -4.194, F -2.306)]  [G loss: 2.846] \n",
      "2204 [D loss: (-3.236)(R -4.228, F -2.244)]  [G loss: 2.727] \n",
      "2205 [D loss: (-3.118)(R -3.881, F -2.356)]  [G loss: 2.586] \n",
      "2205 [D loss: (-3.008)(R -3.787, F -2.229)]  [G loss: 2.265] \n",
      "2206 [D loss: (-3.511)(R -4.594, F -2.429)]  [G loss: 2.338] \n",
      "2206 [D loss: (-3.185)(R -4.354, F -2.015)]  [G loss: 2.241] \n",
      "2207 [D loss: (-3.354)(R -4.388, F -2.320)]  [G loss: 2.456] \n",
      "2207 [D loss: (-3.210)(R -4.146, F -2.273)]  [G loss: 2.520] \n",
      "2208 [D loss: (-3.519)(R -4.040, F -2.997)]  [G loss: 2.801] \n",
      "2208 [D loss: (-3.234)(R -3.791, F -2.677)]  [G loss: 2.381] \n",
      "2209 [D loss: (-3.085)(R -3.779, F -2.391)]  [G loss: 2.414] \n",
      "2209 [D loss: (-3.131)(R -3.869, F -2.393)]  [G loss: 2.708] \n",
      "2210 [D loss: (-3.118)(R -3.762, F -2.473)]  [G loss: 2.713] \n",
      "2210 [D loss: (-3.141)(R -3.798, F -2.485)]  [G loss: 2.615] \n",
      "2211 [D loss: (-2.893)(R -3.368, F -2.418)]  [G loss: 2.998] \n",
      "2211 [D loss: (-3.016)(R -3.583, F -2.450)]  [G loss: 2.757] \n",
      "2212 [D loss: (-3.408)(R -3.622, F -3.194)]  [G loss: 2.928] \n",
      "2212 [D loss: (-2.967)(R -3.408, F -2.526)]  [G loss: 2.779] \n",
      "2213 [D loss: (-3.113)(R -3.639, F -2.587)]  [G loss: 2.531] \n",
      "2213 [D loss: (-3.245)(R -3.897, F -2.592)]  [G loss: 2.785] \n",
      "2214 [D loss: (-2.815)(R -3.299, F -2.330)]  [G loss: 2.499] \n",
      "2214 [D loss: (-3.021)(R -3.532, F -2.509)]  [G loss: 2.841] \n",
      "2215 [D loss: (-3.357)(R -3.817, F -2.896)]  [G loss: 2.704] \n",
      "2215 [D loss: (-3.156)(R -3.682, F -2.630)]  [G loss: 2.681] \n",
      "2216 [D loss: (-2.834)(R -3.288, F -2.381)]  [G loss: 2.895] \n",
      "2216 [D loss: (-2.947)(R -3.176, F -2.718)]  [G loss: 3.011] \n",
      "2217 [D loss: (-2.677)(R -2.984, F -2.370)]  [G loss: 3.155] \n",
      "2217 [D loss: (-2.882)(R -3.342, F -2.422)]  [G loss: 2.543] \n",
      "2218 [D loss: (-3.165)(R -3.671, F -2.660)]  [G loss: 2.508] \n",
      "2218 [D loss: (-2.967)(R -3.638, F -2.295)]  [G loss: 2.518] \n",
      "2219 [D loss: (-3.042)(R -3.586, F -2.499)]  [G loss: 2.770] \n",
      "2219 [D loss: (-2.959)(R -3.202, F -2.715)]  [G loss: 2.752] \n",
      "2220 [D loss: (-3.023)(R -3.349, F -2.698)]  [G loss: 2.681] \n",
      "2220 [D loss: (-3.161)(R -3.476, F -2.846)]  [G loss: 3.135] \n",
      "2221 [D loss: (-3.102)(R -3.541, F -2.662)]  [G loss: 2.735] \n",
      "2221 [D loss: (-2.995)(R -3.395, F -2.596)]  [G loss: 2.683] \n",
      "2222 [D loss: (-3.174)(R -3.661, F -2.686)]  [G loss: 2.784] \n",
      "2222 [D loss: (-3.162)(R -3.634, F -2.690)]  [G loss: 2.438] \n",
      "2223 [D loss: (-3.004)(R -3.368, F -2.639)]  [G loss: 2.788] \n",
      "2223 [D loss: (-3.066)(R -3.876, F -2.255)]  [G loss: 2.166] \n",
      "2224 [D loss: (-2.892)(R -3.645, F -2.139)]  [G loss: 2.256] \n",
      "2224 [D loss: (-3.094)(R -3.964, F -2.224)]  [G loss: 2.348] \n",
      "2225 [D loss: (-3.107)(R -3.967, F -2.247)]  [G loss: 2.033] \n",
      "2225 [D loss: (-2.793)(R -3.682, F -1.903)]  [G loss: 2.160] \n",
      "2226 [D loss: (-3.051)(R -3.675, F -2.428)]  [G loss: 2.370] \n",
      "2226 [D loss: (-2.904)(R -3.849, F -1.960)]  [G loss: 2.246] \n",
      "2227 [D loss: (-3.017)(R -3.783, F -2.251)]  [G loss: 2.304] \n",
      "2227 [D loss: (-2.921)(R -4.120, F -1.723)]  [G loss: 2.483] \n",
      "2228 [D loss: (-2.491)(R -3.595, F -1.387)]  [G loss: 1.993] \n",
      "2228 [D loss: (-3.034)(R -3.881, F -2.187)]  [G loss: 2.130] \n",
      "2229 [D loss: (-2.918)(R -3.704, F -2.131)]  [G loss: 2.281] \n",
      "2229 [D loss: (-2.924)(R -4.134, F -1.714)]  [G loss: 2.200] \n",
      "2230 [D loss: (-2.741)(R -3.719, F -1.762)]  [G loss: 2.235] \n",
      "2230 [D loss: (-2.983)(R -3.906, F -2.059)]  [G loss: 2.124] \n",
      "2231 [D loss: (-3.151)(R -4.215, F -2.087)]  [G loss: 2.099] \n",
      "2231 [D loss: (-2.851)(R -3.736, F -1.966)]  [G loss: 2.202] \n",
      "2232 [D loss: (-2.697)(R -3.640, F -1.755)]  [G loss: 2.330] \n",
      "2232 [D loss: (-2.827)(R -3.963, F -1.690)]  [G loss: 2.188] \n",
      "2233 [D loss: (-2.749)(R -3.850, F -1.648)]  [G loss: 2.112] \n",
      "2233 [D loss: (-2.579)(R -3.686, F -1.471)]  [G loss: 1.780] \n",
      "2234 [D loss: (-2.523)(R -3.994, F -1.052)]  [G loss: 1.810] \n",
      "2234 [D loss: (-2.594)(R -4.170, F -1.019)]  [G loss: 1.709] \n",
      "2235 [D loss: (-2.674)(R -4.166, F -1.182)]  [G loss: 1.343] \n",
      "2235 [D loss: (-2.959)(R -4.525, F -1.394)]  [G loss: 1.511] \n",
      "2236 [D loss: (-2.985)(R -4.597, F -1.373)]  [G loss: 1.530] \n",
      "2236 [D loss: (-2.974)(R -4.207, F -1.741)]  [G loss: 1.323] \n",
      "2237 [D loss: (-2.717)(R -3.857, F -1.578)]  [G loss: 1.590] \n",
      "2237 [D loss: (-3.051)(R -4.105, F -1.997)]  [G loss: 2.097] \n",
      "2238 [D loss: (-2.789)(R -3.961, F -1.616)]  [G loss: 2.170] \n",
      "2238 [D loss: (-2.636)(R -3.748, F -1.525)]  [G loss: 1.853] \n",
      "2239 [D loss: (-2.846)(R -3.862, F -1.830)]  [G loss: 1.828] \n",
      "2239 [D loss: (-2.813)(R -3.836, F -1.790)]  [G loss: 1.960] \n",
      "2240 [D loss: (-2.651)(R -3.429, F -1.874)]  [G loss: 2.262] \n",
      "2240 [D loss: (-2.748)(R -3.486, F -2.011)]  [G loss: 2.107] \n",
      "2241 [D loss: (-2.914)(R -3.879, F -1.949)]  [G loss: 2.374] \n",
      "2241 [D loss: (-2.690)(R -3.403, F -1.976)]  [G loss: 2.153] \n",
      "2242 [D loss: (-2.945)(R -3.510, F -2.381)]  [G loss: 2.244] \n",
      "2242 [D loss: (-2.967)(R -3.543, F -2.390)]  [G loss: 2.221] \n",
      "2243 [D loss: (-2.893)(R -3.707, F -2.080)]  [G loss: 2.162] \n",
      "2243 [D loss: (-3.250)(R -3.671, F -2.830)]  [G loss: 2.044] \n",
      "2244 [D loss: (-2.722)(R -3.401, F -2.044)]  [G loss: 2.084] \n",
      "2244 [D loss: (-2.778)(R -3.445, F -2.111)]  [G loss: 2.021] \n",
      "2245 [D loss: (-2.454)(R -3.225, F -1.684)]  [G loss: 1.898] \n",
      "2245 [D loss: (-2.717)(R -3.568, F -1.865)]  [G loss: 1.996] \n",
      "2246 [D loss: (-2.868)(R -3.656, F -2.079)]  [G loss: 1.600] \n",
      "2246 [D loss: (-2.765)(R -3.690, F -1.840)]  [G loss: 2.037] \n",
      "2247 [D loss: (-2.670)(R -3.486, F -1.853)]  [G loss: 1.770] \n",
      "2247 [D loss: (-2.757)(R -4.079, F -1.436)]  [G loss: 2.323] \n",
      "2248 [D loss: (-2.759)(R -3.804, F -1.713)]  [G loss: 1.854] \n",
      "2248 [D loss: (-2.851)(R -3.674, F -2.028)]  [G loss: 1.992] \n",
      "2249 [D loss: (-2.809)(R -3.706, F -1.913)]  [G loss: 1.998] \n",
      "2249 [D loss: (-2.566)(R -3.478, F -1.653)]  [G loss: 1.863] \n",
      "2250 [D loss: (-3.042)(R -4.200, F -1.884)]  [G loss: 1.753] \n",
      "2250 [D loss: (-2.653)(R -3.732, F -1.574)]  [G loss: 1.571] \n",
      "2251 [D loss: (-2.692)(R -3.828, F -1.555)]  [G loss: 1.653] \n",
      "2251 [D loss: (-2.750)(R -4.021, F -1.479)]  [G loss: 1.326] \n",
      "2252 [D loss: (-2.773)(R -4.226, F -1.321)]  [G loss: 1.538] \n",
      "2252 [D loss: (-2.518)(R -3.920, F -1.116)]  [G loss: 1.700] \n",
      "2253 [D loss: (-2.518)(R -3.915, F -1.121)]  [G loss: 1.526] \n",
      "2253 [D loss: (-2.843)(R -4.102, F -1.584)]  [G loss: 1.668] \n",
      "2254 [D loss: (-2.534)(R -3.965, F -1.103)]  [G loss: 1.334] \n",
      "2254 [D loss: (-2.852)(R -4.495, F -1.208)]  [G loss: 1.496] \n",
      "2255 [D loss: (-2.572)(R -4.093, F -1.050)]  [G loss: 1.201] \n",
      "2255 [D loss: (-2.815)(R -3.961, F -1.669)]  [G loss: 1.600] \n",
      "2256 [D loss: (-2.689)(R -4.053, F -1.326)]  [G loss: 1.792] \n",
      "2256 [D loss: (-2.824)(R -3.979, F -1.669)]  [G loss: 1.627] \n",
      "2257 [D loss: (-2.855)(R -3.885, F -1.825)]  [G loss: 1.930] \n",
      "2257 [D loss: (-2.503)(R -3.718, F -1.288)]  [G loss: 1.613] \n",
      "2258 [D loss: (-2.555)(R -3.978, F -1.132)]  [G loss: 1.897] \n",
      "2258 [D loss: (-2.706)(R -4.000, F -1.411)]  [G loss: 1.474] \n",
      "2259 [D loss: (-2.526)(R -3.855, F -1.197)]  [G loss: 1.590] \n",
      "2259 [D loss: (-2.442)(R -3.822, F -1.061)]  [G loss: 1.674] \n",
      "2260 [D loss: (-2.797)(R -3.960, F -1.633)]  [G loss: 1.294] \n",
      "2260 [D loss: (-2.481)(R -3.887, F -1.074)]  [G loss: 1.232] \n",
      "2261 [D loss: (-2.559)(R -3.864, F -1.255)]  [G loss: 1.218] \n",
      "2261 [D loss: (-2.666)(R -4.079, F -1.252)]  [G loss: 1.234] \n",
      "2262 [D loss: (-2.589)(R -4.011, F -1.166)]  [G loss: 1.755] \n",
      "2262 [D loss: (-2.588)(R -3.708, F -1.467)]  [G loss: 1.355] \n",
      "2263 [D loss: (-2.862)(R -4.134, F -1.589)]  [G loss: 1.570] \n",
      "2263 [D loss: (-2.851)(R -4.149, F -1.553)]  [G loss: 1.417] \n",
      "2264 [D loss: (-2.638)(R -4.073, F -1.203)]  [G loss: 1.149] \n",
      "2264 [D loss: (-2.713)(R -3.815, F -1.611)]  [G loss: 1.494] \n",
      "2265 [D loss: (-2.729)(R -3.795, F -1.662)]  [G loss: 1.255] \n",
      "2265 [D loss: (-3.101)(R -4.299, F -1.902)]  [G loss: 1.369] \n",
      "2266 [D loss: (-2.381)(R -3.748, F -1.014)]  [G loss: 1.689] \n",
      "2266 [D loss: (-2.665)(R -3.778, F -1.552)]  [G loss: 1.567] \n",
      "2267 [D loss: (-2.829)(R -3.822, F -1.837)]  [G loss: 1.842] \n",
      "2267 [D loss: (-2.633)(R -3.725, F -1.541)]  [G loss: 1.589] \n",
      "2268 [D loss: (-2.478)(R -3.609, F -1.347)]  [G loss: 1.203] \n",
      "2268 [D loss: (-2.656)(R -4.050, F -1.262)]  [G loss: 1.482] \n",
      "2269 [D loss: (-2.538)(R -4.217, F -0.859)]  [G loss: 1.091] \n",
      "2269 [D loss: (-2.583)(R -4.132, F -1.035)]  [G loss: 1.140] \n",
      "2270 [D loss: (-2.499)(R -4.219, F -0.780)]  [G loss: 1.074] \n",
      "2270 [D loss: (-2.799)(R -4.719, F -0.879)]  [G loss: 0.951] \n",
      "2271 [D loss: (-2.627)(R -4.089, F -1.165)]  [G loss: 1.004] \n",
      "2271 [D loss: (-2.708)(R -4.252, F -1.163)]  [G loss: 1.224] \n",
      "2272 [D loss: (-2.648)(R -4.385, F -0.912)]  [G loss: 1.304] \n",
      "2272 [D loss: (-2.771)(R -4.406, F -1.135)]  [G loss: 1.375] \n",
      "2273 [D loss: (-2.700)(R -4.368, F -1.032)]  [G loss: 1.534] \n",
      "2273 [D loss: (-2.728)(R -4.107, F -1.349)]  [G loss: 1.314] \n",
      "2274 [D loss: (-2.642)(R -4.098, F -1.186)]  [G loss: 1.373] \n",
      "2274 [D loss: (-2.794)(R -4.109, F -1.479)]  [G loss: 1.064] \n",
      "2275 [D loss: (-2.843)(R -4.254, F -1.432)]  [G loss: 1.127] \n",
      "2275 [D loss: (-2.734)(R -3.937, F -1.531)]  [G loss: 1.314] \n",
      "2276 [D loss: (-2.489)(R -3.638, F -1.339)]  [G loss: 1.533] \n",
      "2276 [D loss: (-2.771)(R -3.798, F -1.744)]  [G loss: 1.382] \n",
      "2277 [D loss: (-2.663)(R -3.812, F -1.514)]  [G loss: 1.614] \n",
      "2277 [D loss: (-2.522)(R -3.922, F -1.123)]  [G loss: 1.508] \n",
      "2278 [D loss: (-2.442)(R -3.783, F -1.101)]  [G loss: 1.246] \n",
      "2278 [D loss: (-2.310)(R -3.756, F -0.864)]  [G loss: 1.190] \n",
      "2279 [D loss: (-2.683)(R -4.181, F -1.185)]  [G loss: 1.220] \n",
      "2279 [D loss: (-2.692)(R -4.067, F -1.318)]  [G loss: 1.065] \n",
      "2280 [D loss: (-2.630)(R -3.995, F -1.265)]  [G loss: 0.848] \n",
      "2280 [D loss: (-2.707)(R -4.282, F -1.131)]  [G loss: 0.956] \n",
      "2281 [D loss: (-2.616)(R -3.759, F -1.472)]  [G loss: 1.124] \n",
      "2281 [D loss: (-2.633)(R -4.194, F -1.071)]  [G loss: 1.092] \n",
      "2282 [D loss: (-2.361)(R -3.779, F -0.943)]  [G loss: 1.211] \n",
      "2282 [D loss: (-2.456)(R -4.085, F -0.827)]  [G loss: 1.234] \n",
      "2283 [D loss: (-2.727)(R -3.994, F -1.460)]  [G loss: 0.985] \n",
      "2283 [D loss: (-2.518)(R -3.921, F -1.115)]  [G loss: 0.997] \n",
      "2284 [D loss: (-2.316)(R -3.882, F -0.750)]  [G loss: 1.239] \n",
      "2284 [D loss: (-2.375)(R -3.638, F -1.112)]  [G loss: 1.081] \n",
      "2285 [D loss: (-2.587)(R -4.036, F -1.138)]  [G loss: 1.324] \n",
      "2285 [D loss: (-2.785)(R -3.834, F -1.736)]  [G loss: 1.249] \n",
      "2286 [D loss: (-2.371)(R -3.738, F -1.004)]  [G loss: 1.221] \n",
      "2286 [D loss: (-2.388)(R -3.868, F -0.908)]  [G loss: 1.407] \n",
      "2287 [D loss: (-2.633)(R -4.021, F -1.244)]  [G loss: 1.235] \n",
      "2287 [D loss: (-2.450)(R -3.855, F -1.044)]  [G loss: 1.235] \n",
      "2288 [D loss: (-2.496)(R -3.875, F -1.116)]  [G loss: 1.205] \n",
      "2288 [D loss: (-2.360)(R -3.944, F -0.776)]  [G loss: 1.152] \n",
      "2289 [D loss: (-2.635)(R -3.971, F -1.299)]  [G loss: 1.313] \n",
      "2289 [D loss: (-2.313)(R -3.581, F -1.045)]  [G loss: 1.177] \n",
      "2290 [D loss: (-2.272)(R -3.824, F -0.720)]  [G loss: 1.439] \n",
      "2290 [D loss: (-2.789)(R -4.189, F -1.388)]  [G loss: 1.300] \n",
      "2291 [D loss: (-2.204)(R -3.842, F -0.566)]  [G loss: 0.988] \n",
      "2291 [D loss: (-2.810)(R -4.128, F -1.492)]  [G loss: 1.070] \n",
      "2292 [D loss: (-2.477)(R -3.893, F -1.062)]  [G loss: 0.920] \n",
      "2292 [D loss: (-2.385)(R -3.986, F -0.783)]  [G loss: 1.152] \n",
      "2293 [D loss: (-2.467)(R -4.248, F -0.685)]  [G loss: 1.176] \n",
      "2293 [D loss: (-2.370)(R -3.898, F -0.842)]  [G loss: 0.903] \n",
      "2294 [D loss: (-2.439)(R -3.984, F -0.893)]  [G loss: 1.080] \n",
      "2294 [D loss: (-2.538)(R -4.108, F -0.968)]  [G loss: 0.894] \n",
      "2295 [D loss: (-2.497)(R -4.382, F -0.613)]  [G loss: 0.880] \n",
      "2295 [D loss: (-2.500)(R -4.278, F -0.722)]  [G loss: 0.527] \n",
      "2296 [D loss: (-2.405)(R -4.470, F -0.340)]  [G loss: 0.438] \n",
      "2296 [D loss: (-2.414)(R -4.588, F -0.240)]  [G loss: 0.332] \n",
      "2297 [D loss: (-2.488)(R -4.541, F -0.435)]  [G loss: 0.707] \n",
      "2297 [D loss: (-2.534)(R -4.465, F -0.603)]  [G loss: 0.794] \n",
      "2298 [D loss: (-2.390)(R -4.285, F -0.495)]  [G loss: 0.491] \n",
      "2298 [D loss: (-2.575)(R -4.550, F -0.599)]  [G loss: 0.803] \n",
      "2299 [D loss: (-2.432)(R -4.480, F -0.385)]  [G loss: 0.556] \n",
      "2299 [D loss: (-2.440)(R -4.197, F -0.683)]  [G loss: 0.550] \n",
      "2300 [D loss: (-2.467)(R -4.672, F -0.262)]  [G loss: 0.610] \n",
      "2300 [D loss: (-2.444)(R -4.600, F -0.288)]  [G loss: 0.468] \n",
      "2301 [D loss: (-2.335)(R -4.592, F -0.078)]  [G loss: 0.453] \n",
      "2301 [D loss: (-2.489)(R -4.634, F -0.343)]  [G loss: 0.379] \n",
      "2302 [D loss: (-2.345)(R -4.405, F -0.285)]  [G loss: 0.289] \n",
      "2302 [D loss: (-2.369)(R -4.328, F -0.410)]  [G loss: 0.373] \n",
      "2303 [D loss: (-2.372)(R -4.457, F -0.286)]  [G loss: 0.740] \n",
      "2303 [D loss: (-2.399)(R -4.318, F -0.479)]  [G loss: 0.558] \n",
      "2304 [D loss: (-2.357)(R -4.276, F -0.438)]  [G loss: 0.689] \n",
      "2304 [D loss: (-2.768)(R -4.369, F -1.167)]  [G loss: 0.646] \n",
      "2305 [D loss: (-2.409)(R -4.327, F -0.492)]  [G loss: 0.570] \n",
      "2305 [D loss: (-2.298)(R -3.977, F -0.619)]  [G loss: 0.835] \n",
      "2306 [D loss: (-2.251)(R -4.303, F -0.199)]  [G loss: 0.797] \n",
      "2306 [D loss: (-2.334)(R -4.260, F -0.407)]  [G loss: 0.649] \n",
      "2307 [D loss: (-2.371)(R -4.418, F -0.324)]  [G loss: 0.700] \n",
      "2307 [D loss: (-2.176)(R -4.351, F -0.002)]  [G loss: 0.286] \n",
      "2308 [D loss: (-2.306)(R -4.671, F 0.060)]  [G loss: 0.149] \n",
      "2308 [D loss: (-2.224)(R -4.950, F 0.502)]  [G loss: -0.065] \n",
      "2309 [D loss: (-2.486)(R -4.952, F -0.020)]  [G loss: 0.249] \n",
      "2309 [D loss: (-2.472)(R -5.091, F 0.147)]  [G loss: -0.172] \n",
      "2310 [D loss: (-2.071)(R -4.564, F 0.423)]  [G loss: -0.190] \n",
      "2310 [D loss: (-2.373)(R -4.747, F 0.002)]  [G loss: -0.080] \n",
      "2311 [D loss: (-2.354)(R -5.025, F 0.316)]  [G loss: 0.211] \n",
      "2311 [D loss: (-2.202)(R -4.920, F 0.515)]  [G loss: -0.196] \n",
      "2312 [D loss: (-2.427)(R -5.152, F 0.299)]  [G loss: -0.433] \n",
      "2312 [D loss: (-2.578)(R -5.137, F -0.019)]  [G loss: -0.116] \n",
      "2313 [D loss: (-2.070)(R -4.723, F 0.583)]  [G loss: -0.214] \n",
      "2313 [D loss: (-2.215)(R -4.909, F 0.478)]  [G loss: -0.009] \n",
      "2314 [D loss: (-2.446)(R -4.640, F -0.252)]  [G loss: -0.144] \n",
      "2314 [D loss: (-2.221)(R -4.730, F 0.287)]  [G loss: -0.040] \n",
      "2315 [D loss: (-2.147)(R -4.548, F 0.255)]  [G loss: -0.203] \n",
      "2315 [D loss: (-2.272)(R -4.680, F 0.137)]  [G loss: 0.073] \n",
      "2316 [D loss: (-2.328)(R -4.756, F 0.100)]  [G loss: -0.094] \n",
      "2316 [D loss: (-2.362)(R -4.471, F -0.253)]  [G loss: -0.029] \n",
      "2317 [D loss: (-2.439)(R -5.047, F 0.169)]  [G loss: 0.106] \n",
      "2317 [D loss: (-2.493)(R -4.922, F -0.063)]  [G loss: 0.050] \n",
      "2318 [D loss: (-2.380)(R -4.752, F -0.008)]  [G loss: 0.207] \n",
      "2318 [D loss: (-2.037)(R -4.521, F 0.448)]  [G loss: 0.239] \n",
      "2319 [D loss: (-2.392)(R -4.724, F -0.060)]  [G loss: 0.349] \n",
      "2319 [D loss: (-2.189)(R -4.461, F 0.084)]  [G loss: 0.156] \n",
      "2320 [D loss: (-2.063)(R -4.479, F 0.354)]  [G loss: -0.111] \n",
      "2320 [D loss: (-2.148)(R -4.805, F 0.509)]  [G loss: -0.356] \n",
      "2321 [D loss: (-2.388)(R -4.812, F 0.035)]  [G loss: -0.098] \n",
      "2321 [D loss: (-2.423)(R -5.020, F 0.174)]  [G loss: -0.250] \n",
      "2322 [D loss: (-2.515)(R -5.062, F 0.031)]  [G loss: -0.278] \n",
      "2322 [D loss: (-2.209)(R -4.670, F 0.252)]  [G loss: -0.528] \n",
      "2323 [D loss: (-2.064)(R -4.803, F 0.675)]  [G loss: -0.469] \n",
      "2323 [D loss: (-2.207)(R -4.818, F 0.403)]  [G loss: -0.226] \n",
      "2324 [D loss: (-2.251)(R -4.976, F 0.475)]  [G loss: -0.087] \n",
      "2324 [D loss: (-2.205)(R -4.859, F 0.449)]  [G loss: -0.344] \n",
      "2325 [D loss: (-2.114)(R -5.092, F 0.865)]  [G loss: -0.520] \n",
      "2325 [D loss: (-2.129)(R -4.809, F 0.550)]  [G loss: -0.488] \n",
      "2326 [D loss: (-2.241)(R -5.109, F 0.627)]  [G loss: -0.613] \n",
      "2326 [D loss: (-2.243)(R -5.138, F 0.652)]  [G loss: -0.814] \n",
      "2327 [D loss: (-2.202)(R -5.342, F 0.939)]  [G loss: -0.413] \n",
      "2327 [D loss: (-2.376)(R -5.264, F 0.512)]  [G loss: -0.533] \n",
      "2328 [D loss: (-2.284)(R -5.140, F 0.572)]  [G loss: -0.546] \n",
      "2328 [D loss: (-2.376)(R -5.201, F 0.449)]  [G loss: -0.652] \n",
      "2329 [D loss: (-2.129)(R -5.022, F 0.765)]  [G loss: -0.532] \n",
      "2329 [D loss: (-1.997)(R -5.058, F 1.064)]  [G loss: -0.569] \n",
      "2330 [D loss: (-2.205)(R -5.123, F 0.714)]  [G loss: -0.542] \n",
      "2330 [D loss: (-2.161)(R -5.190, F 0.867)]  [G loss: -0.645] \n",
      "2331 [D loss: (-1.946)(R -5.188, F 1.295)]  [G loss: -0.559] \n",
      "2331 [D loss: (-2.225)(R -5.421, F 0.970)]  [G loss: -1.076] \n",
      "2332 [D loss: (-2.223)(R -5.360, F 0.914)]  [G loss: -0.661] \n",
      "2332 [D loss: (-2.374)(R -5.246, F 0.497)]  [G loss: -0.753] \n",
      "2333 [D loss: (-2.111)(R -5.007, F 0.785)]  [G loss: -0.627] \n",
      "2333 [D loss: (-2.264)(R -5.328, F 0.800)]  [G loss: -0.738] \n",
      "2334 [D loss: (-2.236)(R -5.081, F 0.610)]  [G loss: -0.710] \n",
      "2334 [D loss: (-2.303)(R -5.187, F 0.580)]  [G loss: -0.752] \n",
      "2335 [D loss: (-1.984)(R -4.905, F 0.937)]  [G loss: -0.757] \n",
      "2335 [D loss: (-2.100)(R -4.753, F 0.553)]  [G loss: -0.390] \n",
      "2336 [D loss: (-2.323)(R -5.015, F 0.370)]  [G loss: -0.363] \n",
      "2336 [D loss: (-2.247)(R -5.076, F 0.582)]  [G loss: -0.463] \n",
      "2337 [D loss: (-1.982)(R -4.689, F 0.724)]  [G loss: -0.562] \n",
      "2337 [D loss: (-2.259)(R -5.104, F 0.586)]  [G loss: -0.516] \n",
      "2338 [D loss: (-2.285)(R -5.138, F 0.568)]  [G loss: -0.416] \n",
      "2338 [D loss: (-2.105)(R -4.824, F 0.614)]  [G loss: -0.447] \n",
      "2339 [D loss: (-2.106)(R -4.789, F 0.577)]  [G loss: -0.393] \n",
      "2339 [D loss: (-2.096)(R -4.831, F 0.640)]  [G loss: -0.414] \n",
      "2340 [D loss: (-2.353)(R -4.897, F 0.191)]  [G loss: -0.253] \n",
      "2340 [D loss: (-2.402)(R -4.977, F 0.172)]  [G loss: -0.306] \n",
      "2341 [D loss: (-2.193)(R -4.826, F 0.440)]  [G loss: -0.349] \n",
      "2341 [D loss: (-2.117)(R -4.660, F 0.425)]  [G loss: -0.358] \n",
      "2342 [D loss: (-2.070)(R -4.854, F 0.714)]  [G loss: -0.697] \n",
      "2342 [D loss: (-2.206)(R -4.936, F 0.524)]  [G loss: -0.473] \n",
      "2343 [D loss: (-2.222)(R -5.031, F 0.587)]  [G loss: -0.691] \n",
      "2343 [D loss: (-1.963)(R -5.035, F 1.110)]  [G loss: -0.510] \n",
      "2344 [D loss: (-2.261)(R -5.172, F 0.650)]  [G loss: -0.446] \n",
      "2344 [D loss: (-2.377)(R -5.212, F 0.457)]  [G loss: -0.720] \n",
      "2345 [D loss: (-2.185)(R -5.170, F 0.800)]  [G loss: -0.739] \n",
      "2345 [D loss: (-2.071)(R -5.267, F 1.126)]  [G loss: -1.140] \n",
      "2346 [D loss: (-2.134)(R -5.651, F 1.382)]  [G loss: -1.075] \n",
      "2346 [D loss: (-2.137)(R -5.554, F 1.280)]  [G loss: -0.978] \n",
      "2347 [D loss: (-2.233)(R -5.512, F 1.046)]  [G loss: -1.158] \n",
      "2347 [D loss: (-2.022)(R -5.365, F 1.321)]  [G loss: -0.877] \n",
      "2348 [D loss: (-1.969)(R -5.329, F 1.392)]  [G loss: -1.010] \n",
      "2348 [D loss: (-2.094)(R -5.363, F 1.174)]  [G loss: -1.125] \n",
      "2349 [D loss: (-2.050)(R -5.494, F 1.393)]  [G loss: -1.245] \n",
      "2349 [D loss: (-2.170)(R -5.551, F 1.212)]  [G loss: -1.039] \n",
      "2350 [D loss: (-2.138)(R -5.542, F 1.266)]  [G loss: -1.036] \n",
      "2350 [D loss: (-2.058)(R -5.344, F 1.228)]  [G loss: -0.848] \n",
      "2351 [D loss: (-2.178)(R -5.337, F 0.981)]  [G loss: -0.930] \n",
      "2351 [D loss: (-2.150)(R -5.455, F 1.156)]  [G loss: -0.883] \n",
      "2352 [D loss: (-2.083)(R -5.472, F 1.305)]  [G loss: -0.941] \n",
      "2352 [D loss: (-2.031)(R -5.030, F 0.967)]  [G loss: -0.758] \n",
      "2353 [D loss: (-2.156)(R -5.087, F 0.776)]  [G loss: -0.488] \n",
      "2353 [D loss: (-1.920)(R -4.718, F 0.879)]  [G loss: -0.538] \n",
      "2354 [D loss: (-2.359)(R -5.224, F 0.506)]  [G loss: -0.488] \n",
      "2354 [D loss: (-2.300)(R -5.100, F 0.501)]  [G loss: -0.705] \n",
      "2355 [D loss: (-2.118)(R -4.897, F 0.661)]  [G loss: -0.486] \n",
      "2355 [D loss: (-2.204)(R -5.017, F 0.610)]  [G loss: -0.562] \n",
      "2356 [D loss: (-2.301)(R -5.121, F 0.520)]  [G loss: -0.662] \n",
      "2356 [D loss: (-2.290)(R -5.225, F 0.644)]  [G loss: -0.721] \n",
      "2357 [D loss: (-2.140)(R -5.107, F 0.828)]  [G loss: -0.797] \n",
      "2357 [D loss: (-2.050)(R -5.200, F 1.100)]  [G loss: -0.704] \n",
      "2358 [D loss: (-2.196)(R -4.978, F 0.587)]  [G loss: -0.825] \n",
      "2358 [D loss: (-2.281)(R -5.129, F 0.567)]  [G loss: -0.574] \n",
      "2359 [D loss: (-2.031)(R -5.057, F 0.994)]  [G loss: -0.627] \n",
      "2359 [D loss: (-2.242)(R -4.958, F 0.474)]  [G loss: -0.654] \n",
      "2360 [D loss: (-2.314)(R -4.898, F 0.270)]  [G loss: -0.434] \n",
      "2360 [D loss: (-1.975)(R -4.600, F 0.651)]  [G loss: -0.721] \n",
      "2361 [D loss: (-2.120)(R -4.795, F 0.556)]  [G loss: -0.559] \n",
      "2361 [D loss: (-2.256)(R -4.983, F 0.470)]  [G loss: -0.436] \n",
      "2362 [D loss: (-2.195)(R -4.906, F 0.515)]  [G loss: -0.513] \n",
      "2362 [D loss: (-2.146)(R -4.673, F 0.381)]  [G loss: -0.444] \n",
      "2363 [D loss: (-2.144)(R -4.778, F 0.490)]  [G loss: -0.253] \n",
      "2363 [D loss: (-2.083)(R -4.777, F 0.611)]  [G loss: -0.394] \n",
      "2364 [D loss: (-2.150)(R -4.761, F 0.461)]  [G loss: -0.484] \n",
      "2364 [D loss: (-2.038)(R -4.720, F 0.644)]  [G loss: -0.486] \n",
      "2365 [D loss: (-2.024)(R -4.765, F 0.717)]  [G loss: -0.357] \n",
      "2365 [D loss: (-2.257)(R -4.858, F 0.344)]  [G loss: -0.562] \n",
      "2366 [D loss: (-2.133)(R -4.758, F 0.492)]  [G loss: -0.260] \n",
      "2366 [D loss: (-2.178)(R -4.899, F 0.543)]  [G loss: -0.398] \n",
      "2367 [D loss: (-2.161)(R -4.749, F 0.427)]  [G loss: -0.334] \n",
      "2367 [D loss: (-2.153)(R -4.847, F 0.540)]  [G loss: -0.391] \n",
      "2368 [D loss: (-2.174)(R -4.796, F 0.448)]  [G loss: -0.356] \n",
      "2368 [D loss: (-2.240)(R -4.908, F 0.428)]  [G loss: -0.395] \n",
      "2369 [D loss: (-2.069)(R -4.793, F 0.655)]  [G loss: -0.088] \n",
      "2369 [D loss: (-2.282)(R -5.060, F 0.496)]  [G loss: -0.336] \n",
      "2370 [D loss: (-2.236)(R -4.855, F 0.382)]  [G loss: -0.764] \n",
      "2370 [D loss: (-2.057)(R -4.844, F 0.730)]  [G loss: -0.687] \n",
      "2371 [D loss: (-2.134)(R -5.132, F 0.864)]  [G loss: -0.504] \n",
      "2371 [D loss: (-2.055)(R -4.949, F 0.840)]  [G loss: -0.531] \n",
      "2372 [D loss: (-2.091)(R -5.002, F 0.820)]  [G loss: -0.673] \n",
      "2372 [D loss: (-2.177)(R -5.136, F 0.781)]  [G loss: -0.708] \n",
      "2373 [D loss: (-2.034)(R -5.022, F 0.955)]  [G loss: -0.639] \n",
      "2373 [D loss: (-2.084)(R -5.166, F 0.998)]  [G loss: -0.766] \n",
      "2374 [D loss: (-2.163)(R -5.270, F 0.944)]  [G loss: -0.850] \n",
      "2374 [D loss: (-2.238)(R -5.098, F 0.623)]  [G loss: -0.745] \n",
      "2375 [D loss: (-2.237)(R -4.979, F 0.506)]  [G loss: -0.675] \n",
      "2375 [D loss: (-2.299)(R -5.105, F 0.506)]  [G loss: -0.377] \n",
      "2376 [D loss: (-2.177)(R -4.795, F 0.441)]  [G loss: -0.565] \n",
      "2376 [D loss: (-2.330)(R -5.104, F 0.445)]  [G loss: -0.638] \n",
      "2377 [D loss: (-2.095)(R -4.667, F 0.477)]  [G loss: -0.406] \n",
      "2377 [D loss: (-1.934)(R -4.722, F 0.853)]  [G loss: -0.709] \n",
      "2378 [D loss: (-1.998)(R -4.736, F 0.741)]  [G loss: -0.554] \n",
      "2378 [D loss: (-2.143)(R -4.977, F 0.690)]  [G loss: -0.570] \n",
      "2379 [D loss: (-2.150)(R -4.849, F 0.549)]  [G loss: -0.549] \n",
      "2379 [D loss: (-2.042)(R -4.780, F 0.695)]  [G loss: -0.697] \n",
      "2380 [D loss: (-2.004)(R -4.827, F 0.820)]  [G loss: -0.732] \n",
      "2380 [D loss: (-2.086)(R -4.874, F 0.703)]  [G loss: -0.734] \n",
      "2381 [D loss: (-2.126)(R -5.007, F 0.755)]  [G loss: -0.511] \n",
      "2381 [D loss: (-1.951)(R -4.822, F 0.920)]  [G loss: -0.486] \n",
      "2382 [D loss: (-2.142)(R -4.938, F 0.653)]  [G loss: -0.589] \n",
      "2382 [D loss: (-2.153)(R -4.789, F 0.482)]  [G loss: -0.375] \n",
      "2383 [D loss: (-2.074)(R -4.695, F 0.547)]  [G loss: -0.501] \n",
      "2383 [D loss: (-1.934)(R -4.322, F 0.454)]  [G loss: -0.641] \n",
      "2384 [D loss: (-2.107)(R -4.871, F 0.657)]  [G loss: -0.571] \n",
      "2384 [D loss: (-1.968)(R -4.885, F 0.949)]  [G loss: -0.699] \n",
      "2385 [D loss: (-1.959)(R -4.699, F 0.780)]  [G loss: -0.588] \n",
      "2385 [D loss: (-2.101)(R -4.875, F 0.672)]  [G loss: -0.646] \n",
      "2386 [D loss: (-2.038)(R -4.862, F 0.786)]  [G loss: -0.595] \n",
      "2386 [D loss: (-1.977)(R -5.024, F 1.071)]  [G loss: -0.676] \n",
      "2387 [D loss: (-2.039)(R -4.947, F 0.869)]  [G loss: -0.665] \n",
      "2387 [D loss: (-2.127)(R -5.006, F 0.752)]  [G loss: -0.714] \n",
      "2388 [D loss: (-1.841)(R -4.887, F 1.204)]  [G loss: -0.815] \n",
      "2388 [D loss: (-2.118)(R -5.214, F 0.977)]  [G loss: -0.933] \n",
      "2389 [D loss: (-2.124)(R -5.273, F 1.024)]  [G loss: -0.979] \n",
      "2389 [D loss: (-1.991)(R -5.137, F 1.154)]  [G loss: -0.980] \n",
      "2390 [D loss: (-1.964)(R -5.007, F 1.080)]  [G loss: -0.850] \n",
      "2390 [D loss: (-2.025)(R -5.011, F 0.962)]  [G loss: -0.993] \n",
      "2391 [D loss: (-1.973)(R -5.249, F 1.302)]  [G loss: -1.007] \n",
      "2391 [D loss: (-1.962)(R -4.924, F 1.000)]  [G loss: -0.897] \n",
      "2392 [D loss: (-1.987)(R -5.070, F 1.095)]  [G loss: -0.748] \n",
      "2392 [D loss: (-1.966)(R -5.018, F 1.085)]  [G loss: -0.785] \n",
      "2393 [D loss: (-1.885)(R -4.865, F 1.096)]  [G loss: -0.841] \n",
      "2393 [D loss: (-1.933)(R -4.908, F 1.041)]  [G loss: -0.974] \n",
      "2394 [D loss: (-2.027)(R -5.153, F 1.098)]  [G loss: -0.743] \n",
      "2394 [D loss: (-2.028)(R -5.139, F 1.083)]  [G loss: -0.919] \n",
      "2395 [D loss: (-1.970)(R -4.879, F 0.940)]  [G loss: -1.052] \n",
      "2395 [D loss: (-1.921)(R -4.684, F 0.841)]  [G loss: -0.643] \n",
      "2396 [D loss: (-1.941)(R -4.746, F 0.865)]  [G loss: -0.562] \n",
      "2396 [D loss: (-1.993)(R -4.849, F 0.863)]  [G loss: -0.690] \n",
      "2397 [D loss: (-1.869)(R -4.730, F 0.991)]  [G loss: -0.773] \n",
      "2397 [D loss: (-1.918)(R -4.997, F 1.160)]  [G loss: -0.837] \n",
      "2398 [D loss: (-2.033)(R -5.110, F 1.043)]  [G loss: -0.812] \n",
      "2398 [D loss: (-2.108)(R -5.081, F 0.866)]  [G loss: -1.012] \n",
      "2399 [D loss: (-1.864)(R -4.749, F 1.021)]  [G loss: -0.985] \n",
      "2399 [D loss: (-1.926)(R -4.919, F 1.066)]  [G loss: -0.780] \n",
      "2400 [D loss: (-1.944)(R -4.910, F 1.023)]  [G loss: -0.842] \n",
      "2400 [D loss: (-2.012)(R -4.962, F 0.938)]  [G loss: -0.777] \n",
      "2401 [D loss: (-2.033)(R -5.008, F 0.942)]  [G loss: -0.780] \n",
      "2401 [D loss: (-2.092)(R -4.941, F 0.756)]  [G loss: -0.609] \n",
      "2402 [D loss: (-1.951)(R -4.710, F 0.808)]  [G loss: -0.757] \n",
      "2402 [D loss: (-1.740)(R -4.601, F 1.120)]  [G loss: -0.582] \n",
      "2403 [D loss: (-1.912)(R -4.834, F 1.010)]  [G loss: -0.897] \n",
      "2403 [D loss: (-1.878)(R -4.565, F 0.808)]  [G loss: -0.809] \n",
      "2404 [D loss: (-2.044)(R -4.688, F 0.600)]  [G loss: -0.709] \n",
      "2404 [D loss: (-2.039)(R -4.780, F 0.703)]  [G loss: -0.428] \n",
      "2405 [D loss: (-2.003)(R -4.665, F 0.660)]  [G loss: -0.576] \n",
      "2405 [D loss: (-1.942)(R -4.484, F 0.600)]  [G loss: -0.730] \n",
      "2406 [D loss: (-1.920)(R -4.695, F 0.854)]  [G loss: -0.433] \n",
      "2406 [D loss: (-1.785)(R -4.478, F 0.909)]  [G loss: -0.680] \n",
      "2407 [D loss: (-1.855)(R -4.564, F 0.855)]  [G loss: -0.823] \n",
      "2407 [D loss: (-2.045)(R -4.966, F 0.877)]  [G loss: -0.580] \n",
      "2408 [D loss: (-2.112)(R -4.780, F 0.555)]  [G loss: -0.666] \n",
      "2408 [D loss: (-2.029)(R -4.700, F 0.642)]  [G loss: -0.539] \n",
      "2409 [D loss: (-2.159)(R -4.726, F 0.409)]  [G loss: -0.528] \n",
      "2409 [D loss: (-1.892)(R -4.491, F 0.708)]  [G loss: -0.408] \n",
      "2410 [D loss: (-1.975)(R -4.412, F 0.463)]  [G loss: -0.545] \n",
      "2410 [D loss: (-2.022)(R -4.640, F 0.596)]  [G loss: -0.347] \n",
      "2411 [D loss: (-1.933)(R -4.402, F 0.536)]  [G loss: -0.600] \n",
      "2411 [D loss: (-1.979)(R -4.638, F 0.680)]  [G loss: -0.367] \n",
      "2412 [D loss: (-1.845)(R -4.378, F 0.688)]  [G loss: -0.358] \n",
      "2412 [D loss: (-1.952)(R -4.390, F 0.486)]  [G loss: -0.488] \n",
      "2413 [D loss: (-1.916)(R -4.372, F 0.539)]  [G loss: -0.348] \n",
      "2413 [D loss: (-1.970)(R -4.490, F 0.550)]  [G loss: -0.531] \n",
      "2414 [D loss: (-1.970)(R -4.611, F 0.671)]  [G loss: -0.621] \n",
      "2414 [D loss: (-1.949)(R -4.456, F 0.559)]  [G loss: -0.520] \n",
      "2415 [D loss: (-2.027)(R -4.679, F 0.625)]  [G loss: -0.703] \n",
      "2415 [D loss: (-1.913)(R -4.408, F 0.583)]  [G loss: -0.244] \n",
      "2416 [D loss: (-2.019)(R -4.406, F 0.368)]  [G loss: -0.665] \n",
      "2416 [D loss: (-1.888)(R -4.354, F 0.577)]  [G loss: -0.618] \n",
      "2417 [D loss: (-1.973)(R -4.475, F 0.529)]  [G loss: -0.705] \n",
      "2417 [D loss: (-2.026)(R -4.542, F 0.491)]  [G loss: -0.349] \n",
      "2418 [D loss: (-2.080)(R -4.414, F 0.254)]  [G loss: -0.277] \n",
      "2418 [D loss: (-1.881)(R -4.044, F 0.282)]  [G loss: -0.182] \n",
      "2419 [D loss: (-1.879)(R -4.103, F 0.345)]  [G loss: -0.194] \n",
      "2419 [D loss: (-1.854)(R -4.230, F 0.523)]  [G loss: -0.392] \n",
      "2420 [D loss: (-1.905)(R -4.368, F 0.558)]  [G loss: -0.211] \n",
      "2420 [D loss: (-2.024)(R -4.513, F 0.466)]  [G loss: -0.559] \n",
      "2421 [D loss: (-1.972)(R -4.475, F 0.531)]  [G loss: -0.583] \n",
      "2421 [D loss: (-1.912)(R -4.438, F 0.614)]  [G loss: -0.445] \n",
      "2422 [D loss: (-1.900)(R -4.367, F 0.567)]  [G loss: -0.422] \n",
      "2422 [D loss: (-1.812)(R -4.278, F 0.653)]  [G loss: -0.182] \n",
      "2423 [D loss: (-1.885)(R -4.345, F 0.576)]  [G loss: -0.643] \n",
      "2423 [D loss: (-1.981)(R -4.400, F 0.437)]  [G loss: -0.300] \n",
      "2424 [D loss: (-1.871)(R -4.383, F 0.640)]  [G loss: -0.445] \n",
      "2424 [D loss: (-1.828)(R -4.354, F 0.698)]  [G loss: -0.581] \n",
      "2425 [D loss: (-1.774)(R -4.493, F 0.945)]  [G loss: -0.621] \n",
      "2425 [D loss: (-1.883)(R -4.764, F 0.998)]  [G loss: -0.914] \n",
      "2426 [D loss: (-1.877)(R -4.709, F 0.955)]  [G loss: -1.031] \n",
      "2426 [D loss: (-1.730)(R -4.808, F 1.347)]  [G loss: -0.932] \n",
      "2427 [D loss: (-1.830)(R -4.856, F 1.195)]  [G loss: -1.059] \n",
      "2427 [D loss: (-1.931)(R -4.989, F 1.127)]  [G loss: -1.015] \n",
      "2428 [D loss: (-1.784)(R -4.711, F 1.142)]  [G loss: -1.093] \n",
      "2428 [D loss: (-1.848)(R -4.657, F 0.960)]  [G loss: -0.905] \n",
      "2429 [D loss: (-1.863)(R -4.714, F 0.988)]  [G loss: -0.976] \n",
      "2429 [D loss: (-1.892)(R -4.941, F 1.157)]  [G loss: -1.237] \n",
      "2430 [D loss: (-1.847)(R -4.792, F 1.098)]  [G loss: -1.141] \n",
      "2430 [D loss: (-1.819)(R -4.740, F 1.103)]  [G loss: -1.000] \n",
      "2431 [D loss: (-1.918)(R -4.929, F 1.092)]  [G loss: -1.096] \n",
      "2431 [D loss: (-1.835)(R -4.835, F 1.164)]  [G loss: -1.114] \n",
      "2432 [D loss: (-1.748)(R -4.652, F 1.157)]  [G loss: -0.942] \n",
      "2432 [D loss: (-1.915)(R -4.675, F 0.845)]  [G loss: -0.809] \n",
      "2433 [D loss: (-1.806)(R -4.556, F 0.945)]  [G loss: -0.980] \n",
      "2433 [D loss: (-1.824)(R -4.708, F 1.060)]  [G loss: -0.901] \n",
      "2434 [D loss: (-1.939)(R -5.019, F 1.142)]  [G loss: -1.168] \n",
      "2434 [D loss: (-1.715)(R -4.553, F 1.123)]  [G loss: -0.980] \n",
      "2435 [D loss: (-1.703)(R -4.655, F 1.249)]  [G loss: -1.077] \n",
      "2435 [D loss: (-1.948)(R -4.694, F 0.798)]  [G loss: -0.859] \n",
      "2436 [D loss: (-1.771)(R -4.586, F 1.043)]  [G loss: -0.928] \n",
      "2436 [D loss: (-1.836)(R -4.480, F 0.809)]  [G loss: -1.007] \n",
      "2437 [D loss: (-1.799)(R -4.489, F 0.891)]  [G loss: -0.815] \n",
      "2437 [D loss: (-1.812)(R -4.469, F 0.845)]  [G loss: -0.614] \n",
      "2438 [D loss: (-1.852)(R -4.550, F 0.845)]  [G loss: -0.848] \n",
      "2438 [D loss: (-1.832)(R -4.657, F 0.994)]  [G loss: -1.007] \n",
      "2439 [D loss: (-1.786)(R -4.443, F 0.872)]  [G loss: -0.993] \n",
      "2439 [D loss: (-1.761)(R -4.551, F 1.030)]  [G loss: -0.783] \n",
      "2440 [D loss: (-1.684)(R -4.599, F 1.231)]  [G loss: -0.851] \n",
      "2440 [D loss: (-1.769)(R -4.599, F 1.061)]  [G loss: -1.096] \n",
      "2441 [D loss: (-1.733)(R -4.802, F 1.336)]  [G loss: -1.275] \n",
      "2441 [D loss: (-1.809)(R -4.979, F 1.362)]  [G loss: -0.988] \n",
      "2442 [D loss: (-1.885)(R -5.018, F 1.249)]  [G loss: -1.178] \n",
      "2442 [D loss: (-1.886)(R -5.051, F 1.278)]  [G loss: -1.200] \n",
      "2443 [D loss: (-1.722)(R -5.072, F 1.628)]  [G loss: -1.254] \n",
      "2443 [D loss: (-1.794)(R -5.048, F 1.460)]  [G loss: -1.344] \n",
      "2444 [D loss: (-1.709)(R -4.958, F 1.540)]  [G loss: -1.388] \n",
      "2444 [D loss: (-1.834)(R -5.129, F 1.461)]  [G loss: -1.558] \n",
      "2445 [D loss: (-1.732)(R -4.893, F 1.430)]  [G loss: -1.329] \n",
      "2445 [D loss: (-1.677)(R -4.893, F 1.538)]  [G loss: -1.384] \n",
      "2446 [D loss: (-1.766)(R -4.719, F 1.186)]  [G loss: -1.155] \n",
      "2446 [D loss: (-1.766)(R -4.884, F 1.353)]  [G loss: -0.977] \n",
      "2447 [D loss: (-1.863)(R -5.000, F 1.275)]  [G loss: -1.091] \n",
      "2447 [D loss: (-1.772)(R -5.012, F 1.468)]  [G loss: -1.314] \n",
      "2448 [D loss: (-1.823)(R -5.132, F 1.486)]  [G loss: -1.662] \n",
      "2448 [D loss: (-1.916)(R -5.071, F 1.239)]  [G loss: -1.449] \n",
      "2449 [D loss: (-1.602)(R -4.769, F 1.565)]  [G loss: -1.384] \n",
      "2449 [D loss: (-1.762)(R -5.013, F 1.489)]  [G loss: -1.413] \n",
      "2450 [D loss: (-1.581)(R -4.681, F 1.520)]  [G loss: -1.384] \n",
      "2450 [D loss: (-1.634)(R -5.044, F 1.776)]  [G loss: -1.538] \n",
      "2451 [D loss: (-1.753)(R -4.892, F 1.387)]  [G loss: -1.337] \n",
      "2451 [D loss: (-1.692)(R -4.904, F 1.520)]  [G loss: -1.181] \n",
      "2452 [D loss: (-1.768)(R -4.919, F 1.384)]  [G loss: -1.139] \n",
      "2452 [D loss: (-1.803)(R -4.847, F 1.240)]  [G loss: -1.422] \n",
      "2453 [D loss: (-1.680)(R -4.823, F 1.463)]  [G loss: -1.391] \n",
      "2453 [D loss: (-1.510)(R -4.834, F 1.815)]  [G loss: -1.557] \n",
      "2454 [D loss: (-1.699)(R -4.984, F 1.585)]  [G loss: -1.448] \n",
      "2454 [D loss: (-1.686)(R -5.113, F 1.741)]  [G loss: -1.552] \n",
      "2455 [D loss: (-1.692)(R -5.021, F 1.636)]  [G loss: -1.384] \n",
      "2455 [D loss: (-1.798)(R -5.148, F 1.552)]  [G loss: -1.671] \n",
      "2456 [D loss: (-1.835)(R -5.130, F 1.460)]  [G loss: -1.576] \n",
      "2456 [D loss: (-1.816)(R -4.976, F 1.345)]  [G loss: -1.371] \n",
      "2457 [D loss: (-1.732)(R -4.895, F 1.431)]  [G loss: -1.367] \n",
      "2457 [D loss: (-1.680)(R -4.853, F 1.493)]  [G loss: -1.331] \n",
      "2458 [D loss: (-1.745)(R -4.993, F 1.503)]  [G loss: -1.398] \n",
      "2458 [D loss: (-1.708)(R -4.982, F 1.566)]  [G loss: -1.383] \n",
      "2459 [D loss: (-1.651)(R -4.849, F 1.547)]  [G loss: -1.478] \n",
      "2459 [D loss: (-1.632)(R -4.771, F 1.508)]  [G loss: -1.448] \n",
      "2460 [D loss: (-1.693)(R -4.979, F 1.594)]  [G loss: -1.389] \n",
      "2460 [D loss: (-1.681)(R -5.068, F 1.706)]  [G loss: -1.545] \n",
      "2461 [D loss: (-1.629)(R -5.088, F 1.829)]  [G loss: -1.476] \n",
      "2461 [D loss: (-1.650)(R -4.975, F 1.675)]  [G loss: -1.537] \n",
      "2462 [D loss: (-1.701)(R -5.243, F 1.841)]  [G loss: -1.731] \n",
      "2462 [D loss: (-1.587)(R -5.053, F 1.880)]  [G loss: -1.598] \n",
      "2463 [D loss: (-1.543)(R -4.941, F 1.856)]  [G loss: -1.681] \n",
      "2463 [D loss: (-1.676)(R -5.181, F 1.828)]  [G loss: -1.461] \n",
      "2464 [D loss: (-1.627)(R -4.985, F 1.731)]  [G loss: -1.602] \n",
      "2464 [D loss: (-1.614)(R -5.081, F 1.852)]  [G loss: -1.480] \n",
      "2465 [D loss: (-1.748)(R -5.032, F 1.536)]  [G loss: -1.279] \n",
      "2465 [D loss: (-1.648)(R -4.995, F 1.699)]  [G loss: -1.386] \n",
      "2466 [D loss: (-1.694)(R -4.874, F 1.487)]  [G loss: -1.382] \n",
      "2466 [D loss: (-1.733)(R -4.779, F 1.314)]  [G loss: -1.371] \n",
      "2467 [D loss: (-1.718)(R -4.981, F 1.545)]  [G loss: -1.338] \n",
      "2467 [D loss: (-1.666)(R -4.825, F 1.494)]  [G loss: -1.282] \n",
      "2468 [D loss: (-1.468)(R -4.723, F 1.786)]  [G loss: -1.286] \n",
      "2468 [D loss: (-1.760)(R -4.991, F 1.472)]  [G loss: -1.632] \n",
      "2469 [D loss: (-1.757)(R -4.862, F 1.348)]  [G loss: -1.527] \n",
      "2469 [D loss: (-1.742)(R -4.770, F 1.286)]  [G loss: -1.658] \n",
      "2470 [D loss: (-1.671)(R -4.770, F 1.428)]  [G loss: -1.427] \n",
      "2470 [D loss: (-1.585)(R -4.807, F 1.636)]  [G loss: -1.395] \n",
      "2471 [D loss: (-1.720)(R -4.862, F 1.421)]  [G loss: -1.358] \n",
      "2471 [D loss: (-1.556)(R -4.875, F 1.763)]  [G loss: -1.657] \n",
      "2472 [D loss: (-1.557)(R -5.088, F 1.974)]  [G loss: -1.867] \n",
      "2472 [D loss: (-1.604)(R -5.080, F 1.872)]  [G loss: -1.577] \n",
      "2473 [D loss: (-1.547)(R -5.100, F 2.006)]  [G loss: -1.580] \n",
      "2473 [D loss: (-1.739)(R -5.310, F 1.832)]  [G loss: -1.637] \n",
      "2474 [D loss: (-1.540)(R -4.936, F 1.855)]  [G loss: -1.456] \n",
      "2474 [D loss: (-1.568)(R -4.834, F 1.698)]  [G loss: -1.828] \n",
      "2475 [D loss: (-1.660)(R -5.053, F 1.732)]  [G loss: -1.672] \n",
      "2475 [D loss: (-1.756)(R -5.065, F 1.553)]  [G loss: -1.601] \n",
      "2476 [D loss: (-1.629)(R -4.790, F 1.532)]  [G loss: -1.367] \n",
      "2476 [D loss: (-1.796)(R -4.812, F 1.219)]  [G loss: -1.130] \n",
      "2477 [D loss: (-1.485)(R -4.572, F 1.601)]  [G loss: -1.003] \n",
      "2477 [D loss: (-1.709)(R -4.864, F 1.445)]  [G loss: -1.285] \n",
      "2478 [D loss: (-1.648)(R -4.912, F 1.615)]  [G loss: -1.632] \n",
      "2478 [D loss: (-1.565)(R -4.860, F 1.730)]  [G loss: -1.196] \n",
      "2479 [D loss: (-1.760)(R -4.876, F 1.355)]  [G loss: -1.391] \n",
      "2479 [D loss: (-1.514)(R -4.681, F 1.652)]  [G loss: -1.577] \n",
      "2480 [D loss: (-1.717)(R -4.784, F 1.350)]  [G loss: -1.461] \n",
      "2480 [D loss: (-1.549)(R -4.836, F 1.738)]  [G loss: -1.536] \n",
      "2481 [D loss: (-1.596)(R -4.942, F 1.751)]  [G loss: -1.567] \n",
      "2481 [D loss: (-1.672)(R -5.079, F 1.734)]  [G loss: -1.644] \n",
      "2482 [D loss: (-1.597)(R -5.066, F 1.872)]  [G loss: -1.790] \n",
      "2482 [D loss: (-1.600)(R -5.216, F 2.017)]  [G loss: -1.987] \n",
      "2483 [D loss: (-1.561)(R -5.097, F 1.975)]  [G loss: -1.967] \n",
      "2483 [D loss: (-1.559)(R -5.056, F 1.938)]  [G loss: -1.800] \n",
      "2484 [D loss: (-1.763)(R -5.284, F 1.758)]  [G loss: -1.686] \n",
      "2484 [D loss: (-1.759)(R -5.268, F 1.749)]  [G loss: -1.697] \n",
      "2485 [D loss: (-1.508)(R -4.949, F 1.934)]  [G loss: -1.687] \n",
      "2485 [D loss: (-1.565)(R -4.796, F 1.667)]  [G loss: -1.703] \n",
      "2486 [D loss: (-1.650)(R -4.972, F 1.672)]  [G loss: -1.815] \n",
      "2486 [D loss: (-1.541)(R -5.055, F 1.974)]  [G loss: -1.778] \n",
      "2487 [D loss: (-1.564)(R -4.903, F 1.775)]  [G loss: -1.641] \n",
      "2487 [D loss: (-1.502)(R -5.144, F 2.140)]  [G loss: -1.579] \n",
      "2488 [D loss: (-1.626)(R -5.049, F 1.796)]  [G loss: -1.808] \n",
      "2488 [D loss: (-1.643)(R -5.096, F 1.810)]  [G loss: -1.776] \n",
      "2489 [D loss: (-1.675)(R -5.163, F 1.812)]  [G loss: -1.565] \n",
      "2489 [D loss: (-1.733)(R -5.116, F 1.651)]  [G loss: -1.958] \n",
      "2490 [D loss: (-1.532)(R -5.130, F 2.066)]  [G loss: -1.734] \n",
      "2490 [D loss: (-1.485)(R -4.976, F 2.006)]  [G loss: -1.896] \n",
      "2491 [D loss: (-1.467)(R -5.140, F 2.207)]  [G loss: -1.727] \n",
      "2491 [D loss: (-1.488)(R -4.926, F 1.950)]  [G loss: -1.811] \n",
      "2492 [D loss: (-1.401)(R -4.946, F 2.145)]  [G loss: -1.675] \n",
      "2492 [D loss: (-1.651)(R -5.183, F 1.881)]  [G loss: -1.803] \n",
      "2493 [D loss: (-1.644)(R -5.210, F 1.923)]  [G loss: -1.780] \n",
      "2493 [D loss: (-1.686)(R -5.211, F 1.838)]  [G loss: -1.654] \n",
      "2494 [D loss: (-1.560)(R -5.153, F 2.033)]  [G loss: -1.613] \n",
      "2494 [D loss: (-1.496)(R -4.933, F 1.941)]  [G loss: -1.580] \n",
      "2495 [D loss: (-1.452)(R -5.057, F 2.153)]  [G loss: -2.132] \n",
      "2495 [D loss: (-1.700)(R -5.216, F 1.816)]  [G loss: -1.781] \n",
      "2496 [D loss: (-1.672)(R -5.386, F 2.043)]  [G loss: -1.942] \n",
      "2496 [D loss: (-1.631)(R -5.198, F 1.936)]  [G loss: -1.966] \n",
      "2497 [D loss: (-1.739)(R -5.241, F 1.764)]  [G loss: -2.021] \n",
      "2497 [D loss: (-1.555)(R -4.900, F 1.790)]  [G loss: -1.760] \n",
      "2498 [D loss: (-1.607)(R -5.063, F 1.850)]  [G loss: -1.617] \n",
      "2498 [D loss: (-1.463)(R -4.869, F 1.942)]  [G loss: -1.570] \n",
      "2499 [D loss: (-1.599)(R -4.902, F 1.704)]  [G loss: -1.647] \n",
      "2499 [D loss: (-1.677)(R -5.120, F 1.767)]  [G loss: -1.875] \n",
      "2500 [D loss: (-1.625)(R -5.004, F 1.755)]  [G loss: -1.748] \n",
      "2500 [D loss: (-1.681)(R -5.117, F 1.755)]  [G loss: -1.749] \n",
      "2501 [D loss: (-1.546)(R -4.783, F 1.690)]  [G loss: -1.470] \n",
      "2501 [D loss: (-1.577)(R -5.049, F 1.896)]  [G loss: -1.610] \n",
      "2502 [D loss: (-1.561)(R -5.130, F 2.007)]  [G loss: -1.923] \n",
      "2502 [D loss: (-1.544)(R -5.129, F 2.041)]  [G loss: -1.934] \n",
      "2503 [D loss: (-1.686)(R -5.175, F 1.803)]  [G loss: -1.743] \n",
      "2503 [D loss: (-1.808)(R -5.344, F 1.729)]  [G loss: -1.865] \n",
      "2504 [D loss: (-1.430)(R -4.952, F 2.092)]  [G loss: -1.916] \n",
      "2504 [D loss: (-1.580)(R -4.963, F 1.803)]  [G loss: -2.187] \n",
      "2505 [D loss: (-1.510)(R -5.086, F 2.067)]  [G loss: -1.968] \n",
      "2505 [D loss: (-1.541)(R -5.158, F 2.076)]  [G loss: -1.904] \n",
      "2506 [D loss: (-1.573)(R -5.226, F 2.080)]  [G loss: -1.909] \n",
      "2506 [D loss: (-1.625)(R -5.216, F 1.965)]  [G loss: -1.610] \n",
      "2507 [D loss: (-1.672)(R -5.229, F 1.884)]  [G loss: -1.958] \n",
      "2507 [D loss: (-1.734)(R -5.215, F 1.746)]  [G loss: -1.813] \n",
      "2508 [D loss: (-1.383)(R -4.781, F 2.016)]  [G loss: -1.634] \n",
      "2508 [D loss: (-1.576)(R -4.901, F 1.750)]  [G loss: -1.444] \n",
      "2509 [D loss: (-1.670)(R -4.954, F 1.614)]  [G loss: -1.855] \n",
      "2509 [D loss: (-1.576)(R -5.079, F 1.927)]  [G loss: -1.638] \n",
      "2510 [D loss: (-1.656)(R -5.070, F 1.759)]  [G loss: -1.695] \n",
      "2510 [D loss: (-1.760)(R -5.107, F 1.587)]  [G loss: -1.573] \n",
      "2511 [D loss: (-1.460)(R -5.056, F 2.136)]  [G loss: -1.654] \n",
      "2511 [D loss: (-1.519)(R -5.118, F 2.080)]  [G loss: -2.029] \n",
      "2512 [D loss: (-1.590)(R -5.432, F 2.252)]  [G loss: -2.003] \n",
      "2512 [D loss: (-1.674)(R -5.227, F 1.879)]  [G loss: -1.684] \n",
      "2513 [D loss: (-1.668)(R -5.065, F 1.729)]  [G loss: -1.511] \n",
      "2513 [D loss: (-1.574)(R -5.000, F 1.851)]  [G loss: -1.623] \n",
      "2514 [D loss: (-1.682)(R -5.149, F 1.786)]  [G loss: -1.807] \n",
      "2514 [D loss: (-1.506)(R -5.228, F 2.215)]  [G loss: -1.960] \n",
      "2515 [D loss: (-1.638)(R -5.157, F 1.882)]  [G loss: -1.999] \n",
      "2515 [D loss: (-1.461)(R -5.075, F 2.153)]  [G loss: -1.804] \n",
      "2516 [D loss: (-1.653)(R -5.260, F 1.954)]  [G loss: -2.007] \n",
      "2516 [D loss: (-1.671)(R -5.325, F 1.983)]  [G loss: -2.114] \n",
      "2517 [D loss: (-1.625)(R -5.561, F 2.311)]  [G loss: -2.188] \n",
      "2517 [D loss: (-1.572)(R -5.337, F 2.193)]  [G loss: -1.761] \n",
      "2518 [D loss: (-1.585)(R -5.247, F 2.077)]  [G loss: -2.065] \n",
      "2518 [D loss: (-1.630)(R -5.265, F 2.005)]  [G loss: -1.913] \n",
      "2519 [D loss: (-1.537)(R -5.209, F 2.136)]  [G loss: -2.005] \n",
      "2519 [D loss: (-1.685)(R -5.296, F 1.926)]  [G loss: -2.008] \n",
      "2520 [D loss: (-1.552)(R -5.184, F 2.080)]  [G loss: -1.774] \n",
      "2520 [D loss: (-1.335)(R -4.912, F 2.242)]  [G loss: -1.718] \n",
      "2521 [D loss: (-1.744)(R -5.313, F 1.825)]  [G loss: -2.087] \n",
      "2521 [D loss: (-1.598)(R -5.140, F 1.945)]  [G loss: -1.753] \n",
      "2522 [D loss: (-1.492)(R -5.113, F 2.129)]  [G loss: -2.071] \n",
      "2522 [D loss: (-1.450)(R -5.043, F 2.142)]  [G loss: -1.878] \n",
      "2523 [D loss: (-1.492)(R -5.123, F 2.140)]  [G loss: -1.636] \n",
      "2523 [D loss: (-1.712)(R -5.267, F 1.842)]  [G loss: -2.129] \n",
      "2524 [D loss: (-1.658)(R -5.427, F 2.110)]  [G loss: -2.169] \n",
      "2524 [D loss: (-1.665)(R -5.301, F 1.972)]  [G loss: -1.969] \n",
      "2525 [D loss: (-1.690)(R -5.118, F 1.737)]  [G loss: -1.755] \n",
      "2525 [D loss: (-1.649)(R -5.102, F 1.804)]  [G loss: -1.891] \n",
      "2526 [D loss: (-1.502)(R -4.926, F 1.922)]  [G loss: -1.785] \n",
      "2526 [D loss: (-1.525)(R -5.286, F 2.237)]  [G loss: -1.862] \n",
      "2527 [D loss: (-1.623)(R -5.384, F 2.139)]  [G loss: -2.093] \n",
      "2527 [D loss: (-1.627)(R -5.207, F 1.954)]  [G loss: -1.712] \n",
      "2528 [D loss: (-1.621)(R -5.197, F 1.955)]  [G loss: -1.791] \n",
      "2528 [D loss: (-1.679)(R -5.263, F 1.904)]  [G loss: -1.996] \n",
      "2529 [D loss: (-1.394)(R -5.141, F 2.352)]  [G loss: -1.934] \n",
      "2529 [D loss: (-1.686)(R -5.192, F 1.820)]  [G loss: -1.865] \n",
      "2530 [D loss: (-1.621)(R -5.103, F 1.861)]  [G loss: -2.050] \n",
      "2530 [D loss: (-1.536)(R -5.241, F 2.170)]  [G loss: -1.714] \n",
      "2531 [D loss: (-1.669)(R -5.158, F 1.820)]  [G loss: -2.047] \n",
      "2531 [D loss: (-1.730)(R -5.336, F 1.876)]  [G loss: -1.917] \n",
      "2532 [D loss: (-1.549)(R -5.094, F 1.997)]  [G loss: -1.972] \n",
      "2532 [D loss: (-1.562)(R -5.222, F 2.098)]  [G loss: -2.264] \n",
      "2533 [D loss: (-1.850)(R -5.456, F 1.756)]  [G loss: -2.040] \n",
      "2533 [D loss: (-1.596)(R -5.326, F 2.135)]  [G loss: -2.162] \n",
      "2534 [D loss: (-1.624)(R -5.315, F 2.067)]  [G loss: -1.848] \n",
      "2534 [D loss: (-1.375)(R -5.109, F 2.360)]  [G loss: -1.982] \n",
      "2535 [D loss: (-1.730)(R -5.303, F 1.842)]  [G loss: -1.938] \n",
      "2535 [D loss: (-1.683)(R -5.428, F 2.063)]  [G loss: -2.089] \n",
      "2536 [D loss: (-1.672)(R -5.342, F 1.998)]  [G loss: -1.979] \n",
      "2536 [D loss: (-1.597)(R -5.249, F 2.055)]  [G loss: -2.054] \n",
      "2537 [D loss: (-1.493)(R -5.315, F 2.328)]  [G loss: -2.097] \n",
      "2537 [D loss: (-1.646)(R -5.537, F 2.245)]  [G loss: -2.138] \n",
      "2538 [D loss: (-1.739)(R -5.593, F 2.115)]  [G loss: -2.149] \n",
      "2538 [D loss: (-1.454)(R -5.398, F 2.490)]  [G loss: -2.194] \n",
      "2539 [D loss: (-1.417)(R -5.385, F 2.552)]  [G loss: -2.383] \n",
      "2539 [D loss: (-1.671)(R -5.748, F 2.406)]  [G loss: -2.288] \n",
      "2540 [D loss: (-1.552)(R -5.599, F 2.496)]  [G loss: -2.205] \n",
      "2540 [D loss: (-1.493)(R -5.667, F 2.680)]  [G loss: -2.385] \n",
      "2541 [D loss: (-1.612)(R -5.503, F 2.279)]  [G loss: -2.080] \n",
      "2541 [D loss: (-1.684)(R -5.500, F 2.132)]  [G loss: -2.358] \n",
      "2542 [D loss: (-1.546)(R -5.477, F 2.386)]  [G loss: -2.325] \n",
      "2542 [D loss: (-1.390)(R -5.352, F 2.571)]  [G loss: -2.054] \n",
      "2543 [D loss: (-1.588)(R -5.554, F 2.378)]  [G loss: -2.214] \n",
      "2543 [D loss: (-1.671)(R -5.750, F 2.408)]  [G loss: -2.099] \n",
      "2544 [D loss: (-1.577)(R -5.610, F 2.455)]  [G loss: -2.326] \n",
      "2544 [D loss: (-1.542)(R -5.577, F 2.493)]  [G loss: -2.176] \n",
      "2545 [D loss: (-1.656)(R -5.714, F 2.402)]  [G loss: -2.371] \n",
      "2545 [D loss: (-1.577)(R -5.640, F 2.486)]  [G loss: -2.090] \n",
      "2546 [D loss: (-1.696)(R -5.548, F 2.156)]  [G loss: -2.239] \n",
      "2546 [D loss: (-1.606)(R -5.233, F 2.021)]  [G loss: -2.166] \n",
      "2547 [D loss: (-1.561)(R -5.439, F 2.317)]  [G loss: -2.400] \n",
      "2547 [D loss: (-1.524)(R -5.236, F 2.187)]  [G loss: -2.084] \n",
      "2548 [D loss: (-1.592)(R -5.425, F 2.242)]  [G loss: -2.087] \n",
      "2548 [D loss: (-1.723)(R -5.568, F 2.121)]  [G loss: -2.191] \n",
      "2549 [D loss: (-1.724)(R -5.597, F 2.149)]  [G loss: -2.286] \n",
      "2549 [D loss: (-1.755)(R -5.497, F 1.987)]  [G loss: -2.107] \n",
      "2550 [D loss: (-1.583)(R -5.485, F 2.319)]  [G loss: -1.491] \n",
      "2550 [D loss: (-1.581)(R -5.284, F 2.123)]  [G loss: -1.883] \n",
      "2551 [D loss: (-1.582)(R -5.172, F 2.007)]  [G loss: -1.999] \n",
      "2551 [D loss: (-1.708)(R -5.439, F 2.023)]  [G loss: -2.352] \n",
      "2552 [D loss: (-1.547)(R -5.341, F 2.247)]  [G loss: -2.151] \n",
      "2552 [D loss: (-1.706)(R -5.395, F 1.984)]  [G loss: -2.018] \n",
      "2553 [D loss: (-1.634)(R -5.409, F 2.141)]  [G loss: -1.986] \n",
      "2553 [D loss: (-1.521)(R -5.350, F 2.308)]  [G loss: -1.731] \n",
      "2554 [D loss: (-1.496)(R -5.279, F 2.288)]  [G loss: -1.727] \n",
      "2554 [D loss: (-1.635)(R -5.131, F 1.861)]  [G loss: -1.839] \n",
      "2555 [D loss: (-1.672)(R -5.072, F 1.729)]  [G loss: -2.137] \n",
      "2555 [D loss: (-1.550)(R -5.249, F 2.148)]  [G loss: -2.177] \n",
      "2556 [D loss: (-1.749)(R -5.553, F 2.055)]  [G loss: -1.791] \n",
      "2556 [D loss: (-1.768)(R -5.519, F 1.983)]  [G loss: -2.125] \n",
      "2557 [D loss: (-1.718)(R -5.562, F 2.126)]  [G loss: -2.228] \n",
      "2557 [D loss: (-1.618)(R -5.520, F 2.283)]  [G loss: -2.232] \n",
      "2558 [D loss: (-1.682)(R -5.462, F 2.099)]  [G loss: -2.397] \n",
      "2558 [D loss: (-1.622)(R -5.436, F 2.192)]  [G loss: -2.613] \n",
      "2559 [D loss: (-1.569)(R -5.519, F 2.381)]  [G loss: -2.227] \n",
      "2559 [D loss: (-1.566)(R -5.634, F 2.502)]  [G loss: -1.991] \n",
      "2560 [D loss: (-1.618)(R -5.487, F 2.250)]  [G loss: -2.153] \n",
      "2560 [D loss: (-1.632)(R -5.396, F 2.132)]  [G loss: -1.902] \n",
      "2561 [D loss: (-1.416)(R -5.263, F 2.431)]  [G loss: -1.941] \n",
      "2561 [D loss: (-1.633)(R -5.348, F 2.082)]  [G loss: -1.701] \n",
      "2562 [D loss: (-1.558)(R -5.106, F 1.989)]  [G loss: -1.978] \n",
      "2562 [D loss: (-1.515)(R -5.320, F 2.289)]  [G loss: -1.964] \n",
      "2563 [D loss: (-1.812)(R -5.501, F 1.877)]  [G loss: -1.864] \n",
      "2563 [D loss: (-1.617)(R -5.415, F 2.181)]  [G loss: -1.883] \n",
      "2564 [D loss: (-1.466)(R -5.062, F 2.131)]  [G loss: -1.999] \n",
      "2564 [D loss: (-1.931)(R -5.455, F 1.593)]  [G loss: -2.157] \n",
      "2565 [D loss: (-1.595)(R -5.656, F 2.466)]  [G loss: -2.125] \n",
      "2565 [D loss: (-1.579)(R -5.343, F 2.184)]  [G loss: -2.167] \n",
      "2566 [D loss: (-1.603)(R -5.469, F 2.263)]  [G loss: -2.333] \n",
      "2566 [D loss: (-1.696)(R -5.708, F 2.317)]  [G loss: -2.000] \n",
      "2567 [D loss: (-1.574)(R -5.472, F 2.323)]  [G loss: -2.386] \n",
      "2567 [D loss: (-1.525)(R -5.403, F 2.354)]  [G loss: -1.994] \n",
      "2568 [D loss: (-1.596)(R -5.352, F 2.159)]  [G loss: -2.280] \n",
      "2568 [D loss: (-1.417)(R -5.490, F 2.656)]  [G loss: -2.114] \n",
      "2569 [D loss: (-1.620)(R -5.650, F 2.409)]  [G loss: -2.343] \n",
      "2569 [D loss: (-1.667)(R -5.669, F 2.335)]  [G loss: -2.181] \n",
      "2570 [D loss: (-1.680)(R -5.622, F 2.262)]  [G loss: -2.105] \n",
      "2570 [D loss: (-1.565)(R -5.662, F 2.531)]  [G loss: -2.419] \n",
      "2571 [D loss: (-1.723)(R -5.754, F 2.307)]  [G loss: -2.356] \n",
      "2571 [D loss: (-1.370)(R -5.413, F 2.674)]  [G loss: -2.239] \n",
      "2572 [D loss: (-1.603)(R -5.661, F 2.455)]  [G loss: -2.150] \n",
      "2572 [D loss: (-1.360)(R -5.368, F 2.649)]  [G loss: -2.625] \n",
      "2573 [D loss: (-1.455)(R -5.455, F 2.545)]  [G loss: -2.304] \n",
      "2573 [D loss: (-1.625)(R -5.927, F 2.678)]  [G loss: -2.453] \n",
      "2574 [D loss: (-1.541)(R -5.796, F 2.714)]  [G loss: -2.553] \n",
      "2574 [D loss: (-1.518)(R -5.583, F 2.547)]  [G loss: -2.204] \n",
      "2575 [D loss: (-1.462)(R -5.763, F 2.840)]  [G loss: -2.180] \n",
      "2575 [D loss: (-1.458)(R -5.652, F 2.736)]  [G loss: -2.295] \n",
      "2576 [D loss: (-1.836)(R -5.943, F 2.270)]  [G loss: -2.479] \n",
      "2576 [D loss: (-1.483)(R -5.674, F 2.708)]  [G loss: -2.421] \n",
      "2577 [D loss: (-1.704)(R -5.582, F 2.174)]  [G loss: -2.380] \n",
      "2577 [D loss: (-1.702)(R -5.696, F 2.292)]  [G loss: -2.196] \n",
      "2578 [D loss: (-1.662)(R -5.577, F 2.253)]  [G loss: -2.193] \n",
      "2578 [D loss: (-1.615)(R -5.368, F 2.137)]  [G loss: -2.247] \n",
      "2579 [D loss: (-1.541)(R -5.505, F 2.423)]  [G loss: -2.167] \n",
      "2579 [D loss: (-1.507)(R -5.488, F 2.475)]  [G loss: -1.953] \n",
      "2580 [D loss: (-1.470)(R -5.269, F 2.330)]  [G loss: -2.302] \n",
      "2580 [D loss: (-1.442)(R -5.485, F 2.601)]  [G loss: -2.363] \n",
      "2581 [D loss: (-1.753)(R -5.593, F 2.087)]  [G loss: -2.100] \n",
      "2581 [D loss: (-1.833)(R -5.848, F 2.181)]  [G loss: -2.213] \n",
      "2582 [D loss: (-1.488)(R -5.724, F 2.749)]  [G loss: -2.296] \n",
      "2582 [D loss: (-1.491)(R -5.601, F 2.620)]  [G loss: -2.376] \n",
      "2583 [D loss: (-1.380)(R -5.966, F 3.205)]  [G loss: -2.381] \n",
      "2583 [D loss: (-1.598)(R -5.857, F 2.661)]  [G loss: -2.509] \n",
      "2584 [D loss: (-1.578)(R -5.629, F 2.473)]  [G loss: -2.510] \n",
      "2584 [D loss: (-1.551)(R -5.698, F 2.596)]  [G loss: -2.546] \n",
      "2585 [D loss: (-1.584)(R -5.925, F 2.756)]  [G loss: -2.494] \n",
      "2585 [D loss: (-1.426)(R -5.742, F 2.891)]  [G loss: -2.511] \n",
      "2586 [D loss: (-1.749)(R -5.862, F 2.364)]  [G loss: -2.487] \n",
      "2586 [D loss: (-1.321)(R -5.832, F 3.190)]  [G loss: -2.568] \n",
      "2587 [D loss: (-1.323)(R -6.011, F 3.364)]  [G loss: -2.694] \n",
      "2587 [D loss: (-1.526)(R -6.135, F 3.082)]  [G loss: -2.802] \n",
      "2588 [D loss: (-1.572)(R -6.172, F 3.029)]  [G loss: -2.962] \n",
      "2588 [D loss: (-1.592)(R -6.157, F 2.972)]  [G loss: -2.763] \n",
      "2589 [D loss: (-1.517)(R -6.053, F 3.019)]  [G loss: -2.601] \n",
      "2589 [D loss: (-1.767)(R -5.924, F 2.390)]  [G loss: -2.588] \n",
      "2590 [D loss: (-1.554)(R -6.046, F 2.939)]  [G loss: -2.782] \n",
      "2590 [D loss: (-1.357)(R -6.044, F 3.330)]  [G loss: -2.724] \n",
      "2591 [D loss: (-1.568)(R -6.007, F 2.871)]  [G loss: -2.583] \n",
      "2591 [D loss: (-1.721)(R -6.182, F 2.740)]  [G loss: -2.621] \n",
      "2592 [D loss: (-1.299)(R -5.808, F 3.211)]  [G loss: -2.792] \n",
      "2592 [D loss: (-1.743)(R -6.395, F 2.909)]  [G loss: -2.888] \n",
      "2593 [D loss: (-1.528)(R -6.436, F 3.379)]  [G loss: -2.729] \n",
      "2593 [D loss: (-1.540)(R -6.164, F 3.083)]  [G loss: -3.024] \n",
      "2594 [D loss: (-1.611)(R -6.265, F 3.043)]  [G loss: -3.028] \n",
      "2594 [D loss: (-1.628)(R -6.243, F 2.988)]  [G loss: -2.993] \n",
      "2595 [D loss: (-1.378)(R -6.126, F 3.369)]  [G loss: -2.955] \n",
      "2595 [D loss: (-1.706)(R -5.987, F 2.575)]  [G loss: -2.750] \n",
      "2596 [D loss: (-1.648)(R -6.082, F 2.786)]  [G loss: -2.664] \n",
      "2596 [D loss: (-1.775)(R -6.029, F 2.480)]  [G loss: -2.381] \n",
      "2597 [D loss: (-1.661)(R -5.808, F 2.487)]  [G loss: -2.614] \n",
      "2597 [D loss: (-1.624)(R -5.794, F 2.547)]  [G loss: -2.287] \n",
      "2598 [D loss: (-1.671)(R -5.720, F 2.377)]  [G loss: -2.765] \n",
      "2598 [D loss: (-1.565)(R -5.786, F 2.655)]  [G loss: -2.397] \n",
      "2599 [D loss: (-1.623)(R -5.607, F 2.360)]  [G loss: -2.431] \n",
      "2599 [D loss: (-1.482)(R -5.705, F 2.742)]  [G loss: -2.412] \n",
      "2600 [D loss: (-1.524)(R -5.685, F 2.636)]  [G loss: -2.757] \n",
      "2600 [D loss: (-1.530)(R -6.015, F 2.954)]  [G loss: -2.780] \n",
      "2601 [D loss: (-1.300)(R -6.139, F 3.539)]  [G loss: -2.699] \n",
      "2601 [D loss: (-1.709)(R -6.085, F 2.667)]  [G loss: -2.762] \n",
      "2602 [D loss: (-1.769)(R -6.080, F 2.541)]  [G loss: -2.457] \n",
      "2602 [D loss: (-1.562)(R -6.172, F 3.047)]  [G loss: -2.771] \n",
      "2603 [D loss: (-1.605)(R -5.919, F 2.709)]  [G loss: -2.793] \n",
      "2603 [D loss: (-1.686)(R -6.162, F 2.790)]  [G loss: -2.870] \n",
      "2604 [D loss: (-1.496)(R -5.898, F 2.905)]  [G loss: -2.558] \n",
      "2604 [D loss: (-1.383)(R -5.681, F 2.914)]  [G loss: -2.474] \n",
      "2605 [D loss: (-1.748)(R -5.827, F 2.331)]  [G loss: -2.502] \n",
      "2605 [D loss: (-1.497)(R -5.746, F 2.753)]  [G loss: -2.789] \n",
      "2606 [D loss: (-1.650)(R -5.822, F 2.523)]  [G loss: -2.440] \n",
      "2606 [D loss: (-1.617)(R -5.849, F 2.616)]  [G loss: -2.737] \n",
      "2607 [D loss: (-1.498)(R -5.707, F 2.712)]  [G loss: -2.655] \n",
      "2607 [D loss: (-1.415)(R -5.793, F 2.963)]  [G loss: -2.479] \n",
      "2608 [D loss: (-1.545)(R -5.914, F 2.825)]  [G loss: -2.706] \n",
      "2608 [D loss: (-1.687)(R -5.838, F 2.463)]  [G loss: -2.700] \n",
      "2609 [D loss: (-1.403)(R -6.039, F 3.232)]  [G loss: -2.863] \n",
      "2609 [D loss: (-1.728)(R -6.080, F 2.624)]  [G loss: -2.775] \n",
      "2610 [D loss: (-1.732)(R -6.125, F 2.662)]  [G loss: -2.578] \n",
      "2610 [D loss: (-1.572)(R -5.784, F 2.641)]  [G loss: -2.753] \n",
      "2611 [D loss: (-1.645)(R -5.683, F 2.393)]  [G loss: -2.521] \n",
      "2611 [D loss: (-1.620)(R -5.920, F 2.679)]  [G loss: -2.619] \n",
      "2612 [D loss: (-1.381)(R -5.485, F 2.723)]  [G loss: -2.524] \n",
      "2612 [D loss: (-1.317)(R -5.403, F 2.769)]  [G loss: -2.493] \n",
      "2613 [D loss: (-1.441)(R -5.566, F 2.684)]  [G loss: -2.637] \n",
      "2613 [D loss: (-1.742)(R -5.701, F 2.217)]  [G loss: -2.306] \n",
      "2614 [D loss: (-1.532)(R -5.638, F 2.575)]  [G loss: -2.422] \n",
      "2614 [D loss: (-1.581)(R -5.795, F 2.633)]  [G loss: -2.349] \n",
      "2615 [D loss: (-1.570)(R -5.621, F 2.481)]  [G loss: -2.588] \n",
      "2615 [D loss: (-1.513)(R -5.577, F 2.550)]  [G loss: -2.231] \n",
      "2616 [D loss: (-1.608)(R -5.484, F 2.267)]  [G loss: -2.381] \n",
      "2616 [D loss: (-1.524)(R -5.532, F 2.484)]  [G loss: -2.344] \n",
      "2617 [D loss: (-1.548)(R -5.608, F 2.513)]  [G loss: -2.474] \n",
      "2617 [D loss: (-1.419)(R -5.474, F 2.635)]  [G loss: -2.457] \n",
      "2618 [D loss: (-1.584)(R -5.659, F 2.490)]  [G loss: -2.275] \n",
      "2618 [D loss: (-1.840)(R -5.788, F 2.107)]  [G loss: -2.176] \n",
      "2619 [D loss: (-1.606)(R -5.475, F 2.263)]  [G loss: -1.988] \n",
      "2619 [D loss: (-1.362)(R -5.339, F 2.614)]  [G loss: -2.351] \n",
      "2620 [D loss: (-1.565)(R -5.079, F 1.948)]  [G loss: -2.126] \n",
      "2620 [D loss: (-1.645)(R -5.321, F 2.031)]  [G loss: -2.185] \n",
      "2621 [D loss: (-1.533)(R -5.445, F 2.379)]  [G loss: -1.929] \n",
      "2621 [D loss: (-1.634)(R -5.245, F 1.977)]  [G loss: -2.042] \n",
      "2622 [D loss: (-1.669)(R -4.984, F 1.647)]  [G loss: -2.059] \n",
      "2622 [D loss: (-1.620)(R -5.117, F 1.876)]  [G loss: -1.725] \n",
      "2623 [D loss: (-1.545)(R -5.136, F 2.046)]  [G loss: -1.865] \n",
      "2623 [D loss: (-1.718)(R -5.398, F 1.963)]  [G loss: -2.243] \n",
      "2624 [D loss: (-1.750)(R -5.200, F 1.700)]  [G loss: -1.993] \n",
      "2624 [D loss: (-1.498)(R -5.022, F 2.026)]  [G loss: -1.738] \n",
      "2625 [D loss: (-1.399)(R -5.170, F 2.372)]  [G loss: -2.124] \n",
      "2625 [D loss: (-1.488)(R -5.301, F 2.324)]  [G loss: -2.141] \n",
      "2626 [D loss: (-1.627)(R -5.561, F 2.306)]  [G loss: -2.183] \n",
      "2626 [D loss: (-1.573)(R -5.632, F 2.486)]  [G loss: -2.243] \n",
      "2627 [D loss: (-1.369)(R -5.160, F 2.422)]  [G loss: -2.192] \n",
      "2627 [D loss: (-1.486)(R -5.400, F 2.428)]  [G loss: -2.646] \n",
      "2628 [D loss: (-1.653)(R -5.493, F 2.186)]  [G loss: -2.465] \n",
      "2628 [D loss: (-1.529)(R -5.472, F 2.414)]  [G loss: -2.202] \n",
      "2629 [D loss: (-1.637)(R -5.357, F 2.083)]  [G loss: -2.427] \n",
      "2629 [D loss: (-1.702)(R -5.378, F 1.973)]  [G loss: -2.363] \n",
      "2630 [D loss: (-1.750)(R -5.581, F 2.081)]  [G loss: -2.479] \n",
      "2630 [D loss: (-1.553)(R -5.671, F 2.564)]  [G loss: -2.343] \n",
      "2631 [D loss: (-1.552)(R -5.523, F 2.419)]  [G loss: -2.108] \n",
      "2631 [D loss: (-1.601)(R -5.336, F 2.134)]  [G loss: -2.121] \n",
      "2632 [D loss: (-1.623)(R -5.589, F 2.343)]  [G loss: -2.076] \n",
      "2632 [D loss: (-1.703)(R -5.353, F 1.947)]  [G loss: -2.081] \n",
      "2633 [D loss: (-1.603)(R -5.515, F 2.308)]  [G loss: -2.120] \n",
      "2633 [D loss: (-1.329)(R -4.991, F 2.332)]  [G loss: -2.599] \n",
      "2634 [D loss: (-1.645)(R -5.291, F 2.000)]  [G loss: -2.389] \n",
      "2634 [D loss: (-1.582)(R -5.486, F 2.323)]  [G loss: -2.132] \n",
      "2635 [D loss: (-1.410)(R -5.579, F 2.759)]  [G loss: -2.306] \n",
      "2635 [D loss: (-1.312)(R -5.137, F 2.513)]  [G loss: -2.256] \n",
      "2636 [D loss: (-1.541)(R -5.434, F 2.352)]  [G loss: -2.087] \n",
      "2636 [D loss: (-1.334)(R -5.240, F 2.572)]  [G loss: -2.507] \n",
      "2637 [D loss: (-1.732)(R -5.591, F 2.128)]  [G loss: -2.751] \n",
      "2637 [D loss: (-1.427)(R -5.658, F 2.804)]  [G loss: -2.753] \n",
      "2638 [D loss: (-1.592)(R -5.770, F 2.586)]  [G loss: -2.510] \n",
      "2638 [D loss: (-1.693)(R -5.692, F 2.305)]  [G loss: -2.545] \n",
      "2639 [D loss: (-1.682)(R -5.541, F 2.178)]  [G loss: -2.650] \n",
      "2639 [D loss: (-1.535)(R -5.584, F 2.513)]  [G loss: -2.340] \n",
      "2640 [D loss: (-1.512)(R -5.518, F 2.494)]  [G loss: -2.679] \n",
      "2640 [D loss: (-1.721)(R -5.440, F 1.999)]  [G loss: -2.250] \n",
      "2641 [D loss: (-1.371)(R -5.427, F 2.685)]  [G loss: -2.268] \n",
      "2641 [D loss: (-1.423)(R -5.434, F 2.589)]  [G loss: -2.463] \n",
      "2642 [D loss: (-1.468)(R -5.425, F 2.489)]  [G loss: -2.374] \n",
      "2642 [D loss: (-1.421)(R -5.530, F 2.687)]  [G loss: -2.542] \n",
      "2643 [D loss: (-1.413)(R -5.547, F 2.721)]  [G loss: -2.328] \n",
      "2643 [D loss: (-1.491)(R -5.678, F 2.697)]  [G loss: -2.284] \n",
      "2644 [D loss: (-1.563)(R -5.554, F 2.427)]  [G loss: -2.499] \n",
      "2644 [D loss: (-1.511)(R -5.682, F 2.660)]  [G loss: -2.344] \n",
      "2645 [D loss: (-1.551)(R -5.595, F 2.493)]  [G loss: -2.240] \n",
      "2645 [D loss: (-1.362)(R -5.396, F 2.671)]  [G loss: -2.585] \n",
      "2646 [D loss: (-1.282)(R -5.284, F 2.720)]  [G loss: -2.464] \n",
      "2646 [D loss: (-1.547)(R -5.630, F 2.536)]  [G loss: -2.225] \n",
      "2647 [D loss: (-1.634)(R -5.911, F 2.642)]  [G loss: -2.481] \n",
      "2647 [D loss: (-1.422)(R -5.656, F 2.811)]  [G loss: -2.471] \n",
      "2648 [D loss: (-1.674)(R -5.754, F 2.407)]  [G loss: -2.665] \n",
      "2648 [D loss: (-1.668)(R -5.921, F 2.585)]  [G loss: -2.633] \n",
      "2649 [D loss: (-1.332)(R -5.767, F 3.104)]  [G loss: -2.765] \n",
      "2649 [D loss: (-1.462)(R -5.732, F 2.807)]  [G loss: -2.721] \n",
      "2650 [D loss: (-1.464)(R -5.736, F 2.808)]  [G loss: -2.856] \n",
      "2650 [D loss: (-1.493)(R -5.944, F 2.958)]  [G loss: -3.037] \n",
      "2651 [D loss: (-1.621)(R -5.739, F 2.497)]  [G loss: -2.736] \n",
      "2651 [D loss: (-1.675)(R -5.764, F 2.414)]  [G loss: -2.817] \n",
      "2652 [D loss: (-1.556)(R -5.745, F 2.632)]  [G loss: -3.019] \n",
      "2652 [D loss: (-1.464)(R -5.798, F 2.870)]  [G loss: -2.633] \n",
      "2653 [D loss: (-1.685)(R -5.912, F 2.542)]  [G loss: -2.710] \n",
      "2653 [D loss: (-1.620)(R -5.792, F 2.553)]  [G loss: -2.777] \n",
      "2654 [D loss: (-1.716)(R -5.930, F 2.498)]  [G loss: -2.747] \n",
      "2654 [D loss: (-1.398)(R -5.703, F 2.907)]  [G loss: -2.315] \n",
      "2655 [D loss: (-1.280)(R -5.685, F 3.124)]  [G loss: -2.656] \n",
      "2655 [D loss: (-1.630)(R -5.859, F 2.599)]  [G loss: -2.399] \n",
      "2656 [D loss: (-1.555)(R -5.717, F 2.606)]  [G loss: -2.519] \n",
      "2656 [D loss: (-1.365)(R -5.768, F 3.037)]  [G loss: -2.676] \n",
      "2657 [D loss: (-1.514)(R -5.630, F 2.602)]  [G loss: -2.566] \n",
      "2657 [D loss: (-1.756)(R -5.848, F 2.335)]  [G loss: -2.615] \n",
      "2658 [D loss: (-1.748)(R -5.731, F 2.236)]  [G loss: -2.521] \n",
      "2658 [D loss: (-1.593)(R -5.803, F 2.616)]  [G loss: -2.542] \n",
      "2659 [D loss: (-1.897)(R -5.823, F 2.029)]  [G loss: -2.575] \n",
      "2659 [D loss: (-1.460)(R -5.564, F 2.643)]  [G loss: -2.539] \n",
      "2660 [D loss: (-1.803)(R -5.682, F 2.076)]  [G loss: -2.615] \n",
      "2660 [D loss: (-1.618)(R -5.606, F 2.370)]  [G loss: -2.284] \n",
      "2661 [D loss: (-1.487)(R -5.746, F 2.773)]  [G loss: -2.237] \n",
      "2661 [D loss: (-1.308)(R -5.736, F 3.120)]  [G loss: -2.641] \n",
      "2662 [D loss: (-1.648)(R -6.061, F 2.765)]  [G loss: -2.862] \n",
      "2662 [D loss: (-1.561)(R -5.837, F 2.715)]  [G loss: -2.680] \n",
      "2663 [D loss: (-1.511)(R -5.758, F 2.735)]  [G loss: -2.878] \n",
      "2663 [D loss: (-1.459)(R -5.846, F 2.929)]  [G loss: -2.864] \n",
      "2664 [D loss: (-1.571)(R -6.008, F 2.865)]  [G loss: -2.896] \n",
      "2664 [D loss: (-1.447)(R -6.015, F 3.122)]  [G loss: -3.065] \n",
      "2665 [D loss: (-1.519)(R -6.294, F 3.257)]  [G loss: -3.318] \n",
      "2665 [D loss: (-1.499)(R -6.270, F 3.272)]  [G loss: -3.378] \n",
      "2666 [D loss: (-1.428)(R -6.209, F 3.352)]  [G loss: -3.249] \n",
      "2666 [D loss: (-1.384)(R -6.371, F 3.603)]  [G loss: -3.521] \n",
      "2667 [D loss: (-1.423)(R -6.628, F 3.782)]  [G loss: -3.515] \n",
      "2667 [D loss: (-1.576)(R -6.504, F 3.351)]  [G loss: -3.367] \n",
      "2668 [D loss: (-1.513)(R -6.443, F 3.418)]  [G loss: -3.339] \n",
      "2668 [D loss: (-1.318)(R -6.069, F 3.434)]  [G loss: -3.256] \n",
      "2669 [D loss: (-1.667)(R -6.755, F 3.421)]  [G loss: -3.449] \n",
      "2669 [D loss: (-1.583)(R -6.568, F 3.402)]  [G loss: -3.326] \n",
      "2670 [D loss: (-1.445)(R -6.205, F 3.314)]  [G loss: -3.112] \n",
      "2670 [D loss: (-1.434)(R -6.204, F 3.336)]  [G loss: -3.546] \n",
      "2671 [D loss: (-1.438)(R -6.431, F 3.556)]  [G loss: -3.596] \n",
      "2671 [D loss: (-1.454)(R -6.462, F 3.554)]  [G loss: -3.476] \n",
      "2672 [D loss: (-1.611)(R -6.594, F 3.372)]  [G loss: -3.551] \n",
      "2672 [D loss: (-1.372)(R -6.403, F 3.658)]  [G loss: -3.480] \n",
      "2673 [D loss: (-1.371)(R -6.396, F 3.654)]  [G loss: -3.120] \n",
      "2673 [D loss: (-1.456)(R -6.383, F 3.471)]  [G loss: -3.339] \n",
      "2674 [D loss: (-1.473)(R -6.349, F 3.402)]  [G loss: -3.078] \n",
      "2674 [D loss: (-1.518)(R -6.303, F 3.267)]  [G loss: -3.244] \n",
      "2675 [D loss: (-1.540)(R -6.610, F 3.530)]  [G loss: -3.323] \n",
      "2675 [D loss: (-1.236)(R -6.200, F 3.728)]  [G loss: -3.379] \n",
      "2676 [D loss: (-1.551)(R -6.443, F 3.341)]  [G loss: -3.134] \n",
      "2676 [D loss: (-1.448)(R -6.593, F 3.696)]  [G loss: -3.198] \n",
      "2677 [D loss: (-1.344)(R -6.319, F 3.631)]  [G loss: -3.422] \n",
      "2677 [D loss: (-1.476)(R -6.442, F 3.490)]  [G loss: -3.591] \n",
      "2678 [D loss: (-1.529)(R -6.584, F 3.527)]  [G loss: -3.562] \n",
      "2678 [D loss: (-1.597)(R -6.781, F 3.587)]  [G loss: -3.655] \n",
      "2679 [D loss: (-1.494)(R -6.606, F 3.619)]  [G loss: -3.415] \n",
      "2679 [D loss: (-1.358)(R -6.400, F 3.685)]  [G loss: -3.331] \n",
      "2680 [D loss: (-1.609)(R -6.525, F 3.308)]  [G loss: -3.649] \n",
      "2680 [D loss: (-1.568)(R -6.459, F 3.324)]  [G loss: -3.437] \n",
      "2681 [D loss: (-1.496)(R -6.528, F 3.535)]  [G loss: -3.358] \n",
      "2681 [D loss: (-1.589)(R -6.628, F 3.450)]  [G loss: -3.326] \n",
      "2682 [D loss: (-1.472)(R -6.513, F 3.569)]  [G loss: -3.740] \n",
      "2682 [D loss: (-1.408)(R -6.361, F 3.546)]  [G loss: -3.458] \n",
      "2683 [D loss: (-1.470)(R -6.469, F 3.529)]  [G loss: -3.451] \n",
      "2683 [D loss: (-1.418)(R -6.116, F 3.281)]  [G loss: -3.251] \n",
      "2684 [D loss: (-1.573)(R -6.420, F 3.274)]  [G loss: -3.370] \n",
      "2684 [D loss: (-1.480)(R -6.385, F 3.425)]  [G loss: -3.275] \n",
      "2685 [D loss: (-1.597)(R -6.480, F 3.286)]  [G loss: -3.277] \n",
      "2685 [D loss: (-1.594)(R -6.076, F 2.888)]  [G loss: -3.248] \n",
      "2686 [D loss: (-1.287)(R -6.063, F 3.489)]  [G loss: -3.316] \n",
      "2686 [D loss: (-1.243)(R -6.043, F 3.557)]  [G loss: -3.187] \n",
      "2687 [D loss: (-1.715)(R -6.215, F 2.785)]  [G loss: -3.188] \n",
      "2687 [D loss: (-1.417)(R -6.405, F 3.572)]  [G loss: -3.056] \n",
      "2688 [D loss: (-1.292)(R -5.969, F 3.385)]  [G loss: -3.375] \n",
      "2688 [D loss: (-1.435)(R -6.281, F 3.411)]  [G loss: -3.255] \n",
      "2689 [D loss: (-1.413)(R -6.301, F 3.475)]  [G loss: -3.218] \n",
      "2689 [D loss: (-1.281)(R -6.304, F 3.742)]  [G loss: -3.296] \n",
      "2690 [D loss: (-1.311)(R -6.221, F 3.600)]  [G loss: -3.417] \n",
      "2690 [D loss: (-1.315)(R -6.285, F 3.654)]  [G loss: -3.286] \n",
      "2691 [D loss: (-1.512)(R -6.551, F 3.528)]  [G loss: -3.404] \n",
      "2691 [D loss: (-1.369)(R -6.603, F 3.865)]  [G loss: -3.568] \n",
      "2692 [D loss: (-1.565)(R -6.732, F 3.602)]  [G loss: -3.635] \n",
      "2692 [D loss: (-1.399)(R -6.756, F 3.957)]  [G loss: -3.702] \n",
      "2693 [D loss: (-1.296)(R -6.559, F 3.968)]  [G loss: -3.652] \n",
      "2693 [D loss: (-1.421)(R -6.705, F 3.863)]  [G loss: -3.478] \n",
      "2694 [D loss: (-1.255)(R -6.768, F 4.258)]  [G loss: -3.840] \n",
      "2694 [D loss: (-1.445)(R -6.779, F 3.890)]  [G loss: -3.665] \n",
      "2695 [D loss: (-1.537)(R -6.892, F 3.818)]  [G loss: -3.692] \n",
      "2695 [D loss: (-1.289)(R -6.409, F 3.830)]  [G loss: -3.822] \n",
      "2696 [D loss: (-1.345)(R -6.510, F 3.820)]  [G loss: -4.056] \n",
      "2696 [D loss: (-1.591)(R -6.817, F 3.635)]  [G loss: -3.771] \n",
      "2697 [D loss: (-1.445)(R -6.469, F 3.579)]  [G loss: -3.710] \n",
      "2697 [D loss: (-1.313)(R -6.669, F 4.043)]  [G loss: -3.908] \n",
      "2698 [D loss: (-1.343)(R -6.668, F 3.982)]  [G loss: -3.567] \n",
      "2698 [D loss: (-1.670)(R -6.757, F 3.416)]  [G loss: -3.510] \n",
      "2699 [D loss: (-1.378)(R -6.501, F 3.745)]  [G loss: -3.607] \n",
      "2699 [D loss: (-1.436)(R -6.601, F 3.729)]  [G loss: -3.626] \n",
      "2700 [D loss: (-1.357)(R -6.615, F 3.900)]  [G loss: -3.696] \n",
      "2700 [D loss: (-1.519)(R -6.832, F 3.794)]  [G loss: -3.614] \n",
      "2701 [D loss: (-1.578)(R -6.672, F 3.517)]  [G loss: -3.890] \n",
      "2701 [D loss: (-1.459)(R -6.723, F 3.804)]  [G loss: -3.668] \n",
      "2702 [D loss: (-1.626)(R -6.902, F 3.650)]  [G loss: -3.826] \n",
      "2702 [D loss: (-1.411)(R -6.692, F 3.870)]  [G loss: -3.839] \n",
      "2703 [D loss: (-1.574)(R -6.710, F 3.562)]  [G loss: -3.477] \n",
      "2703 [D loss: (-1.444)(R -6.559, F 3.672)]  [G loss: -3.666] \n",
      "2704 [D loss: (-1.583)(R -6.823, F 3.656)]  [G loss: -3.485] \n",
      "2704 [D loss: (-1.430)(R -6.654, F 3.793)]  [G loss: -3.687] \n",
      "2705 [D loss: (-1.378)(R -6.594, F 3.838)]  [G loss: -3.628] \n",
      "2705 [D loss: (-1.476)(R -6.761, F 3.808)]  [G loss: -3.682] \n",
      "2706 [D loss: (-1.309)(R -6.725, F 4.106)]  [G loss: -3.813] \n",
      "2706 [D loss: (-1.497)(R -6.643, F 3.649)]  [G loss: -3.715] \n",
      "2707 [D loss: (-1.528)(R -6.973, F 3.916)]  [G loss: -3.879] \n",
      "2707 [D loss: (-1.483)(R -6.915, F 3.949)]  [G loss: -3.873] \n",
      "2708 [D loss: (-1.330)(R -6.869, F 4.209)]  [G loss: -3.951] \n",
      "2708 [D loss: (-1.428)(R -6.713, F 3.857)]  [G loss: -3.852] \n",
      "2709 [D loss: (-1.350)(R -6.905, F 4.205)]  [G loss: -3.914] \n",
      "2709 [D loss: (-1.511)(R -6.993, F 3.972)]  [G loss: -4.006] \n",
      "2710 [D loss: (-1.566)(R -7.030, F 3.898)]  [G loss: -4.146] \n",
      "2710 [D loss: (-1.252)(R -6.775, F 4.270)]  [G loss: -4.106] \n",
      "2711 [D loss: (-1.428)(R -7.114, F 4.259)]  [G loss: -4.210] \n",
      "2711 [D loss: (-1.429)(R -6.750, F 3.893)]  [G loss: -3.656] \n",
      "2712 [D loss: (-1.406)(R -6.811, F 3.999)]  [G loss: -3.559] \n",
      "2712 [D loss: (-1.247)(R -6.488, F 3.995)]  [G loss: -3.637] \n",
      "2713 [D loss: (-1.522)(R -6.633, F 3.590)]  [G loss: -3.584] \n",
      "2713 [D loss: (-1.513)(R -6.672, F 3.646)]  [G loss: -3.650] \n",
      "2714 [D loss: (-1.436)(R -6.681, F 3.810)]  [G loss: -3.949] \n",
      "2714 [D loss: (-1.307)(R -6.541, F 3.926)]  [G loss: -3.788] \n",
      "2715 [D loss: (-1.433)(R -6.578, F 3.713)]  [G loss: -3.323] \n",
      "2715 [D loss: (-1.448)(R -6.568, F 3.672)]  [G loss: -3.673] \n",
      "2716 [D loss: (-1.346)(R -6.643, F 3.952)]  [G loss: -3.905] \n",
      "2716 [D loss: (-1.551)(R -6.753, F 3.650)]  [G loss: -3.749] \n",
      "2717 [D loss: (-1.523)(R -6.739, F 3.693)]  [G loss: -4.068] \n",
      "2717 [D loss: (-1.406)(R -6.799, F 3.987)]  [G loss: -3.842] \n",
      "2718 [D loss: (-1.288)(R -6.640, F 4.065)]  [G loss: -3.921] \n",
      "2718 [D loss: (-1.441)(R -6.660, F 3.778)]  [G loss: -3.704] \n",
      "2719 [D loss: (-1.380)(R -6.761, F 4.000)]  [G loss: -3.874] \n",
      "2719 [D loss: (-1.370)(R -6.761, F 4.020)]  [G loss: -3.856] \n",
      "2720 [D loss: (-1.330)(R -6.681, F 4.020)]  [G loss: -3.875] \n",
      "2720 [D loss: (-1.417)(R -6.601, F 3.766)]  [G loss: -4.431] \n",
      "2721 [D loss: (-1.311)(R -6.860, F 4.238)]  [G loss: -4.104] \n",
      "2721 [D loss: (-1.443)(R -6.934, F 4.049)]  [G loss: -4.136] \n",
      "2722 [D loss: (-1.367)(R -6.896, F 4.162)]  [G loss: -3.947] \n",
      "2722 [D loss: (-1.431)(R -6.912, F 4.051)]  [G loss: -4.206] \n",
      "2723 [D loss: (-1.373)(R -7.103, F 4.358)]  [G loss: -4.184] \n",
      "2723 [D loss: (-1.324)(R -7.024, F 4.375)]  [G loss: -4.164] \n",
      "2724 [D loss: (-1.417)(R -7.075, F 4.242)]  [G loss: -4.400] \n",
      "2724 [D loss: (-1.475)(R -7.248, F 4.297)]  [G loss: -4.204] \n",
      "2725 [D loss: (-1.328)(R -6.856, F 4.201)]  [G loss: -4.362] \n",
      "2725 [D loss: (-1.232)(R -6.962, F 4.498)]  [G loss: -4.050] \n",
      "2726 [D loss: (-1.288)(R -7.035, F 4.459)]  [G loss: -4.385] \n",
      "2726 [D loss: (-1.150)(R -6.946, F 4.647)]  [G loss: -4.485] \n",
      "2727 [D loss: (-1.367)(R -7.029, F 4.295)]  [G loss: -4.224] \n",
      "2727 [D loss: (-1.202)(R -6.981, F 4.577)]  [G loss: -4.650] \n",
      "2728 [D loss: (-1.308)(R -6.977, F 4.361)]  [G loss: -4.327] \n",
      "2728 [D loss: (-1.285)(R -7.148, F 4.579)]  [G loss: -4.289] \n",
      "2729 [D loss: (-1.264)(R -6.987, F 4.459)]  [G loss: -4.354] \n",
      "2729 [D loss: (-1.422)(R -7.064, F 4.221)]  [G loss: -4.430] \n",
      "2730 [D loss: (-1.544)(R -7.220, F 4.132)]  [G loss: -4.352] \n",
      "2730 [D loss: (-1.443)(R -6.910, F 4.025)]  [G loss: -4.402] \n",
      "2731 [D loss: (-1.315)(R -7.047, F 4.416)]  [G loss: -4.280] \n",
      "2731 [D loss: (-1.218)(R -6.865, F 4.430)]  [G loss: -3.980] \n",
      "2732 [D loss: (-1.391)(R -7.023, F 4.241)]  [G loss: -4.096] \n",
      "2732 [D loss: (-1.329)(R -6.847, F 4.189)]  [G loss: -4.056] \n",
      "2733 [D loss: (-1.187)(R -6.850, F 4.476)]  [G loss: -3.929] \n",
      "2733 [D loss: (-1.398)(R -6.926, F 4.129)]  [G loss: -4.118] \n",
      "2734 [D loss: (-1.362)(R -6.984, F 4.260)]  [G loss: -4.124] \n",
      "2734 [D loss: (-1.373)(R -7.154, F 4.407)]  [G loss: -4.217] \n",
      "2735 [D loss: (-1.300)(R -7.134, F 4.534)]  [G loss: -3.987] \n",
      "2735 [D loss: (-1.370)(R -7.056, F 4.316)]  [G loss: -4.248] \n",
      "2736 [D loss: (-1.332)(R -6.875, F 4.212)]  [G loss: -4.031] \n",
      "2736 [D loss: (-1.478)(R -7.002, F 4.046)]  [G loss: -4.262] \n",
      "2737 [D loss: (-1.269)(R -6.863, F 4.324)]  [G loss: -4.374] \n",
      "2737 [D loss: (-1.317)(R -7.170, F 4.535)]  [G loss: -4.169] \n",
      "2738 [D loss: (-1.346)(R -6.909, F 4.217)]  [G loss: -4.271] \n",
      "2738 [D loss: (-1.451)(R -7.064, F 4.163)]  [G loss: -4.071] \n",
      "2739 [D loss: (-1.390)(R -7.053, F 4.274)]  [G loss: -4.150] \n",
      "2739 [D loss: (-1.449)(R -7.285, F 4.386)]  [G loss: -4.526] \n",
      "2740 [D loss: (-1.390)(R -7.334, F 4.554)]  [G loss: -4.312] \n",
      "2740 [D loss: (-1.556)(R -7.223, F 4.111)]  [G loss: -4.627] \n",
      "2741 [D loss: (-1.335)(R -7.115, F 4.445)]  [G loss: -4.547] \n",
      "2741 [D loss: (-1.302)(R -7.040, F 4.436)]  [G loss: -4.295] \n",
      "2742 [D loss: (-1.427)(R -7.033, F 4.178)]  [G loss: -4.341] \n",
      "2742 [D loss: (-1.225)(R -6.800, F 4.349)]  [G loss: -4.244] \n",
      "2743 [D loss: (-1.319)(R -6.990, F 4.353)]  [G loss: -4.424] \n",
      "2743 [D loss: (-1.459)(R -7.152, F 4.234)]  [G loss: -4.393] \n",
      "2744 [D loss: (-1.201)(R -6.924, F 4.521)]  [G loss: -4.454] \n",
      "2744 [D loss: (-1.268)(R -6.873, F 4.338)]  [G loss: -3.889] \n",
      "2745 [D loss: (-1.405)(R -7.275, F 4.466)]  [G loss: -4.456] \n",
      "2745 [D loss: (-1.416)(R -7.274, F 4.442)]  [G loss: -4.426] \n",
      "2746 [D loss: (-1.261)(R -7.233, F 4.710)]  [G loss: -4.619] \n",
      "2746 [D loss: (-1.335)(R -7.297, F 4.628)]  [G loss: -4.572] \n",
      "2747 [D loss: (-1.163)(R -7.176, F 4.850)]  [G loss: -4.508] \n",
      "2747 [D loss: (-1.522)(R -7.477, F 4.433)]  [G loss: -4.811] \n",
      "2748 [D loss: (-1.352)(R -7.293, F 4.589)]  [G loss: -4.414] \n",
      "2748 [D loss: (-1.314)(R -7.127, F 4.499)]  [G loss: -4.552] \n",
      "2749 [D loss: (-1.490)(R -7.347, F 4.367)]  [G loss: -4.593] \n",
      "2749 [D loss: (-1.220)(R -6.975, F 4.535)]  [G loss: -4.498] \n",
      "2750 [D loss: (-1.335)(R -7.096, F 4.426)]  [G loss: -4.369] \n",
      "2750 [D loss: (-1.242)(R -6.997, F 4.513)]  [G loss: -4.070] \n",
      "2751 [D loss: (-1.378)(R -7.180, F 4.423)]  [G loss: -3.789] \n",
      "2751 [D loss: (-1.345)(R -7.107, F 4.416)]  [G loss: -4.296] \n",
      "2752 [D loss: (-1.393)(R -6.922, F 4.136)]  [G loss: -4.166] \n",
      "2752 [D loss: (-1.129)(R -6.712, F 4.455)]  [G loss: -4.455] \n",
      "2753 [D loss: (-1.372)(R -6.996, F 4.252)]  [G loss: -4.368] \n",
      "2753 [D loss: (-1.223)(R -6.886, F 4.441)]  [G loss: -4.092] \n",
      "2754 [D loss: (-1.310)(R -7.227, F 4.607)]  [G loss: -4.682] \n",
      "2754 [D loss: (-1.290)(R -7.413, F 4.832)]  [G loss: -4.718] \n",
      "2755 [D loss: (-1.195)(R -7.295, F 4.905)]  [G loss: -4.807] \n",
      "2755 [D loss: (-1.301)(R -7.758, F 5.156)]  [G loss: -5.030] \n",
      "2756 [D loss: (-1.244)(R -7.509, F 5.020)]  [G loss: -4.558] \n",
      "2756 [D loss: (-1.215)(R -7.330, F 4.900)]  [G loss: -4.722] \n",
      "2757 [D loss: (-1.238)(R -7.465, F 4.988)]  [G loss: -4.775] \n",
      "2757 [D loss: (-1.342)(R -7.646, F 4.962)]  [G loss: -4.649] \n",
      "2758 [D loss: (-1.231)(R -7.291, F 4.829)]  [G loss: -4.757] \n",
      "2758 [D loss: (-1.332)(R -7.482, F 4.817)]  [G loss: -4.999] \n",
      "2759 [D loss: (-1.225)(R -7.517, F 5.066)]  [G loss: -4.752] \n",
      "2759 [D loss: (-1.162)(R -7.528, F 5.205)]  [G loss: -4.836] \n",
      "2760 [D loss: (-1.114)(R -7.595, F 5.366)]  [G loss: -4.916] \n",
      "2760 [D loss: (-1.149)(R -7.529, F 5.231)]  [G loss: -4.684] \n",
      "2761 [D loss: (-1.383)(R -7.634, F 4.868)]  [G loss: -4.795] \n",
      "2761 [D loss: (-1.466)(R -7.650, F 4.718)]  [G loss: -4.993] \n",
      "2762 [D loss: (-1.347)(R -7.564, F 4.870)]  [G loss: -4.684] \n",
      "2762 [D loss: (-1.338)(R -7.341, F 4.664)]  [G loss: -4.963] \n",
      "2763 [D loss: (-1.251)(R -7.244, F 4.742)]  [G loss: -4.467] \n",
      "2763 [D loss: (-1.274)(R -7.277, F 4.729)]  [G loss: -4.467] \n",
      "2764 [D loss: (-1.333)(R -7.133, F 4.466)]  [G loss: -4.368] \n",
      "2764 [D loss: (-1.365)(R -7.112, F 4.382)]  [G loss: -4.470] \n",
      "2765 [D loss: (-1.418)(R -7.195, F 4.359)]  [G loss: -4.503] \n",
      "2765 [D loss: (-1.279)(R -6.995, F 4.437)]  [G loss: -4.305] \n",
      "2766 [D loss: (-1.175)(R -7.130, F 4.781)]  [G loss: -4.828] \n",
      "2766 [D loss: (-1.266)(R -7.306, F 4.774)]  [G loss: -4.585] \n",
      "2767 [D loss: (-1.208)(R -7.158, F 4.742)]  [G loss: -4.574] \n",
      "2767 [D loss: (-1.402)(R -7.519, F 4.715)]  [G loss: -4.685] \n",
      "2768 [D loss: (-1.443)(R -7.311, F 4.425)]  [G loss: -4.563] \n",
      "2768 [D loss: (-1.215)(R -7.049, F 4.619)]  [G loss: -4.435] \n",
      "2769 [D loss: (-1.387)(R -7.267, F 4.493)]  [G loss: -4.605] \n",
      "2769 [D loss: (-1.159)(R -7.142, F 4.825)]  [G loss: -4.725] \n",
      "2770 [D loss: (-1.251)(R -7.455, F 4.954)]  [G loss: -4.712] \n",
      "2770 [D loss: (-1.101)(R -7.505, F 5.303)]  [G loss: -5.112] \n",
      "2771 [D loss: (-1.336)(R -7.538, F 4.865)]  [G loss: -5.063] \n",
      "2771 [D loss: (-1.297)(R -7.672, F 5.078)]  [G loss: -5.142] \n",
      "2772 [D loss: (-1.281)(R -7.543, F 4.980)]  [G loss: -5.113] \n",
      "2772 [D loss: (-1.039)(R -7.408, F 5.331)]  [G loss: -4.851] \n",
      "2773 [D loss: (-1.369)(R -7.771, F 5.034)]  [G loss: -4.976] \n",
      "2773 [D loss: (-1.232)(R -7.743, F 5.280)]  [G loss: -5.081] \n",
      "2774 [D loss: (-1.190)(R -7.443, F 5.062)]  [G loss: -5.109] \n",
      "2774 [D loss: (-1.306)(R -7.582, F 4.970)]  [G loss: -4.891] \n",
      "2775 [D loss: (-1.333)(R -7.593, F 4.926)]  [G loss: -4.930] \n",
      "2775 [D loss: (-1.156)(R -7.535, F 5.223)]  [G loss: -4.981] \n",
      "2776 [D loss: (-1.361)(R -7.648, F 4.926)]  [G loss: -5.022] \n",
      "2776 [D loss: (-1.272)(R -7.506, F 4.961)]  [G loss: -4.999] \n",
      "2777 [D loss: (-1.192)(R -7.379, F 4.996)]  [G loss: -4.746] \n",
      "2777 [D loss: (-1.261)(R -7.515, F 4.992)]  [G loss: -4.887] \n",
      "2778 [D loss: (-1.253)(R -7.403, F 4.897)]  [G loss: -4.564] \n",
      "2778 [D loss: (-1.237)(R -7.343, F 4.869)]  [G loss: -4.797] \n",
      "2779 [D loss: (-1.137)(R -7.151, F 4.878)]  [G loss: -4.942] \n",
      "2779 [D loss: (-1.187)(R -7.290, F 4.915)]  [G loss: -4.712] \n",
      "2780 [D loss: (-1.211)(R -7.223, F 4.801)]  [G loss: -4.802] \n",
      "2780 [D loss: (-1.145)(R -7.259, F 4.969)]  [G loss: -4.826] \n",
      "2781 [D loss: (-1.298)(R -7.513, F 4.918)]  [G loss: -4.738] \n",
      "2781 [D loss: (-1.204)(R -7.547, F 5.139)]  [G loss: -4.889] \n",
      "2782 [D loss: (-1.265)(R -7.404, F 4.875)]  [G loss: -4.834] \n",
      "2782 [D loss: (-1.216)(R -7.372, F 4.940)]  [G loss: -4.802] \n",
      "2783 [D loss: (-1.390)(R -7.586, F 4.807)]  [G loss: -4.719] \n",
      "2783 [D loss: (-1.386)(R -7.399, F 4.628)]  [G loss: -4.778] \n",
      "2784 [D loss: (-1.163)(R -7.320, F 4.994)]  [G loss: -4.726] \n",
      "2784 [D loss: (-1.089)(R -7.230, F 5.053)]  [G loss: -4.436] \n",
      "2785 [D loss: (-1.263)(R -7.280, F 4.753)]  [G loss: -4.801] \n",
      "2785 [D loss: (-1.166)(R -7.373, F 5.042)]  [G loss: -4.729] \n",
      "2786 [D loss: (-1.202)(R -7.422, F 5.019)]  [G loss: -5.021] \n",
      "2786 [D loss: (-1.227)(R -7.563, F 5.110)]  [G loss: -4.829] \n",
      "2787 [D loss: (-1.121)(R -7.429, F 5.186)]  [G loss: -5.174] \n",
      "2787 [D loss: (-1.269)(R -7.601, F 5.063)]  [G loss: -4.948] \n",
      "2788 [D loss: (-1.186)(R -7.612, F 5.241)]  [G loss: -5.052] \n",
      "2788 [D loss: (-1.204)(R -7.644, F 5.237)]  [G loss: -5.276] \n",
      "2789 [D loss: (-1.095)(R -7.526, F 5.336)]  [G loss: -5.368] \n",
      "2789 [D loss: (-1.220)(R -7.828, F 5.389)]  [G loss: -5.458] \n",
      "2790 [D loss: (-1.318)(R -7.992, F 5.356)]  [G loss: -5.490] \n",
      "2790 [D loss: (-1.215)(R -7.795, F 5.364)]  [G loss: -5.109] \n",
      "2791 [D loss: (-1.234)(R -7.835, F 5.366)]  [G loss: -5.546] \n",
      "2791 [D loss: (-1.223)(R -7.865, F 5.418)]  [G loss: -5.249] \n",
      "2792 [D loss: (-1.178)(R -7.779, F 5.423)]  [G loss: -5.406] \n",
      "2792 [D loss: (-1.129)(R -7.661, F 5.402)]  [G loss: -5.260] \n",
      "2793 [D loss: (-1.255)(R -7.645, F 5.136)]  [G loss: -5.370] \n",
      "2793 [D loss: (-1.150)(R -7.525, F 5.225)]  [G loss: -5.236] \n",
      "2794 [D loss: (-1.172)(R -7.468, F 5.124)]  [G loss: -4.813] \n",
      "2794 [D loss: (-1.209)(R -7.637, F 5.219)]  [G loss: -5.016] \n",
      "2795 [D loss: (-1.075)(R -7.331, F 5.181)]  [G loss: -5.023] \n",
      "2795 [D loss: (-1.019)(R -7.496, F 5.458)]  [G loss: -5.054] \n",
      "2796 [D loss: (-1.202)(R -7.822, F 5.417)]  [G loss: -5.236] \n",
      "2796 [D loss: (-1.208)(R -7.800, F 5.383)]  [G loss: -5.107] \n",
      "2797 [D loss: (-1.277)(R -7.869, F 5.316)]  [G loss: -5.233] \n",
      "2797 [D loss: (-1.297)(R -7.982, F 5.388)]  [G loss: -5.554] \n",
      "2798 [D loss: (-1.202)(R -7.893, F 5.489)]  [G loss: -5.481] \n",
      "2798 [D loss: (-1.207)(R -7.890, F 5.475)]  [G loss: -5.573] \n",
      "2799 [D loss: (-1.205)(R -8.007, F 5.597)]  [G loss: -5.346] \n",
      "2799 [D loss: (-1.216)(R -7.941, F 5.509)]  [G loss: -5.719] \n",
      "2800 [D loss: (-1.171)(R -7.939, F 5.597)]  [G loss: -5.600] \n",
      "2800 [D loss: (-1.228)(R -8.063, F 5.607)]  [G loss: -5.223] \n",
      "2801 [D loss: (-1.239)(R -7.912, F 5.434)]  [G loss: -5.415] \n",
      "2801 [D loss: (-1.217)(R -7.840, F 5.405)]  [G loss: -5.129] \n",
      "2802 [D loss: (-1.139)(R -7.821, F 5.544)]  [G loss: -5.358] \n",
      "2802 [D loss: (-1.182)(R -7.927, F 5.564)]  [G loss: -5.547] \n",
      "2803 [D loss: (-1.176)(R -7.944, F 5.592)]  [G loss: -5.396] \n",
      "2803 [D loss: (-1.263)(R -8.175, F 5.648)]  [G loss: -5.680] \n",
      "2804 [D loss: (-1.167)(R -8.124, F 5.791)]  [G loss: -5.574] \n",
      "2804 [D loss: (-1.182)(R -8.001, F 5.637)]  [G loss: -5.576] \n",
      "2805 [D loss: (-1.207)(R -8.137, F 5.724)]  [G loss: -5.788] \n",
      "2805 [D loss: (-1.074)(R -7.887, F 5.739)]  [G loss: -5.593] \n",
      "2806 [D loss: (-1.087)(R -7.904, F 5.730)]  [G loss: -5.594] \n",
      "2806 [D loss: (-1.145)(R -8.145, F 5.855)]  [G loss: -5.606] \n",
      "2807 [D loss: (-1.113)(R -8.215, F 5.989)]  [G loss: -5.740] \n",
      "2807 [D loss: (-1.099)(R -8.042, F 5.844)]  [G loss: -5.401] \n",
      "2808 [D loss: (-1.311)(R -8.451, F 5.828)]  [G loss: -5.679] \n",
      "2808 [D loss: (-1.096)(R -8.101, F 5.909)]  [G loss: -5.869] \n",
      "2809 [D loss: (-1.178)(R -8.290, F 5.935)]  [G loss: -5.737] \n",
      "2809 [D loss: (-1.101)(R -8.285, F 6.083)]  [G loss: -5.875] \n",
      "2810 [D loss: (-1.158)(R -8.223, F 5.908)]  [G loss: -5.706] \n",
      "2810 [D loss: (-1.260)(R -8.333, F 5.813)]  [G loss: -5.918] \n",
      "2811 [D loss: (-1.128)(R -8.056, F 5.800)]  [G loss: -5.740] \n",
      "2811 [D loss: (-1.168)(R -8.036, F 5.700)]  [G loss: -5.478] \n",
      "2812 [D loss: (-1.136)(R -7.938, F 5.666)]  [G loss: -5.655] \n",
      "2812 [D loss: (-1.166)(R -7.983, F 5.650)]  [G loss: -5.473] \n",
      "2813 [D loss: (-1.102)(R -7.843, F 5.639)]  [G loss: -5.564] \n",
      "2813 [D loss: (-1.257)(R -8.057, F 5.543)]  [G loss: -5.399] \n",
      "2814 [D loss: (-1.192)(R -8.070, F 5.685)]  [G loss: -5.606] \n",
      "2814 [D loss: (-1.165)(R -8.035, F 5.705)]  [G loss: -5.584] \n",
      "2815 [D loss: (-1.131)(R -8.006, F 5.745)]  [G loss: -5.765] \n",
      "2815 [D loss: (-1.014)(R -7.916, F 5.888)]  [G loss: -5.614] \n",
      "2816 [D loss: (-1.209)(R -8.193, F 5.775)]  [G loss: -5.587] \n",
      "2816 [D loss: (-1.138)(R -7.919, F 5.644)]  [G loss: -5.682] \n",
      "2817 [D loss: (-1.218)(R -8.085, F 5.649)]  [G loss: -5.660] \n",
      "2817 [D loss: (-1.171)(R -8.018, F 5.676)]  [G loss: -5.795] \n",
      "2818 [D loss: (-1.235)(R -8.178, F 5.707)]  [G loss: -5.621] \n",
      "2818 [D loss: (-1.116)(R -8.072, F 5.840)]  [G loss: -5.899] \n",
      "2819 [D loss: (-1.151)(R -8.258, F 5.957)]  [G loss: -5.483] \n",
      "2819 [D loss: (-1.120)(R -8.094, F 5.855)]  [G loss: -6.043] \n",
      "2820 [D loss: (-1.108)(R -8.223, F 6.007)]  [G loss: -5.805] \n",
      "2820 [D loss: (-1.166)(R -8.473, F 6.141)]  [G loss: -5.868] \n",
      "2821 [D loss: (-1.156)(R -8.336, F 6.023)]  [G loss: -6.217] \n",
      "2821 [D loss: (-1.143)(R -8.445, F 6.159)]  [G loss: -6.150] \n",
      "2822 [D loss: (-1.201)(R -8.537, F 6.136)]  [G loss: -6.130] \n",
      "2822 [D loss: (-1.193)(R -8.597, F 6.211)]  [G loss: -6.085] \n",
      "2823 [D loss: (-1.147)(R -8.597, F 6.303)]  [G loss: -6.140] \n",
      "2823 [D loss: (-1.222)(R -8.507, F 6.063)]  [G loss: -5.972] \n",
      "2824 [D loss: (-1.230)(R -8.587, F 6.126)]  [G loss: -5.883] \n",
      "2824 [D loss: (-1.218)(R -8.509, F 6.073)]  [G loss: -5.942] \n",
      "2825 [D loss: (-1.162)(R -8.368, F 6.044)]  [G loss: -6.084] \n",
      "2825 [D loss: (-1.202)(R -8.614, F 6.210)]  [G loss: -6.186] \n",
      "2826 [D loss: (-1.221)(R -8.613, F 6.171)]  [G loss: -5.961] \n",
      "2826 [D loss: (-1.085)(R -8.428, F 6.257)]  [G loss: -6.314] \n",
      "2827 [D loss: (-1.101)(R -8.498, F 6.297)]  [G loss: -6.077] \n",
      "2827 [D loss: (-1.162)(R -8.625, F 6.300)]  [G loss: -6.306] \n",
      "2828 [D loss: (-1.210)(R -8.707, F 6.287)]  [G loss: -6.337] \n",
      "2828 [D loss: (-1.156)(R -8.611, F 6.300)]  [G loss: -6.277] \n",
      "2829 [D loss: (-0.981)(R -8.374, F 6.413)]  [G loss: -6.253] \n",
      "2829 [D loss: (-0.990)(R -8.511, F 6.531)]  [G loss: -6.269] \n",
      "2830 [D loss: (-1.170)(R -8.533, F 6.192)]  [G loss: -6.080] \n",
      "2830 [D loss: (-1.072)(R -8.476, F 6.332)]  [G loss: -6.101] \n",
      "2831 [D loss: (-1.039)(R -8.355, F 6.277)]  [G loss: -6.174] \n",
      "2831 [D loss: (-0.965)(R -8.218, F 6.288)]  [G loss: -6.117] \n",
      "2832 [D loss: (-1.167)(R -8.554, F 6.221)]  [G loss: -6.258] \n",
      "2832 [D loss: (-1.109)(R -8.408, F 6.190)]  [G loss: -6.187] \n",
      "2833 [D loss: (-1.172)(R -8.675, F 6.331)]  [G loss: -6.038] \n",
      "2833 [D loss: (-1.142)(R -8.588, F 6.305)]  [G loss: -6.162] \n",
      "2834 [D loss: (-1.166)(R -8.698, F 6.366)]  [G loss: -6.024] \n",
      "2834 [D loss: (-1.091)(R -8.666, F 6.483)]  [G loss: -6.547] \n",
      "2835 [D loss: (-1.090)(R -8.660, F 6.479)]  [G loss: -6.469] \n",
      "2835 [D loss: (-1.109)(R -8.554, F 6.336)]  [G loss: -6.295] \n",
      "2836 [D loss: (-1.157)(R -8.512, F 6.197)]  [G loss: -6.125] \n",
      "2836 [D loss: (-1.106)(R -8.416, F 6.204)]  [G loss: -6.104] \n",
      "2837 [D loss: (-1.075)(R -8.482, F 6.331)]  [G loss: -6.518] \n",
      "2837 [D loss: (-1.033)(R -8.414, F 6.348)]  [G loss: -6.451] \n",
      "2838 [D loss: (-1.148)(R -8.522, F 6.225)]  [G loss: -6.356] \n",
      "2838 [D loss: (-1.227)(R -8.580, F 6.126)]  [G loss: -6.324] \n",
      "2839 [D loss: (-1.057)(R -8.297, F 6.183)]  [G loss: -6.193] \n",
      "2839 [D loss: (-1.073)(R -8.324, F 6.177)]  [G loss: -6.184] \n",
      "2840 [D loss: (-1.131)(R -8.418, F 6.156)]  [G loss: -6.223] \n",
      "2840 [D loss: (-1.074)(R -8.238, F 6.091)]  [G loss: -6.016] \n",
      "2841 [D loss: (-1.225)(R -8.362, F 5.912)]  [G loss: -6.001] \n",
      "2841 [D loss: (-1.108)(R -8.380, F 6.164)]  [G loss: -6.027] \n",
      "2842 [D loss: (-1.041)(R -8.244, F 6.163)]  [G loss: -5.877] \n",
      "2842 [D loss: (-1.132)(R -8.334, F 6.070)]  [G loss: -5.869] \n",
      "2843 [D loss: (-1.040)(R -8.163, F 6.083)]  [G loss: -6.092] \n",
      "2843 [D loss: (-1.168)(R -8.450, F 6.114)]  [G loss: -6.177] \n",
      "2844 [D loss: (-1.249)(R -8.447, F 5.948)]  [G loss: -5.852] \n",
      "2844 [D loss: (-1.068)(R -8.358, F 6.222)]  [G loss: -6.157] \n",
      "2845 [D loss: (-1.028)(R -8.281, F 6.225)]  [G loss: -6.043] \n",
      "2845 [D loss: (-1.131)(R -8.485, F 6.223)]  [G loss: -6.090] \n",
      "2846 [D loss: (-1.054)(R -8.386, F 6.278)]  [G loss: -6.168] \n",
      "2846 [D loss: (-1.185)(R -8.595, F 6.225)]  [G loss: -6.156] \n",
      "2847 [D loss: (-1.163)(R -8.718, F 6.392)]  [G loss: -6.232] \n",
      "2847 [D loss: (-1.037)(R -8.689, F 6.615)]  [G loss: -6.493] \n",
      "2848 [D loss: (-1.062)(R -8.666, F 6.543)]  [G loss: -6.567] \n",
      "2848 [D loss: (-1.104)(R -8.796, F 6.588)]  [G loss: -6.395] \n",
      "2849 [D loss: (-1.084)(R -8.702, F 6.534)]  [G loss: -6.391] \n",
      "2849 [D loss: (-1.059)(R -8.880, F 6.762)]  [G loss: -6.542] \n",
      "2850 [D loss: (-1.139)(R -9.008, F 6.730)]  [G loss: -6.586] \n",
      "2850 [D loss: (-0.901)(R -8.748, F 6.946)]  [G loss: -6.798] \n",
      "2851 [D loss: (-1.125)(R -9.067, F 6.816)]  [G loss: -6.820] \n",
      "2851 [D loss: (-1.070)(R -9.097, F 6.957)]  [G loss: -6.728] \n",
      "2852 [D loss: (-1.119)(R -9.177, F 6.939)]  [G loss: -6.835] \n",
      "2852 [D loss: (-1.041)(R -9.118, F 7.036)]  [G loss: -6.649] \n",
      "2853 [D loss: (-0.964)(R -9.089, F 7.160)]  [G loss: -6.764] \n",
      "2853 [D loss: (-1.017)(R -8.955, F 6.922)]  [G loss: -6.796] \n",
      "2854 [D loss: (-1.107)(R -9.099, F 6.884)]  [G loss: -6.768] \n",
      "2854 [D loss: (-1.109)(R -9.009, F 6.791)]  [G loss: -6.796] \n",
      "2855 [D loss: (-1.061)(R -9.096, F 6.974)]  [G loss: -6.666] \n",
      "2855 [D loss: (-1.050)(R -8.931, F 6.830)]  [G loss: -6.925] \n",
      "2856 [D loss: (-0.886)(R -8.764, F 6.992)]  [G loss: -6.708] \n",
      "2856 [D loss: (-0.967)(R -8.718, F 6.783)]  [G loss: -6.718] \n",
      "2857 [D loss: (-0.996)(R -8.833, F 6.841)]  [G loss: -6.420] \n",
      "2857 [D loss: (-1.094)(R -8.971, F 6.783)]  [G loss: -6.591] \n",
      "2858 [D loss: (-1.029)(R -8.780, F 6.721)]  [G loss: -6.718] \n",
      "2858 [D loss: (-1.060)(R -8.744, F 6.625)]  [G loss: -6.682] \n",
      "2859 [D loss: (-1.008)(R -8.880, F 6.863)]  [G loss: -6.798] \n",
      "2859 [D loss: (-1.179)(R -9.059, F 6.701)]  [G loss: -6.563] \n",
      "2860 [D loss: (-1.184)(R -8.909, F 6.540)]  [G loss: -6.619] \n",
      "2860 [D loss: (-1.116)(R -8.882, F 6.651)]  [G loss: -6.663] \n",
      "2861 [D loss: (-1.060)(R -9.034, F 6.914)]  [G loss: -6.856] \n",
      "2861 [D loss: (-1.092)(R -9.159, F 6.976)]  [G loss: -6.534] \n",
      "2862 [D loss: (-1.091)(R -8.922, F 6.740)]  [G loss: -6.735] \n",
      "2862 [D loss: (-1.195)(R -9.050, F 6.661)]  [G loss: -6.828] \n",
      "2863 [D loss: (-1.093)(R -8.898, F 6.713)]  [G loss: -6.682] \n",
      "2863 [D loss: (-1.027)(R -8.806, F 6.752)]  [G loss: -6.579] \n",
      "2864 [D loss: (-1.005)(R -8.754, F 6.744)]  [G loss: -6.557] \n",
      "2864 [D loss: (-1.073)(R -8.783, F 6.638)]  [G loss: -6.862] \n",
      "2865 [D loss: (-1.211)(R -9.063, F 6.641)]  [G loss: -6.539] \n",
      "2865 [D loss: (-1.008)(R -8.834, F 6.817)]  [G loss: -6.611] \n",
      "2866 [D loss: (-1.112)(R -8.802, F 6.579)]  [G loss: -6.728] \n",
      "2866 [D loss: (-1.111)(R -8.943, F 6.721)]  [G loss: -6.945] \n",
      "2867 [D loss: (-1.171)(R -8.910, F 6.568)]  [G loss: -6.717] \n",
      "2867 [D loss: (-1.047)(R -8.788, F 6.694)]  [G loss: -6.920] \n",
      "2868 [D loss: (-1.086)(R -9.066, F 6.894)]  [G loss: -6.836] \n",
      "2868 [D loss: (-0.995)(R -8.917, F 6.927)]  [G loss: -6.785] \n",
      "2869 [D loss: (-0.945)(R -8.952, F 7.061)]  [G loss: -6.666] \n",
      "2869 [D loss: (-1.052)(R -8.917, F 6.813)]  [G loss: -6.709] \n",
      "2870 [D loss: (-1.080)(R -9.004, F 6.844)]  [G loss: -6.871] \n",
      "2870 [D loss: (-1.002)(R -8.927, F 6.923)]  [G loss: -7.111] \n",
      "2871 [D loss: (-0.975)(R -8.946, F 6.996)]  [G loss: -7.064] \n",
      "2871 [D loss: (-0.998)(R -9.026, F 7.030)]  [G loss: -6.975] \n",
      "2872 [D loss: (-1.000)(R -8.982, F 6.982)]  [G loss: -6.815] \n",
      "2872 [D loss: (-0.916)(R -8.857, F 7.025)]  [G loss: -6.939] \n",
      "2873 [D loss: (-0.964)(R -8.728, F 6.800)]  [G loss: -6.735] \n",
      "2873 [D loss: (-1.033)(R -9.015, F 6.948)]  [G loss: -6.482] \n",
      "2874 [D loss: (-1.086)(R -8.824, F 6.652)]  [G loss: -6.886] \n",
      "2874 [D loss: (-0.790)(R -8.802, F 7.221)]  [G loss: -6.819] \n",
      "2875 [D loss: (-1.189)(R -9.215, F 6.837)]  [G loss: -6.888] \n",
      "2875 [D loss: (-1.021)(R -9.032, F 6.991)]  [G loss: -7.078] \n",
      "2876 [D loss: (-0.846)(R -8.644, F 6.952)]  [G loss: -6.795] \n",
      "2876 [D loss: (-0.955)(R -8.984, F 7.073)]  [G loss: -6.938] \n",
      "2877 [D loss: (-1.084)(R -9.251, F 7.082)]  [G loss: -7.043] \n",
      "2877 [D loss: (-0.919)(R -9.123, F 7.285)]  [G loss: -7.006] \n",
      "2878 [D loss: (-0.818)(R -9.000, F 7.365)]  [G loss: -7.082] \n",
      "2878 [D loss: (-1.114)(R -9.311, F 7.084)]  [G loss: -6.979] \n",
      "2879 [D loss: (-1.005)(R -9.124, F 7.113)]  [G loss: -6.924] \n",
      "2879 [D loss: (-0.937)(R -8.940, F 7.067)]  [G loss: -7.015] \n",
      "2880 [D loss: (-1.075)(R -9.080, F 6.930)]  [G loss: -6.738] \n",
      "2880 [D loss: (-0.832)(R -8.630, F 6.966)]  [G loss: -6.511] \n",
      "2881 [D loss: (-1.015)(R -8.846, F 6.816)]  [G loss: -6.801] \n",
      "2881 [D loss: (-1.146)(R -8.789, F 6.497)]  [G loss: -6.650] \n",
      "2882 [D loss: (-1.070)(R -8.936, F 6.795)]  [G loss: -6.949] \n",
      "2882 [D loss: (-0.825)(R -8.578, F 6.928)]  [G loss: -6.530] \n",
      "2883 [D loss: (-0.995)(R -8.782, F 6.793)]  [G loss: -6.671] \n",
      "2883 [D loss: (-1.040)(R -8.815, F 6.735)]  [G loss: -6.715] \n",
      "2884 [D loss: (-0.778)(R -8.478, F 6.921)]  [G loss: -6.578] \n",
      "2884 [D loss: (-1.009)(R -8.720, F 6.703)]  [G loss: -6.878] \n",
      "2885 [D loss: (-1.059)(R -8.924, F 6.807)]  [G loss: -6.570] \n",
      "2885 [D loss: (-0.913)(R -8.607, F 6.782)]  [G loss: -6.462] \n",
      "2886 [D loss: (-0.879)(R -8.318, F 6.561)]  [G loss: -6.564] \n",
      "2886 [D loss: (-0.939)(R -8.518, F 6.640)]  [G loss: -6.589] \n",
      "2887 [D loss: (-0.944)(R -8.691, F 6.804)]  [G loss: -6.643] \n",
      "2887 [D loss: (-1.015)(R -8.510, F 6.480)]  [G loss: -6.679] \n",
      "2888 [D loss: (-1.030)(R -8.666, F 6.606)]  [G loss: -6.648] \n",
      "2888 [D loss: (-0.833)(R -8.611, F 6.945)]  [G loss: -6.765] \n",
      "2889 [D loss: (-0.948)(R -8.572, F 6.676)]  [G loss: -6.828] \n",
      "2889 [D loss: (-1.035)(R -8.949, F 6.880)]  [G loss: -6.948] \n",
      "2890 [D loss: (-0.994)(R -9.036, F 7.048)]  [G loss: -6.773] \n",
      "2890 [D loss: (-0.914)(R -8.949, F 7.121)]  [G loss: -6.860] \n",
      "2891 [D loss: (-0.989)(R -9.114, F 7.136)]  [G loss: -6.835] \n",
      "2891 [D loss: (-0.918)(R -9.065, F 7.229)]  [G loss: -6.912] \n",
      "2892 [D loss: (-1.158)(R -9.115, F 6.799)]  [G loss: -6.707] \n",
      "2892 [D loss: (-0.840)(R -8.919, F 7.239)]  [G loss: -7.043] \n",
      "2893 [D loss: (-1.114)(R -8.994, F 6.766)]  [G loss: -7.166] \n",
      "2893 [D loss: (-0.993)(R -9.152, F 7.166)]  [G loss: -6.816] \n",
      "2894 [D loss: (-0.976)(R -8.891, F 6.938)]  [G loss: -6.868] \n",
      "2894 [D loss: (-0.992)(R -9.137, F 7.152)]  [G loss: -7.150] \n",
      "2895 [D loss: (-1.106)(R -9.102, F 6.891)]  [G loss: -6.789] \n",
      "2895 [D loss: (-0.972)(R -9.143, F 7.198)]  [G loss: -6.822] \n",
      "2896 [D loss: (-1.152)(R -9.009, F 6.704)]  [G loss: -7.018] \n",
      "2896 [D loss: (-0.925)(R -8.951, F 7.100)]  [G loss: -6.736] \n",
      "2897 [D loss: (-0.883)(R -8.790, F 7.025)]  [G loss: -6.964] \n",
      "2897 [D loss: (-1.041)(R -8.989, F 6.907)]  [G loss: -7.005] \n",
      "2898 [D loss: (-0.878)(R -8.788, F 7.033)]  [G loss: -6.783] \n",
      "2898 [D loss: (-1.068)(R -8.933, F 6.798)]  [G loss: -6.899] \n",
      "2899 [D loss: (-0.941)(R -8.921, F 7.039)]  [G loss: -6.803] \n",
      "2899 [D loss: (-0.952)(R -8.816, F 6.912)]  [G loss: -6.868] \n",
      "2900 [D loss: (-0.890)(R -8.800, F 7.021)]  [G loss: -6.642] \n",
      "2900 [D loss: (-0.943)(R -8.978, F 7.091)]  [G loss: -6.893] \n",
      "2901 [D loss: (-0.940)(R -8.895, F 7.015)]  [G loss: -7.103] \n",
      "2901 [D loss: (-1.005)(R -9.017, F 7.008)]  [G loss: -6.878] \n",
      "2902 [D loss: (-1.031)(R -8.742, F 6.680)]  [G loss: -7.072] \n",
      "2902 [D loss: (-0.926)(R -8.611, F 6.758)]  [G loss: -6.999] \n",
      "2903 [D loss: (-0.938)(R -8.896, F 7.020)]  [G loss: -6.963] \n",
      "2903 [D loss: (-1.110)(R -8.756, F 6.537)]  [G loss: -6.955] \n",
      "2904 [D loss: (-0.977)(R -8.787, F 6.833)]  [G loss: -6.783] \n",
      "2904 [D loss: (-0.742)(R -8.523, F 7.039)]  [G loss: -6.767] \n",
      "2905 [D loss: (-0.910)(R -8.861, F 7.040)]  [G loss: -6.793] \n",
      "2905 [D loss: (-0.781)(R -8.658, F 7.097)]  [G loss: -6.908] \n",
      "2906 [D loss: (-0.878)(R -8.877, F 7.122)]  [G loss: -7.009] \n",
      "2906 [D loss: (-1.044)(R -8.901, F 6.813)]  [G loss: -6.989] \n",
      "2907 [D loss: (-1.005)(R -9.006, F 6.996)]  [G loss: -7.284] \n",
      "2907 [D loss: (-1.109)(R -9.226, F 7.008)]  [G loss: -7.111] \n",
      "2908 [D loss: (-1.074)(R -9.315, F 7.167)]  [G loss: -7.250] \n",
      "2908 [D loss: (-0.836)(R -9.025, F 7.353)]  [G loss: -7.315] \n",
      "2909 [D loss: (-0.799)(R -9.120, F 7.521)]  [G loss: -7.262] \n",
      "2909 [D loss: (-0.886)(R -8.889, F 7.118)]  [G loss: -7.160] \n",
      "2910 [D loss: (-0.890)(R -8.856, F 7.076)]  [G loss: -7.303] \n",
      "2910 [D loss: (-0.737)(R -9.020, F 7.547)]  [G loss: -7.274] \n",
      "2911 [D loss: (-0.830)(R -8.778, F 7.118)]  [G loss: -7.069] \n",
      "2911 [D loss: (-0.669)(R -8.880, F 7.542)]  [G loss: -7.129] \n",
      "2912 [D loss: (-0.754)(R -8.888, F 7.379)]  [G loss: -7.102] \n",
      "2912 [D loss: (-0.794)(R -8.901, F 7.314)]  [G loss: -7.104] \n",
      "2913 [D loss: (-0.729)(R -8.886, F 7.427)]  [G loss: -7.130] \n",
      "2913 [D loss: (-0.961)(R -9.079, F 7.157)]  [G loss: -7.211] \n",
      "2914 [D loss: (-0.833)(R -8.951, F 7.285)]  [G loss: -7.115] \n",
      "2914 [D loss: (-0.781)(R -8.981, F 7.419)]  [G loss: -7.194] \n",
      "2915 [D loss: (-0.937)(R -8.922, F 7.047)]  [G loss: -7.264] \n",
      "2915 [D loss: (-0.946)(R -9.067, F 7.176)]  [G loss: -6.886] \n",
      "2916 [D loss: (-0.908)(R -8.886, F 7.069)]  [G loss: -7.222] \n",
      "2916 [D loss: (-0.904)(R -8.926, F 7.118)]  [G loss: -7.245] \n",
      "2917 [D loss: (-0.749)(R -8.753, F 7.255)]  [G loss: -7.072] \n",
      "2917 [D loss: (-0.852)(R -8.992, F 7.288)]  [G loss: -7.291] \n",
      "2918 [D loss: (-0.723)(R -8.867, F 7.421)]  [G loss: -7.206] \n",
      "2918 [D loss: (-1.082)(R -9.408, F 7.243)]  [G loss: -7.252] \n",
      "2919 [D loss: (-0.772)(R -8.995, F 7.451)]  [G loss: -7.281] \n",
      "2919 [D loss: (-0.794)(R -8.975, F 7.387)]  [G loss: -7.323] \n",
      "2920 [D loss: (-0.713)(R -9.167, F 7.741)]  [G loss: -7.160] \n",
      "2920 [D loss: (-0.903)(R -9.319, F 7.513)]  [G loss: -7.292] \n",
      "2921 [D loss: (-0.805)(R -9.028, F 7.418)]  [G loss: -7.240] \n",
      "2921 [D loss: (-0.940)(R -9.257, F 7.377)]  [G loss: -7.410] \n",
      "2922 [D loss: (-0.823)(R -9.004, F 7.358)]  [G loss: -7.443] \n",
      "2922 [D loss: (-0.788)(R -9.050, F 7.474)]  [G loss: -7.262] \n",
      "2923 [D loss: (-0.963)(R -9.397, F 7.471)]  [G loss: -7.249] \n",
      "2923 [D loss: (-0.674)(R -9.014, F 7.666)]  [G loss: -7.348] \n",
      "2924 [D loss: (-0.671)(R -8.897, F 7.555)]  [G loss: -7.291] \n",
      "2924 [D loss: (-0.879)(R -9.076, F 7.318)]  [G loss: -7.181] \n",
      "2925 [D loss: (-0.833)(R -9.187, F 7.521)]  [G loss: -7.262] \n",
      "2925 [D loss: (-1.036)(R -9.152, F 7.080)]  [G loss: -7.300] \n",
      "2926 [D loss: (-0.770)(R -9.048, F 7.508)]  [G loss: -7.234] \n",
      "2926 [D loss: (-0.730)(R -8.772, F 7.311)]  [G loss: -7.225] \n",
      "2927 [D loss: (-0.652)(R -8.579, F 7.275)]  [G loss: -7.233] \n",
      "2927 [D loss: (-0.540)(R -8.653, F 7.572)]  [G loss: -7.203] \n",
      "2928 [D loss: (-0.897)(R -9.018, F 7.224)]  [G loss: -7.385] \n",
      "2928 [D loss: (-0.992)(R -9.271, F 7.287)]  [G loss: -7.307] \n",
      "2929 [D loss: (-0.891)(R -9.215, F 7.432)]  [G loss: -7.456] \n",
      "2929 [D loss: (-0.847)(R -9.226, F 7.532)]  [G loss: -7.421] \n",
      "2930 [D loss: (-0.802)(R -9.000, F 7.396)]  [G loss: -7.368] \n",
      "2930 [D loss: (-0.795)(R -8.946, F 7.356)]  [G loss: -7.087] \n",
      "2931 [D loss: (-0.833)(R -9.053, F 7.386)]  [G loss: -7.351] \n",
      "2931 [D loss: (-0.808)(R -8.866, F 7.250)]  [G loss: -7.180] \n",
      "2932 [D loss: (-0.824)(R -8.908, F 7.261)]  [G loss: -7.340] \n",
      "2932 [D loss: (-0.890)(R -9.204, F 7.423)]  [G loss: -7.466] \n",
      "2933 [D loss: (-0.854)(R -9.072, F 7.363)]  [G loss: -7.291] \n",
      "2933 [D loss: (-0.941)(R -9.294, F 7.412)]  [G loss: -7.451] \n",
      "2934 [D loss: (-0.599)(R -8.892, F 7.694)]  [G loss: -7.466] \n",
      "2934 [D loss: (-1.038)(R -9.310, F 7.235)]  [G loss: -7.359] \n",
      "2935 [D loss: (-0.538)(R -9.127, F 8.051)]  [G loss: -7.334] \n",
      "2935 [D loss: (-0.735)(R -9.198, F 7.728)]  [G loss: -7.523] \n",
      "2936 [D loss: (-0.820)(R -9.141, F 7.500)]  [G loss: -7.589] \n",
      "2936 [D loss: (-0.980)(R -9.289, F 7.329)]  [G loss: -7.392] \n",
      "2937 [D loss: (-0.856)(R -8.958, F 7.246)]  [G loss: -7.481] \n",
      "2937 [D loss: (-0.712)(R -8.944, F 7.519)]  [G loss: -7.271] \n",
      "2938 [D loss: (-0.743)(R -9.263, F 7.777)]  [G loss: -7.379] \n",
      "2938 [D loss: (-1.044)(R -9.330, F 7.242)]  [G loss: -7.601] \n",
      "2939 [D loss: (-0.862)(R -9.477, F 7.753)]  [G loss: -7.659] \n",
      "2939 [D loss: (-0.786)(R -9.376, F 7.803)]  [G loss: -7.651] \n",
      "2940 [D loss: (-0.846)(R -9.252, F 7.559)]  [G loss: -7.743] \n",
      "2940 [D loss: (-0.755)(R -9.201, F 7.691)]  [G loss: -7.847] \n",
      "2941 [D loss: (-0.861)(R -9.577, F 7.854)]  [G loss: -7.542] \n",
      "2941 [D loss: (-0.732)(R -9.215, F 7.751)]  [G loss: -7.707] \n",
      "2942 [D loss: (-0.971)(R -9.487, F 7.545)]  [G loss: -7.469] \n",
      "2942 [D loss: (-0.702)(R -8.846, F 7.441)]  [G loss: -7.793] \n",
      "2943 [D loss: (-0.938)(R -9.215, F 7.339)]  [G loss: -7.589] \n",
      "2943 [D loss: (-0.827)(R -9.462, F 7.809)]  [G loss: -7.676] \n",
      "2944 [D loss: (-0.791)(R -9.180, F 7.599)]  [G loss: -7.662] \n",
      "2944 [D loss: (-0.983)(R -9.397, F 7.432)]  [G loss: -7.566] \n",
      "2945 [D loss: (-0.821)(R -9.384, F 7.741)]  [G loss: -7.739] \n",
      "2945 [D loss: (-0.929)(R -9.660, F 7.802)]  [G loss: -7.661] \n",
      "2946 [D loss: (-0.823)(R -9.033, F 7.388)]  [G loss: -7.549] \n",
      "2946 [D loss: (-0.618)(R -8.952, F 7.716)]  [G loss: -7.790] \n",
      "2947 [D loss: (-0.505)(R -9.265, F 8.256)]  [G loss: -7.705] \n",
      "2947 [D loss: (-0.749)(R -9.418, F 7.920)]  [G loss: -7.738] \n",
      "2948 [D loss: (-0.853)(R -9.356, F 7.650)]  [G loss: -7.787] \n",
      "2948 [D loss: (-0.825)(R -9.498, F 7.848)]  [G loss: -7.713] \n",
      "2949 [D loss: (-0.571)(R -9.071, F 7.929)]  [G loss: -7.643] \n",
      "2949 [D loss: (-0.820)(R -9.138, F 7.499)]  [G loss: -7.699] \n",
      "2950 [D loss: (-0.699)(R -9.138, F 7.741)]  [G loss: -7.645] \n",
      "2950 [D loss: (-0.781)(R -9.282, F 7.720)]  [G loss: -7.479] \n",
      "2951 [D loss: (-1.036)(R -9.526, F 7.454)]  [G loss: -7.719] \n",
      "2951 [D loss: (-0.683)(R -9.372, F 8.005)]  [G loss: -7.618] \n",
      "2952 [D loss: (-0.896)(R -9.439, F 7.647)]  [G loss: -7.800] \n",
      "2952 [D loss: (-0.816)(R -9.537, F 7.904)]  [G loss: -7.842] \n",
      "2953 [D loss: (-0.868)(R -9.371, F 7.635)]  [G loss: -7.981] \n",
      "2953 [D loss: (-0.520)(R -9.415, F 8.375)]  [G loss: -7.949] \n",
      "2954 [D loss: (-0.755)(R -9.400, F 7.890)]  [G loss: -7.994] \n",
      "2954 [D loss: (-0.636)(R -9.358, F 8.087)]  [G loss: -7.959] \n",
      "2955 [D loss: (-0.907)(R -9.563, F 7.748)]  [G loss: -7.894] \n",
      "2955 [D loss: (-0.891)(R -9.576, F 7.794)]  [G loss: -7.771] \n",
      "2956 [D loss: (-0.947)(R -9.674, F 7.780)]  [G loss: -7.822] \n",
      "2956 [D loss: (-0.831)(R -9.568, F 7.905)]  [G loss: -7.741] \n",
      "2957 [D loss: (-0.769)(R -9.151, F 7.613)]  [G loss: -7.653] \n",
      "2957 [D loss: (-0.669)(R -9.104, F 7.766)]  [G loss: -7.567] \n",
      "2958 [D loss: (-0.872)(R -9.431, F 7.688)]  [G loss: -7.670] \n",
      "2958 [D loss: (-0.623)(R -8.979, F 7.734)]  [G loss: -7.621] \n",
      "2959 [D loss: (-0.632)(R -8.974, F 7.710)]  [G loss: -7.570] \n",
      "2959 [D loss: (-0.543)(R -8.857, F 7.772)]  [G loss: -7.255] \n",
      "2960 [D loss: (-0.986)(R -9.092, F 7.120)]  [G loss: -7.446] \n",
      "2960 [D loss: (-0.865)(R -8.965, F 7.235)]  [G loss: -7.468] \n",
      "2961 [D loss: (-0.706)(R -9.035, F 7.622)]  [G loss: -7.405] \n",
      "2961 [D loss: (-0.795)(R -9.220, F 7.630)]  [G loss: -7.591] \n",
      "2962 [D loss: (-0.646)(R -9.145, F 7.852)]  [G loss: -7.545] \n",
      "2962 [D loss: (-0.643)(R -9.128, F 7.843)]  [G loss: -7.720] \n",
      "2963 [D loss: (-0.744)(R -9.253, F 7.766)]  [G loss: -7.850] \n",
      "2963 [D loss: (-0.638)(R -9.256, F 7.981)]  [G loss: -7.581] \n",
      "2964 [D loss: (-0.575)(R -9.143, F 7.994)]  [G loss: -7.791] \n",
      "2964 [D loss: (-0.698)(R -9.334, F 7.937)]  [G loss: -7.721] \n",
      "2965 [D loss: (-0.526)(R -9.323, F 8.271)]  [G loss: -7.543] \n",
      "2965 [D loss: (-0.862)(R -9.380, F 7.655)]  [G loss: -7.598] \n",
      "2966 [D loss: (-0.817)(R -9.112, F 7.477)]  [G loss: -7.716] \n",
      "2966 [D loss: (-0.743)(R -9.308, F 7.822)]  [G loss: -7.693] \n",
      "2967 [D loss: (-0.788)(R -9.147, F 7.570)]  [G loss: -7.633] \n",
      "2967 [D loss: (-0.756)(R -9.217, F 7.705)]  [G loss: -7.653] \n",
      "2968 [D loss: (-0.670)(R -8.916, F 7.576)]  [G loss: -7.623] \n",
      "2968 [D loss: (-0.875)(R -9.350, F 7.599)]  [G loss: -7.708] \n",
      "2969 [D loss: (-0.780)(R -9.267, F 7.708)]  [G loss: -7.824] \n",
      "2969 [D loss: (-0.846)(R -9.305, F 7.613)]  [G loss: -7.716] \n",
      "2970 [D loss: (-0.940)(R -9.535, F 7.656)]  [G loss: -7.919] \n",
      "2970 [D loss: (-0.584)(R -9.231, F 8.064)]  [G loss: -7.775] \n",
      "2971 [D loss: (-0.677)(R -9.231, F 7.878)]  [G loss: -7.843] \n",
      "2971 [D loss: (-0.913)(R -9.655, F 7.829)]  [G loss: -7.606] \n",
      "2972 [D loss: (-0.652)(R -9.253, F 7.948)]  [G loss: -7.705] \n",
      "2972 [D loss: (-0.892)(R -9.366, F 7.582)]  [G loss: -7.618] \n",
      "2973 [D loss: (-0.707)(R -9.116, F 7.703)]  [G loss: -7.622] \n",
      "2973 [D loss: (-0.765)(R -9.012, F 7.482)]  [G loss: -7.603] \n",
      "2974 [D loss: (-0.872)(R -9.543, F 7.800)]  [G loss: -7.676] \n",
      "2974 [D loss: (-0.919)(R -9.105, F 7.267)]  [G loss: -7.637] \n",
      "2975 [D loss: (-0.730)(R -9.066, F 7.606)]  [G loss: -7.758] \n",
      "2975 [D loss: (-0.559)(R -9.164, F 8.046)]  [G loss: -7.532] \n",
      "2976 [D loss: (-0.796)(R -9.478, F 7.886)]  [G loss: -7.779] \n",
      "2976 [D loss: (-0.600)(R -9.431, F 8.231)]  [G loss: -7.550] \n",
      "2977 [D loss: (-0.917)(R -9.335, F 7.502)]  [G loss: -7.822] \n",
      "2977 [D loss: (-0.641)(R -9.106, F 7.824)]  [G loss: -7.650] \n",
      "2978 [D loss: (-0.696)(R -9.025, F 7.634)]  [G loss: -7.589] \n",
      "2978 [D loss: (-0.854)(R -9.199, F 7.492)]  [G loss: -7.551] \n",
      "2979 [D loss: (-0.696)(R -9.145, F 7.753)]  [G loss: -7.490] \n",
      "2979 [D loss: (-0.718)(R -9.323, F 7.887)]  [G loss: -7.460] \n",
      "2980 [D loss: (-0.947)(R -9.365, F 7.470)]  [G loss: -7.564] \n",
      "2980 [D loss: (-0.789)(R -8.904, F 7.326)]  [G loss: -7.434] \n",
      "2981 [D loss: (-0.709)(R -8.860, F 7.442)]  [G loss: -7.450] \n",
      "2981 [D loss: (-0.656)(R -9.185, F 7.873)]  [G loss: -7.761] \n",
      "2982 [D loss: (-0.591)(R -9.144, F 7.963)]  [G loss: -7.704] \n",
      "2982 [D loss: (-0.913)(R -9.343, F 7.518)]  [G loss: -7.705] \n",
      "2983 [D loss: (-0.914)(R -9.506, F 7.679)]  [G loss: -7.625] \n",
      "2983 [D loss: (-0.795)(R -9.071, F 7.481)]  [G loss: -7.773] \n",
      "2984 [D loss: (-0.765)(R -9.056, F 7.525)]  [G loss: -7.695] \n",
      "2984 [D loss: (-0.694)(R -9.136, F 7.748)]  [G loss: -7.659] \n",
      "2985 [D loss: (-0.811)(R -9.262, F 7.640)]  [G loss: -7.776] \n",
      "2985 [D loss: (-0.819)(R -9.274, F 7.635)]  [G loss: -7.510] \n",
      "2986 [D loss: (-0.752)(R -9.381, F 7.877)]  [G loss: -7.677] \n",
      "2986 [D loss: (-0.863)(R -9.330, F 7.604)]  [G loss: -7.543] \n",
      "2987 [D loss: (-0.675)(R -9.276, F 7.926)]  [G loss: -7.679] \n",
      "2987 [D loss: (-0.716)(R -9.160, F 7.727)]  [G loss: -7.477] \n",
      "2988 [D loss: (-0.707)(R -9.231, F 7.817)]  [G loss: -7.613] \n",
      "2988 [D loss: (-0.806)(R -9.317, F 7.704)]  [G loss: -7.568] \n",
      "2989 [D loss: (-0.736)(R -9.174, F 7.701)]  [G loss: -7.692] \n",
      "2989 [D loss: (-0.884)(R -9.325, F 7.557)]  [G loss: -7.602] \n",
      "2990 [D loss: (-0.695)(R -9.059, F 7.669)]  [G loss: -7.695] \n",
      "2990 [D loss: (-0.767)(R -9.335, F 7.802)]  [G loss: -7.843] \n",
      "2991 [D loss: (-0.944)(R -9.244, F 7.356)]  [G loss: -7.626] \n",
      "2991 [D loss: (-0.865)(R -9.476, F 7.747)]  [G loss: -7.602] \n",
      "2992 [D loss: (-0.735)(R -8.972, F 7.501)]  [G loss: -7.625] \n",
      "2992 [D loss: (-0.869)(R -9.477, F 7.739)]  [G loss: -7.752] \n",
      "2993 [D loss: (-0.968)(R -9.200, F 7.265)]  [G loss: -7.651] \n",
      "2993 [D loss: (-0.554)(R -9.281, F 8.173)]  [G loss: -7.606] \n",
      "2994 [D loss: (-0.858)(R -9.447, F 7.732)]  [G loss: -7.672] \n",
      "2994 [D loss: (-0.906)(R -9.191, F 7.378)]  [G loss: -7.688] \n",
      "2995 [D loss: (-1.025)(R -9.624, F 7.573)]  [G loss: -7.700] \n",
      "2995 [D loss: (-1.027)(R -9.388, F 7.334)]  [G loss: -7.603] \n",
      "2996 [D loss: (-0.758)(R -9.006, F 7.491)]  [G loss: -7.651] \n",
      "2996 [D loss: (-0.874)(R -9.246, F 7.498)]  [G loss: -7.596] \n",
      "2997 [D loss: (-0.637)(R -9.049, F 7.775)]  [G loss: -7.562] \n",
      "2997 [D loss: (-0.760)(R -9.263, F 7.743)]  [G loss: -7.527] \n",
      "2998 [D loss: (-0.777)(R -9.230, F 7.675)]  [G loss: -7.600] \n",
      "2998 [D loss: (-1.046)(R -9.291, F 7.200)]  [G loss: -7.678] \n",
      "2999 [D loss: (-0.939)(R -9.404, F 7.527)]  [G loss: -7.568] \n",
      "2999 [D loss: (-0.879)(R -9.430, F 7.672)]  [G loss: -7.566] \n",
      "3000 [D loss: (-0.905)(R -9.224, F 7.414)]  [G loss: -7.460] \n",
      "3000 [D loss: (-0.678)(R -9.135, F 7.778)]  [G loss: -7.613] \n",
      "3001 [D loss: (-0.687)(R -9.253, F 7.878)]  [G loss: -7.653] \n",
      "3001 [D loss: (-0.803)(R -9.044, F 7.439)]  [G loss: -7.645] \n",
      "3002 [D loss: (-0.862)(R -9.385, F 7.661)]  [G loss: -7.597] \n",
      "3002 [D loss: (-0.803)(R -9.120, F 7.515)]  [G loss: -7.451] \n",
      "3003 [D loss: (-0.578)(R -8.921, F 7.766)]  [G loss: -7.614] \n",
      "3003 [D loss: (-0.719)(R -9.208, F 7.770)]  [G loss: -7.428] \n",
      "3004 [D loss: (-0.805)(R -9.308, F 7.697)]  [G loss: -7.656] \n",
      "3004 [D loss: (-0.784)(R -9.176, F 7.609)]  [G loss: -7.707] \n",
      "3005 [D loss: (-0.901)(R -9.411, F 7.608)]  [G loss: -7.642] \n",
      "3005 [D loss: (-0.716)(R -9.066, F 7.633)]  [G loss: -7.529] \n",
      "3006 [D loss: (-0.786)(R -9.154, F 7.582)]  [G loss: -7.449] \n",
      "3006 [D loss: (-0.689)(R -9.138, F 7.760)]  [G loss: -7.615] \n",
      "3007 [D loss: (-0.952)(R -9.306, F 7.402)]  [G loss: -7.533] \n",
      "3007 [D loss: (-0.890)(R -9.046, F 7.266)]  [G loss: -7.605] \n",
      "3008 [D loss: (-0.972)(R -9.168, F 7.224)]  [G loss: -7.595] \n",
      "3008 [D loss: (-0.598)(R -9.064, F 7.869)]  [G loss: -7.309] \n",
      "3009 [D loss: (-0.606)(R -8.991, F 7.779)]  [G loss: -7.601] \n",
      "3009 [D loss: (-0.775)(R -9.260, F 7.710)]  [G loss: -7.538] \n",
      "3010 [D loss: (-0.843)(R -9.189, F 7.503)]  [G loss: -7.457] \n",
      "3010 [D loss: (-0.832)(R -9.052, F 7.388)]  [G loss: -7.534] \n",
      "3011 [D loss: (-0.995)(R -9.348, F 7.358)]  [G loss: -7.519] \n",
      "3011 [D loss: (-0.911)(R -9.183, F 7.362)]  [G loss: -7.486] \n",
      "3012 [D loss: (-0.793)(R -9.242, F 7.656)]  [G loss: -7.568] \n",
      "3012 [D loss: (-1.010)(R -9.373, F 7.353)]  [G loss: -7.546] \n",
      "3013 [D loss: (-0.709)(R -9.213, F 7.795)]  [G loss: -7.479] \n",
      "3013 [D loss: (-1.018)(R -9.531, F 7.496)]  [G loss: -7.496] \n",
      "3014 [D loss: (-0.859)(R -9.476, F 7.758)]  [G loss: -7.505] \n",
      "3014 [D loss: (-0.918)(R -9.235, F 7.400)]  [G loss: -7.512] \n",
      "3015 [D loss: (-0.706)(R -9.180, F 7.769)]  [G loss: -7.564] \n",
      "3015 [D loss: (-0.965)(R -9.096, F 7.166)]  [G loss: -7.537] \n",
      "3016 [D loss: (-0.940)(R -9.021, F 7.141)]  [G loss: -7.434] \n",
      "3016 [D loss: (-0.944)(R -9.321, F 7.433)]  [G loss: -7.202] \n",
      "3017 [D loss: (-0.700)(R -9.038, F 7.638)]  [G loss: -7.495] \n",
      "3017 [D loss: (-1.040)(R -9.414, F 7.335)]  [G loss: -7.374] \n",
      "3018 [D loss: (-0.714)(R -8.781, F 7.352)]  [G loss: -7.474] \n",
      "3018 [D loss: (-0.988)(R -9.062, F 7.085)]  [G loss: -7.438] \n",
      "3019 [D loss: (-0.713)(R -8.963, F 7.537)]  [G loss: -7.289] \n",
      "3019 [D loss: (-0.825)(R -9.135, F 7.486)]  [G loss: -7.363] \n",
      "3020 [D loss: (-0.752)(R -8.925, F 7.421)]  [G loss: -7.353] \n",
      "3020 [D loss: (-0.993)(R -9.243, F 7.257)]  [G loss: -7.284] \n",
      "3021 [D loss: (-0.799)(R -9.009, F 7.410)]  [G loss: -7.244] \n",
      "3021 [D loss: (-0.747)(R -8.994, F 7.501)]  [G loss: -7.201] \n",
      "3022 [D loss: (-0.612)(R -8.578, F 7.353)]  [G loss: -7.243] \n",
      "3022 [D loss: (-0.778)(R -9.003, F 7.447)]  [G loss: -7.184] \n",
      "3023 [D loss: (-0.902)(R -8.986, F 7.181)]  [G loss: -7.172] \n",
      "3023 [D loss: (-0.818)(R -9.008, F 7.371)]  [G loss: -7.055] \n",
      "3024 [D loss: (-0.785)(R -8.910, F 7.340)]  [G loss: -7.171] \n",
      "3024 [D loss: (-0.657)(R -8.728, F 7.414)]  [G loss: -7.224] \n",
      "3025 [D loss: (-0.745)(R -8.875, F 7.385)]  [G loss: -7.054] \n",
      "3025 [D loss: (-0.840)(R -9.004, F 7.325)]  [G loss: -7.089] \n",
      "3026 [D loss: (-0.748)(R -8.695, F 7.199)]  [G loss: -7.076] \n",
      "3026 [D loss: (-0.718)(R -8.540, F 7.104)]  [G loss: -7.025] \n",
      "3027 [D loss: (-0.608)(R -8.667, F 7.451)]  [G loss: -7.049] \n",
      "3027 [D loss: (-0.734)(R -8.718, F 7.249)]  [G loss: -6.980] \n",
      "3028 [D loss: (-0.647)(R -8.696, F 7.402)]  [G loss: -7.011] \n",
      "3028 [D loss: (-0.827)(R -8.813, F 7.158)]  [G loss: -7.040] \n",
      "3029 [D loss: (-0.843)(R -8.988, F 7.302)]  [G loss: -6.972] \n",
      "3029 [D loss: (-0.718)(R -8.602, F 7.166)]  [G loss: -7.133] \n",
      "3030 [D loss: (-0.898)(R -8.751, F 6.954)]  [G loss: -7.106] \n",
      "3030 [D loss: (-0.748)(R -8.647, F 7.151)]  [G loss: -6.953] \n",
      "3031 [D loss: (-0.961)(R -8.745, F 6.824)]  [G loss: -6.968] \n",
      "3031 [D loss: (-0.772)(R -8.539, F 6.995)]  [G loss: -6.920] \n",
      "3032 [D loss: (-0.929)(R -8.935, F 7.076)]  [G loss: -7.010] \n",
      "3032 [D loss: (-0.702)(R -8.706, F 7.301)]  [G loss: -6.983] \n",
      "3033 [D loss: (-0.640)(R -8.520, F 7.239)]  [G loss: -6.871] \n",
      "3033 [D loss: (-0.892)(R -8.409, F 6.625)]  [G loss: -6.764] \n",
      "3034 [D loss: (-0.808)(R -8.422, F 6.806)]  [G loss: -6.598] \n",
      "3034 [D loss: (-1.023)(R -8.689, F 6.644)]  [G loss: -6.714] \n",
      "3035 [D loss: (-0.872)(R -8.477, F 6.732)]  [G loss: -6.979] \n",
      "3035 [D loss: (-0.814)(R -8.618, F 6.990)]  [G loss: -6.876] \n",
      "3036 [D loss: (-0.687)(R -8.294, F 6.919)]  [G loss: -6.901] \n",
      "3036 [D loss: (-0.824)(R -8.556, F 6.909)]  [G loss: -6.787] \n",
      "3037 [D loss: (-1.002)(R -8.701, F 6.697)]  [G loss: -6.682] \n",
      "3037 [D loss: (-0.905)(R -8.402, F 6.592)]  [G loss: -6.524] \n",
      "3038 [D loss: (-0.898)(R -8.244, F 6.447)]  [G loss: -6.534] \n",
      "3038 [D loss: (-0.795)(R -8.072, F 6.483)]  [G loss: -6.377] \n",
      "3039 [D loss: (-0.882)(R -8.467, F 6.704)]  [G loss: -6.445] \n",
      "3039 [D loss: (-0.852)(R -8.205, F 6.501)]  [G loss: -6.484] \n",
      "3040 [D loss: (-1.043)(R -8.486, F 6.399)]  [G loss: -6.370] \n",
      "3040 [D loss: (-1.168)(R -8.732, F 6.396)]  [G loss: -6.406] \n",
      "3041 [D loss: (-0.966)(R -8.281, F 6.348)]  [G loss: -6.404] \n",
      "3041 [D loss: (-0.833)(R -7.983, F 6.317)]  [G loss: -6.397] \n",
      "3042 [D loss: (-0.931)(R -8.329, F 6.466)]  [G loss: -6.380] \n",
      "3042 [D loss: (-0.904)(R -8.185, F 6.377)]  [G loss: -6.381] \n",
      "3043 [D loss: (-0.837)(R -8.251, F 6.578)]  [G loss: -6.303] \n",
      "3043 [D loss: (-0.864)(R -8.064, F 6.335)]  [G loss: -6.102] \n",
      "3044 [D loss: (-1.045)(R -8.238, F 6.148)]  [G loss: -6.212] \n",
      "3044 [D loss: (-0.698)(R -8.119, F 6.724)]  [G loss: -6.126] \n",
      "3045 [D loss: (-0.796)(R -8.156, F 6.564)]  [G loss: -6.120] \n",
      "3045 [D loss: (-1.057)(R -8.319, F 6.205)]  [G loss: -6.108] \n",
      "3046 [D loss: (-0.926)(R -8.027, F 6.175)]  [G loss: -5.979] \n",
      "3046 [D loss: (-0.994)(R -7.951, F 5.963)]  [G loss: -6.034] \n",
      "3047 [D loss: (-1.200)(R -8.301, F 5.902)]  [G loss: -6.053] \n",
      "3047 [D loss: (-0.935)(R -7.841, F 5.971)]  [G loss: -5.950] \n",
      "3048 [D loss: (-1.115)(R -7.955, F 5.725)]  [G loss: -5.894] \n",
      "3048 [D loss: (-0.908)(R -8.029, F 6.213)]  [G loss: -5.834] \n",
      "3049 [D loss: (-1.055)(R -7.986, F 5.876)]  [G loss: -5.941] \n",
      "3049 [D loss: (-1.105)(R -8.096, F 5.886)]  [G loss: -5.889] \n",
      "3050 [D loss: (-1.043)(R -8.056, F 5.970)]  [G loss: -5.820] \n",
      "3050 [D loss: (-1.116)(R -8.136, F 5.905)]  [G loss: -5.972] \n",
      "3051 [D loss: (-0.971)(R -7.875, F 5.933)]  [G loss: -5.895] \n",
      "3051 [D loss: (-1.049)(R -8.047, F 5.949)]  [G loss: -5.873] \n",
      "3052 [D loss: (-0.907)(R -7.764, F 5.951)]  [G loss: -5.818] \n",
      "3052 [D loss: (-0.890)(R -7.765, F 5.986)]  [G loss: -5.820] \n",
      "3053 [D loss: (-1.216)(R -8.078, F 5.647)]  [G loss: -5.836] \n",
      "3053 [D loss: (-0.947)(R -7.667, F 5.773)]  [G loss: -5.770] \n",
      "3054 [D loss: (-0.893)(R -7.592, F 5.807)]  [G loss: -5.741] \n",
      "3054 [D loss: (-1.107)(R -7.935, F 5.721)]  [G loss: -5.681] \n",
      "3055 [D loss: (-0.976)(R -7.630, F 5.677)]  [G loss: -5.764] \n",
      "3055 [D loss: (-1.058)(R -7.902, F 5.786)]  [G loss: -5.687] \n",
      "3056 [D loss: (-1.049)(R -7.777, F 5.679)]  [G loss: -5.554] \n",
      "3056 [D loss: (-1.145)(R -7.891, F 5.601)]  [G loss: -5.700] \n",
      "3057 [D loss: (-0.862)(R -7.441, F 5.717)]  [G loss: -5.637] \n",
      "3057 [D loss: (-0.953)(R -7.541, F 5.635)]  [G loss: -5.568] \n",
      "3058 [D loss: (-1.085)(R -7.872, F 5.702)]  [G loss: -5.562] \n",
      "3058 [D loss: (-1.074)(R -7.680, F 5.532)]  [G loss: -5.481] \n",
      "3059 [D loss: (-0.944)(R -7.460, F 5.572)]  [G loss: -5.513] \n",
      "3059 [D loss: (-1.127)(R -7.736, F 5.481)]  [G loss: -5.456] \n",
      "3060 [D loss: (-1.141)(R -7.862, F 5.581)]  [G loss: -5.415] \n",
      "3060 [D loss: (-0.973)(R -7.531, F 5.585)]  [G loss: -5.496] \n",
      "3061 [D loss: (-0.942)(R -7.664, F 5.780)]  [G loss: -5.458] \n",
      "3061 [D loss: (-1.073)(R -7.612, F 5.465)]  [G loss: -5.370] \n",
      "3062 [D loss: (-1.154)(R -7.692, F 5.384)]  [G loss: -5.418] \n",
      "3062 [D loss: (-0.967)(R -7.560, F 5.626)]  [G loss: -5.391] \n",
      "3063 [D loss: (-1.200)(R -7.771, F 5.371)]  [G loss: -5.458] \n",
      "3063 [D loss: (-1.181)(R -7.895, F 5.532)]  [G loss: -5.401] \n",
      "3064 [D loss: (-1.187)(R -7.595, F 5.222)]  [G loss: -5.465] \n",
      "3064 [D loss: (-1.156)(R -7.770, F 5.458)]  [G loss: -5.329] \n",
      "3065 [D loss: (-1.056)(R -7.539, F 5.428)]  [G loss: -5.302] \n",
      "3065 [D loss: (-1.151)(R -7.695, F 5.392)]  [G loss: -5.223] \n",
      "3066 [D loss: (-1.172)(R -7.531, F 5.188)]  [G loss: -5.416] \n",
      "3066 [D loss: (-1.013)(R -7.458, F 5.432)]  [G loss: -5.328] \n",
      "3067 [D loss: (-1.093)(R -7.540, F 5.353)]  [G loss: -5.252] \n",
      "3067 [D loss: (-1.077)(R -7.390, F 5.236)]  [G loss: -5.189] \n",
      "3068 [D loss: (-1.129)(R -7.409, F 5.150)]  [G loss: -5.140] \n",
      "3068 [D loss: (-1.153)(R -7.339, F 5.033)]  [G loss: -5.162] \n",
      "3069 [D loss: (-1.138)(R -7.476, F 5.199)]  [G loss: -5.135] \n",
      "3069 [D loss: (-0.966)(R -7.322, F 5.390)]  [G loss: -5.273] \n",
      "3070 [D loss: (-1.126)(R -7.360, F 5.108)]  [G loss: -4.998] \n",
      "3070 [D loss: (-1.045)(R -7.215, F 5.125)]  [G loss: -5.164] \n",
      "3071 [D loss: (-1.097)(R -7.530, F 5.336)]  [G loss: -5.181] \n",
      "3071 [D loss: (-1.360)(R -7.713, F 4.994)]  [G loss: -5.173] \n",
      "3072 [D loss: (-1.108)(R -7.528, F 5.312)]  [G loss: -5.136] \n",
      "3072 [D loss: (-1.160)(R -7.530, F 5.210)]  [G loss: -5.162] \n",
      "3073 [D loss: (-1.052)(R -7.461, F 5.357)]  [G loss: -5.156] \n",
      "3073 [D loss: (-1.208)(R -7.540, F 5.125)]  [G loss: -5.070] \n",
      "3074 [D loss: (-1.379)(R -7.751, F 4.993)]  [G loss: -5.056] \n",
      "3074 [D loss: (-1.230)(R -7.433, F 4.973)]  [G loss: -5.174] \n",
      "3075 [D loss: (-1.199)(R -7.440, F 5.042)]  [G loss: -5.060] \n",
      "3075 [D loss: (-1.219)(R -7.462, F 5.023)]  [G loss: -4.929] \n",
      "3076 [D loss: (-1.255)(R -7.511, F 5.001)]  [G loss: -4.993] \n",
      "3076 [D loss: (-1.139)(R -7.350, F 5.073)]  [G loss: -4.967] \n",
      "3077 [D loss: (-1.233)(R -7.493, F 5.026)]  [G loss: -4.984] \n",
      "3077 [D loss: (-1.078)(R -7.190, F 5.034)]  [G loss: -4.900] \n",
      "3078 [D loss: (-0.873)(R -6.887, F 5.141)]  [G loss: -4.804] \n",
      "3078 [D loss: (-1.136)(R -7.049, F 4.777)]  [G loss: -4.758] \n",
      "3079 [D loss: (-1.252)(R -7.414, F 4.910)]  [G loss: -4.795] \n",
      "3079 [D loss: (-1.299)(R -7.283, F 4.685)]  [G loss: -4.726] \n",
      "3080 [D loss: (-1.237)(R -7.282, F 4.807)]  [G loss: -4.687] \n",
      "3080 [D loss: (-1.264)(R -7.347, F 4.818)]  [G loss: -4.726] \n",
      "3081 [D loss: (-1.165)(R -6.966, F 4.637)]  [G loss: -4.672] \n",
      "3081 [D loss: (-1.262)(R -7.130, F 4.606)]  [G loss: -4.714] \n",
      "3082 [D loss: (-1.335)(R -7.125, F 4.455)]  [G loss: -4.480] \n",
      "3082 [D loss: (-1.316)(R -7.205, F 4.573)]  [G loss: -4.619] \n",
      "3083 [D loss: (-1.200)(R -6.790, F 4.390)]  [G loss: -4.477] \n",
      "3083 [D loss: (-1.296)(R -6.992, F 4.400)]  [G loss: -4.561] \n",
      "3084 [D loss: (-1.101)(R -6.679, F 4.477)]  [G loss: -4.458] \n",
      "3084 [D loss: (-1.247)(R -7.124, F 4.629)]  [G loss: -4.615] \n",
      "3085 [D loss: (-1.152)(R -7.076, F 4.773)]  [G loss: -4.476] \n",
      "3085 [D loss: (-1.278)(R -7.142, F 4.586)]  [G loss: -4.544] \n",
      "3086 [D loss: (-1.452)(R -7.148, F 4.244)]  [G loss: -4.479] \n",
      "3086 [D loss: (-1.331)(R -7.152, F 4.490)]  [G loss: -4.543] \n",
      "3087 [D loss: (-1.219)(R -6.951, F 4.514)]  [G loss: -4.570] \n",
      "3087 [D loss: (-1.095)(R -6.964, F 4.773)]  [G loss: -4.599] \n",
      "3088 [D loss: (-1.393)(R -7.119, F 4.333)]  [G loss: -4.574] \n",
      "3088 [D loss: (-1.249)(R -7.186, F 4.689)]  [G loss: -4.515] \n",
      "3089 [D loss: (-1.239)(R -7.024, F 4.546)]  [G loss: -4.512] \n",
      "3089 [D loss: (-1.511)(R -7.453, F 4.432)]  [G loss: -4.477] \n",
      "3090 [D loss: (-1.331)(R -7.173, F 4.510)]  [G loss: -4.591] \n",
      "3090 [D loss: (-1.339)(R -7.316, F 4.639)]  [G loss: -4.476] \n",
      "3091 [D loss: (-1.495)(R -7.290, F 4.299)]  [G loss: -4.493] \n",
      "3091 [D loss: (-1.425)(R -7.224, F 4.374)]  [G loss: -4.484] \n",
      "3092 [D loss: (-1.201)(R -7.040, F 4.637)]  [G loss: -4.606] \n",
      "3092 [D loss: (-1.386)(R -7.192, F 4.420)]  [G loss: -4.540] \n",
      "3093 [D loss: (-1.286)(R -7.118, F 4.546)]  [G loss: -4.495] \n",
      "3093 [D loss: (-1.368)(R -7.026, F 4.291)]  [G loss: -4.418] \n",
      "3094 [D loss: (-1.337)(R -6.996, F 4.321)]  [G loss: -4.475] \n",
      "3094 [D loss: (-1.456)(R -7.121, F 4.210)]  [G loss: -4.465] \n",
      "3095 [D loss: (-1.415)(R -7.110, F 4.280)]  [G loss: -4.625] \n",
      "3095 [D loss: (-1.369)(R -7.508, F 4.770)]  [G loss: -4.585] \n",
      "3096 [D loss: (-1.285)(R -7.222, F 4.652)]  [G loss: -4.631] \n",
      "3096 [D loss: (-1.357)(R -7.297, F 4.583)]  [G loss: -4.613] \n",
      "3097 [D loss: (-1.273)(R -7.509, F 4.963)]  [G loss: -4.614] \n",
      "3097 [D loss: (-1.398)(R -7.258, F 4.463)]  [G loss: -4.656] \n",
      "3098 [D loss: (-1.419)(R -7.467, F 4.628)]  [G loss: -4.635] \n",
      "3098 [D loss: (-1.326)(R -7.107, F 4.455)]  [G loss: -4.616] \n",
      "3099 [D loss: (-1.219)(R -7.181, F 4.743)]  [G loss: -4.511] \n",
      "3099 [D loss: (-1.092)(R -6.888, F 4.705)]  [G loss: -4.589] \n",
      "3100 [D loss: (-1.402)(R -7.406, F 4.602)]  [G loss: -4.452] \n",
      "3100 [D loss: (-1.400)(R -7.162, F 4.362)]  [G loss: -4.385] \n",
      "3101 [D loss: (-1.157)(R -6.972, F 4.659)]  [G loss: -4.249] \n",
      "3101 [D loss: (-1.399)(R -6.955, F 4.157)]  [G loss: -4.291] \n",
      "3102 [D loss: (-1.317)(R -7.019, F 4.385)]  [G loss: -4.151] \n",
      "3102 [D loss: (-1.372)(R -7.163, F 4.419)]  [G loss: -4.397] \n",
      "3103 [D loss: (-1.373)(R -7.040, F 4.293)]  [G loss: -4.246] \n",
      "3103 [D loss: (-1.297)(R -6.838, F 4.244)]  [G loss: -4.216] \n",
      "3104 [D loss: (-1.486)(R -7.224, F 4.253)]  [G loss: -4.464] \n",
      "3104 [D loss: (-1.457)(R -7.385, F 4.471)]  [G loss: -4.272] \n",
      "3105 [D loss: (-1.246)(R -7.049, F 4.557)]  [G loss: -4.117] \n",
      "3105 [D loss: (-1.512)(R -7.278, F 4.253)]  [G loss: -4.255] \n",
      "3106 [D loss: (-1.315)(R -6.931, F 4.300)]  [G loss: -4.200] \n",
      "3106 [D loss: (-1.486)(R -7.104, F 4.131)]  [G loss: -4.249] \n",
      "3107 [D loss: (-1.433)(R -7.015, F 4.149)]  [G loss: -4.229] \n",
      "3107 [D loss: (-1.280)(R -7.044, F 4.483)]  [G loss: -4.228] \n",
      "3108 [D loss: (-1.437)(R -7.125, F 4.251)]  [G loss: -4.185] \n",
      "3108 [D loss: (-1.244)(R -7.009, F 4.522)]  [G loss: -4.052] \n",
      "3109 [D loss: (-1.440)(R -7.065, F 4.185)]  [G loss: -4.031] \n",
      "3109 [D loss: (-1.431)(R -7.141, F 4.280)]  [G loss: -4.191] \n",
      "3110 [D loss: (-1.451)(R -6.980, F 4.077)]  [G loss: -3.861] \n",
      "3110 [D loss: (-1.271)(R -6.779, F 4.237)]  [G loss: -4.116] \n",
      "3111 [D loss: (-1.433)(R -7.081, F 4.215)]  [G loss: -4.098] \n",
      "3111 [D loss: (-1.394)(R -6.869, F 4.081)]  [G loss: -4.203] \n",
      "3112 [D loss: (-1.629)(R -7.133, F 3.875)]  [G loss: -4.090] \n",
      "3112 [D loss: (-1.488)(R -6.908, F 3.933)]  [G loss: -4.174] \n",
      "3113 [D loss: (-1.383)(R -7.107, F 4.341)]  [G loss: -4.173] \n",
      "3113 [D loss: (-1.499)(R -6.967, F 3.968)]  [G loss: -4.094] \n",
      "3114 [D loss: (-1.427)(R -7.038, F 4.185)]  [G loss: -3.942] \n",
      "3114 [D loss: (-1.569)(R -7.062, F 3.924)]  [G loss: -3.993] \n",
      "3115 [D loss: (-1.541)(R -7.057, F 3.976)]  [G loss: -4.001] \n",
      "3115 [D loss: (-1.422)(R -7.033, F 4.190)]  [G loss: -4.076] \n",
      "3116 [D loss: (-1.692)(R -7.288, F 3.904)]  [G loss: -3.952] \n",
      "3116 [D loss: (-1.339)(R -6.666, F 3.987)]  [G loss: -3.906] \n",
      "3117 [D loss: (-1.574)(R -6.859, F 3.711)]  [G loss: -3.951] \n",
      "3117 [D loss: (-1.641)(R -6.888, F 3.606)]  [G loss: -3.727] \n",
      "3118 [D loss: (-1.272)(R -6.661, F 4.116)]  [G loss: -3.800] \n",
      "3118 [D loss: (-1.533)(R -6.846, F 3.780)]  [G loss: -3.732] \n",
      "3119 [D loss: (-1.637)(R -6.721, F 3.446)]  [G loss: -3.806] \n",
      "3119 [D loss: (-1.461)(R -6.829, F 3.908)]  [G loss: -3.862] \n",
      "3120 [D loss: (-1.545)(R -6.984, F 3.894)]  [G loss: -3.795] \n",
      "3120 [D loss: (-1.542)(R -6.694, F 3.609)]  [G loss: -3.798] \n",
      "3121 [D loss: (-1.273)(R -6.486, F 3.941)]  [G loss: -3.746] \n",
      "3121 [D loss: (-1.349)(R -6.619, F 3.922)]  [G loss: -3.628] \n",
      "3122 [D loss: (-1.564)(R -6.849, F 3.721)]  [G loss: -3.610] \n",
      "3122 [D loss: (-1.547)(R -6.952, F 3.859)]  [G loss: -3.740] \n",
      "3123 [D loss: (-1.511)(R -6.614, F 3.591)]  [G loss: -3.754] \n",
      "3123 [D loss: (-1.501)(R -6.542, F 3.541)]  [G loss: -3.675] \n",
      "3124 [D loss: (-1.547)(R -7.012, F 3.917)]  [G loss: -3.701] \n",
      "3124 [D loss: (-1.475)(R -6.897, F 3.947)]  [G loss: -3.806] \n",
      "3125 [D loss: (-1.384)(R -6.556, F 3.789)]  [G loss: -3.721] \n",
      "3125 [D loss: (-1.465)(R -6.698, F 3.769)]  [G loss: -3.950] \n",
      "3126 [D loss: (-1.702)(R -6.979, F 3.575)]  [G loss: -3.896] \n",
      "3126 [D loss: (-1.456)(R -6.841, F 3.929)]  [G loss: -3.709] \n",
      "3127 [D loss: (-1.384)(R -6.573, F 3.805)]  [G loss: -3.645] \n",
      "3127 [D loss: (-1.514)(R -6.767, F 3.739)]  [G loss: -3.737] \n",
      "3128 [D loss: (-1.653)(R -6.828, F 3.523)]  [G loss: -3.720] \n",
      "3128 [D loss: (-1.585)(R -6.852, F 3.681)]  [G loss: -3.650] \n",
      "3129 [D loss: (-1.499)(R -7.038, F 4.041)]  [G loss: -3.708] \n",
      "3129 [D loss: (-1.720)(R -6.811, F 3.370)]  [G loss: -3.698] \n",
      "3130 [D loss: (-1.388)(R -6.491, F 3.714)]  [G loss: -3.743] \n",
      "3130 [D loss: (-1.441)(R -6.548, F 3.666)]  [G loss: -3.600] \n",
      "3131 [D loss: (-1.458)(R -6.678, F 3.762)]  [G loss: -3.727] \n",
      "3131 [D loss: (-1.650)(R -6.989, F 3.689)]  [G loss: -3.728] \n",
      "3132 [D loss: (-1.436)(R -6.833, F 3.962)]  [G loss: -3.541] \n",
      "3132 [D loss: (-1.756)(R -6.926, F 3.413)]  [G loss: -3.560] \n",
      "3133 [D loss: (-1.455)(R -6.558, F 3.647)]  [G loss: -3.532] \n",
      "3133 [D loss: (-1.714)(R -6.678, F 3.250)]  [G loss: -3.696] \n",
      "3134 [D loss: (-1.666)(R -6.876, F 3.544)]  [G loss: -3.551] \n",
      "3134 [D loss: (-1.527)(R -6.649, F 3.595)]  [G loss: -3.629] \n",
      "3135 [D loss: (-1.659)(R -6.902, F 3.583)]  [G loss: -3.629] \n",
      "3135 [D loss: (-1.707)(R -6.960, F 3.546)]  [G loss: -3.558] \n",
      "3136 [D loss: (-1.454)(R -6.629, F 3.721)]  [G loss: -3.748] \n",
      "3136 [D loss: (-1.547)(R -6.970, F 3.876)]  [G loss: -3.664] \n",
      "3137 [D loss: (-1.364)(R -6.423, F 3.695)]  [G loss: -3.651] \n",
      "3137 [D loss: (-1.769)(R -6.785, F 3.248)]  [G loss: -3.381] \n",
      "3138 [D loss: (-1.569)(R -6.757, F 3.619)]  [G loss: -3.417] \n",
      "3138 [D loss: (-1.560)(R -6.667, F 3.546)]  [G loss: -3.565] \n",
      "3139 [D loss: (-1.627)(R -6.711, F 3.456)]  [G loss: -3.629] \n",
      "3139 [D loss: (-1.616)(R -6.853, F 3.622)]  [G loss: -3.564] \n",
      "3140 [D loss: (-1.558)(R -6.661, F 3.546)]  [G loss: -3.544] \n",
      "3140 [D loss: (-1.262)(R -6.310, F 3.786)]  [G loss: -3.489] \n",
      "3141 [D loss: (-1.538)(R -6.551, F 3.475)]  [G loss: -3.549] \n",
      "3141 [D loss: (-1.663)(R -6.772, F 3.447)]  [G loss: -3.461] \n",
      "3142 [D loss: (-1.694)(R -6.653, F 3.265)]  [G loss: -3.505] \n",
      "3142 [D loss: (-1.523)(R -6.493, F 3.448)]  [G loss: -3.637] \n",
      "3143 [D loss: (-1.566)(R -6.807, F 3.676)]  [G loss: -3.509] \n",
      "3143 [D loss: (-1.479)(R -6.708, F 3.751)]  [G loss: -3.374] \n",
      "3144 [D loss: (-1.721)(R -6.842, F 3.399)]  [G loss: -3.533] \n",
      "3144 [D loss: (-1.490)(R -6.432, F 3.452)]  [G loss: -3.369] \n",
      "3145 [D loss: (-1.515)(R -6.504, F 3.473)]  [G loss: -3.545] \n",
      "3145 [D loss: (-1.502)(R -6.473, F 3.468)]  [G loss: -3.577] \n",
      "3146 [D loss: (-1.638)(R -6.679, F 3.404)]  [G loss: -3.586] \n",
      "3146 [D loss: (-1.677)(R -6.766, F 3.411)]  [G loss: -3.495] \n",
      "3147 [D loss: (-1.470)(R -6.502, F 3.562)]  [G loss: -3.425] \n",
      "3147 [D loss: (-1.393)(R -6.417, F 3.632)]  [G loss: -3.593] \n",
      "3148 [D loss: (-1.304)(R -6.509, F 3.900)]  [G loss: -3.446] \n",
      "3148 [D loss: (-1.445)(R -6.640, F 3.751)]  [G loss: -3.336] \n",
      "3149 [D loss: (-1.320)(R -6.218, F 3.579)]  [G loss: -3.264] \n",
      "3149 [D loss: (-1.580)(R -6.552, F 3.393)]  [G loss: -3.372] \n",
      "3150 [D loss: (-1.607)(R -6.495, F 3.282)]  [G loss: -3.449] \n",
      "3150 [D loss: (-1.746)(R -6.882, F 3.390)]  [G loss: -3.480] \n",
      "3151 [D loss: (-1.559)(R -6.466, F 3.347)]  [G loss: -3.493] \n",
      "3151 [D loss: (-1.496)(R -6.733, F 3.741)]  [G loss: -3.330] \n",
      "3152 [D loss: (-1.560)(R -6.318, F 3.198)]  [G loss: -3.361] \n",
      "3152 [D loss: (-1.452)(R -6.301, F 3.397)]  [G loss: -3.369] \n",
      "3153 [D loss: (-1.466)(R -6.267, F 3.334)]  [G loss: -3.327] \n",
      "3153 [D loss: (-1.586)(R -6.497, F 3.325)]  [G loss: -3.255] \n",
      "3154 [D loss: (-1.730)(R -6.742, F 3.282)]  [G loss: -3.309] \n",
      "3154 [D loss: (-1.443)(R -6.319, F 3.433)]  [G loss: -3.268] \n",
      "3155 [D loss: (-1.436)(R -6.512, F 3.640)]  [G loss: -3.353] \n",
      "3155 [D loss: (-1.315)(R -6.309, F 3.679)]  [G loss: -3.414] \n",
      "3156 [D loss: (-1.269)(R -6.179, F 3.642)]  [G loss: -3.472] \n",
      "3156 [D loss: (-1.518)(R -6.317, F 3.280)]  [G loss: -3.248] \n",
      "3157 [D loss: (-1.388)(R -6.363, F 3.587)]  [G loss: -3.301] \n",
      "3157 [D loss: (-1.479)(R -6.121, F 3.164)]  [G loss: -3.239] \n",
      "3158 [D loss: (-1.456)(R -6.110, F 3.199)]  [G loss: -3.077] \n",
      "3158 [D loss: (-1.569)(R -6.522, F 3.385)]  [G loss: -3.326] \n",
      "3159 [D loss: (-1.480)(R -6.364, F 3.404)]  [G loss: -3.249] \n",
      "3159 [D loss: (-1.359)(R -6.207, F 3.490)]  [G loss: -3.144] \n",
      "3160 [D loss: (-1.340)(R -6.150, F 3.471)]  [G loss: -3.247] \n",
      "3160 [D loss: (-1.609)(R -6.401, F 3.183)]  [G loss: -2.960] \n",
      "3161 [D loss: (-1.475)(R -6.206, F 3.257)]  [G loss: -3.116] \n",
      "3161 [D loss: (-1.487)(R -6.228, F 3.254)]  [G loss: -3.168] \n",
      "3162 [D loss: (-1.531)(R -6.293, F 3.230)]  [G loss: -3.082] \n",
      "3162 [D loss: (-1.648)(R -6.409, F 3.113)]  [G loss: -3.167] \n",
      "3163 [D loss: (-1.354)(R -5.990, F 3.282)]  [G loss: -3.263] \n",
      "3163 [D loss: (-1.500)(R -6.205, F 3.204)]  [G loss: -3.276] \n",
      "3164 [D loss: (-1.755)(R -6.335, F 2.825)]  [G loss: -3.208] \n",
      "3164 [D loss: (-1.400)(R -6.220, F 3.419)]  [G loss: -3.332] \n",
      "3165 [D loss: (-1.383)(R -5.955, F 3.190)]  [G loss: -3.177] \n",
      "3165 [D loss: (-1.570)(R -6.331, F 3.192)]  [G loss: -3.297] \n",
      "3166 [D loss: (-1.588)(R -6.226, F 3.050)]  [G loss: -3.206] \n",
      "3166 [D loss: (-1.595)(R -6.589, F 3.400)]  [G loss: -3.129] \n",
      "3167 [D loss: (-1.487)(R -6.314, F 3.340)]  [G loss: -3.137] \n",
      "3167 [D loss: (-1.399)(R -5.981, F 3.182)]  [G loss: -3.131] \n",
      "3168 [D loss: (-1.539)(R -6.442, F 3.363)]  [G loss: -3.290] \n",
      "3168 [D loss: (-1.672)(R -6.197, F 2.853)]  [G loss: -3.155] \n",
      "3169 [D loss: (-1.704)(R -6.411, F 3.002)]  [G loss: -3.175] \n",
      "3169 [D loss: (-1.649)(R -6.388, F 3.089)]  [G loss: -3.177] \n",
      "3170 [D loss: (-1.677)(R -6.738, F 3.384)]  [G loss: -3.387] \n",
      "3170 [D loss: (-1.634)(R -6.383, F 3.115)]  [G loss: -3.222] \n",
      "3171 [D loss: (-1.524)(R -6.203, F 3.154)]  [G loss: -3.121] \n",
      "3171 [D loss: (-1.837)(R -6.453, F 2.779)]  [G loss: -3.296] \n",
      "3172 [D loss: (-1.628)(R -6.530, F 3.275)]  [G loss: -3.295] \n",
      "3172 [D loss: (-1.671)(R -6.648, F 3.306)]  [G loss: -3.367] \n",
      "3173 [D loss: (-1.414)(R -6.260, F 3.431)]  [G loss: -3.139] \n",
      "3173 [D loss: (-1.575)(R -6.315, F 3.166)]  [G loss: -3.172] \n",
      "3174 [D loss: (-1.354)(R -6.486, F 3.778)]  [G loss: -3.250] \n",
      "3174 [D loss: (-1.432)(R -6.113, F 3.249)]  [G loss: -3.220] \n",
      "3175 [D loss: (-1.467)(R -6.255, F 3.321)]  [G loss: -3.148] \n",
      "3175 [D loss: (-1.490)(R -6.145, F 3.164)]  [G loss: -3.258] \n",
      "3176 [D loss: (-1.690)(R -6.164, F 2.784)]  [G loss: -3.244] \n",
      "3176 [D loss: (-1.687)(R -6.282, F 2.908)]  [G loss: -3.124] \n",
      "3177 [D loss: (-1.385)(R -6.112, F 3.342)]  [G loss: -3.251] \n",
      "3177 [D loss: (-1.332)(R -6.084, F 3.421)]  [G loss: -3.082] \n",
      "3178 [D loss: (-1.669)(R -6.328, F 2.989)]  [G loss: -3.071] \n",
      "3178 [D loss: (-1.556)(R -6.287, F 3.175)]  [G loss: -3.149] \n",
      "3179 [D loss: (-1.604)(R -6.371, F 3.162)]  [G loss: -3.273] \n",
      "3179 [D loss: (-1.616)(R -6.583, F 3.352)]  [G loss: -3.261] \n",
      "3180 [D loss: (-1.464)(R -5.900, F 2.973)]  [G loss: -3.245] \n",
      "3180 [D loss: (-1.513)(R -6.389, F 3.363)]  [G loss: -3.266] \n",
      "3181 [D loss: (-1.450)(R -6.064, F 3.164)]  [G loss: -3.404] \n",
      "3181 [D loss: (-1.619)(R -6.345, F 3.107)]  [G loss: -3.315] \n",
      "3182 [D loss: (-1.753)(R -6.674, F 3.168)]  [G loss: -3.308] \n",
      "3182 [D loss: (-1.385)(R -6.407, F 3.637)]  [G loss: -3.441] \n",
      "3183 [D loss: (-1.705)(R -6.441, F 3.032)]  [G loss: -3.314] \n",
      "3183 [D loss: (-1.377)(R -6.295, F 3.541)]  [G loss: -3.292] \n",
      "3184 [D loss: (-1.461)(R -6.232, F 3.310)]  [G loss: -3.264] \n",
      "3184 [D loss: (-1.386)(R -6.076, F 3.304)]  [G loss: -3.337] \n",
      "3185 [D loss: (-1.684)(R -6.452, F 3.084)]  [G loss: -3.325] \n",
      "3185 [D loss: (-1.341)(R -5.852, F 3.170)]  [G loss: -3.283] \n",
      "3186 [D loss: (-1.463)(R -6.087, F 3.162)]  [G loss: -3.110] \n",
      "3186 [D loss: (-1.457)(R -6.323, F 3.409)]  [G loss: -3.167] \n",
      "3187 [D loss: (-1.499)(R -6.157, F 3.158)]  [G loss: -3.003] \n",
      "3187 [D loss: (-1.424)(R -5.790, F 2.942)]  [G loss: -3.036] \n",
      "3188 [D loss: (-1.510)(R -5.928, F 2.907)]  [G loss: -3.106] \n",
      "3188 [D loss: (-1.558)(R -6.098, F 2.981)]  [G loss: -2.911] \n",
      "3189 [D loss: (-1.639)(R -6.266, F 2.988)]  [G loss: -3.063] \n",
      "3189 [D loss: (-1.658)(R -6.455, F 3.138)]  [G loss: -2.981] \n",
      "3190 [D loss: (-1.233)(R -5.859, F 3.393)]  [G loss: -2.991] \n",
      "3190 [D loss: (-1.387)(R -5.881, F 3.107)]  [G loss: -2.895] \n",
      "3191 [D loss: (-1.454)(R -5.807, F 2.900)]  [G loss: -3.134] \n",
      "3191 [D loss: (-1.644)(R -6.164, F 2.876)]  [G loss: -3.023] \n",
      "3192 [D loss: (-1.310)(R -5.883, F 3.264)]  [G loss: -3.000] \n",
      "3192 [D loss: (-1.620)(R -6.018, F 2.778)]  [G loss: -2.933] \n",
      "3193 [D loss: (-1.573)(R -6.049, F 2.904)]  [G loss: -3.017] \n",
      "3193 [D loss: (-1.575)(R -6.024, F 2.874)]  [G loss: -2.933] \n",
      "3194 [D loss: (-1.542)(R -5.876, F 2.792)]  [G loss: -3.001] \n",
      "3194 [D loss: (-1.358)(R -5.789, F 3.073)]  [G loss: -3.075] \n",
      "3195 [D loss: (-1.578)(R -6.097, F 2.942)]  [G loss: -3.012] \n",
      "3195 [D loss: (-1.171)(R -5.665, F 3.323)]  [G loss: -3.088] \n",
      "3196 [D loss: (-1.378)(R -6.116, F 3.360)]  [G loss: -3.131] \n",
      "3196 [D loss: (-1.571)(R -5.996, F 2.855)]  [G loss: -3.093] \n",
      "3197 [D loss: (-1.216)(R -5.695, F 3.262)]  [G loss: -2.980] \n",
      "3197 [D loss: (-1.623)(R -6.108, F 2.861)]  [G loss: -2.983] \n",
      "3198 [D loss: (-1.447)(R -6.196, F 3.301)]  [G loss: -2.934] \n",
      "3198 [D loss: (-1.406)(R -6.011, F 3.200)]  [G loss: -3.026] \n",
      "3199 [D loss: (-1.309)(R -5.682, F 3.064)]  [G loss: -2.960] \n",
      "3199 [D loss: (-1.571)(R -5.907, F 2.765)]  [G loss: -2.937] \n",
      "3200 [D loss: (-1.649)(R -6.045, F 2.746)]  [G loss: -2.835] \n",
      "3200 [D loss: (-1.271)(R -5.570, F 3.028)]  [G loss: -2.914] \n",
      "3201 [D loss: (-1.063)(R -5.595, F 3.470)]  [G loss: -2.941] \n",
      "3201 [D loss: (-1.281)(R -5.761, F 3.200)]  [G loss: -2.889] \n",
      "3202 [D loss: (-1.470)(R -5.853, F 2.914)]  [G loss: -2.961] \n",
      "3202 [D loss: (-1.344)(R -5.590, F 2.901)]  [G loss: -3.027] \n",
      "3203 [D loss: (-1.341)(R -6.028, F 3.346)]  [G loss: -2.928] \n",
      "3203 [D loss: (-1.480)(R -5.648, F 2.689)]  [G loss: -2.908] \n",
      "3204 [D loss: (-1.327)(R -5.600, F 2.947)]  [G loss: -2.831] \n",
      "3204 [D loss: (-1.418)(R -5.588, F 2.751)]  [G loss: -2.953] \n",
      "3205 [D loss: (-1.374)(R -6.009, F 3.261)]  [G loss: -3.047] \n",
      "3205 [D loss: (-1.519)(R -5.995, F 2.956)]  [G loss: -2.880] \n",
      "3206 [D loss: (-1.430)(R -5.650, F 2.789)]  [G loss: -3.111] \n",
      "3206 [D loss: (-1.463)(R -6.095, F 3.170)]  [G loss: -3.129] \n",
      "3207 [D loss: (-1.122)(R -5.706, F 3.462)]  [G loss: -2.949] \n",
      "3207 [D loss: (-1.501)(R -5.623, F 2.621)]  [G loss: -2.881] \n",
      "3208 [D loss: (-1.428)(R -5.686, F 2.830)]  [G loss: -2.898] \n",
      "3208 [D loss: (-1.302)(R -5.621, F 3.017)]  [G loss: -2.857] \n",
      "3209 [D loss: (-1.526)(R -5.947, F 2.894)]  [G loss: -2.873] \n",
      "3209 [D loss: (-1.439)(R -5.679, F 2.801)]  [G loss: -2.847] \n",
      "3210 [D loss: (-1.213)(R -5.366, F 2.940)]  [G loss: -2.951] \n",
      "3210 [D loss: (-1.235)(R -5.902, F 3.432)]  [G loss: -2.901] \n",
      "3211 [D loss: (-1.565)(R -5.707, F 2.577)]  [G loss: -3.019] \n",
      "3211 [D loss: (-1.084)(R -5.682, F 3.514)]  [G loss: -2.968] \n",
      "3212 [D loss: (-1.444)(R -5.881, F 2.992)]  [G loss: -2.959] \n",
      "3212 [D loss: (-1.551)(R -5.732, F 2.629)]  [G loss: -2.835] \n",
      "3213 [D loss: (-1.311)(R -5.613, F 2.992)]  [G loss: -2.718] \n",
      "3213 [D loss: (-1.228)(R -5.602, F 3.146)]  [G loss: -2.901] \n",
      "3214 [D loss: (-1.492)(R -5.913, F 2.928)]  [G loss: -2.788] \n",
      "3214 [D loss: (-1.397)(R -5.784, F 2.990)]  [G loss: -2.802] \n",
      "3215 [D loss: (-1.302)(R -5.366, F 2.763)]  [G loss: -2.728] \n",
      "3215 [D loss: (-1.203)(R -5.268, F 2.863)]  [G loss: -2.702] \n",
      "3216 [D loss: (-1.370)(R -5.586, F 2.846)]  [G loss: -2.723] \n",
      "3216 [D loss: (-1.416)(R -5.424, F 2.591)]  [G loss: -2.543] \n",
      "3217 [D loss: (-1.448)(R -5.557, F 2.662)]  [G loss: -2.671] \n",
      "3217 [D loss: (-1.023)(R -5.339, F 3.293)]  [G loss: -2.664] \n",
      "3218 [D loss: (-1.411)(R -5.503, F 2.681)]  [G loss: -2.495] \n",
      "3218 [D loss: (-1.558)(R -5.613, F 2.497)]  [G loss: -2.534] \n",
      "3219 [D loss: (-1.588)(R -5.704, F 2.529)]  [G loss: -2.562] \n",
      "3219 [D loss: (-1.523)(R -5.592, F 2.547)]  [G loss: -2.774] \n",
      "3220 [D loss: (-1.405)(R -5.380, F 2.571)]  [G loss: -2.684] \n",
      "3220 [D loss: (-1.152)(R -5.616, F 3.312)]  [G loss: -2.824] \n",
      "3221 [D loss: (-1.252)(R -5.566, F 3.063)]  [G loss: -2.884] \n",
      "3221 [D loss: (-1.416)(R -5.639, F 2.808)]  [G loss: -2.794] \n",
      "3222 [D loss: (-1.402)(R -5.612, F 2.809)]  [G loss: -2.864] \n",
      "3222 [D loss: (-1.392)(R -5.680, F 2.896)]  [G loss: -3.006] \n",
      "3223 [D loss: (-1.409)(R -5.555, F 2.737)]  [G loss: -2.861] \n",
      "3223 [D loss: (-1.291)(R -5.405, F 2.823)]  [G loss: -2.766] \n",
      "3224 [D loss: (-1.333)(R -5.626, F 2.960)]  [G loss: -2.910] \n",
      "3224 [D loss: (-1.313)(R -5.784, F 3.158)]  [G loss: -2.819] \n",
      "3225 [D loss: (-1.500)(R -5.670, F 2.671)]  [G loss: -2.829] \n",
      "3225 [D loss: (-1.141)(R -5.436, F 3.155)]  [G loss: -2.794] \n",
      "3226 [D loss: (-1.326)(R -5.595, F 2.943)]  [G loss: -2.881] \n",
      "3226 [D loss: (-1.485)(R -5.625, F 2.656)]  [G loss: -2.810] \n",
      "3227 [D loss: (-1.516)(R -5.510, F 2.478)]  [G loss: -2.939] \n",
      "3227 [D loss: (-1.292)(R -5.864, F 3.280)]  [G loss: -2.852] \n",
      "3228 [D loss: (-1.260)(R -5.593, F 3.074)]  [G loss: -2.939] \n",
      "3228 [D loss: (-1.520)(R -6.012, F 2.973)]  [G loss: -2.873] \n",
      "3229 [D loss: (-1.360)(R -5.715, F 2.994)]  [G loss: -2.928] \n",
      "3229 [D loss: (-1.162)(R -5.746, F 3.423)]  [G loss: -2.916] \n",
      "3230 [D loss: (-1.402)(R -5.906, F 3.102)]  [G loss: -3.000] \n",
      "3230 [D loss: (-1.489)(R -5.802, F 2.823)]  [G loss: -3.106] \n",
      "3231 [D loss: (-1.238)(R -5.613, F 3.137)]  [G loss: -2.987] \n",
      "3231 [D loss: (-1.245)(R -5.628, F 3.138)]  [G loss: -3.038] \n",
      "3232 [D loss: (-1.249)(R -5.595, F 3.097)]  [G loss: -3.035] \n",
      "3232 [D loss: (-1.364)(R -5.790, F 3.062)]  [G loss: -3.009] \n",
      "3233 [D loss: (-1.422)(R -5.807, F 2.963)]  [G loss: -3.020] \n",
      "3233 [D loss: (-1.358)(R -5.643, F 2.926)]  [G loss: -2.828] \n",
      "3234 [D loss: (-1.426)(R -5.480, F 2.628)]  [G loss: -2.980] \n",
      "3234 [D loss: (-1.254)(R -5.607, F 3.098)]  [G loss: -2.916] \n",
      "3235 [D loss: (-1.217)(R -5.620, F 3.187)]  [G loss: -2.887] \n",
      "3235 [D loss: (-1.272)(R -5.765, F 3.221)]  [G loss: -2.937] \n",
      "3236 [D loss: (-1.274)(R -5.600, F 3.052)]  [G loss: -2.901] \n",
      "3236 [D loss: (-1.536)(R -5.739, F 2.667)]  [G loss: -2.898] \n",
      "3237 [D loss: (-1.384)(R -5.682, F 2.915)]  [G loss: -2.839] \n",
      "3237 [D loss: (-1.174)(R -5.551, F 3.202)]  [G loss: -2.834] \n",
      "3238 [D loss: (-1.329)(R -5.382, F 2.724)]  [G loss: -2.714] \n",
      "3238 [D loss: (-1.198)(R -5.546, F 3.151)]  [G loss: -2.750] \n",
      "3239 [D loss: (-1.218)(R -5.443, F 3.008)]  [G loss: -2.853] \n",
      "3239 [D loss: (-1.227)(R -5.491, F 3.037)]  [G loss: -2.757] \n",
      "3240 [D loss: (-1.660)(R -5.709, F 2.389)]  [G loss: -2.786] \n",
      "3240 [D loss: (-1.238)(R -5.312, F 2.837)]  [G loss: -2.872] \n",
      "3241 [D loss: (-1.074)(R -5.429, F 3.282)]  [G loss: -2.812] \n",
      "3241 [D loss: (-1.276)(R -5.572, F 3.021)]  [G loss: -2.892] \n",
      "3242 [D loss: (-1.415)(R -5.681, F 2.851)]  [G loss: -2.825] \n",
      "3242 [D loss: (-1.274)(R -5.712, F 3.165)]  [G loss: -2.832] \n",
      "3243 [D loss: (-1.551)(R -5.711, F 2.610)]  [G loss: -2.834] \n",
      "3243 [D loss: (-1.575)(R -5.872, F 2.723)]  [G loss: -2.866] \n",
      "3244 [D loss: (-1.642)(R -6.084, F 2.800)]  [G loss: -3.013] \n",
      "3244 [D loss: (-1.154)(R -5.674, F 3.367)]  [G loss: -3.160] \n",
      "3245 [D loss: (-1.218)(R -5.641, F 3.206)]  [G loss: -2.826] \n",
      "3245 [D loss: (-1.473)(R -5.817, F 2.871)]  [G loss: -3.073] \n",
      "3246 [D loss: (-1.417)(R -5.762, F 2.929)]  [G loss: -3.077] \n",
      "3246 [D loss: (-1.374)(R -5.832, F 3.084)]  [G loss: -3.044] \n",
      "3247 [D loss: (-1.420)(R -6.035, F 3.194)]  [G loss: -3.085] \n",
      "3247 [D loss: (-1.381)(R -5.862, F 3.099)]  [G loss: -3.154] \n",
      "3248 [D loss: (-1.599)(R -5.742, F 2.544)]  [G loss: -3.031] \n",
      "3248 [D loss: (-1.266)(R -5.682, F 3.149)]  [G loss: -3.173] \n",
      "3249 [D loss: (-1.561)(R -5.768, F 2.645)]  [G loss: -3.082] \n",
      "3249 [D loss: (-1.332)(R -5.670, F 3.005)]  [G loss: -3.160] \n",
      "3250 [D loss: (-1.362)(R -5.997, F 3.274)]  [G loss: -3.338] \n",
      "3250 [D loss: (-1.104)(R -5.613, F 3.405)]  [G loss: -2.987] \n",
      "3251 [D loss: (-1.418)(R -5.692, F 2.856)]  [G loss: -3.142] \n",
      "3251 [D loss: (-1.393)(R -5.938, F 3.153)]  [G loss: -3.120] \n",
      "3252 [D loss: (-1.170)(R -5.507, F 3.166)]  [G loss: -3.230] \n",
      "3252 [D loss: (-1.494)(R -5.825, F 2.837)]  [G loss: -2.972] \n",
      "3253 [D loss: (-1.085)(R -5.546, F 3.377)]  [G loss: -3.158] \n",
      "3253 [D loss: (-1.262)(R -5.739, F 3.215)]  [G loss: -2.948] \n",
      "3254 [D loss: (-1.241)(R -5.691, F 3.208)]  [G loss: -3.001] \n",
      "3254 [D loss: (-1.393)(R -5.549, F 2.764)]  [G loss: -2.983] \n",
      "3255 [D loss: (-1.118)(R -5.476, F 3.240)]  [G loss: -3.077] \n",
      "3255 [D loss: (-1.222)(R -5.807, F 3.364)]  [G loss: -2.981] \n",
      "3256 [D loss: (-1.209)(R -5.503, F 3.085)]  [G loss: -3.031] \n",
      "3256 [D loss: (-1.267)(R -5.772, F 3.238)]  [G loss: -2.930] \n",
      "3257 [D loss: (-0.997)(R -5.250, F 3.257)]  [G loss: -2.917] \n",
      "3257 [D loss: (-1.190)(R -5.151, F 2.770)]  [G loss: -2.844] \n",
      "3258 [D loss: (-1.263)(R -5.465, F 2.939)]  [G loss: -2.895] \n",
      "3258 [D loss: (-1.203)(R -5.364, F 2.958)]  [G loss: -2.732] \n",
      "3259 [D loss: (-1.195)(R -5.414, F 3.025)]  [G loss: -2.819] \n",
      "3259 [D loss: (-1.202)(R -5.496, F 3.093)]  [G loss: -2.693] \n",
      "3260 [D loss: (-1.162)(R -5.265, F 2.941)]  [G loss: -2.724] \n",
      "3260 [D loss: (-1.405)(R -5.466, F 2.657)]  [G loss: -2.686] \n",
      "3261 [D loss: (-1.272)(R -5.339, F 2.794)]  [G loss: -2.747] \n",
      "3261 [D loss: (-1.190)(R -5.289, F 2.908)]  [G loss: -2.699] \n",
      "3262 [D loss: (-1.454)(R -5.290, F 2.381)]  [G loss: -2.789] \n",
      "3262 [D loss: (-1.219)(R -5.051, F 2.613)]  [G loss: -2.841] \n",
      "3263 [D loss: (-1.292)(R -5.199, F 2.616)]  [G loss: -2.706] \n",
      "3263 [D loss: (-1.369)(R -5.355, F 2.617)]  [G loss: -2.801] \n",
      "3264 [D loss: (-1.482)(R -5.452, F 2.487)]  [G loss: -2.856] \n",
      "3264 [D loss: (-1.124)(R -5.205, F 2.957)]  [G loss: -2.772] \n",
      "3265 [D loss: (-1.301)(R -5.643, F 3.042)]  [G loss: -3.062] \n",
      "3265 [D loss: (-1.392)(R -5.500, F 2.717)]  [G loss: -2.976] \n",
      "3266 [D loss: (-1.305)(R -5.396, F 2.785)]  [G loss: -2.964] \n",
      "3266 [D loss: (-1.401)(R -5.716, F 2.914)]  [G loss: -2.861] \n",
      "3267 [D loss: (-1.177)(R -5.683, F 3.328)]  [G loss: -2.830] \n",
      "3267 [D loss: (-0.828)(R -5.099, F 3.442)]  [G loss: -3.005] \n",
      "3268 [D loss: (-1.468)(R -5.496, F 2.559)]  [G loss: -3.040] \n",
      "3268 [D loss: (-1.130)(R -5.734, F 3.474)]  [G loss: -3.127] \n",
      "3269 [D loss: (-1.268)(R -5.540, F 3.004)]  [G loss: -3.013] \n",
      "3269 [D loss: (-0.983)(R -5.230, F 3.265)]  [G loss: -3.006] \n",
      "3270 [D loss: (-1.134)(R -5.316, F 3.049)]  [G loss: -2.976] \n",
      "3270 [D loss: (-1.167)(R -5.419, F 3.084)]  [G loss: -2.948] \n",
      "3271 [D loss: (-1.263)(R -5.408, F 2.882)]  [G loss: -2.977] \n",
      "3271 [D loss: (-1.443)(R -5.835, F 2.948)]  [G loss: -2.931] \n",
      "3272 [D loss: (-1.257)(R -5.261, F 2.746)]  [G loss: -2.942] \n",
      "3272 [D loss: (-1.357)(R -5.388, F 2.674)]  [G loss: -2.901] \n",
      "3273 [D loss: (-1.136)(R -5.215, F 2.943)]  [G loss: -2.872] \n",
      "3273 [D loss: (-1.497)(R -5.662, F 2.668)]  [G loss: -2.987] \n",
      "3274 [D loss: (-1.425)(R -5.570, F 2.720)]  [G loss: -2.858] \n",
      "3274 [D loss: (-1.323)(R -5.355, F 2.710)]  [G loss: -2.954] \n",
      "3275 [D loss: (-0.951)(R -5.262, F 3.361)]  [G loss: -3.030] \n",
      "3275 [D loss: (-1.080)(R -5.302, F 3.141)]  [G loss: -2.842] \n",
      "3276 [D loss: (-1.242)(R -5.370, F 2.887)]  [G loss: -2.886] \n",
      "3276 [D loss: (-0.999)(R -5.233, F 3.234)]  [G loss: -2.828] \n",
      "3277 [D loss: (-1.376)(R -5.403, F 2.652)]  [G loss: -3.021] \n",
      "3277 [D loss: (-1.390)(R -5.328, F 2.547)]  [G loss: -2.977] \n",
      "3278 [D loss: (-1.359)(R -5.604, F 2.886)]  [G loss: -2.743] \n",
      "3278 [D loss: (-1.331)(R -5.313, F 2.651)]  [G loss: -3.028] \n",
      "3279 [D loss: (-1.451)(R -5.499, F 2.596)]  [G loss: -2.954] \n",
      "3279 [D loss: (-1.267)(R -5.461, F 2.927)]  [G loss: -3.095] \n",
      "3280 [D loss: (-1.234)(R -5.632, F 3.164)]  [G loss: -3.199] \n",
      "3280 [D loss: (-1.160)(R -5.245, F 2.926)]  [G loss: -3.038] \n",
      "3281 [D loss: (-1.022)(R -5.556, F 3.513)]  [G loss: -3.013] \n",
      "3281 [D loss: (-1.229)(R -5.429, F 2.972)]  [G loss: -3.042] \n",
      "3282 [D loss: (-1.185)(R -5.357, F 2.986)]  [G loss: -3.002] \n",
      "3282 [D loss: (-1.115)(R -5.400, F 3.169)]  [G loss: -2.886] \n",
      "3283 [D loss: (-1.164)(R -5.165, F 2.837)]  [G loss: -3.154] \n",
      "3283 [D loss: (-1.203)(R -5.594, F 3.189)]  [G loss: -2.870] \n",
      "3284 [D loss: (-1.281)(R -5.407, F 2.845)]  [G loss: -2.921] \n",
      "3284 [D loss: (-1.125)(R -5.370, F 3.120)]  [G loss: -2.993] \n",
      "3285 [D loss: (-1.069)(R -5.253, F 3.114)]  [G loss: -2.902] \n",
      "3285 [D loss: (-0.942)(R -5.154, F 3.270)]  [G loss: -3.091] \n",
      "3286 [D loss: (-1.103)(R -5.104, F 2.899)]  [G loss: -3.104] \n",
      "3286 [D loss: (-1.210)(R -5.334, F 2.914)]  [G loss: -2.956] \n",
      "3287 [D loss: (-0.989)(R -5.400, F 3.423)]  [G loss: -2.859] \n",
      "3287 [D loss: (-1.074)(R -5.349, F 3.201)]  [G loss: -2.872] \n",
      "3288 [D loss: (-1.280)(R -5.397, F 2.837)]  [G loss: -2.787] \n",
      "3288 [D loss: (-1.009)(R -5.147, F 3.130)]  [G loss: -2.902] \n",
      "3289 [D loss: (-1.507)(R -5.701, F 2.687)]  [G loss: -2.892] \n",
      "3289 [D loss: (-1.113)(R -5.492, F 3.265)]  [G loss: -2.971] \n",
      "3290 [D loss: (-1.300)(R -5.347, F 2.748)]  [G loss: -2.883] \n",
      "3290 [D loss: (-1.150)(R -5.224, F 2.923)]  [G loss: -2.883] \n",
      "3291 [D loss: (-1.050)(R -5.020, F 2.920)]  [G loss: -2.903] \n",
      "3291 [D loss: (-0.976)(R -5.051, F 3.098)]  [G loss: -2.729] \n",
      "3292 [D loss: (-1.191)(R -5.203, F 2.821)]  [G loss: -2.931] \n",
      "3292 [D loss: (-1.085)(R -5.157, F 2.987)]  [G loss: -2.820] \n",
      "3293 [D loss: (-1.018)(R -5.105, F 3.069)]  [G loss: -2.894] \n",
      "3293 [D loss: (-1.072)(R -4.994, F 2.850)]  [G loss: -2.720] \n",
      "3294 [D loss: (-1.272)(R -5.087, F 2.543)]  [G loss: -2.797] \n",
      "3294 [D loss: (-1.129)(R -5.053, F 2.795)]  [G loss: -2.822] \n",
      "3295 [D loss: (-1.066)(R -4.666, F 2.534)]  [G loss: -2.790] \n",
      "3295 [D loss: (-1.277)(R -4.984, F 2.430)]  [G loss: -2.654] \n",
      "3296 [D loss: (-1.307)(R -4.981, F 2.367)]  [G loss: -2.576] \n",
      "3296 [D loss: (-1.144)(R -4.976, F 2.688)]  [G loss: -2.730] \n",
      "3297 [D loss: (-1.197)(R -4.911, F 2.516)]  [G loss: -2.743] \n",
      "3297 [D loss: (-0.897)(R -4.635, F 2.841)]  [G loss: -2.816] \n",
      "3298 [D loss: (-1.064)(R -5.010, F 2.882)]  [G loss: -2.770] \n",
      "3298 [D loss: (-1.203)(R -4.956, F 2.549)]  [G loss: -2.845] \n",
      "3299 [D loss: (-1.248)(R -4.889, F 2.393)]  [G loss: -2.772] \n",
      "3299 [D loss: (-1.137)(R -5.026, F 2.751)]  [G loss: -2.871] \n",
      "3300 [D loss: (-1.161)(R -5.309, F 2.987)]  [G loss: -2.758] \n",
      "3300 [D loss: (-1.149)(R -5.022, F 2.723)]  [G loss: -2.716] \n",
      "3301 [D loss: (-1.000)(R -4.986, F 2.985)]  [G loss: -2.970] \n",
      "3301 [D loss: (-1.061)(R -5.157, F 3.036)]  [G loss: -2.877] \n",
      "3302 [D loss: (-1.354)(R -5.341, F 2.634)]  [G loss: -2.900] \n",
      "3302 [D loss: (-1.160)(R -5.121, F 2.801)]  [G loss: -2.925] \n",
      "3303 [D loss: (-1.191)(R -5.130, F 2.748)]  [G loss: -2.934] \n",
      "3303 [D loss: (-1.090)(R -5.116, F 2.937)]  [G loss: -2.884] \n",
      "3304 [D loss: (-1.034)(R -4.960, F 2.891)]  [G loss: -2.908] \n",
      "3304 [D loss: (-0.917)(R -4.963, F 3.129)]  [G loss: -2.969] \n",
      "3305 [D loss: (-1.086)(R -5.028, F 2.857)]  [G loss: -2.884] \n",
      "3305 [D loss: (-0.903)(R -5.004, F 3.197)]  [G loss: -3.028] \n",
      "3306 [D loss: (-1.091)(R -5.008, F 2.825)]  [G loss: -2.826] \n",
      "3306 [D loss: (-1.093)(R -5.119, F 2.933)]  [G loss: -2.774] \n",
      "3307 [D loss: (-1.118)(R -4.911, F 2.675)]  [G loss: -2.811] \n",
      "3307 [D loss: (-0.961)(R -4.846, F 2.923)]  [G loss: -2.769] \n",
      "3308 [D loss: (-0.768)(R -4.825, F 3.289)]  [G loss: -2.743] \n",
      "3308 [D loss: (-1.099)(R -4.900, F 2.702)]  [G loss: -2.732] \n",
      "3309 [D loss: (-1.350)(R -4.973, F 2.274)]  [G loss: -2.813] \n",
      "3309 [D loss: (-1.196)(R -4.988, F 2.596)]  [G loss: -2.799] \n",
      "3310 [D loss: (-1.078)(R -4.919, F 2.764)]  [G loss: -2.697] \n",
      "3310 [D loss: (-0.977)(R -4.871, F 2.917)]  [G loss: -2.676] \n",
      "3311 [D loss: (-0.876)(R -4.439, F 2.687)]  [G loss: -2.716] \n",
      "3311 [D loss: (-1.086)(R -5.161, F 2.989)]  [G loss: -2.658] \n",
      "3312 [D loss: (-0.927)(R -4.986, F 3.131)]  [G loss: -2.689] \n",
      "3312 [D loss: (-1.113)(R -4.977, F 2.750)]  [G loss: -2.805] \n",
      "3313 [D loss: (-1.137)(R -5.105, F 2.830)]  [G loss: -2.717] \n",
      "3313 [D loss: (-1.022)(R -4.697, F 2.654)]  [G loss: -2.681] \n",
      "3314 [D loss: (-0.973)(R -4.747, F 2.801)]  [G loss: -2.663] \n",
      "3314 [D loss: (-1.185)(R -5.084, F 2.714)]  [G loss: -2.655] \n",
      "3315 [D loss: (-0.901)(R -4.715, F 2.913)]  [G loss: -2.877] \n",
      "3315 [D loss: (-1.174)(R -5.188, F 2.841)]  [G loss: -2.738] \n",
      "3316 [D loss: (-1.155)(R -4.954, F 2.644)]  [G loss: -2.777] \n",
      "3316 [D loss: (-1.068)(R -5.078, F 2.943)]  [G loss: -2.795] \n",
      "3317 [D loss: (-1.009)(R -5.043, F 3.026)]  [G loss: -2.758] \n",
      "3317 [D loss: (-1.028)(R -4.753, F 2.696)]  [G loss: -2.814] \n",
      "3318 [D loss: (-0.915)(R -4.643, F 2.814)]  [G loss: -2.818] \n",
      "3318 [D loss: (-1.097)(R -4.984, F 2.790)]  [G loss: -2.745] \n",
      "3319 [D loss: (-0.918)(R -4.586, F 2.749)]  [G loss: -2.745] \n",
      "3319 [D loss: (-0.970)(R -4.735, F 2.795)]  [G loss: -2.711] \n",
      "3320 [D loss: (-1.113)(R -4.878, F 2.651)]  [G loss: -2.824] \n",
      "3320 [D loss: (-1.037)(R -4.997, F 2.922)]  [G loss: -2.673] \n",
      "3321 [D loss: (-1.029)(R -4.818, F 2.759)]  [G loss: -2.806] \n",
      "3321 [D loss: (-0.962)(R -4.737, F 2.814)]  [G loss: -2.774] \n",
      "3322 [D loss: (-1.007)(R -4.669, F 2.656)]  [G loss: -2.730] \n",
      "3322 [D loss: (-1.035)(R -4.672, F 2.601)]  [G loss: -2.731] \n",
      "3323 [D loss: (-1.070)(R -4.701, F 2.560)]  [G loss: -2.600] \n",
      "3323 [D loss: (-0.994)(R -4.676, F 2.689)]  [G loss: -2.542] \n",
      "3324 [D loss: (-1.093)(R -4.764, F 2.578)]  [G loss: -2.651] \n",
      "3324 [D loss: (-0.941)(R -4.468, F 2.586)]  [G loss: -2.565] \n",
      "3325 [D loss: (-1.036)(R -4.646, F 2.574)]  [G loss: -2.668] \n",
      "3325 [D loss: (-1.002)(R -4.624, F 2.620)]  [G loss: -2.597] \n",
      "3326 [D loss: (-0.964)(R -4.668, F 2.740)]  [G loss: -2.689] \n",
      "3326 [D loss: (-1.014)(R -4.589, F 2.561)]  [G loss: -2.620] \n",
      "3327 [D loss: (-1.129)(R -4.879, F 2.622)]  [G loss: -2.596] \n",
      "3327 [D loss: (-0.868)(R -4.299, F 2.562)]  [G loss: -2.647] \n",
      "3328 [D loss: (-0.906)(R -4.529, F 2.718)]  [G loss: -2.704] \n",
      "3328 [D loss: (-1.112)(R -4.678, F 2.454)]  [G loss: -2.754] \n",
      "3329 [D loss: (-0.950)(R -4.600, F 2.701)]  [G loss: -2.733] \n",
      "3329 [D loss: (-0.968)(R -4.638, F 2.702)]  [G loss: -2.860] \n",
      "3330 [D loss: (-1.040)(R -4.741, F 2.661)]  [G loss: -2.943] \n",
      "3330 [D loss: (-1.058)(R -4.868, F 2.751)]  [G loss: -2.679] \n",
      "3331 [D loss: (-1.001)(R -4.721, F 2.720)]  [G loss: -2.863] \n",
      "3331 [D loss: (-1.204)(R -4.998, F 2.590)]  [G loss: -2.929] \n",
      "3332 [D loss: (-0.953)(R -4.533, F 2.627)]  [G loss: -2.955] \n",
      "3332 [D loss: (-0.717)(R -4.502, F 3.069)]  [G loss: -2.885] \n",
      "3333 [D loss: (-0.901)(R -4.851, F 3.050)]  [G loss: -2.766] \n",
      "3333 [D loss: (-1.074)(R -4.850, F 2.701)]  [G loss: -2.804] \n",
      "3334 [D loss: (-0.969)(R -4.731, F 2.794)]  [G loss: -2.894] \n",
      "3334 [D loss: (-1.160)(R -4.883, F 2.564)]  [G loss: -2.864] \n",
      "3335 [D loss: (-1.004)(R -4.755, F 2.748)]  [G loss: -2.772] \n",
      "3335 [D loss: (-0.873)(R -4.740, F 2.994)]  [G loss: -2.803] \n",
      "3336 [D loss: (-0.922)(R -4.682, F 2.838)]  [G loss: -2.866] \n",
      "3336 [D loss: (-0.987)(R -4.690, F 2.716)]  [G loss: -2.731] \n",
      "3337 [D loss: (-1.053)(R -4.720, F 2.613)]  [G loss: -2.857] \n",
      "3337 [D loss: (-0.898)(R -4.523, F 2.727)]  [G loss: -2.656] \n",
      "3338 [D loss: (-1.024)(R -4.702, F 2.654)]  [G loss: -2.787] \n",
      "3338 [D loss: (-0.857)(R -4.611, F 2.898)]  [G loss: -2.597] \n",
      "3339 [D loss: (-0.842)(R -4.578, F 2.893)]  [G loss: -2.608] \n",
      "3339 [D loss: (-0.843)(R -4.506, F 2.820)]  [G loss: -2.480] \n",
      "3340 [D loss: (-0.817)(R -4.342, F 2.709)]  [G loss: -2.482] \n",
      "3340 [D loss: (-0.971)(R -4.346, F 2.404)]  [G loss: -2.445] \n",
      "3341 [D loss: (-1.064)(R -4.411, F 2.283)]  [G loss: -2.547] \n",
      "3341 [D loss: (-0.771)(R -4.099, F 2.556)]  [G loss: -2.472] \n",
      "3342 [D loss: (-0.919)(R -4.237, F 2.399)]  [G loss: -2.504] \n",
      "3342 [D loss: (-0.831)(R -4.222, F 2.559)]  [G loss: -2.508] \n",
      "3343 [D loss: (-0.965)(R -4.480, F 2.551)]  [G loss: -2.535] \n",
      "3343 [D loss: (-0.907)(R -4.084, F 2.269)]  [G loss: -2.501] \n",
      "3344 [D loss: (-0.757)(R -4.182, F 2.669)]  [G loss: -2.347] \n",
      "3344 [D loss: (-0.767)(R -4.112, F 2.578)]  [G loss: -2.343] \n",
      "3345 [D loss: (-0.886)(R -4.110, F 2.338)]  [G loss: -2.334] \n",
      "3345 [D loss: (-0.857)(R -3.951, F 2.237)]  [G loss: -2.344] \n",
      "3346 [D loss: (-0.867)(R -4.137, F 2.403)]  [G loss: -2.182] \n",
      "3346 [D loss: (-0.899)(R -3.833, F 2.035)]  [G loss: -2.195] \n",
      "3347 [D loss: (-0.828)(R -3.934, F 2.278)]  [G loss: -2.045] \n",
      "3347 [D loss: (-0.825)(R -3.750, F 2.099)]  [G loss: -2.019] \n",
      "3348 [D loss: (-0.818)(R -4.104, F 2.469)]  [G loss: -2.161] \n",
      "3348 [D loss: (-0.832)(R -3.880, F 2.216)]  [G loss: -2.036] \n",
      "3349 [D loss: (-0.809)(R -3.996, F 2.378)]  [G loss: -2.121] \n",
      "3349 [D loss: (-0.996)(R -3.916, F 1.925)]  [G loss: -2.133] \n",
      "3350 [D loss: (-0.820)(R -3.739, F 2.100)]  [G loss: -2.114] \n",
      "3350 [D loss: (-0.803)(R -3.710, F 2.104)]  [G loss: -2.086] \n",
      "3351 [D loss: (-0.888)(R -3.942, F 2.166)]  [G loss: -2.000] \n",
      "3351 [D loss: (-0.795)(R -3.653, F 2.064)]  [G loss: -2.041] \n",
      "3352 [D loss: (-0.890)(R -3.947, F 2.166)]  [G loss: -2.098] \n",
      "3352 [D loss: (-0.889)(R -3.824, F 2.047)]  [G loss: -2.099] \n",
      "3353 [D loss: (-1.034)(R -4.064, F 1.996)]  [G loss: -2.244] \n",
      "3353 [D loss: (-0.892)(R -3.893, F 2.108)]  [G loss: -2.153] \n",
      "3354 [D loss: (-0.858)(R -3.676, F 1.960)]  [G loss: -2.070] \n",
      "3354 [D loss: (-0.805)(R -3.708, F 2.099)]  [G loss: -2.150] \n",
      "3355 [D loss: (-0.865)(R -3.844, F 2.114)]  [G loss: -2.106] \n",
      "3355 [D loss: (-0.812)(R -3.649, F 2.025)]  [G loss: -2.128] \n",
      "3356 [D loss: (-0.866)(R -3.806, F 2.074)]  [G loss: -1.974] \n",
      "3356 [D loss: (-0.864)(R -3.836, F 2.108)]  [G loss: -2.159] \n",
      "3357 [D loss: (-0.753)(R -3.738, F 2.233)]  [G loss: -2.075] \n",
      "3357 [D loss: (-0.977)(R -3.877, F 1.924)]  [G loss: -2.055] \n",
      "3358 [D loss: (-0.845)(R -3.742, F 2.053)]  [G loss: -2.028] \n",
      "3358 [D loss: (-0.880)(R -3.726, F 1.967)]  [G loss: -1.968] \n",
      "3359 [D loss: (-0.969)(R -3.876, F 1.937)]  [G loss: -1.904] \n",
      "3359 [D loss: (-0.664)(R -3.592, F 2.263)]  [G loss: -2.032] \n",
      "3360 [D loss: (-0.771)(R -3.495, F 1.953)]  [G loss: -1.962] \n",
      "3360 [D loss: (-0.925)(R -3.855, F 2.004)]  [G loss: -2.039] \n",
      "3361 [D loss: (-0.701)(R -3.234, F 1.832)]  [G loss: -1.778] \n",
      "3361 [D loss: (-0.862)(R -3.392, F 1.668)]  [G loss: -1.850] \n",
      "3362 [D loss: (-0.876)(R -3.749, F 1.996)]  [G loss: -1.847] \n",
      "3362 [D loss: (-0.850)(R -3.716, F 2.016)]  [G loss: -1.966] \n",
      "3363 [D loss: (-0.753)(R -3.413, F 1.907)]  [G loss: -1.917] \n",
      "3363 [D loss: (-0.839)(R -3.565, F 1.887)]  [G loss: -1.853] \n",
      "3364 [D loss: (-0.879)(R -3.666, F 1.908)]  [G loss: -1.988] \n",
      "3364 [D loss: (-0.782)(R -3.475, F 1.911)]  [G loss: -1.903] \n",
      "3365 [D loss: (-0.932)(R -3.575, F 1.712)]  [G loss: -1.728] \n",
      "3365 [D loss: (-0.784)(R -3.478, F 1.911)]  [G loss: -1.811] \n",
      "3366 [D loss: (-0.602)(R -3.080, F 1.877)]  [G loss: -1.754] \n",
      "3366 [D loss: (-0.844)(R -3.616, F 1.928)]  [G loss: -1.806] \n",
      "3367 [D loss: (-0.831)(R -3.533, F 1.870)]  [G loss: -1.692] \n",
      "3367 [D loss: (-0.802)(R -3.561, F 1.956)]  [G loss: -1.907] \n",
      "3368 [D loss: (-0.873)(R -3.555, F 1.810)]  [G loss: -1.827] \n",
      "3368 [D loss: (-0.945)(R -3.596, F 1.705)]  [G loss: -1.791] \n",
      "3369 [D loss: (-0.790)(R -3.432, F 1.853)]  [G loss: -1.760] \n",
      "3369 [D loss: (-0.684)(R -3.182, F 1.813)]  [G loss: -1.702] \n",
      "3370 [D loss: (-0.766)(R -3.315, F 1.783)]  [G loss: -1.798] \n",
      "3370 [D loss: (-0.960)(R -3.508, F 1.589)]  [G loss: -1.808] \n",
      "3371 [D loss: (-0.763)(R -3.244, F 1.717)]  [G loss: -1.689] \n",
      "3371 [D loss: (-0.761)(R -3.282, F 1.760)]  [G loss: -1.530] \n",
      "3372 [D loss: (-0.797)(R -3.175, F 1.581)]  [G loss: -1.631] \n",
      "3372 [D loss: (-0.758)(R -3.250, F 1.734)]  [G loss: -1.453] \n",
      "3373 [D loss: (-0.755)(R -3.051, F 1.542)]  [G loss: -1.362] \n",
      "3373 [D loss: (-0.650)(R -2.835, F 1.535)]  [G loss: -1.446] \n",
      "3374 [D loss: (-0.835)(R -2.966, F 1.297)]  [G loss: -1.365] \n",
      "3374 [D loss: (-0.786)(R -2.881, F 1.309)]  [G loss: -1.420] \n",
      "3375 [D loss: (-0.761)(R -2.900, F 1.377)]  [G loss: -1.382] \n",
      "3375 [D loss: (-0.688)(R -2.864, F 1.487)]  [G loss: -1.224] \n",
      "3376 [D loss: (-0.761)(R -2.770, F 1.248)]  [G loss: -1.301] \n",
      "3376 [D loss: (-0.625)(R -2.762, F 1.512)]  [G loss: -1.280] \n",
      "3377 [D loss: (-0.729)(R -2.782, F 1.324)]  [G loss: -1.477] \n",
      "3377 [D loss: (-0.793)(R -2.903, F 1.318)]  [G loss: -1.160] \n",
      "3378 [D loss: (-0.675)(R -2.684, F 1.333)]  [G loss: -1.185] \n",
      "3378 [D loss: (-0.714)(R -2.737, F 1.310)]  [G loss: -1.199] \n",
      "3379 [D loss: (-0.771)(R -2.744, F 1.201)]  [G loss: -1.235] \n",
      "3379 [D loss: (-0.898)(R -2.886, F 1.091)]  [G loss: -1.120] \n",
      "3380 [D loss: (-0.666)(R -2.557, F 1.225)]  [G loss: -1.093] \n",
      "3380 [D loss: (-0.817)(R -2.778, F 1.143)]  [G loss: -1.175] \n",
      "3381 [D loss: (-0.690)(R -2.631, F 1.251)]  [G loss: -1.260] \n",
      "3381 [D loss: (-0.609)(R -2.653, F 1.434)]  [G loss: -1.005] \n",
      "3382 [D loss: (-0.767)(R -2.687, F 1.154)]  [G loss: -1.115] \n",
      "3382 [D loss: (-0.743)(R -2.535, F 1.049)]  [G loss: -0.966] \n",
      "3383 [D loss: (-0.819)(R -2.650, F 1.012)]  [G loss: -1.068] \n",
      "3383 [D loss: (-0.716)(R -2.478, F 1.046)]  [G loss: -0.930] \n",
      "3384 [D loss: (-0.603)(R -2.349, F 1.143)]  [G loss: -0.926] \n",
      "3384 [D loss: (-0.655)(R -2.438, F 1.128)]  [G loss: -0.817] \n",
      "3385 [D loss: (-0.781)(R -2.466, F 0.905)]  [G loss: -0.867] \n",
      "3385 [D loss: (-0.801)(R -2.498, F 0.897)]  [G loss: -0.834] \n",
      "3386 [D loss: (-0.624)(R -2.154, F 0.905)]  [G loss: -0.936] \n",
      "3386 [D loss: (-0.679)(R -2.191, F 0.834)]  [G loss: -0.856] \n",
      "3387 [D loss: (-0.630)(R -2.027, F 0.767)]  [G loss: -0.634] \n",
      "3387 [D loss: (-0.773)(R -2.323, F 0.778)]  [G loss: -0.725] \n",
      "3388 [D loss: (-0.757)(R -2.171, F 0.657)]  [G loss: -0.567] \n",
      "3388 [D loss: (-0.625)(R -1.883, F 0.633)]  [G loss: -0.575] \n",
      "3389 [D loss: (-0.728)(R -1.993, F 0.537)]  [G loss: -0.563] \n",
      "3389 [D loss: (-0.669)(R -1.908, F 0.570)]  [G loss: -0.617] \n",
      "3390 [D loss: (-0.685)(R -1.903, F 0.533)]  [G loss: -0.511] \n",
      "3390 [D loss: (-0.750)(R -2.029, F 0.530)]  [G loss: -0.451] \n",
      "3391 [D loss: (-0.765)(R -2.065, F 0.535)]  [G loss: -0.519] \n",
      "3391 [D loss: (-0.681)(R -1.957, F 0.595)]  [G loss: -0.585] \n",
      "3392 [D loss: (-0.782)(R -2.047, F 0.483)]  [G loss: -0.534] \n",
      "3392 [D loss: (-0.791)(R -2.060, F 0.478)]  [G loss: -0.628] \n",
      "3393 [D loss: (-0.660)(R -2.041, F 0.722)]  [G loss: -0.711] \n",
      "3393 [D loss: (-0.600)(R -1.910, F 0.710)]  [G loss: -0.682] \n",
      "3394 [D loss: (-0.728)(R -2.106, F 0.651)]  [G loss: -0.718] \n",
      "3394 [D loss: (-0.769)(R -2.256, F 0.718)]  [G loss: -0.682] \n",
      "3395 [D loss: (-0.851)(R -2.433, F 0.731)]  [G loss: -0.640] \n",
      "3395 [D loss: (-0.678)(R -1.953, F 0.598)]  [G loss: -0.719] \n",
      "3396 [D loss: (-0.784)(R -2.201, F 0.634)]  [G loss: -0.802] \n",
      "3396 [D loss: (-0.620)(R -1.976, F 0.736)]  [G loss: -0.672] \n",
      "3397 [D loss: (-0.660)(R -2.005, F 0.685)]  [G loss: -0.687] \n",
      "3397 [D loss: (-0.741)(R -2.172, F 0.689)]  [G loss: -0.772] \n",
      "3398 [D loss: (-0.783)(R -2.334, F 0.768)]  [G loss: -0.591] \n",
      "3398 [D loss: (-0.724)(R -2.273, F 0.825)]  [G loss: -0.700] \n",
      "3399 [D loss: (-0.808)(R -2.229, F 0.613)]  [G loss: -0.607] \n",
      "3399 [D loss: (-0.694)(R -2.081, F 0.693)]  [G loss: -0.628] \n",
      "3400 [D loss: (-0.667)(R -2.080, F 0.746)]  [G loss: -0.650] \n",
      "3400 [D loss: (-0.759)(R -2.143, F 0.625)]  [G loss: -0.637] \n",
      "3401 [D loss: (-0.710)(R -2.123, F 0.703)]  [G loss: -0.650] \n",
      "3401 [D loss: (-0.599)(R -2.021, F 0.822)]  [G loss: -0.584] \n",
      "3402 [D loss: (-0.761)(R -2.160, F 0.637)]  [G loss: -0.585] \n",
      "3402 [D loss: (-0.741)(R -2.135, F 0.652)]  [G loss: -0.652] \n",
      "3403 [D loss: (-0.680)(R -2.049, F 0.688)]  [G loss: -0.672] \n",
      "3403 [D loss: (-0.648)(R -1.992, F 0.697)]  [G loss: -0.598] \n",
      "3404 [D loss: (-0.717)(R -2.104, F 0.669)]  [G loss: -0.741] \n",
      "3404 [D loss: (-0.745)(R -2.115, F 0.625)]  [G loss: -0.652] \n",
      "3405 [D loss: (-0.657)(R -1.956, F 0.643)]  [G loss: -0.698] \n",
      "3405 [D loss: (-0.685)(R -2.134, F 0.764)]  [G loss: -0.727] \n",
      "3406 [D loss: (-0.679)(R -2.078, F 0.720)]  [G loss: -0.633] \n",
      "3406 [D loss: (-0.603)(R -1.946, F 0.739)]  [G loss: -0.532] \n",
      "3407 [D loss: (-0.786)(R -2.201, F 0.630)]  [G loss: -0.715] \n",
      "3407 [D loss: (-0.553)(R -1.792, F 0.687)]  [G loss: -0.597] \n",
      "3408 [D loss: (-0.725)(R -2.072, F 0.622)]  [G loss: -0.652] \n",
      "3408 [D loss: (-0.647)(R -1.942, F 0.647)]  [G loss: -0.528] \n",
      "3409 [D loss: (-0.545)(R -1.842, F 0.752)]  [G loss: -0.444] \n",
      "3409 [D loss: (-0.732)(R -1.945, F 0.480)]  [G loss: -0.516] \n",
      "3410 [D loss: (-0.739)(R -1.852, F 0.374)]  [G loss: -0.399] \n",
      "3410 [D loss: (-0.673)(R -2.024, F 0.678)]  [G loss: -0.454] \n",
      "3411 [D loss: (-0.690)(R -2.007, F 0.627)]  [G loss: -0.484] \n",
      "3411 [D loss: (-0.728)(R -1.933, F 0.477)]  [G loss: -0.456] \n",
      "3412 [D loss: (-0.621)(R -1.971, F 0.729)]  [G loss: -0.540] \n",
      "3412 [D loss: (-0.605)(R -1.847, F 0.636)]  [G loss: -0.502] \n",
      "3413 [D loss: (-0.664)(R -1.785, F 0.456)]  [G loss: -0.552] \n",
      "3413 [D loss: (-0.719)(R -2.036, F 0.598)]  [G loss: -0.640] \n",
      "3414 [D loss: (-0.746)(R -1.965, F 0.473)]  [G loss: -0.491] \n",
      "3414 [D loss: (-0.816)(R -2.097, F 0.464)]  [G loss: -0.553] \n",
      "3415 [D loss: (-0.669)(R -1.874, F 0.536)]  [G loss: -0.614] \n",
      "3415 [D loss: (-0.613)(R -1.785, F 0.559)]  [G loss: -0.537] \n",
      "3416 [D loss: (-0.672)(R -1.872, F 0.529)]  [G loss: -0.461] \n",
      "3416 [D loss: (-0.617)(R -1.691, F 0.457)]  [G loss: -0.545] \n",
      "3417 [D loss: (-0.706)(R -1.832, F 0.421)]  [G loss: -0.430] \n",
      "3417 [D loss: (-0.604)(R -1.584, F 0.377)]  [G loss: -0.320] \n",
      "3418 [D loss: (-0.671)(R -1.727, F 0.385)]  [G loss: -0.368] \n",
      "3418 [D loss: (-0.825)(R -1.846, F 0.196)]  [G loss: -0.335] \n",
      "3419 [D loss: (-0.555)(R -1.382, F 0.272)]  [G loss: -0.199] \n",
      "3419 [D loss: (-0.740)(R -1.795, F 0.315)]  [G loss: -0.328] \n",
      "3420 [D loss: (-0.643)(R -1.707, F 0.422)]  [G loss: -0.334] \n",
      "3420 [D loss: (-0.544)(R -1.459, F 0.371)]  [G loss: -0.212] \n",
      "3421 [D loss: (-0.610)(R -1.524, F 0.303)]  [G loss: -0.288] \n",
      "3421 [D loss: (-0.686)(R -1.528, F 0.157)]  [G loss: -0.206] \n",
      "3422 [D loss: (-0.716)(R -1.634, F 0.202)]  [G loss: -0.119] \n",
      "3422 [D loss: (-0.703)(R -1.466, F 0.060)]  [G loss: -0.229] \n",
      "3423 [D loss: (-0.707)(R -1.597, F 0.183)]  [G loss: -0.197] \n",
      "3423 [D loss: (-0.752)(R -1.563, F 0.058)]  [G loss: -0.171] \n",
      "3424 [D loss: (-0.679)(R -1.468, F 0.109)]  [G loss: -0.187] \n",
      "3424 [D loss: (-0.571)(R -1.371, F 0.229)]  [G loss: -0.118] \n",
      "3425 [D loss: (-0.595)(R -1.528, F 0.339)]  [G loss: -0.110] \n",
      "3425 [D loss: (-0.740)(R -1.648, F 0.169)]  [G loss: -0.242] \n",
      "3426 [D loss: (-0.540)(R -1.314, F 0.233)]  [G loss: -0.167] \n",
      "3426 [D loss: (-0.545)(R -1.296, F 0.205)]  [G loss: -0.261] \n",
      "3427 [D loss: (-0.688)(R -1.515, F 0.139)]  [G loss: -0.155] \n",
      "3427 [D loss: (-0.615)(R -1.521, F 0.291)]  [G loss: -0.145] \n",
      "3428 [D loss: (-0.600)(R -1.321, F 0.121)]  [G loss: -0.209] \n",
      "3428 [D loss: (-0.579)(R -1.333, F 0.175)]  [G loss: -0.099] \n",
      "3429 [D loss: (-0.637)(R -1.417, F 0.142)]  [G loss: -0.174] \n",
      "3429 [D loss: (-0.687)(R -1.464, F 0.090)]  [G loss: -0.166] \n",
      "3430 [D loss: (-0.608)(R -1.267, F 0.051)]  [G loss: -0.075] \n",
      "3430 [D loss: (-0.643)(R -1.277, F -0.009)]  [G loss: -0.020] \n",
      "3431 [D loss: (-0.708)(R -1.440, F 0.023)]  [G loss: -0.036] \n",
      "3431 [D loss: (-0.522)(R -1.196, F 0.151)]  [G loss: 0.113] \n",
      "3432 [D loss: (-0.597)(R -1.139, F -0.056)]  [G loss: 0.006] \n",
      "3432 [D loss: (-0.726)(R -1.275, F -0.178)]  [G loss: -0.025] \n",
      "3433 [D loss: (-0.545)(R -1.093, F 0.002)]  [G loss: -0.071] \n",
      "3433 [D loss: (-0.527)(R -1.150, F 0.097)]  [G loss: 0.063] \n",
      "3434 [D loss: (-0.526)(R -1.144, F 0.091)]  [G loss: 0.110] \n",
      "3434 [D loss: (-0.707)(R -1.351, F -0.064)]  [G loss: 0.002] \n",
      "3435 [D loss: (-0.709)(R -1.363, F -0.055)]  [G loss: 0.026] \n",
      "3435 [D loss: (-0.631)(R -1.180, F -0.082)]  [G loss: 0.128] \n",
      "3436 [D loss: (-0.661)(R -1.168, F -0.153)]  [G loss: 0.131] \n",
      "3436 [D loss: (-0.580)(R -0.974, F -0.187)]  [G loss: 0.185] \n",
      "3437 [D loss: (-0.632)(R -1.100, F -0.164)]  [G loss: 0.133] \n",
      "3437 [D loss: (-0.646)(R -1.116, F -0.176)]  [G loss: 0.125] \n",
      "3438 [D loss: (-0.590)(R -1.189, F 0.010)]  [G loss: 0.226] \n",
      "3438 [D loss: (-0.732)(R -1.276, F -0.189)]  [G loss: 0.167] \n",
      "3439 [D loss: (-0.652)(R -1.187, F -0.118)]  [G loss: 0.237] \n",
      "3439 [D loss: (-0.653)(R -1.290, F -0.016)]  [G loss: 0.100] \n",
      "3440 [D loss: (-0.538)(R -1.218, F 0.142)]  [G loss: 0.076] \n",
      "3440 [D loss: (-0.542)(R -1.120, F 0.036)]  [G loss: 0.117] \n",
      "3441 [D loss: (-0.751)(R -1.156, F -0.346)]  [G loss: 0.194] \n",
      "3441 [D loss: (-0.650)(R -1.082, F -0.217)]  [G loss: 0.150] \n",
      "3442 [D loss: (-0.577)(R -1.033, F -0.122)]  [G loss: 0.239] \n",
      "3442 [D loss: (-0.536)(R -0.953, F -0.118)]  [G loss: 0.395] \n",
      "3443 [D loss: (-0.587)(R -0.977, F -0.197)]  [G loss: 0.232] \n",
      "3443 [D loss: (-0.581)(R -0.961, F -0.201)]  [G loss: 0.263] \n",
      "3444 [D loss: (-0.543)(R -0.819, F -0.267)]  [G loss: 0.303] \n",
      "3444 [D loss: (-0.735)(R -1.092, F -0.379)]  [G loss: 0.368] \n",
      "3445 [D loss: (-0.566)(R -0.864, F -0.269)]  [G loss: 0.427] \n",
      "3445 [D loss: (-0.674)(R -1.095, F -0.252)]  [G loss: 0.476] \n",
      "3446 [D loss: (-0.675)(R -1.031, F -0.319)]  [G loss: 0.321] \n",
      "3446 [D loss: (-0.609)(R -0.772, F -0.445)]  [G loss: 0.477] \n",
      "3447 [D loss: (-0.623)(R -0.926, F -0.319)]  [G loss: 0.467] \n",
      "3447 [D loss: (-0.591)(R -0.939, F -0.243)]  [G loss: 0.465] \n",
      "3448 [D loss: (-0.435)(R -0.670, F -0.201)]  [G loss: 0.264] \n",
      "3448 [D loss: (-0.495)(R -0.833, F -0.157)]  [G loss: 0.400] \n",
      "3449 [D loss: (-0.677)(R -0.960, F -0.394)]  [G loss: 0.298] \n",
      "3449 [D loss: (-0.666)(R -1.090, F -0.241)]  [G loss: 0.313] \n",
      "3450 [D loss: (-0.653)(R -1.025, F -0.281)]  [G loss: 0.153] \n",
      "3450 [D loss: (-0.658)(R -1.063, F -0.254)]  [G loss: 0.253] \n",
      "3451 [D loss: (-0.604)(R -0.969, F -0.239)]  [G loss: 0.194] \n",
      "3451 [D loss: (-0.614)(R -0.971, F -0.256)]  [G loss: 0.297] \n",
      "3452 [D loss: (-0.629)(R -1.074, F -0.184)]  [G loss: 0.145] \n",
      "3452 [D loss: (-0.474)(R -0.686, F -0.263)]  [G loss: 0.102] \n",
      "3453 [D loss: (-0.561)(R -0.892, F -0.229)]  [G loss: 0.230] \n",
      "3453 [D loss: (-0.619)(R -1.029, F -0.208)]  [G loss: 0.196] \n",
      "3454 [D loss: (-0.496)(R -0.845, F -0.148)]  [G loss: 0.277] \n",
      "3454 [D loss: (-0.551)(R -0.812, F -0.291)]  [G loss: 0.374] \n",
      "3455 [D loss: (-0.597)(R -0.844, F -0.350)]  [G loss: 0.493] \n",
      "3455 [D loss: (-0.542)(R -0.824, F -0.260)]  [G loss: 0.357] \n",
      "3456 [D loss: (-0.625)(R -0.965, F -0.285)]  [G loss: 0.323] \n",
      "3456 [D loss: (-0.570)(R -0.796, F -0.344)]  [G loss: 0.294] \n",
      "3457 [D loss: (-0.537)(R -0.716, F -0.358)]  [G loss: 0.315] \n",
      "3457 [D loss: (-0.565)(R -0.768, F -0.362)]  [G loss: 0.353] \n",
      "3458 [D loss: (-0.511)(R -0.753, F -0.269)]  [G loss: 0.492] \n",
      "3458 [D loss: (-0.638)(R -0.728, F -0.548)]  [G loss: 0.397] \n",
      "3459 [D loss: (-0.624)(R -0.788, F -0.460)]  [G loss: 0.371] \n",
      "3459 [D loss: (-0.632)(R -0.792, F -0.472)]  [G loss: 0.410] \n",
      "3460 [D loss: (-0.529)(R -0.651, F -0.406)]  [G loss: 0.394] \n",
      "3460 [D loss: (-0.551)(R -0.674, F -0.429)]  [G loss: 0.662] \n",
      "3461 [D loss: (-0.707)(R -0.753, F -0.661)]  [G loss: 0.641] \n",
      "3461 [D loss: (-0.643)(R -0.635, F -0.650)]  [G loss: 0.691] \n",
      "3462 [D loss: (-0.598)(R -0.594, F -0.601)]  [G loss: 0.687] \n",
      "3462 [D loss: (-0.528)(R -0.318, F -0.738)]  [G loss: 0.703] \n",
      "3463 [D loss: (-0.650)(R -0.530, F -0.770)]  [G loss: 0.631] \n",
      "3463 [D loss: (-0.520)(R -0.382, F -0.657)]  [G loss: 0.774] \n",
      "3464 [D loss: (-0.539)(R -0.443, F -0.634)]  [G loss: 0.653] \n",
      "3464 [D loss: (-0.560)(R -0.532, F -0.588)]  [G loss: 0.718] \n",
      "3465 [D loss: (-0.513)(R -0.562, F -0.463)]  [G loss: 0.671] \n",
      "3465 [D loss: (-0.509)(R -0.492, F -0.526)]  [G loss: 0.564] \n",
      "3466 [D loss: (-0.496)(R -0.485, F -0.508)]  [G loss: 0.632] \n",
      "3466 [D loss: (-0.546)(R -0.453, F -0.639)]  [G loss: 0.658] \n",
      "3467 [D loss: (-0.518)(R -0.478, F -0.557)]  [G loss: 0.822] \n",
      "3467 [D loss: (-0.519)(R -0.306, F -0.732)]  [G loss: 0.807] \n",
      "3468 [D loss: (-0.532)(R -0.399, F -0.665)]  [G loss: 0.763] \n",
      "3468 [D loss: (-0.592)(R -0.458, F -0.727)]  [G loss: 0.701] \n",
      "3469 [D loss: (-0.592)(R -0.446, F -0.738)]  [G loss: 0.838] \n",
      "3469 [D loss: (-0.609)(R -0.519, F -0.699)]  [G loss: 0.743] \n",
      "3470 [D loss: (-0.472)(R -0.338, F -0.606)]  [G loss: 0.774] \n",
      "3470 [D loss: (-0.647)(R -0.587, F -0.708)]  [G loss: 0.761] \n",
      "3471 [D loss: (-0.650)(R -0.672, F -0.627)]  [G loss: 0.759] \n",
      "3471 [D loss: (-0.585)(R -0.451, F -0.719)]  [G loss: 0.718] \n",
      "3472 [D loss: (-0.555)(R -0.405, F -0.706)]  [G loss: 0.791] \n",
      "3472 [D loss: (-0.698)(R -0.629, F -0.767)]  [G loss: 0.917] \n",
      "3473 [D loss: (-0.648)(R -0.427, F -0.869)]  [G loss: 0.845] \n",
      "3473 [D loss: (-0.561)(R -0.324, F -0.799)]  [G loss: 0.810] \n",
      "3474 [D loss: (-0.623)(R -0.446, F -0.800)]  [G loss: 0.893] \n",
      "3474 [D loss: (-0.612)(R -0.397, F -0.828)]  [G loss: 0.855] \n",
      "3475 [D loss: (-0.603)(R -0.386, F -0.820)]  [G loss: 0.822] \n",
      "3475 [D loss: (-0.644)(R -0.245, F -1.043)]  [G loss: 0.776] \n",
      "3476 [D loss: (-0.553)(R -0.270, F -0.835)]  [G loss: 0.990] \n",
      "3476 [D loss: (-0.598)(R -0.388, F -0.808)]  [G loss: 0.979] \n",
      "3477 [D loss: (-0.673)(R -0.410, F -0.937)]  [G loss: 1.082] \n",
      "3477 [D loss: (-0.611)(R -0.360, F -0.862)]  [G loss: 0.925] \n",
      "3478 [D loss: (-0.584)(R -0.263, F -0.904)]  [G loss: 1.046] \n",
      "3478 [D loss: (-0.500)(R -0.190, F -0.811)]  [G loss: 0.785] \n",
      "3479 [D loss: (-0.685)(R -0.375, F -0.996)]  [G loss: 0.650] \n",
      "3479 [D loss: (-0.583)(R -0.275, F -0.891)]  [G loss: 0.862] \n",
      "3480 [D loss: (-0.580)(R -0.450, F -0.711)]  [G loss: 0.779] \n",
      "3480 [D loss: (-0.698)(R -0.457, F -0.939)]  [G loss: 0.745] \n",
      "3481 [D loss: (-0.575)(R -0.408, F -0.741)]  [G loss: 0.886] \n",
      "3481 [D loss: (-0.415)(R -0.171, F -0.659)]  [G loss: 0.907] \n",
      "3482 [D loss: (-0.487)(R -0.335, F -0.639)]  [G loss: 0.763] \n",
      "3482 [D loss: (-0.507)(R -0.516, F -0.498)]  [G loss: 0.606] \n",
      "3483 [D loss: (-0.498)(R -0.373, F -0.623)]  [G loss: 0.804] \n",
      "3483 [D loss: (-0.498)(R -0.318, F -0.677)]  [G loss: 0.759] \n",
      "3484 [D loss: (-0.585)(R -0.499, F -0.671)]  [G loss: 0.856] \n",
      "3484 [D loss: (-0.548)(R -0.446, F -0.651)]  [G loss: 0.721] \n",
      "3485 [D loss: (-0.528)(R -0.347, F -0.710)]  [G loss: 0.689] \n",
      "3485 [D loss: (-0.585)(R -0.437, F -0.732)]  [G loss: 0.689] \n",
      "3486 [D loss: (-0.576)(R -0.554, F -0.597)]  [G loss: 0.841] \n",
      "3486 [D loss: (-0.508)(R -0.559, F -0.457)]  [G loss: 0.576] \n",
      "3487 [D loss: (-0.606)(R -0.590, F -0.623)]  [G loss: 0.641] \n",
      "3487 [D loss: (-0.515)(R -0.614, F -0.416)]  [G loss: 0.479] \n",
      "3488 [D loss: (-0.535)(R -0.624, F -0.445)]  [G loss: 0.610] \n",
      "3488 [D loss: (-0.560)(R -0.632, F -0.488)]  [G loss: 0.414] \n",
      "3489 [D loss: (-0.629)(R -0.746, F -0.512)]  [G loss: 0.401] \n",
      "3489 [D loss: (-0.550)(R -0.633, F -0.467)]  [G loss: 0.548] \n",
      "3490 [D loss: (-0.589)(R -0.578, F -0.599)]  [G loss: 0.511] \n",
      "3490 [D loss: (-0.559)(R -0.691, F -0.428)]  [G loss: 0.599] \n",
      "3491 [D loss: (-0.646)(R -0.599, F -0.694)]  [G loss: 0.569] \n",
      "3491 [D loss: (-0.584)(R -0.822, F -0.346)]  [G loss: 0.359] \n",
      "3492 [D loss: (-0.555)(R -0.811, F -0.298)]  [G loss: 0.523] \n",
      "3492 [D loss: (-0.561)(R -0.778, F -0.343)]  [G loss: 0.288] \n",
      "3493 [D loss: (-0.566)(R -0.873, F -0.258)]  [G loss: 0.376] \n",
      "3493 [D loss: (-0.473)(R -0.828, F -0.118)]  [G loss: 0.205] \n",
      "3494 [D loss: (-0.541)(R -0.886, F -0.197)]  [G loss: 0.233] \n",
      "3494 [D loss: (-0.591)(R -0.949, F -0.233)]  [G loss: 0.310] \n",
      "3495 [D loss: (-0.535)(R -1.002, F -0.068)]  [G loss: 0.183] \n",
      "3495 [D loss: (-0.555)(R -1.032, F -0.077)]  [G loss: 0.134] \n",
      "3496 [D loss: (-0.497)(R -0.972, F -0.023)]  [G loss: 0.245] \n",
      "3496 [D loss: (-0.530)(R -1.045, F -0.015)]  [G loss: 0.218] \n",
      "3497 [D loss: (-0.486)(R -0.940, F -0.033)]  [G loss: 0.121] \n",
      "3497 [D loss: (-0.606)(R -1.176, F -0.037)]  [G loss: -0.004] \n",
      "3498 [D loss: (-0.488)(R -0.993, F 0.017)]  [G loss: 0.194] \n",
      "3498 [D loss: (-0.621)(R -1.260, F 0.019)]  [G loss: 0.100] \n",
      "3499 [D loss: (-0.596)(R -1.286, F 0.094)]  [G loss: 0.011] \n",
      "3499 [D loss: (-0.568)(R -1.213, F 0.077)]  [G loss: 0.031] \n",
      "3500 [D loss: (-0.573)(R -1.263, F 0.117)]  [G loss: -0.131] \n",
      "3500 [D loss: (-0.486)(R -1.110, F 0.138)]  [G loss: -0.022] \n",
      "3501 [D loss: (-0.672)(R -1.345, F 0.001)]  [G loss: 0.036] \n",
      "3501 [D loss: (-0.631)(R -1.282, F 0.019)]  [G loss: 0.081] \n",
      "3502 [D loss: (-0.627)(R -1.228, F -0.025)]  [G loss: -0.002] \n",
      "3502 [D loss: (-0.632)(R -1.212, F -0.053)]  [G loss: -0.027] \n",
      "3503 [D loss: (-0.642)(R -1.218, F -0.066)]  [G loss: -0.025] \n",
      "3503 [D loss: (-0.577)(R -1.056, F -0.098)]  [G loss: -0.014] \n",
      "3504 [D loss: (-0.606)(R -1.117, F -0.096)]  [G loss: 0.036] \n",
      "3504 [D loss: (-0.651)(R -1.134, F -0.168)]  [G loss: 0.102] \n",
      "3505 [D loss: (-0.671)(R -1.226, F -0.115)]  [G loss: 0.179] \n",
      "3505 [D loss: (-0.652)(R -1.227, F -0.077)]  [G loss: 0.086] \n",
      "3506 [D loss: (-0.508)(R -0.965, F -0.052)]  [G loss: 0.052] \n",
      "3506 [D loss: (-0.478)(R -1.045, F 0.089)]  [G loss: 0.048] \n",
      "3507 [D loss: (-0.404)(R -0.981, F 0.173)]  [G loss: 0.051] \n",
      "3507 [D loss: (-0.606)(R -1.129, F -0.083)]  [G loss: 0.003] \n",
      "3508 [D loss: (-0.573)(R -1.122, F -0.024)]  [G loss: 0.088] \n",
      "3508 [D loss: (-0.500)(R -1.027, F 0.027)]  [G loss: 0.240] \n",
      "3509 [D loss: (-0.672)(R -1.201, F -0.143)]  [G loss: 0.142] \n",
      "3509 [D loss: (-0.565)(R -1.231, F 0.101)]  [G loss: -0.031] \n",
      "3510 [D loss: (-0.622)(R -1.369, F 0.125)]  [G loss: -0.095] \n",
      "3510 [D loss: (-0.619)(R -1.303, F 0.064)]  [G loss: -0.106] \n",
      "3511 [D loss: (-0.498)(R -1.189, F 0.192)]  [G loss: -0.132] \n",
      "3511 [D loss: (-0.608)(R -1.319, F 0.103)]  [G loss: 0.085] \n",
      "3512 [D loss: (-0.399)(R -0.995, F 0.197)]  [G loss: 0.046] \n",
      "3512 [D loss: (-0.506)(R -1.026, F 0.014)]  [G loss: -0.109] \n",
      "3513 [D loss: (-0.481)(R -1.089, F 0.128)]  [G loss: -0.000] \n",
      "3513 [D loss: (-0.537)(R -1.106, F 0.032)]  [G loss: -0.035] \n",
      "3514 [D loss: (-0.453)(R -1.093, F 0.187)]  [G loss: 0.135] \n",
      "3514 [D loss: (-0.620)(R -1.107, F -0.134)]  [G loss: 0.128] \n",
      "3515 [D loss: (-0.710)(R -1.148, F -0.272)]  [G loss: -0.011] \n",
      "3515 [D loss: (-0.610)(R -1.171, F -0.049)]  [G loss: 0.016] \n",
      "3516 [D loss: (-0.574)(R -1.250, F 0.101)]  [G loss: 0.161] \n",
      "3516 [D loss: (-0.572)(R -1.160, F 0.016)]  [G loss: 0.178] \n",
      "3517 [D loss: (-0.514)(R -1.017, F -0.011)]  [G loss: 0.179] \n",
      "3517 [D loss: (-0.525)(R -1.126, F 0.077)]  [G loss: 0.080] \n",
      "3518 [D loss: (-0.570)(R -1.112, F -0.028)]  [G loss: 0.157] \n",
      "3518 [D loss: (-0.637)(R -1.151, F -0.124)]  [G loss: 0.042] \n",
      "3519 [D loss: (-0.514)(R -1.117, F 0.088)]  [G loss: -0.158] \n",
      "3519 [D loss: (-0.606)(R -1.261, F 0.049)]  [G loss: -0.039] \n",
      "3520 [D loss: (-0.607)(R -1.322, F 0.108)]  [G loss: -0.176] \n",
      "3520 [D loss: (-0.496)(R -1.226, F 0.234)]  [G loss: -0.086] \n",
      "3521 [D loss: (-0.531)(R -1.340, F 0.278)]  [G loss: -0.116] \n",
      "3521 [D loss: (-0.613)(R -1.275, F 0.048)]  [G loss: 0.055] \n",
      "3522 [D loss: (-0.486)(R -1.165, F 0.193)]  [G loss: -0.135] \n",
      "3522 [D loss: (-0.662)(R -1.291, F -0.033)]  [G loss: -0.103] \n",
      "3523 [D loss: (-0.573)(R -1.291, F 0.145)]  [G loss: 0.012] \n",
      "3523 [D loss: (-0.630)(R -1.317, F 0.057)]  [G loss: -0.108] \n",
      "3524 [D loss: (-0.639)(R -1.428, F 0.151)]  [G loss: -0.083] \n",
      "3524 [D loss: (-0.545)(R -1.286, F 0.197)]  [G loss: -0.102] \n",
      "3525 [D loss: (-0.447)(R -1.054, F 0.161)]  [G loss: -0.132] \n",
      "3525 [D loss: (-0.643)(R -1.353, F 0.068)]  [G loss: 0.051] \n",
      "3526 [D loss: (-0.599)(R -1.391, F 0.194)]  [G loss: -0.265] \n",
      "3526 [D loss: (-0.556)(R -1.163, F 0.052)]  [G loss: 0.050] \n",
      "3527 [D loss: (-0.652)(R -1.301, F -0.003)]  [G loss: -0.185] \n",
      "3527 [D loss: (-0.637)(R -1.308, F 0.034)]  [G loss: -0.222] \n",
      "3528 [D loss: (-0.550)(R -1.412, F 0.312)]  [G loss: -0.077] \n",
      "3528 [D loss: (-0.593)(R -1.326, F 0.139)]  [G loss: -0.176] \n",
      "3529 [D loss: (-0.618)(R -1.334, F 0.098)]  [G loss: -0.219] \n",
      "3529 [D loss: (-0.526)(R -1.277, F 0.224)]  [G loss: -0.093] \n",
      "3530 [D loss: (-0.570)(R -1.324, F 0.184)]  [G loss: -0.192] \n",
      "3530 [D loss: (-0.699)(R -1.356, F -0.042)]  [G loss: -0.108] \n",
      "3531 [D loss: (-0.515)(R -1.442, F 0.413)]  [G loss: -0.129] \n",
      "3531 [D loss: (-0.464)(R -1.283, F 0.355)]  [G loss: -0.098] \n",
      "3532 [D loss: (-0.533)(R -1.354, F 0.289)]  [G loss: -0.229] \n",
      "3532 [D loss: (-0.597)(R -1.525, F 0.332)]  [G loss: -0.206] \n",
      "3533 [D loss: (-0.550)(R -1.452, F 0.352)]  [G loss: -0.263] \n",
      "3533 [D loss: (-0.560)(R -1.362, F 0.242)]  [G loss: -0.189] \n",
      "3534 [D loss: (-0.643)(R -1.460, F 0.174)]  [G loss: -0.119] \n",
      "3534 [D loss: (-0.568)(R -1.219, F 0.083)]  [G loss: -0.108] \n",
      "3535 [D loss: (-0.486)(R -1.270, F 0.297)]  [G loss: -0.077] \n",
      "3535 [D loss: (-0.571)(R -1.271, F 0.129)]  [G loss: -0.030] \n",
      "3536 [D loss: (-0.637)(R -1.308, F 0.034)]  [G loss: -0.041] \n",
      "3536 [D loss: (-0.629)(R -1.207, F -0.050)]  [G loss: -0.186] \n",
      "3537 [D loss: (-0.685)(R -1.332, F -0.038)]  [G loss: 0.041] \n",
      "3537 [D loss: (-0.503)(R -1.180, F 0.175)]  [G loss: -0.101] \n",
      "3538 [D loss: (-0.511)(R -1.177, F 0.155)]  [G loss: -0.166] \n",
      "3538 [D loss: (-0.544)(R -1.317, F 0.229)]  [G loss: 0.022] \n",
      "3539 [D loss: (-0.484)(R -1.204, F 0.237)]  [G loss: 0.022] \n",
      "3539 [D loss: (-0.705)(R -1.361, F -0.048)]  [G loss: -0.131] \n",
      "3540 [D loss: (-0.652)(R -1.353, F 0.048)]  [G loss: -0.051] \n",
      "3540 [D loss: (-0.640)(R -1.302, F 0.022)]  [G loss: 0.031] \n",
      "3541 [D loss: (-0.593)(R -1.225, F 0.038)]  [G loss: -0.152] \n",
      "3541 [D loss: (-0.626)(R -1.297, F 0.045)]  [G loss: 0.114] \n",
      "3542 [D loss: (-0.612)(R -1.382, F 0.157)]  [G loss: -0.158] \n",
      "3542 [D loss: (-0.594)(R -1.300, F 0.113)]  [G loss: -0.262] \n",
      "3543 [D loss: (-0.496)(R -1.349, F 0.357)]  [G loss: -0.100] \n",
      "3543 [D loss: (-0.618)(R -1.466, F 0.231)]  [G loss: -0.116] \n",
      "3544 [D loss: (-0.562)(R -1.347, F 0.223)]  [G loss: -0.126] \n",
      "3544 [D loss: (-0.670)(R -1.359, F 0.020)]  [G loss: -0.103] \n",
      "3545 [D loss: (-0.578)(R -1.400, F 0.245)]  [G loss: -0.103] \n",
      "3545 [D loss: (-0.633)(R -1.150, F -0.117)]  [G loss: -0.123] \n",
      "3546 [D loss: (-0.678)(R -1.396, F 0.039)]  [G loss: -0.049] \n",
      "3546 [D loss: (-0.490)(R -1.296, F 0.317)]  [G loss: -0.243] \n",
      "3547 [D loss: (-0.655)(R -1.416, F 0.105)]  [G loss: -0.077] \n",
      "3547 [D loss: (-0.679)(R -1.457, F 0.100)]  [G loss: -0.247] \n",
      "3548 [D loss: (-0.608)(R -1.427, F 0.211)]  [G loss: -0.176] \n",
      "3548 [D loss: (-0.742)(R -1.424, F -0.059)]  [G loss: -0.116] \n",
      "3549 [D loss: (-0.636)(R -1.332, F 0.060)]  [G loss: -0.138] \n",
      "3549 [D loss: (-0.656)(R -1.456, F 0.144)]  [G loss: -0.149] \n",
      "3550 [D loss: (-0.592)(R -1.302, F 0.119)]  [G loss: -0.079] \n",
      "3550 [D loss: (-0.709)(R -1.402, F -0.015)]  [G loss: 0.028] \n",
      "3551 [D loss: (-0.616)(R -1.237, F 0.005)]  [G loss: -0.124] \n",
      "3551 [D loss: (-0.622)(R -1.343, F 0.100)]  [G loss: 0.063] \n",
      "3552 [D loss: (-0.479)(R -1.123, F 0.166)]  [G loss: 0.082] \n",
      "3552 [D loss: (-0.628)(R -1.250, F -0.007)]  [G loss: 0.019] \n",
      "3553 [D loss: (-0.564)(R -1.213, F 0.086)]  [G loss: 0.005] \n",
      "3553 [D loss: (-0.682)(R -1.205, F -0.158)]  [G loss: -0.011] \n",
      "3554 [D loss: (-0.631)(R -1.286, F 0.024)]  [G loss: -0.189] \n",
      "3554 [D loss: (-0.424)(R -1.273, F 0.424)]  [G loss: 0.094] \n",
      "3555 [D loss: (-0.595)(R -1.272, F 0.081)]  [G loss: 0.018] \n",
      "3555 [D loss: (-0.645)(R -1.233, F -0.058)]  [G loss: -0.205] \n",
      "3556 [D loss: (-0.661)(R -1.492, F 0.169)]  [G loss: -0.259] \n",
      "3556 [D loss: (-0.631)(R -1.379, F 0.116)]  [G loss: -0.300] \n",
      "3557 [D loss: (-0.721)(R -1.531, F 0.088)]  [G loss: -0.143] \n",
      "3557 [D loss: (-0.538)(R -1.488, F 0.411)]  [G loss: -0.291] \n",
      "3558 [D loss: (-0.559)(R -1.526, F 0.408)]  [G loss: -0.158] \n",
      "3558 [D loss: (-0.604)(R -1.515, F 0.308)]  [G loss: -0.298] \n",
      "3559 [D loss: (-0.727)(R -1.693, F 0.239)]  [G loss: -0.197] \n",
      "3559 [D loss: (-0.607)(R -1.480, F 0.266)]  [G loss: -0.360] \n",
      "3560 [D loss: (-0.425)(R -1.490, F 0.640)]  [G loss: -0.473] \n",
      "3560 [D loss: (-0.643)(R -1.597, F 0.310)]  [G loss: -0.401] \n",
      "3561 [D loss: (-0.672)(R -1.666, F 0.323)]  [G loss: -0.475] \n",
      "3561 [D loss: (-0.479)(R -1.628, F 0.671)]  [G loss: -0.373] \n",
      "3562 [D loss: (-0.567)(R -1.575, F 0.440)]  [G loss: -0.530] \n",
      "3562 [D loss: (-0.643)(R -1.681, F 0.396)]  [G loss: -0.494] \n",
      "3563 [D loss: (-0.538)(R -1.674, F 0.598)]  [G loss: -0.547] \n",
      "3563 [D loss: (-0.613)(R -1.655, F 0.429)]  [G loss: -0.427] \n",
      "3564 [D loss: (-0.681)(R -1.780, F 0.417)]  [G loss: -0.555] \n",
      "3564 [D loss: (-0.769)(R -1.875, F 0.337)]  [G loss: -0.504] \n",
      "3565 [D loss: (-0.513)(R -1.569, F 0.544)]  [G loss: -0.479] \n",
      "3565 [D loss: (-0.597)(R -1.837, F 0.644)]  [G loss: -0.498] \n",
      "3566 [D loss: (-0.619)(R -1.899, F 0.662)]  [G loss: -0.577] \n",
      "3566 [D loss: (-0.738)(R -1.960, F 0.485)]  [G loss: -0.612] \n",
      "3567 [D loss: (-0.564)(R -1.757, F 0.629)]  [G loss: -0.655] \n",
      "3567 [D loss: (-0.656)(R -1.802, F 0.491)]  [G loss: -0.483] \n",
      "3568 [D loss: (-0.541)(R -1.855, F 0.774)]  [G loss: -0.479] \n",
      "3568 [D loss: (-0.659)(R -1.881, F 0.563)]  [G loss: -0.499] \n",
      "3569 [D loss: (-0.615)(R -1.751, F 0.522)]  [G loss: -0.535] \n",
      "3569 [D loss: (-0.636)(R -1.849, F 0.577)]  [G loss: -0.579] \n",
      "3570 [D loss: (-0.638)(R -1.844, F 0.567)]  [G loss: -0.653] \n",
      "3570 [D loss: (-0.674)(R -1.843, F 0.494)]  [G loss: -0.513] \n",
      "3571 [D loss: (-0.555)(R -1.881, F 0.771)]  [G loss: -0.592] \n",
      "3571 [D loss: (-0.579)(R -1.785, F 0.628)]  [G loss: -0.481] \n",
      "3572 [D loss: (-0.695)(R -1.894, F 0.505)]  [G loss: -0.661] \n",
      "3572 [D loss: (-0.606)(R -1.908, F 0.696)]  [G loss: -0.509] \n",
      "3573 [D loss: (-0.570)(R -1.760, F 0.619)]  [G loss: -0.630] \n",
      "3573 [D loss: (-0.592)(R -1.870, F 0.685)]  [G loss: -0.555] \n",
      "3574 [D loss: (-0.747)(R -2.042, F 0.548)]  [G loss: -0.703] \n",
      "3574 [D loss: (-0.689)(R -2.099, F 0.722)]  [G loss: -0.740] \n",
      "3575 [D loss: (-0.478)(R -1.930, F 0.974)]  [G loss: -0.713] \n",
      "3575 [D loss: (-0.690)(R -1.915, F 0.534)]  [G loss: -0.603] \n",
      "3576 [D loss: (-0.562)(R -1.902, F 0.778)]  [G loss: -0.748] \n",
      "3576 [D loss: (-0.756)(R -2.090, F 0.579)]  [G loss: -0.843] \n",
      "3577 [D loss: (-0.524)(R -2.009, F 0.960)]  [G loss: -0.643] \n",
      "3577 [D loss: (-0.694)(R -2.122, F 0.733)]  [G loss: -0.735] \n",
      "3578 [D loss: (-0.518)(R -2.073, F 1.037)]  [G loss: -0.875] \n",
      "3578 [D loss: (-0.672)(R -2.227, F 0.883)]  [G loss: -0.883] \n",
      "3579 [D loss: (-0.701)(R -2.240, F 0.838)]  [G loss: -0.882] \n",
      "3579 [D loss: (-0.726)(R -2.285, F 0.832)]  [G loss: -0.998] \n",
      "3580 [D loss: (-0.722)(R -2.360, F 0.916)]  [G loss: -0.895] \n",
      "3580 [D loss: (-0.745)(R -2.409, F 0.919)]  [G loss: -0.955] \n",
      "3581 [D loss: (-0.717)(R -2.418, F 0.984)]  [G loss: -1.162] \n",
      "3581 [D loss: (-0.539)(R -2.296, F 1.219)]  [G loss: -1.038] \n",
      "3582 [D loss: (-0.608)(R -2.388, F 1.172)]  [G loss: -1.210] \n",
      "3582 [D loss: (-0.617)(R -2.493, F 1.260)]  [G loss: -1.109] \n",
      "3583 [D loss: (-0.639)(R -2.604, F 1.325)]  [G loss: -1.225] \n",
      "3583 [D loss: (-0.588)(R -2.483, F 1.306)]  [G loss: -1.227] \n",
      "3584 [D loss: (-0.645)(R -2.499, F 1.209)]  [G loss: -1.311] \n",
      "3584 [D loss: (-0.522)(R -2.407, F 1.363)]  [G loss: -1.139] \n",
      "3585 [D loss: (-0.596)(R -2.377, F 1.184)]  [G loss: -1.142] \n",
      "3585 [D loss: (-0.605)(R -2.506, F 1.296)]  [G loss: -1.112] \n",
      "3586 [D loss: (-0.717)(R -2.582, F 1.147)]  [G loss: -1.204] \n",
      "3586 [D loss: (-0.708)(R -2.426, F 1.009)]  [G loss: -1.098] \n",
      "3587 [D loss: (-0.667)(R -2.561, F 1.227)]  [G loss: -1.363] \n",
      "3587 [D loss: (-0.579)(R -2.495, F 1.337)]  [G loss: -1.243] \n",
      "3588 [D loss: (-0.719)(R -2.746, F 1.308)]  [G loss: -1.280] \n",
      "3588 [D loss: (-0.413)(R -2.476, F 1.650)]  [G loss: -1.159] \n",
      "3589 [D loss: (-0.690)(R -2.615, F 1.235)]  [G loss: -1.363] \n",
      "3589 [D loss: (-0.716)(R -2.741, F 1.310)]  [G loss: -1.372] \n",
      "3590 [D loss: (-0.672)(R -2.703, F 1.359)]  [G loss: -1.339] \n",
      "3590 [D loss: (-0.713)(R -2.734, F 1.307)]  [G loss: -1.414] \n",
      "3591 [D loss: (-0.554)(R -2.715, F 1.608)]  [G loss: -1.415] \n",
      "3591 [D loss: (-0.616)(R -2.858, F 1.627)]  [G loss: -1.464] \n",
      "3592 [D loss: (-0.505)(R -2.718, F 1.708)]  [G loss: -1.345] \n",
      "3592 [D loss: (-0.599)(R -2.748, F 1.549)]  [G loss: -1.354] \n",
      "3593 [D loss: (-0.794)(R -2.987, F 1.400)]  [G loss: -1.463] \n",
      "3593 [D loss: (-0.712)(R -2.912, F 1.489)]  [G loss: -1.475] \n",
      "3594 [D loss: (-0.633)(R -2.943, F 1.677)]  [G loss: -1.721] \n",
      "3594 [D loss: (-0.781)(R -3.116, F 1.554)]  [G loss: -1.728] \n",
      "3595 [D loss: (-0.749)(R -3.005, F 1.508)]  [G loss: -1.675] \n",
      "3595 [D loss: (-0.662)(R -3.001, F 1.676)]  [G loss: -1.644] \n",
      "3596 [D loss: (-0.745)(R -3.126, F 1.636)]  [G loss: -1.701] \n",
      "3596 [D loss: (-0.730)(R -3.127, F 1.668)]  [G loss: -1.766] \n",
      "3597 [D loss: (-0.639)(R -3.021, F 1.743)]  [G loss: -1.773] \n",
      "3597 [D loss: (-0.667)(R -3.053, F 1.718)]  [G loss: -1.641] \n",
      "3598 [D loss: (-0.732)(R -3.034, F 1.569)]  [G loss: -1.821] \n",
      "3598 [D loss: (-0.590)(R -2.941, F 1.762)]  [G loss: -1.762] \n",
      "3599 [D loss: (-0.641)(R -3.083, F 1.801)]  [G loss: -1.731] \n",
      "3599 [D loss: (-0.725)(R -3.095, F 1.646)]  [G loss: -1.797] \n",
      "3600 [D loss: (-0.706)(R -3.241, F 1.830)]  [G loss: -1.697] \n",
      "3600 [D loss: (-0.715)(R -3.246, F 1.817)]  [G loss: -1.696] \n",
      "3601 [D loss: (-0.583)(R -3.220, F 2.055)]  [G loss: -1.873] \n",
      "3601 [D loss: (-0.552)(R -3.170, F 2.066)]  [G loss: -1.837] \n",
      "3602 [D loss: (-0.638)(R -3.286, F 2.010)]  [G loss: -1.968] \n",
      "3602 [D loss: (-0.578)(R -3.222, F 2.066)]  [G loss: -2.110] \n",
      "3603 [D loss: (-0.692)(R -3.342, F 1.959)]  [G loss: -1.811] \n",
      "3603 [D loss: (-0.676)(R -3.318, F 1.966)]  [G loss: -1.971] \n",
      "3604 [D loss: (-0.690)(R -3.305, F 1.925)]  [G loss: -1.978] \n",
      "3604 [D loss: (-0.743)(R -3.479, F 1.993)]  [G loss: -1.906] \n",
      "3605 [D loss: (-0.649)(R -3.335, F 2.037)]  [G loss: -1.870] \n",
      "3605 [D loss: (-0.553)(R -3.461, F 2.354)]  [G loss: -1.945] \n",
      "3606 [D loss: (-0.597)(R -3.404, F 2.210)]  [G loss: -2.181] \n",
      "3606 [D loss: (-0.671)(R -3.508, F 2.166)]  [G loss: -2.190] \n",
      "3607 [D loss: (-0.602)(R -3.600, F 2.396)]  [G loss: -2.346] \n",
      "3607 [D loss: (-0.654)(R -3.639, F 2.331)]  [G loss: -2.279] \n",
      "3608 [D loss: (-0.682)(R -3.751, F 2.388)]  [G loss: -2.272] \n",
      "3608 [D loss: (-0.754)(R -3.747, F 2.239)]  [G loss: -2.412] \n",
      "3609 [D loss: (-0.668)(R -3.732, F 2.396)]  [G loss: -2.503] \n",
      "3609 [D loss: (-0.731)(R -3.791, F 2.329)]  [G loss: -2.385] \n",
      "3610 [D loss: (-0.682)(R -3.736, F 2.372)]  [G loss: -2.274] \n",
      "3610 [D loss: (-0.622)(R -3.802, F 2.558)]  [G loss: -2.236] \n",
      "3611 [D loss: (-0.587)(R -3.690, F 2.516)]  [G loss: -2.479] \n",
      "3611 [D loss: (-0.720)(R -3.939, F 2.498)]  [G loss: -2.493] \n",
      "3612 [D loss: (-0.586)(R -3.880, F 2.707)]  [G loss: -2.295] \n",
      "3612 [D loss: (-0.734)(R -3.956, F 2.488)]  [G loss: -2.492] \n",
      "3613 [D loss: (-0.816)(R -3.964, F 2.331)]  [G loss: -2.589] \n",
      "3613 [D loss: (-0.652)(R -3.952, F 2.647)]  [G loss: -2.429] \n",
      "3614 [D loss: (-0.773)(R -4.124, F 2.578)]  [G loss: -2.634] \n",
      "3614 [D loss: (-0.599)(R -4.017, F 2.818)]  [G loss: -2.691] \n",
      "3615 [D loss: (-0.706)(R -4.017, F 2.605)]  [G loss: -2.631] \n",
      "3615 [D loss: (-0.796)(R -3.970, F 2.379)]  [G loss: -2.569] \n",
      "3616 [D loss: (-0.834)(R -4.010, F 2.341)]  [G loss: -2.528] \n",
      "3616 [D loss: (-0.692)(R -4.008, F 2.625)]  [G loss: -2.587] \n",
      "3617 [D loss: (-0.856)(R -3.977, F 2.264)]  [G loss: -2.562] \n",
      "3617 [D loss: (-0.654)(R -4.055, F 2.747)]  [G loss: -2.587] \n",
      "3618 [D loss: (-0.697)(R -3.997, F 2.604)]  [G loss: -2.718] \n",
      "3618 [D loss: (-0.709)(R -4.033, F 2.616)]  [G loss: -2.761] \n",
      "3619 [D loss: (-0.777)(R -4.036, F 2.481)]  [G loss: -2.740] \n",
      "3619 [D loss: (-0.675)(R -4.088, F 2.738)]  [G loss: -2.734] \n",
      "3620 [D loss: (-0.654)(R -4.189, F 2.882)]  [G loss: -2.590] \n",
      "3620 [D loss: (-0.737)(R -4.122, F 2.648)]  [G loss: -2.722] \n",
      "3621 [D loss: (-0.606)(R -4.167, F 2.955)]  [G loss: -2.869] \n",
      "3621 [D loss: (-0.678)(R -4.177, F 2.820)]  [G loss: -2.673] \n",
      "3622 [D loss: (-0.538)(R -4.200, F 3.123)]  [G loss: -2.612] \n",
      "3622 [D loss: (-0.717)(R -4.294, F 2.860)]  [G loss: -2.764] \n",
      "3623 [D loss: (-0.753)(R -4.273, F 2.767)]  [G loss: -2.742] \n",
      "3623 [D loss: (-0.694)(R -4.289, F 2.900)]  [G loss: -2.814] \n",
      "3624 [D loss: (-0.567)(R -4.189, F 3.055)]  [G loss: -2.856] \n",
      "3624 [D loss: (-0.701)(R -4.409, F 3.008)]  [G loss: -2.957] \n",
      "3625 [D loss: (-0.727)(R -4.533, F 3.078)]  [G loss: -3.101] \n",
      "3625 [D loss: (-0.724)(R -4.488, F 3.041)]  [G loss: -3.067] \n",
      "3626 [D loss: (-0.834)(R -4.493, F 2.825)]  [G loss: -2.865] \n",
      "3626 [D loss: (-0.677)(R -4.422, F 3.067)]  [G loss: -2.965] \n",
      "3627 [D loss: (-0.544)(R -4.498, F 3.410)]  [G loss: -3.032] \n",
      "3627 [D loss: (-0.841)(R -4.675, F 2.993)]  [G loss: -3.113] \n",
      "3628 [D loss: (-0.722)(R -4.551, F 3.107)]  [G loss: -2.926] \n",
      "3628 [D loss: (-0.661)(R -4.737, F 3.414)]  [G loss: -3.037] \n",
      "3629 [D loss: (-0.804)(R -4.571, F 2.963)]  [G loss: -3.115] \n",
      "3629 [D loss: (-0.712)(R -4.682, F 3.258)]  [G loss: -3.104] \n",
      "3630 [D loss: (-0.709)(R -4.644, F 3.226)]  [G loss: -3.132] \n",
      "3630 [D loss: (-0.796)(R -4.644, F 3.052)]  [G loss: -3.310] \n",
      "3631 [D loss: (-0.737)(R -4.649, F 3.175)]  [G loss: -3.041] \n",
      "3631 [D loss: (-0.806)(R -4.708, F 3.096)]  [G loss: -2.955] \n",
      "3632 [D loss: (-0.634)(R -4.785, F 3.516)]  [G loss: -3.046] \n",
      "3632 [D loss: (-0.737)(R -4.599, F 3.124)]  [G loss: -3.223] \n",
      "3633 [D loss: (-0.909)(R -4.657, F 2.839)]  [G loss: -3.023] \n",
      "3633 [D loss: (-0.762)(R -4.527, F 3.003)]  [G loss: -3.194] \n",
      "3634 [D loss: (-0.807)(R -4.540, F 2.927)]  [G loss: -3.024] \n",
      "3634 [D loss: (-0.700)(R -4.500, F 3.100)]  [G loss: -3.061] \n",
      "3635 [D loss: (-0.646)(R -4.481, F 3.188)]  [G loss: -2.986] \n",
      "3635 [D loss: (-0.799)(R -4.601, F 3.003)]  [G loss: -3.116] \n",
      "3636 [D loss: (-0.730)(R -4.573, F 3.113)]  [G loss: -3.115] \n",
      "3636 [D loss: (-0.725)(R -4.556, F 3.106)]  [G loss: -2.971] \n",
      "3637 [D loss: (-0.862)(R -4.713, F 2.989)]  [G loss: -3.011] \n",
      "3637 [D loss: (-0.877)(R -4.706, F 2.952)]  [G loss: -3.152] \n",
      "3638 [D loss: (-0.632)(R -4.609, F 3.345)]  [G loss: -3.155] \n",
      "3638 [D loss: (-0.761)(R -4.679, F 3.156)]  [G loss: -3.266] \n",
      "3639 [D loss: (-0.657)(R -4.615, F 3.302)]  [G loss: -3.331] \n",
      "3639 [D loss: (-0.853)(R -4.795, F 3.088)]  [G loss: -3.135] \n",
      "3640 [D loss: (-0.694)(R -4.771, F 3.383)]  [G loss: -3.048] \n",
      "3640 [D loss: (-0.885)(R -4.729, F 2.958)]  [G loss: -3.194] \n",
      "3641 [D loss: (-0.869)(R -4.623, F 2.885)]  [G loss: -3.279] \n",
      "3641 [D loss: (-0.641)(R -4.724, F 3.442)]  [G loss: -3.209] \n",
      "3642 [D loss: (-0.794)(R -4.740, F 3.152)]  [G loss: -3.192] \n",
      "3642 [D loss: (-0.738)(R -4.698, F 3.222)]  [G loss: -3.022] \n",
      "3643 [D loss: (-0.847)(R -4.825, F 3.130)]  [G loss: -3.115] \n",
      "3643 [D loss: (-0.656)(R -4.767, F 3.455)]  [G loss: -3.195] \n",
      "3644 [D loss: (-0.752)(R -4.782, F 3.278)]  [G loss: -3.022] \n",
      "3644 [D loss: (-0.868)(R -4.715, F 2.980)]  [G loss: -3.164] \n",
      "3645 [D loss: (-0.752)(R -4.636, F 3.131)]  [G loss: -3.058] \n",
      "3645 [D loss: (-0.755)(R -4.646, F 3.136)]  [G loss: -3.068] \n",
      "3646 [D loss: (-0.970)(R -4.758, F 2.818)]  [G loss: -3.234] \n",
      "3646 [D loss: (-0.711)(R -4.597, F 3.175)]  [G loss: -2.982] \n",
      "3647 [D loss: (-0.969)(R -4.547, F 2.608)]  [G loss: -3.107] \n",
      "3647 [D loss: (-1.013)(R -4.791, F 2.765)]  [G loss: -2.985] \n",
      "3648 [D loss: (-0.786)(R -4.601, F 3.030)]  [G loss: -3.093] \n",
      "3648 [D loss: (-0.679)(R -4.668, F 3.309)]  [G loss: -2.939] \n",
      "3649 [D loss: (-0.680)(R -4.774, F 3.415)]  [G loss: -3.174] \n",
      "3649 [D loss: (-0.833)(R -4.903, F 3.238)]  [G loss: -3.202] \n",
      "3650 [D loss: (-0.849)(R -4.792, F 3.094)]  [G loss: -3.156] \n",
      "3650 [D loss: (-0.617)(R -4.669, F 3.435)]  [G loss: -3.178] \n",
      "3651 [D loss: (-0.618)(R -4.693, F 3.458)]  [G loss: -3.340] \n",
      "3651 [D loss: (-0.759)(R -4.743, F 3.225)]  [G loss: -3.336] \n",
      "3652 [D loss: (-0.652)(R -4.939, F 3.635)]  [G loss: -3.304] \n",
      "3652 [D loss: (-0.912)(R -4.824, F 3.001)]  [G loss: -3.338] \n",
      "3653 [D loss: (-0.899)(R -5.008, F 3.211)]  [G loss: -3.297] \n",
      "3653 [D loss: (-0.515)(R -4.870, F 3.839)]  [G loss: -3.507] \n",
      "3654 [D loss: (-0.767)(R -4.970, F 3.437)]  [G loss: -3.475] \n",
      "3654 [D loss: (-0.728)(R -4.998, F 3.543)]  [G loss: -3.345] \n",
      "3655 [D loss: (-0.701)(R -4.830, F 3.429)]  [G loss: -3.159] \n",
      "3655 [D loss: (-0.782)(R -4.924, F 3.359)]  [G loss: -3.393] \n",
      "3656 [D loss: (-0.815)(R -4.920, F 3.290)]  [G loss: -3.108] \n",
      "3656 [D loss: (-0.828)(R -4.863, F 3.207)]  [G loss: -3.389] \n",
      "3657 [D loss: (-0.682)(R -4.907, F 3.544)]  [G loss: -3.361] \n",
      "3657 [D loss: (-0.792)(R -4.925, F 3.340)]  [G loss: -3.413] \n",
      "3658 [D loss: (-0.708)(R -4.867, F 3.451)]  [G loss: -3.246] \n",
      "3658 [D loss: (-0.903)(R -4.969, F 3.164)]  [G loss: -3.429] \n",
      "3659 [D loss: (-0.930)(R -4.989, F 3.129)]  [G loss: -3.222] \n",
      "3659 [D loss: (-0.835)(R -5.118, F 3.448)]  [G loss: -3.484] \n",
      "3660 [D loss: (-0.825)(R -5.001, F 3.351)]  [G loss: -3.465] \n",
      "3660 [D loss: (-0.657)(R -4.874, F 3.560)]  [G loss: -3.350] \n",
      "3661 [D loss: (-0.826)(R -5.046, F 3.395)]  [G loss: -3.421] \n",
      "3661 [D loss: (-0.675)(R -4.894, F 3.544)]  [G loss: -3.335] \n",
      "3662 [D loss: (-0.786)(R -5.068, F 3.495)]  [G loss: -3.340] \n",
      "3662 [D loss: (-0.623)(R -4.982, F 3.736)]  [G loss: -3.467] \n",
      "3663 [D loss: (-0.779)(R -5.186, F 3.628)]  [G loss: -3.672] \n",
      "3663 [D loss: (-0.839)(R -5.170, F 3.491)]  [G loss: -3.401] \n",
      "3664 [D loss: (-0.876)(R -5.157, F 3.406)]  [G loss: -3.517] \n",
      "3664 [D loss: (-0.779)(R -5.077, F 3.520)]  [G loss: -3.501] \n",
      "3665 [D loss: (-0.782)(R -5.044, F 3.481)]  [G loss: -3.496] \n",
      "3665 [D loss: (-0.752)(R -5.135, F 3.631)]  [G loss: -3.545] \n",
      "3666 [D loss: (-0.878)(R -5.137, F 3.382)]  [G loss: -3.531] \n",
      "3666 [D loss: (-0.730)(R -5.158, F 3.698)]  [G loss: -3.321] \n",
      "3667 [D loss: (-0.735)(R -5.113, F 3.644)]  [G loss: -3.481] \n",
      "3667 [D loss: (-0.658)(R -5.149, F 3.832)]  [G loss: -3.614] \n",
      "3668 [D loss: (-0.948)(R -5.197, F 3.301)]  [G loss: -3.625] \n",
      "3668 [D loss: (-0.752)(R -5.115, F 3.611)]  [G loss: -3.543] \n",
      "3669 [D loss: (-0.690)(R -4.972, F 3.592)]  [G loss: -3.414] \n",
      "3669 [D loss: (-0.503)(R -5.081, F 4.075)]  [G loss: -3.432] \n",
      "3670 [D loss: (-0.798)(R -5.135, F 3.539)]  [G loss: -3.461] \n",
      "3670 [D loss: (-0.661)(R -5.063, F 3.741)]  [G loss: -3.556] \n",
      "3671 [D loss: (-0.669)(R -5.052, F 3.714)]  [G loss: -3.207] \n",
      "3671 [D loss: (-0.833)(R -4.892, F 3.226)]  [G loss: -3.479] \n",
      "3672 [D loss: (-0.849)(R -4.941, F 3.244)]  [G loss: -3.483] \n",
      "3672 [D loss: (-0.714)(R -4.966, F 3.538)]  [G loss: -3.244] \n",
      "3673 [D loss: (-0.959)(R -5.002, F 3.084)]  [G loss: -3.202] \n",
      "3673 [D loss: (-0.740)(R -4.893, F 3.412)]  [G loss: -3.438] \n",
      "3674 [D loss: (-0.743)(R -5.099, F 3.612)]  [G loss: -3.309] \n",
      "3674 [D loss: (-0.796)(R -4.870, F 3.278)]  [G loss: -3.260] \n",
      "3675 [D loss: (-0.924)(R -5.009, F 3.161)]  [G loss: -3.466] \n",
      "3675 [D loss: (-0.787)(R -4.913, F 3.338)]  [G loss: -3.507] \n",
      "3676 [D loss: (-0.714)(R -5.033, F 3.605)]  [G loss: -3.371] \n",
      "3676 [D loss: (-0.837)(R -4.900, F 3.226)]  [G loss: -3.131] \n",
      "3677 [D loss: (-0.687)(R -4.776, F 3.402)]  [G loss: -3.320] \n",
      "3677 [D loss: (-0.981)(R -5.048, F 3.085)]  [G loss: -3.160] \n",
      "3678 [D loss: (-0.893)(R -4.876, F 3.090)]  [G loss: -3.263] \n",
      "3678 [D loss: (-0.610)(R -4.833, F 3.613)]  [G loss: -3.174] \n",
      "3679 [D loss: (-0.984)(R -4.950, F 2.983)]  [G loss: -3.290] \n",
      "3679 [D loss: (-0.972)(R -4.806, F 2.862)]  [G loss: -3.029] \n",
      "3680 [D loss: (-0.753)(R -4.719, F 3.213)]  [G loss: -3.179] \n",
      "3680 [D loss: (-0.934)(R -4.873, F 3.006)]  [G loss: -3.274] \n",
      "3681 [D loss: (-0.832)(R -4.848, F 3.184)]  [G loss: -3.182] \n",
      "3681 [D loss: (-0.831)(R -4.690, F 3.028)]  [G loss: -2.856] \n",
      "3682 [D loss: (-0.888)(R -4.683, F 2.908)]  [G loss: -3.268] \n",
      "3682 [D loss: (-0.752)(R -4.850, F 3.346)]  [G loss: -3.233] \n",
      "3683 [D loss: (-0.696)(R -4.810, F 3.418)]  [G loss: -3.131] \n",
      "3683 [D loss: (-0.847)(R -4.799, F 3.106)]  [G loss: -3.186] \n",
      "3684 [D loss: (-0.789)(R -4.783, F 3.205)]  [G loss: -3.119] \n",
      "3684 [D loss: (-0.660)(R -4.582, F 3.261)]  [G loss: -3.009] \n",
      "3685 [D loss: (-0.610)(R -4.667, F 3.447)]  [G loss: -3.277] \n",
      "3685 [D loss: (-0.703)(R -4.748, F 3.343)]  [G loss: -3.244] \n",
      "3686 [D loss: (-0.775)(R -4.805, F 3.255)]  [G loss: -3.153] \n",
      "3686 [D loss: (-0.749)(R -4.901, F 3.402)]  [G loss: -3.235] \n",
      "3687 [D loss: (-0.884)(R -4.939, F 3.170)]  [G loss: -3.150] \n",
      "3687 [D loss: (-0.883)(R -4.716, F 2.951)]  [G loss: -3.031] \n",
      "3688 [D loss: (-0.755)(R -4.870, F 3.360)]  [G loss: -3.319] \n",
      "3688 [D loss: (-0.894)(R -4.898, F 3.111)]  [G loss: -3.324] \n",
      "3689 [D loss: (-0.753)(R -4.832, F 3.326)]  [G loss: -3.168] \n",
      "3689 [D loss: (-0.802)(R -4.834, F 3.229)]  [G loss: -3.043] \n",
      "3690 [D loss: (-0.817)(R -4.969, F 3.334)]  [G loss: -3.185] \n",
      "3690 [D loss: (-0.947)(R -4.793, F 2.899)]  [G loss: -3.150] \n",
      "3691 [D loss: (-0.607)(R -4.781, F 3.567)]  [G loss: -3.226] \n",
      "3691 [D loss: (-0.876)(R -4.752, F 3.000)]  [G loss: -3.162] \n",
      "3692 [D loss: (-0.775)(R -4.709, F 3.159)]  [G loss: -3.236] \n",
      "3692 [D loss: (-0.775)(R -4.807, F 3.257)]  [G loss: -3.184] \n",
      "3693 [D loss: (-0.708)(R -4.809, F 3.393)]  [G loss: -3.071] \n",
      "3693 [D loss: (-0.902)(R -4.814, F 3.010)]  [G loss: -2.991] \n",
      "3694 [D loss: (-0.993)(R -4.770, F 2.784)]  [G loss: -2.991] \n",
      "3694 [D loss: (-0.884)(R -4.727, F 2.960)]  [G loss: -2.990] \n",
      "3695 [D loss: (-0.868)(R -4.673, F 2.937)]  [G loss: -2.925] \n",
      "3695 [D loss: (-0.769)(R -4.778, F 3.240)]  [G loss: -2.996] \n",
      "3696 [D loss: (-1.038)(R -4.898, F 2.821)]  [G loss: -3.065] \n",
      "3696 [D loss: (-0.920)(R -4.666, F 2.826)]  [G loss: -2.970] \n",
      "3697 [D loss: (-0.877)(R -4.753, F 2.999)]  [G loss: -3.216] \n",
      "3697 [D loss: (-1.011)(R -4.757, F 2.735)]  [G loss: -2.887] \n",
      "3698 [D loss: (-0.777)(R -4.758, F 3.204)]  [G loss: -3.177] \n",
      "3698 [D loss: (-0.827)(R -4.756, F 3.103)]  [G loss: -3.291] \n",
      "3699 [D loss: (-1.009)(R -4.699, F 2.680)]  [G loss: -3.023] \n",
      "3699 [D loss: (-0.847)(R -4.730, F 3.037)]  [G loss: -2.934] \n",
      "3700 [D loss: (-0.786)(R -4.616, F 3.044)]  [G loss: -2.855] \n",
      "3700 [D loss: (-0.925)(R -4.689, F 2.839)]  [G loss: -3.092] \n",
      "3701 [D loss: (-0.959)(R -4.755, F 2.836)]  [G loss: -2.983] \n",
      "3701 [D loss: (-0.725)(R -4.656, F 3.205)]  [G loss: -2.986] \n",
      "3702 [D loss: (-0.849)(R -4.479, F 2.781)]  [G loss: -3.069] \n",
      "3702 [D loss: (-0.669)(R -4.504, F 3.167)]  [G loss: -2.767] \n",
      "3703 [D loss: (-0.897)(R -4.805, F 3.011)]  [G loss: -3.032] \n",
      "3703 [D loss: (-0.674)(R -4.630, F 3.283)]  [G loss: -2.861] \n",
      "3704 [D loss: (-0.857)(R -4.787, F 3.074)]  [G loss: -3.012] \n",
      "3704 [D loss: (-0.822)(R -4.521, F 2.877)]  [G loss: -2.992] \n",
      "3705 [D loss: (-0.756)(R -4.677, F 3.164)]  [G loss: -2.852] \n",
      "3705 [D loss: (-0.827)(R -4.595, F 2.940)]  [G loss: -3.035] \n",
      "3706 [D loss: (-0.687)(R -4.512, F 3.138)]  [G loss: -3.110] \n",
      "3706 [D loss: (-0.819)(R -4.764, F 3.127)]  [G loss: -3.008] \n",
      "3707 [D loss: (-0.936)(R -4.812, F 2.940)]  [G loss: -2.909] \n",
      "3707 [D loss: (-0.920)(R -4.766, F 2.927)]  [G loss: -3.012] \n",
      "3708 [D loss: (-0.883)(R -4.687, F 2.922)]  [G loss: -2.988] \n",
      "3708 [D loss: (-0.858)(R -4.563, F 2.848)]  [G loss: -2.946] \n",
      "3709 [D loss: (-0.941)(R -4.539, F 2.657)]  [G loss: -3.005] \n",
      "3709 [D loss: (-0.668)(R -4.688, F 3.353)]  [G loss: -2.896] \n",
      "3710 [D loss: (-0.632)(R -4.687, F 3.423)]  [G loss: -2.980] \n",
      "3710 [D loss: (-0.787)(R -4.693, F 3.119)]  [G loss: -2.891] \n",
      "3711 [D loss: (-0.999)(R -4.905, F 2.907)]  [G loss: -3.046] \n",
      "3711 [D loss: (-1.040)(R -4.650, F 2.571)]  [G loss: -2.919] \n",
      "3712 [D loss: (-0.809)(R -4.798, F 3.180)]  [G loss: -3.101] \n",
      "3712 [D loss: (-0.885)(R -4.629, F 2.859)]  [G loss: -3.064] \n",
      "3713 [D loss: (-0.813)(R -4.709, F 3.082)]  [G loss: -2.886] \n",
      "3713 [D loss: (-0.980)(R -4.594, F 2.634)]  [G loss: -2.941] \n",
      "3714 [D loss: (-0.941)(R -4.784, F 2.903)]  [G loss: -3.155] \n",
      "3714 [D loss: (-1.041)(R -4.572, F 2.489)]  [G loss: -2.792] \n",
      "3715 [D loss: (-0.816)(R -4.594, F 2.963)]  [G loss: -2.838] \n",
      "3715 [D loss: (-0.914)(R -4.691, F 2.864)]  [G loss: -2.908] \n",
      "3716 [D loss: (-0.776)(R -4.456, F 2.905)]  [G loss: -2.957] \n",
      "3716 [D loss: (-0.943)(R -4.625, F 2.739)]  [G loss: -2.934] \n",
      "3717 [D loss: (-0.995)(R -4.639, F 2.649)]  [G loss: -2.761] \n",
      "3717 [D loss: (-0.842)(R -4.485, F 2.801)]  [G loss: -2.913] \n",
      "3718 [D loss: (-0.719)(R -4.608, F 3.169)]  [G loss: -2.695] \n",
      "3718 [D loss: (-0.953)(R -4.497, F 2.591)]  [G loss: -2.774] \n",
      "3719 [D loss: (-0.964)(R -4.699, F 2.771)]  [G loss: -2.651] \n",
      "3719 [D loss: (-0.849)(R -4.626, F 2.927)]  [G loss: -2.887] \n",
      "3720 [D loss: (-0.794)(R -4.442, F 2.853)]  [G loss: -2.747] \n",
      "3720 [D loss: (-0.827)(R -4.416, F 2.761)]  [G loss: -2.807] \n",
      "3721 [D loss: (-0.951)(R -4.479, F 2.578)]  [G loss: -2.769] \n",
      "3721 [D loss: (-0.806)(R -4.355, F 2.742)]  [G loss: -2.823] \n",
      "3722 [D loss: (-0.874)(R -4.355, F 2.608)]  [G loss: -2.473] \n",
      "3722 [D loss: (-0.745)(R -4.474, F 2.984)]  [G loss: -2.722] \n",
      "3723 [D loss: (-1.034)(R -4.476, F 2.407)]  [G loss: -2.709] \n",
      "3723 [D loss: (-0.740)(R -4.390, F 2.910)]  [G loss: -2.685] \n",
      "3724 [D loss: (-0.749)(R -4.472, F 2.974)]  [G loss: -2.723] \n",
      "3724 [D loss: (-1.001)(R -4.416, F 2.414)]  [G loss: -2.728] \n",
      "3725 [D loss: (-0.900)(R -4.491, F 2.691)]  [G loss: -2.884] \n",
      "3725 [D loss: (-0.967)(R -4.634, F 2.701)]  [G loss: -2.688] \n",
      "3726 [D loss: (-0.725)(R -4.380, F 2.929)]  [G loss: -2.660] \n",
      "3726 [D loss: (-0.751)(R -4.311, F 2.809)]  [G loss: -2.876] \n",
      "3727 [D loss: (-0.838)(R -4.540, F 2.863)]  [G loss: -2.864] \n",
      "3727 [D loss: (-1.057)(R -4.485, F 2.372)]  [G loss: -2.783] \n",
      "3728 [D loss: (-0.853)(R -4.403, F 2.696)]  [G loss: -2.715] \n",
      "3728 [D loss: (-0.868)(R -4.704, F 2.967)]  [G loss: -2.568] \n",
      "3729 [D loss: (-0.888)(R -4.493, F 2.718)]  [G loss: -2.677] \n",
      "3729 [D loss: (-0.950)(R -4.636, F 2.736)]  [G loss: -2.512] \n",
      "3730 [D loss: (-0.948)(R -4.408, F 2.511)]  [G loss: -2.666] \n",
      "3730 [D loss: (-0.960)(R -4.332, F 2.412)]  [G loss: -2.785] \n",
      "3731 [D loss: (-0.603)(R -4.400, F 3.195)]  [G loss: -2.834] \n",
      "3731 [D loss: (-1.049)(R -4.554, F 2.455)]  [G loss: -2.684] \n",
      "3732 [D loss: (-0.678)(R -4.415, F 3.058)]  [G loss: -2.921] \n",
      "3732 [D loss: (-0.817)(R -4.563, F 2.929)]  [G loss: -2.624] \n",
      "3733 [D loss: (-0.859)(R -4.625, F 2.906)]  [G loss: -2.936] \n",
      "3733 [D loss: (-1.061)(R -4.540, F 2.418)]  [G loss: -2.732] \n",
      "3734 [D loss: (-0.794)(R -4.513, F 2.926)]  [G loss: -2.767] \n",
      "3734 [D loss: (-0.872)(R -4.665, F 2.922)]  [G loss: -2.819] \n",
      "3735 [D loss: (-0.804)(R -4.784, F 3.176)]  [G loss: -2.839] \n",
      "3735 [D loss: (-1.016)(R -4.704, F 2.672)]  [G loss: -2.778] \n",
      "3736 [D loss: (-0.805)(R -4.530, F 2.920)]  [G loss: -3.157] \n",
      "3736 [D loss: (-0.703)(R -4.643, F 3.237)]  [G loss: -2.874] \n",
      "3737 [D loss: (-0.772)(R -4.623, F 3.079)]  [G loss: -2.971] \n",
      "3737 [D loss: (-0.666)(R -4.607, F 3.275)]  [G loss: -2.916] \n",
      "3738 [D loss: (-0.768)(R -4.726, F 3.190)]  [G loss: -2.936] \n",
      "3738 [D loss: (-0.578)(R -4.716, F 3.559)]  [G loss: -3.059] \n",
      "3739 [D loss: (-0.915)(R -4.847, F 3.016)]  [G loss: -2.941] \n",
      "3739 [D loss: (-0.688)(R -4.697, F 3.321)]  [G loss: -3.047] \n",
      "3740 [D loss: (-0.970)(R -4.613, F 2.673)]  [G loss: -2.810] \n",
      "3740 [D loss: (-0.783)(R -4.689, F 3.122)]  [G loss: -2.907] \n",
      "3741 [D loss: (-0.931)(R -4.815, F 2.952)]  [G loss: -2.962] \n",
      "3741 [D loss: (-0.765)(R -4.651, F 3.120)]  [G loss: -3.032] \n",
      "3742 [D loss: (-0.872)(R -4.743, F 2.999)]  [G loss: -3.121] \n",
      "3742 [D loss: (-0.637)(R -4.491, F 3.218)]  [G loss: -3.035] \n",
      "3743 [D loss: (-0.762)(R -4.568, F 3.045)]  [G loss: -3.081] \n",
      "3743 [D loss: (-0.622)(R -4.742, F 3.498)]  [G loss: -2.741] \n",
      "3744 [D loss: (-0.842)(R -4.561, F 2.876)]  [G loss: -2.790] \n",
      "3744 [D loss: (-0.723)(R -4.627, F 3.181)]  [G loss: -3.181] \n",
      "3745 [D loss: (-0.863)(R -4.708, F 2.982)]  [G loss: -2.999] \n",
      "3745 [D loss: (-0.977)(R -4.843, F 2.889)]  [G loss: -2.802] \n",
      "3746 [D loss: (-0.911)(R -4.507, F 2.685)]  [G loss: -2.801] \n",
      "3746 [D loss: (-1.006)(R -4.806, F 2.793)]  [G loss: -2.889] \n",
      "3747 [D loss: (-0.946)(R -4.664, F 2.772)]  [G loss: -3.121] \n",
      "3747 [D loss: (-0.912)(R -4.629, F 2.804)]  [G loss: -2.772] \n",
      "3748 [D loss: (-0.764)(R -4.489, F 2.962)]  [G loss: -2.873] \n",
      "3748 [D loss: (-0.756)(R -4.500, F 2.988)]  [G loss: -2.845] \n",
      "3749 [D loss: (-1.169)(R -4.600, F 2.262)]  [G loss: -2.948] \n",
      "3749 [D loss: (-0.851)(R -4.687, F 2.986)]  [G loss: -2.847] \n",
      "3750 [D loss: (-0.968)(R -4.490, F 2.554)]  [G loss: -2.615] \n",
      "3750 [D loss: (-0.961)(R -4.536, F 2.613)]  [G loss: -2.701] \n",
      "3751 [D loss: (-1.028)(R -4.514, F 2.458)]  [G loss: -2.741] \n",
      "3751 [D loss: (-0.684)(R -4.330, F 2.962)]  [G loss: -2.576] \n",
      "3752 [D loss: (-0.998)(R -4.553, F 2.557)]  [G loss: -2.404] \n",
      "3752 [D loss: (-0.901)(R -4.376, F 2.574)]  [G loss: -2.730] \n",
      "3753 [D loss: (-0.921)(R -4.625, F 2.783)]  [G loss: -2.905] \n",
      "3753 [D loss: (-0.841)(R -4.374, F 2.693)]  [G loss: -2.514] \n",
      "3754 [D loss: (-0.714)(R -4.312, F 2.884)]  [G loss: -2.680] \n",
      "3754 [D loss: (-0.718)(R -4.433, F 2.996)]  [G loss: -2.687] \n",
      "3755 [D loss: (-0.858)(R -4.136, F 2.420)]  [G loss: -2.797] \n",
      "3755 [D loss: (-0.929)(R -4.423, F 2.564)]  [G loss: -2.547] \n",
      "3756 [D loss: (-0.968)(R -4.460, F 2.524)]  [G loss: -2.762] \n",
      "3756 [D loss: (-1.026)(R -4.390, F 2.338)]  [G loss: -2.904] \n",
      "3757 [D loss: (-0.894)(R -4.267, F 2.478)]  [G loss: -2.634] \n",
      "3757 [D loss: (-1.040)(R -4.334, F 2.255)]  [G loss: -2.672] \n",
      "3758 [D loss: (-0.809)(R -4.340, F 2.722)]  [G loss: -2.545] \n",
      "3758 [D loss: (-0.694)(R -4.281, F 2.894)]  [G loss: -2.528] \n",
      "3759 [D loss: (-0.953)(R -4.399, F 2.494)]  [G loss: -2.759] \n",
      "3759 [D loss: (-0.992)(R -4.319, F 2.334)]  [G loss: -2.818] \n",
      "3760 [D loss: (-0.760)(R -4.377, F 2.858)]  [G loss: -2.518] \n",
      "3760 [D loss: (-1.020)(R -4.475, F 2.434)]  [G loss: -2.595] \n",
      "3761 [D loss: (-0.817)(R -4.507, F 2.874)]  [G loss: -2.624] \n",
      "3761 [D loss: (-1.084)(R -4.423, F 2.255)]  [G loss: -2.746] \n",
      "3762 [D loss: (-0.908)(R -4.363, F 2.547)]  [G loss: -2.522] \n",
      "3762 [D loss: (-1.133)(R -4.499, F 2.234)]  [G loss: -2.355] \n",
      "3763 [D loss: (-0.968)(R -4.187, F 2.252)]  [G loss: -2.542] \n",
      "3763 [D loss: (-0.780)(R -4.368, F 2.808)]  [G loss: -2.798] \n",
      "3764 [D loss: (-0.690)(R -4.370, F 2.990)]  [G loss: -2.564] \n",
      "3764 [D loss: (-1.150)(R -4.561, F 2.261)]  [G loss: -2.541] \n",
      "3765 [D loss: (-0.911)(R -4.193, F 2.370)]  [G loss: -2.429] \n",
      "3765 [D loss: (-0.925)(R -4.402, F 2.551)]  [G loss: -2.521] \n",
      "3766 [D loss: (-0.758)(R -4.243, F 2.728)]  [G loss: -2.698] \n",
      "3766 [D loss: (-0.682)(R -4.345, F 2.981)]  [G loss: -2.593] \n",
      "3767 [D loss: (-0.746)(R -4.089, F 2.596)]  [G loss: -2.306] \n",
      "3767 [D loss: (-0.831)(R -4.423, F 2.760)]  [G loss: -2.723] \n",
      "3768 [D loss: (-0.826)(R -4.428, F 2.776)]  [G loss: -2.748] \n",
      "3768 [D loss: (-0.862)(R -4.531, F 2.807)]  [G loss: -2.625] \n",
      "3769 [D loss: (-0.624)(R -4.446, F 3.198)]  [G loss: -2.762] \n",
      "3769 [D loss: (-0.909)(R -4.565, F 2.747)]  [G loss: -2.893] \n",
      "3770 [D loss: (-1.181)(R -4.281, F 1.919)]  [G loss: -2.824] \n",
      "3770 [D loss: (-0.826)(R -4.442, F 2.790)]  [G loss: -2.636] \n",
      "3771 [D loss: (-0.892)(R -4.304, F 2.521)]  [G loss: -2.548] \n",
      "3771 [D loss: (-0.911)(R -4.415, F 2.592)]  [G loss: -2.577] \n",
      "3772 [D loss: (-0.803)(R -4.463, F 2.857)]  [G loss: -2.417] \n",
      "3772 [D loss: (-0.814)(R -4.254, F 2.626)]  [G loss: -2.241] \n",
      "3773 [D loss: (-0.734)(R -4.290, F 2.823)]  [G loss: -2.647] \n",
      "3773 [D loss: (-1.090)(R -4.381, F 2.201)]  [G loss: -2.645] \n",
      "3774 [D loss: (-1.170)(R -4.452, F 2.113)]  [G loss: -2.653] \n",
      "3774 [D loss: (-1.119)(R -4.497, F 2.260)]  [G loss: -2.537] \n",
      "3775 [D loss: (-0.869)(R -4.271, F 2.533)]  [G loss: -2.345] \n",
      "3775 [D loss: (-0.822)(R -4.323, F 2.678)]  [G loss: -2.557] \n",
      "3776 [D loss: (-0.831)(R -4.489, F 2.828)]  [G loss: -2.541] \n",
      "3776 [D loss: (-0.866)(R -4.390, F 2.659)]  [G loss: -2.581] \n",
      "3777 [D loss: (-0.819)(R -4.439, F 2.802)]  [G loss: -2.601] \n",
      "3777 [D loss: (-1.084)(R -4.404, F 2.237)]  [G loss: -2.498] \n",
      "3778 [D loss: (-0.900)(R -4.290, F 2.490)]  [G loss: -2.385] \n",
      "3778 [D loss: (-1.171)(R -4.136, F 1.795)]  [G loss: -2.364] \n",
      "3779 [D loss: (-0.811)(R -4.133, F 2.511)]  [G loss: -2.316] \n",
      "3779 [D loss: (-0.642)(R -4.119, F 2.835)]  [G loss: -2.443] \n",
      "3780 [D loss: (-1.010)(R -4.300, F 2.279)]  [G loss: -2.377] \n",
      "3780 [D loss: (-0.764)(R -4.160, F 2.632)]  [G loss: -2.223] \n",
      "3781 [D loss: (-0.877)(R -4.166, F 2.413)]  [G loss: -2.647] \n",
      "3781 [D loss: (-0.888)(R -4.216, F 2.439)]  [G loss: -2.441] \n",
      "3782 [D loss: (-0.442)(R -4.151, F 3.266)]  [G loss: -2.482] \n",
      "3782 [D loss: (-0.918)(R -4.221, F 2.385)]  [G loss: -2.518] \n",
      "3783 [D loss: (-0.680)(R -4.282, F 2.921)]  [G loss: -2.627] \n",
      "3783 [D loss: (-0.913)(R -4.461, F 2.635)]  [G loss: -2.477] \n",
      "3784 [D loss: (-0.809)(R -4.385, F 2.767)]  [G loss: -2.678] \n",
      "3784 [D loss: (-0.720)(R -4.293, F 2.853)]  [G loss: -2.546] \n",
      "3785 [D loss: (-1.120)(R -4.668, F 2.429)]  [G loss: -2.898] \n",
      "3785 [D loss: (-0.568)(R -4.292, F 3.156)]  [G loss: -2.718] \n",
      "3786 [D loss: (-0.749)(R -4.475, F 2.978)]  [G loss: -2.791] \n",
      "3786 [D loss: (-1.151)(R -4.512, F 2.211)]  [G loss: -2.897] \n",
      "3787 [D loss: (-0.786)(R -4.356, F 2.784)]  [G loss: -2.731] \n",
      "3787 [D loss: (-0.848)(R -4.449, F 2.753)]  [G loss: -2.600] \n",
      "3788 [D loss: (-0.706)(R -4.363, F 2.952)]  [G loss: -2.696] \n",
      "3788 [D loss: (-0.841)(R -4.457, F 2.775)]  [G loss: -2.887] \n",
      "3789 [D loss: (-1.120)(R -4.768, F 2.528)]  [G loss: -2.967] \n",
      "3789 [D loss: (-0.754)(R -4.619, F 3.112)]  [G loss: -2.894] \n",
      "3790 [D loss: (-1.093)(R -4.645, F 2.459)]  [G loss: -2.904] \n",
      "3790 [D loss: (-0.686)(R -4.724, F 3.351)]  [G loss: -2.786] \n",
      "3791 [D loss: (-0.765)(R -4.491, F 2.961)]  [G loss: -2.800] \n",
      "3791 [D loss: (-0.722)(R -4.431, F 2.987)]  [G loss: -2.973] \n",
      "3792 [D loss: (-0.829)(R -4.495, F 2.836)]  [G loss: -2.763] \n",
      "3792 [D loss: (-0.745)(R -4.711, F 3.221)]  [G loss: -3.060] \n",
      "3793 [D loss: (-0.679)(R -4.549, F 3.190)]  [G loss: -2.955] \n",
      "3793 [D loss: (-0.682)(R -4.607, F 3.243)]  [G loss: -2.772] \n",
      "3794 [D loss: (-0.969)(R -4.612, F 2.673)]  [G loss: -2.800] \n",
      "3794 [D loss: (-0.860)(R -4.385, F 2.665)]  [G loss: -2.663] \n",
      "3795 [D loss: (-0.700)(R -4.548, F 3.148)]  [G loss: -2.804] \n",
      "3795 [D loss: (-0.973)(R -4.769, F 2.822)]  [G loss: -2.956] \n",
      "3796 [D loss: (-1.060)(R -4.613, F 2.493)]  [G loss: -2.843] \n",
      "3796 [D loss: (-0.779)(R -4.528, F 2.970)]  [G loss: -2.817] \n",
      "3797 [D loss: (-0.647)(R -4.516, F 3.222)]  [G loss: -2.856] \n",
      "3797 [D loss: (-0.995)(R -4.583, F 2.592)]  [G loss: -2.793] \n",
      "3798 [D loss: (-0.807)(R -4.543, F 2.930)]  [G loss: -2.968] \n",
      "3798 [D loss: (-0.614)(R -4.475, F 3.247)]  [G loss: -2.954] \n",
      "3799 [D loss: (-0.768)(R -4.623, F 3.087)]  [G loss: -3.026] \n",
      "3799 [D loss: (-0.914)(R -4.662, F 2.834)]  [G loss: -2.947] \n",
      "3800 [D loss: (-1.124)(R -4.615, F 2.366)]  [G loss: -2.979] \n",
      "3800 [D loss: (-0.997)(R -4.716, F 2.723)]  [G loss: -2.747] \n",
      "3801 [D loss: (-0.961)(R -4.541, F 2.618)]  [G loss: -2.596] \n",
      "3801 [D loss: (-0.778)(R -4.592, F 3.036)]  [G loss: -2.803] \n",
      "3802 [D loss: (-0.725)(R -4.267, F 2.818)]  [G loss: -2.890] \n",
      "3802 [D loss: (-0.829)(R -4.561, F 2.904)]  [G loss: -2.717] \n",
      "3803 [D loss: (-0.983)(R -4.310, F 2.343)]  [G loss: -2.808] \n",
      "3803 [D loss: (-0.922)(R -4.159, F 2.315)]  [G loss: -2.547] \n",
      "3804 [D loss: (-0.976)(R -4.363, F 2.411)]  [G loss: -2.732] \n",
      "3804 [D loss: (-0.847)(R -4.512, F 2.817)]  [G loss: -2.944] \n",
      "3805 [D loss: (-0.768)(R -4.307, F 2.771)]  [G loss: -2.867] \n",
      "3805 [D loss: (-0.733)(R -4.411, F 2.945)]  [G loss: -2.792] \n",
      "3806 [D loss: (-0.884)(R -4.555, F 2.787)]  [G loss: -2.626] \n",
      "3806 [D loss: (-0.767)(R -4.440, F 2.906)]  [G loss: -2.649] \n",
      "3807 [D loss: (-0.884)(R -4.491, F 2.723)]  [G loss: -2.678] \n",
      "3807 [D loss: (-0.922)(R -4.441, F 2.596)]  [G loss: -2.649] \n",
      "3808 [D loss: (-0.973)(R -4.442, F 2.495)]  [G loss: -2.903] \n",
      "3808 [D loss: (-0.665)(R -4.301, F 2.970)]  [G loss: -2.894] \n",
      "3809 [D loss: (-0.985)(R -4.361, F 2.392)]  [G loss: -2.711] \n",
      "3809 [D loss: (-0.809)(R -4.437, F 2.820)]  [G loss: -2.526] \n",
      "3810 [D loss: (-0.610)(R -4.256, F 3.036)]  [G loss: -2.507] \n",
      "3810 [D loss: (-0.946)(R -4.427, F 2.535)]  [G loss: -2.599] \n",
      "3811 [D loss: (-0.982)(R -4.303, F 2.339)]  [G loss: -2.722] \n",
      "3811 [D loss: (-0.774)(R -3.890, F 2.343)]  [G loss: -2.453] \n",
      "3812 [D loss: (-0.888)(R -4.216, F 2.440)]  [G loss: -2.676] \n",
      "3812 [D loss: (-1.155)(R -4.416, F 2.106)]  [G loss: -2.743] \n",
      "3813 [D loss: (-0.913)(R -4.188, F 2.361)]  [G loss: -2.640] \n",
      "3813 [D loss: (-0.818)(R -4.431, F 2.796)]  [G loss: -2.606] \n",
      "3814 [D loss: (-0.806)(R -4.366, F 2.754)]  [G loss: -2.488] \n",
      "3814 [D loss: (-0.915)(R -4.380, F 2.550)]  [G loss: -2.661] \n",
      "3815 [D loss: (-0.776)(R -4.257, F 2.705)]  [G loss: -2.684] \n",
      "3815 [D loss: (-0.857)(R -4.309, F 2.596)]  [G loss: -2.552] \n",
      "3816 [D loss: (-0.719)(R -4.118, F 2.679)]  [G loss: -2.561] \n",
      "3816 [D loss: (-1.019)(R -4.553, F 2.515)]  [G loss: -2.326] \n",
      "3817 [D loss: (-0.752)(R -4.165, F 2.661)]  [G loss: -2.487] \n",
      "3817 [D loss: (-0.879)(R -3.967, F 2.208)]  [G loss: -2.389] \n",
      "3818 [D loss: (-0.545)(R -4.080, F 2.991)]  [G loss: -2.158] \n",
      "3818 [D loss: (-0.711)(R -3.824, F 2.402)]  [G loss: -2.522] \n",
      "3819 [D loss: (-1.019)(R -4.306, F 2.268)]  [G loss: -2.357] \n",
      "3819 [D loss: (-0.967)(R -4.098, F 2.165)]  [G loss: -2.348] \n",
      "3820 [D loss: (-0.888)(R -4.009, F 2.233)]  [G loss: -2.425] \n",
      "3820 [D loss: (-0.572)(R -3.888, F 2.744)]  [G loss: -2.437] \n",
      "3821 [D loss: (-0.760)(R -4.256, F 2.736)]  [G loss: -2.380] \n",
      "3821 [D loss: (-0.751)(R -3.875, F 2.373)]  [G loss: -2.286] \n",
      "3822 [D loss: (-1.025)(R -4.198, F 2.147)]  [G loss: -2.443] \n",
      "3822 [D loss: (-0.914)(R -3.993, F 2.165)]  [G loss: -2.349] \n",
      "3823 [D loss: (-0.901)(R -4.036, F 2.234)]  [G loss: -2.313] \n",
      "3823 [D loss: (-1.044)(R -4.186, F 2.097)]  [G loss: -2.143] \n",
      "3824 [D loss: (-0.903)(R -4.116, F 2.310)]  [G loss: -2.320] \n",
      "3824 [D loss: (-0.877)(R -3.946, F 2.193)]  [G loss: -2.336] \n",
      "3825 [D loss: (-0.672)(R -4.068, F 2.723)]  [G loss: -2.333] \n",
      "3825 [D loss: (-0.808)(R -4.172, F 2.556)]  [G loss: -2.376] \n",
      "3826 [D loss: (-1.085)(R -4.427, F 2.257)]  [G loss: -2.263] \n",
      "3826 [D loss: (-0.636)(R -4.147, F 2.876)]  [G loss: -2.234] \n",
      "3827 [D loss: (-0.910)(R -4.384, F 2.564)]  [G loss: -2.465] \n",
      "3827 [D loss: (-0.594)(R -4.097, F 2.909)]  [G loss: -2.324] \n",
      "3828 [D loss: (-0.864)(R -4.258, F 2.529)]  [G loss: -2.602] \n",
      "3828 [D loss: (-0.855)(R -4.237, F 2.528)]  [G loss: -2.477] \n",
      "3829 [D loss: (-0.771)(R -4.401, F 2.859)]  [G loss: -2.466] \n",
      "3829 [D loss: (-1.148)(R -4.165, F 1.870)]  [G loss: -2.303] \n",
      "3830 [D loss: (-0.894)(R -4.365, F 2.577)]  [G loss: -2.543] \n",
      "3830 [D loss: (-0.829)(R -4.131, F 2.473)]  [G loss: -2.593] \n",
      "3831 [D loss: (-0.817)(R -4.145, F 2.511)]  [G loss: -2.463] \n",
      "3831 [D loss: (-0.611)(R -4.335, F 3.114)]  [G loss: -2.622] \n",
      "3832 [D loss: (-1.124)(R -4.410, F 2.161)]  [G loss: -2.720] \n",
      "3832 [D loss: (-0.925)(R -4.640, F 2.790)]  [G loss: -2.521] \n",
      "3833 [D loss: (-0.979)(R -4.395, F 2.436)]  [G loss: -2.714] \n",
      "3833 [D loss: (-0.849)(R -4.491, F 2.792)]  [G loss: -2.676] \n",
      "3834 [D loss: (-0.864)(R -4.414, F 2.685)]  [G loss: -2.578] \n",
      "3834 [D loss: (-0.849)(R -4.681, F 2.984)]  [G loss: -2.444] \n",
      "3835 [D loss: (-0.883)(R -4.232, F 2.466)]  [G loss: -2.635] \n",
      "3835 [D loss: (-1.189)(R -4.637, F 2.259)]  [G loss: -2.729] \n",
      "3836 [D loss: (-0.828)(R -4.265, F 2.609)]  [G loss: -2.587] \n",
      "3836 [D loss: (-0.875)(R -4.285, F 2.534)]  [G loss: -2.413] \n",
      "3837 [D loss: (-0.595)(R -4.178, F 2.988)]  [G loss: -2.484] \n",
      "3837 [D loss: (-0.664)(R -4.092, F 2.764)]  [G loss: -2.783] \n",
      "3838 [D loss: (-0.886)(R -4.384, F 2.612)]  [G loss: -2.461] \n",
      "3838 [D loss: (-0.632)(R -4.259, F 2.995)]  [G loss: -2.650] \n",
      "3839 [D loss: (-0.984)(R -4.432, F 2.464)]  [G loss: -2.639] \n",
      "3839 [D loss: (-0.996)(R -4.200, F 2.208)]  [G loss: -2.631] \n",
      "3840 [D loss: (-0.859)(R -4.203, F 2.485)]  [G loss: -2.529] \n",
      "3840 [D loss: (-0.856)(R -4.299, F 2.587)]  [G loss: -2.753] \n",
      "3841 [D loss: (-0.916)(R -4.375, F 2.544)]  [G loss: -2.608] \n",
      "3841 [D loss: (-0.920)(R -4.309, F 2.469)]  [G loss: -2.686] \n",
      "3842 [D loss: (-0.835)(R -4.175, F 2.504)]  [G loss: -2.713] \n",
      "3842 [D loss: (-0.627)(R -4.233, F 2.979)]  [G loss: -2.442] \n",
      "3843 [D loss: (-0.887)(R -4.386, F 2.612)]  [G loss: -2.626] \n",
      "3843 [D loss: (-0.931)(R -4.064, F 2.203)]  [G loss: -2.438] \n",
      "3844 [D loss: (-0.707)(R -4.131, F 2.717)]  [G loss: -2.532] \n",
      "3844 [D loss: (-0.787)(R -4.415, F 2.841)]  [G loss: -2.566] \n",
      "3845 [D loss: (-0.854)(R -4.208, F 2.501)]  [G loss: -2.373] \n",
      "3845 [D loss: (-0.823)(R -4.236, F 2.589)]  [G loss: -2.641] \n",
      "3846 [D loss: (-0.801)(R -4.188, F 2.586)]  [G loss: -2.415] \n",
      "3846 [D loss: (-1.160)(R -4.259, F 1.939)]  [G loss: -2.349] \n",
      "3847 [D loss: (-0.866)(R -4.110, F 2.378)]  [G loss: -2.543] \n",
      "3847 [D loss: (-0.986)(R -4.146, F 2.173)]  [G loss: -2.380] \n",
      "3848 [D loss: (-0.730)(R -4.192, F 2.731)]  [G loss: -2.273] \n",
      "3848 [D loss: (-1.067)(R -4.085, F 1.951)]  [G loss: -2.223] \n",
      "3849 [D loss: (-0.813)(R -4.404, F 2.777)]  [G loss: -2.528] \n",
      "3849 [D loss: (-1.185)(R -4.364, F 1.993)]  [G loss: -2.545] \n",
      "3850 [D loss: (-0.760)(R -4.034, F 2.514)]  [G loss: -2.348] \n",
      "3850 [D loss: (-0.771)(R -4.228, F 2.685)]  [G loss: -2.644] \n",
      "3851 [D loss: (-1.053)(R -4.069, F 1.962)]  [G loss: -2.451] \n",
      "3851 [D loss: (-0.891)(R -3.948, F 2.165)]  [G loss: -2.415] \n",
      "3852 [D loss: (-0.751)(R -4.151, F 2.650)]  [G loss: -2.402] \n",
      "3852 [D loss: (-0.903)(R -4.214, F 2.408)]  [G loss: -2.310] \n",
      "3853 [D loss: (-1.058)(R -4.298, F 2.182)]  [G loss: -2.274] \n",
      "3853 [D loss: (-0.578)(R -4.109, F 2.954)]  [G loss: -2.571] \n",
      "3854 [D loss: (-0.746)(R -4.308, F 2.815)]  [G loss: -2.426] \n",
      "3854 [D loss: (-0.715)(R -4.160, F 2.731)]  [G loss: -2.277] \n",
      "3855 [D loss: (-0.711)(R -4.052, F 2.630)]  [G loss: -2.395] \n",
      "3855 [D loss: (-0.730)(R -3.870, F 2.410)]  [G loss: -2.544] \n",
      "3856 [D loss: (-0.872)(R -4.128, F 2.385)]  [G loss: -2.360] \n",
      "3856 [D loss: (-0.716)(R -4.136, F 2.703)]  [G loss: -2.625] \n",
      "3857 [D loss: (-0.906)(R -4.220, F 2.407)]  [G loss: -2.501] \n",
      "3857 [D loss: (-0.709)(R -4.069, F 2.651)]  [G loss: -2.500] \n",
      "3858 [D loss: (-0.721)(R -4.111, F 2.668)]  [G loss: -2.502] \n",
      "3858 [D loss: (-0.765)(R -3.917, F 2.386)]  [G loss: -2.552] \n",
      "3859 [D loss: (-0.996)(R -4.443, F 2.451)]  [G loss: -2.623] \n",
      "3859 [D loss: (-0.526)(R -4.121, F 3.070)]  [G loss: -2.643] \n",
      "3860 [D loss: (-0.908)(R -4.201, F 2.384)]  [G loss: -2.717] \n",
      "3860 [D loss: (-0.800)(R -4.137, F 2.536)]  [G loss: -2.496] \n",
      "3861 [D loss: (-0.760)(R -4.154, F 2.635)]  [G loss: -2.549] \n",
      "3861 [D loss: (-0.744)(R -4.217, F 2.729)]  [G loss: -2.603] \n",
      "3862 [D loss: (-0.821)(R -4.177, F 2.534)]  [G loss: -2.306] \n",
      "3862 [D loss: (-0.876)(R -3.874, F 2.121)]  [G loss: -2.547] \n",
      "3863 [D loss: (-0.550)(R -4.148, F 3.049)]  [G loss: -2.775] \n",
      "3863 [D loss: (-0.657)(R -4.030, F 2.716)]  [G loss: -2.695] \n",
      "3864 [D loss: (-0.782)(R -4.313, F 2.749)]  [G loss: -2.363] \n",
      "3864 [D loss: (-0.790)(R -4.068, F 2.488)]  [G loss: -2.589] \n",
      "3865 [D loss: (-0.792)(R -4.361, F 2.776)]  [G loss: -2.555] \n",
      "3865 [D loss: (-1.129)(R -4.271, F 2.012)]  [G loss: -2.595] \n",
      "3866 [D loss: (-0.911)(R -4.248, F 2.426)]  [G loss: -2.775] \n",
      "3866 [D loss: (-0.888)(R -4.558, F 2.782)]  [G loss: -2.399] \n",
      "3867 [D loss: (-1.142)(R -4.348, F 2.065)]  [G loss: -2.412] \n",
      "3867 [D loss: (-0.787)(R -4.330, F 2.756)]  [G loss: -2.667] \n",
      "3868 [D loss: (-0.554)(R -4.261, F 3.152)]  [G loss: -2.528] \n",
      "3868 [D loss: (-0.716)(R -4.031, F 2.598)]  [G loss: -2.621] \n",
      "3869 [D loss: (-0.980)(R -4.090, F 2.130)]  [G loss: -2.423] \n",
      "3869 [D loss: (-0.772)(R -4.231, F 2.686)]  [G loss: -2.435] \n",
      "3870 [D loss: (-0.809)(R -4.166, F 2.548)]  [G loss: -2.558] \n",
      "3870 [D loss: (-0.992)(R -4.001, F 2.017)]  [G loss: -2.561] \n",
      "3871 [D loss: (-0.750)(R -3.913, F 2.413)]  [G loss: -2.559] \n",
      "3871 [D loss: (-0.972)(R -4.084, F 2.140)]  [G loss: -2.424] \n",
      "3872 [D loss: (-0.868)(R -4.101, F 2.366)]  [G loss: -2.503] \n",
      "3872 [D loss: (-1.037)(R -4.308, F 2.234)]  [G loss: -2.561] \n",
      "3873 [D loss: (-0.825)(R -3.987, F 2.337)]  [G loss: -2.741] \n",
      "3873 [D loss: (-0.873)(R -3.917, F 2.170)]  [G loss: -2.451] \n",
      "3874 [D loss: (-0.902)(R -4.052, F 2.249)]  [G loss: -2.684] \n",
      "3874 [D loss: (-0.912)(R -4.322, F 2.498)]  [G loss: -2.436] \n",
      "3875 [D loss: (-0.669)(R -4.039, F 2.702)]  [G loss: -2.312] \n",
      "3875 [D loss: (-1.047)(R -3.977, F 1.883)]  [G loss: -2.430] \n",
      "3876 [D loss: (-0.912)(R -3.861, F 2.037)]  [G loss: -2.753] \n",
      "3876 [D loss: (-0.727)(R -3.901, F 2.446)]  [G loss: -2.199] \n",
      "3877 [D loss: (-1.009)(R -4.001, F 1.983)]  [G loss: -2.538] \n",
      "3877 [D loss: (-1.007)(R -3.759, F 1.745)]  [G loss: -2.424] \n",
      "3878 [D loss: (-0.725)(R -3.915, F 2.465)]  [G loss: -2.392] \n",
      "3878 [D loss: (-0.874)(R -3.892, F 2.143)]  [G loss: -2.218] \n",
      "3879 [D loss: (-0.672)(R -3.954, F 2.610)]  [G loss: -2.465] \n",
      "3879 [D loss: (-0.713)(R -4.160, F 2.733)]  [G loss: -2.340] \n",
      "3880 [D loss: (-0.754)(R -3.909, F 2.400)]  [G loss: -2.389] \n",
      "3880 [D loss: (-0.643)(R -4.007, F 2.722)]  [G loss: -2.415] \n",
      "3881 [D loss: (-0.663)(R -3.958, F 2.631)]  [G loss: -2.406] \n",
      "3881 [D loss: (-0.725)(R -3.905, F 2.455)]  [G loss: -2.332] \n",
      "3882 [D loss: (-0.744)(R -3.843, F 2.354)]  [G loss: -2.173] \n",
      "3882 [D loss: (-0.964)(R -4.140, F 2.213)]  [G loss: -2.443] \n",
      "3883 [D loss: (-1.065)(R -4.071, F 1.940)]  [G loss: -2.463] \n",
      "3883 [D loss: (-0.959)(R -4.105, F 2.187)]  [G loss: -2.356] \n",
      "3884 [D loss: (-0.912)(R -4.003, F 2.179)]  [G loss: -2.564] \n",
      "3884 [D loss: (-0.825)(R -3.966, F 2.316)]  [G loss: -2.317] \n",
      "3885 [D loss: (-0.780)(R -4.061, F 2.500)]  [G loss: -2.683] \n",
      "3885 [D loss: (-0.847)(R -3.985, F 2.290)]  [G loss: -2.517] \n",
      "3886 [D loss: (-0.817)(R -3.986, F 2.352)]  [G loss: -2.543] \n",
      "3886 [D loss: (-0.441)(R -3.966, F 3.084)]  [G loss: -2.289] \n",
      "3887 [D loss: (-0.563)(R -3.783, F 2.656)]  [G loss: -2.329] \n",
      "3887 [D loss: (-0.776)(R -3.848, F 2.296)]  [G loss: -2.113] \n",
      "3888 [D loss: (-0.694)(R -3.899, F 2.512)]  [G loss: -2.108] \n",
      "3888 [D loss: (-0.592)(R -3.895, F 2.711)]  [G loss: -2.252] \n",
      "3889 [D loss: (-0.439)(R -3.828, F 2.951)]  [G loss: -2.294] \n",
      "3889 [D loss: (-0.871)(R -4.060, F 2.318)]  [G loss: -2.566] \n",
      "3890 [D loss: (-0.731)(R -4.032, F 2.570)]  [G loss: -2.228] \n",
      "3890 [D loss: (-1.009)(R -3.900, F 1.882)]  [G loss: -2.452] \n",
      "3891 [D loss: (-0.759)(R -3.898, F 2.381)]  [G loss: -2.466] \n",
      "3891 [D loss: (-0.838)(R -3.945, F 2.268)]  [G loss: -2.481] \n",
      "3892 [D loss: (-0.611)(R -4.007, F 2.784)]  [G loss: -2.352] \n",
      "3892 [D loss: (-0.999)(R -3.961, F 1.963)]  [G loss: -2.455] \n",
      "3893 [D loss: (-0.631)(R -3.954, F 2.692)]  [G loss: -2.487] \n",
      "3893 [D loss: (-0.906)(R -4.026, F 2.214)]  [G loss: -2.590] \n",
      "3894 [D loss: (-0.515)(R -3.854, F 2.825)]  [G loss: -2.488] \n",
      "3894 [D loss: (-0.931)(R -3.938, F 2.075)]  [G loss: -2.361] \n",
      "3895 [D loss: (-0.601)(R -4.036, F 2.835)]  [G loss: -2.644] \n",
      "3895 [D loss: (-0.812)(R -4.005, F 2.382)]  [G loss: -2.335] \n",
      "3896 [D loss: (-0.816)(R -4.148, F 2.516)]  [G loss: -2.497] \n",
      "3896 [D loss: (-0.885)(R -4.031, F 2.262)]  [G loss: -2.323] \n",
      "3897 [D loss: (-0.771)(R -3.953, F 2.412)]  [G loss: -2.537] \n",
      "3897 [D loss: (-0.727)(R -4.058, F 2.605)]  [G loss: -2.536] \n",
      "3898 [D loss: (-0.389)(R -4.180, F 3.403)]  [G loss: -2.432] \n",
      "3898 [D loss: (-0.687)(R -4.281, F 2.907)]  [G loss: -2.363] \n",
      "3899 [D loss: (-0.686)(R -4.192, F 2.820)]  [G loss: -2.602] \n",
      "3899 [D loss: (-1.006)(R -4.228, F 2.216)]  [G loss: -2.396] \n",
      "3900 [D loss: (-0.776)(R -4.239, F 2.687)]  [G loss: -2.795] \n",
      "3900 [D loss: (-0.647)(R -4.277, F 2.982)]  [G loss: -2.468] \n",
      "3901 [D loss: (-0.555)(R -4.029, F 2.918)]  [G loss: -2.476] \n",
      "3901 [D loss: (-0.473)(R -4.013, F 3.067)]  [G loss: -2.633] \n",
      "3902 [D loss: (-1.155)(R -4.256, F 1.946)]  [G loss: -2.388] \n",
      "3902 [D loss: (-0.870)(R -4.223, F 2.483)]  [G loss: -2.565] \n",
      "3903 [D loss: (-0.714)(R -4.075, F 2.646)]  [G loss: -2.542] \n",
      "3903 [D loss: (-0.445)(R -3.778, F 2.888)]  [G loss: -2.388] \n",
      "3904 [D loss: (-0.716)(R -3.941, F 2.508)]  [G loss: -2.472] \n",
      "3904 [D loss: (-0.703)(R -4.236, F 2.830)]  [G loss: -2.408] \n",
      "3905 [D loss: (-0.847)(R -4.140, F 2.446)]  [G loss: -2.584] \n",
      "3905 [D loss: (-0.986)(R -4.164, F 2.192)]  [G loss: -2.637] \n",
      "3906 [D loss: (-0.892)(R -4.154, F 2.371)]  [G loss: -2.403] \n",
      "3906 [D loss: (-0.980)(R -4.144, F 2.185)]  [G loss: -2.619] \n",
      "3907 [D loss: (-0.932)(R -4.187, F 2.322)]  [G loss: -2.576] \n",
      "3907 [D loss: (-0.794)(R -3.956, F 2.368)]  [G loss: -2.369] \n",
      "3908 [D loss: (-0.541)(R -3.868, F 2.786)]  [G loss: -2.623] \n",
      "3908 [D loss: (-0.818)(R -4.220, F 2.585)]  [G loss: -2.654] \n",
      "3909 [D loss: (-0.586)(R -4.025, F 2.853)]  [G loss: -2.752] \n",
      "3909 [D loss: (-0.392)(R -3.902, F 3.119)]  [G loss: -2.622] \n",
      "3910 [D loss: (-0.794)(R -4.257, F 2.668)]  [G loss: -2.736] \n",
      "3910 [D loss: (-0.575)(R -4.010, F 2.860)]  [G loss: -2.310] \n",
      "3911 [D loss: (-0.865)(R -4.153, F 2.424)]  [G loss: -2.482] \n",
      "3911 [D loss: (-0.913)(R -4.201, F 2.375)]  [G loss: -2.540] \n",
      "3912 [D loss: (-0.914)(R -4.054, F 2.227)]  [G loss: -2.494] \n",
      "3912 [D loss: (-0.728)(R -4.161, F 2.704)]  [G loss: -2.642] \n",
      "3913 [D loss: (-0.891)(R -3.913, F 2.131)]  [G loss: -2.648] \n",
      "3913 [D loss: (-0.726)(R -3.890, F 2.437)]  [G loss: -2.387] \n",
      "3914 [D loss: (-0.768)(R -3.954, F 2.417)]  [G loss: -2.403] \n",
      "3914 [D loss: (-0.643)(R -3.784, F 2.499)]  [G loss: -2.449] \n",
      "3915 [D loss: (-0.800)(R -3.877, F 2.277)]  [G loss: -2.372] \n",
      "3915 [D loss: (-0.793)(R -3.949, F 2.363)]  [G loss: -2.173] \n",
      "3916 [D loss: (-0.789)(R -4.140, F 2.563)]  [G loss: -2.461] \n",
      "3916 [D loss: (-1.032)(R -4.025, F 1.961)]  [G loss: -2.337] \n",
      "3917 [D loss: (-0.419)(R -3.620, F 2.782)]  [G loss: -2.289] \n",
      "3917 [D loss: (-0.825)(R -3.806, F 2.157)]  [G loss: -2.349] \n",
      "3918 [D loss: (-0.717)(R -3.881, F 2.446)]  [G loss: -2.257] \n",
      "3918 [D loss: (-0.729)(R -3.672, F 2.214)]  [G loss: -2.398] \n",
      "3919 [D loss: (-0.838)(R -4.077, F 2.402)]  [G loss: -2.134] \n",
      "3919 [D loss: (-0.577)(R -3.969, F 2.816)]  [G loss: -2.387] \n",
      "3920 [D loss: (-0.746)(R -3.874, F 2.381)]  [G loss: -2.434] \n",
      "3920 [D loss: (-0.868)(R -4.013, F 2.278)]  [G loss: -2.304] \n",
      "3921 [D loss: (-0.765)(R -3.818, F 2.287)]  [G loss: -2.425] \n",
      "3921 [D loss: (-0.621)(R -3.833, F 2.592)]  [G loss: -2.159] \n",
      "3922 [D loss: (-0.793)(R -3.735, F 2.148)]  [G loss: -2.365] \n",
      "3922 [D loss: (-0.787)(R -4.076, F 2.502)]  [G loss: -2.385] \n",
      "3923 [D loss: (-0.514)(R -4.175, F 3.148)]  [G loss: -2.272] \n",
      "3923 [D loss: (-0.525)(R -3.840, F 2.790)]  [G loss: -2.595] \n",
      "3924 [D loss: (-0.694)(R -3.783, F 2.394)]  [G loss: -2.490] \n",
      "3924 [D loss: (-0.521)(R -3.891, F 2.850)]  [G loss: -2.347] \n",
      "3925 [D loss: (-0.727)(R -3.936, F 2.482)]  [G loss: -2.440] \n",
      "3925 [D loss: (-0.592)(R -3.943, F 2.759)]  [G loss: -2.704] \n",
      "3926 [D loss: (-0.694)(R -4.315, F 2.928)]  [G loss: -2.682] \n",
      "3926 [D loss: (-1.064)(R -4.025, F 1.897)]  [G loss: -2.418] \n",
      "3927 [D loss: (-0.797)(R -4.083, F 2.489)]  [G loss: -2.751] \n",
      "3927 [D loss: (-0.824)(R -4.044, F 2.395)]  [G loss: -2.469] \n",
      "3928 [D loss: (-0.550)(R -3.638, F 2.539)]  [G loss: -2.715] \n",
      "3928 [D loss: (-0.927)(R -4.037, F 2.184)]  [G loss: -2.682] \n",
      "3929 [D loss: (-0.749)(R -4.218, F 2.719)]  [G loss: -2.570] \n",
      "3929 [D loss: (-0.570)(R -4.204, F 3.064)]  [G loss: -2.644] \n",
      "3930 [D loss: (-0.869)(R -3.926, F 2.188)]  [G loss: -2.550] \n",
      "3930 [D loss: (-0.797)(R -3.974, F 2.379)]  [G loss: -2.532] \n",
      "3931 [D loss: (-0.973)(R -4.116, F 2.170)]  [G loss: -2.550] \n",
      "3931 [D loss: (-0.809)(R -4.073, F 2.456)]  [G loss: -2.440] \n",
      "3932 [D loss: (-0.965)(R -4.177, F 2.246)]  [G loss: -2.539] \n",
      "3932 [D loss: (-0.579)(R -3.914, F 2.756)]  [G loss: -2.472] \n",
      "3933 [D loss: (-0.579)(R -4.049, F 2.891)]  [G loss: -2.558] \n",
      "3933 [D loss: (-0.732)(R -4.184, F 2.719)]  [G loss: -2.759] \n",
      "3934 [D loss: (-0.757)(R -4.062, F 2.548)]  [G loss: -2.474] \n",
      "3934 [D loss: (-1.116)(R -4.257, F 2.025)]  [G loss: -2.646] \n",
      "3935 [D loss: (-1.000)(R -4.106, F 2.106)]  [G loss: -2.649] \n",
      "3935 [D loss: (-0.690)(R -4.130, F 2.751)]  [G loss: -2.468] \n",
      "3936 [D loss: (-0.712)(R -4.066, F 2.641)]  [G loss: -2.620] \n",
      "3936 [D loss: (-0.765)(R -4.136, F 2.606)]  [G loss: -2.592] \n",
      "3937 [D loss: (-0.674)(R -4.170, F 2.822)]  [G loss: -2.467] \n",
      "3937 [D loss: (-0.950)(R -4.173, F 2.273)]  [G loss: -2.718] \n",
      "3938 [D loss: (-0.753)(R -4.002, F 2.495)]  [G loss: -2.761] \n",
      "3938 [D loss: (-0.717)(R -4.186, F 2.753)]  [G loss: -2.725] \n",
      "3939 [D loss: (-0.508)(R -4.128, F 3.113)]  [G loss: -2.542] \n",
      "3939 [D loss: (-0.765)(R -4.113, F 2.583)]  [G loss: -2.552] \n",
      "3940 [D loss: (-0.869)(R -4.234, F 2.496)]  [G loss: -2.619] \n",
      "3940 [D loss: (-0.733)(R -4.062, F 2.596)]  [G loss: -2.495] \n",
      "3941 [D loss: (-0.657)(R -3.899, F 2.585)]  [G loss: -2.385] \n",
      "3941 [D loss: (-0.654)(R -4.004, F 2.696)]  [G loss: -2.508] \n",
      "3942 [D loss: (-0.552)(R -4.082, F 2.977)]  [G loss: -2.558] \n",
      "3942 [D loss: (-0.897)(R -4.415, F 2.621)]  [G loss: -2.558] \n",
      "3943 [D loss: (-0.735)(R -4.060, F 2.589)]  [G loss: -2.593] \n",
      "3943 [D loss: (-0.886)(R -4.328, F 2.556)]  [G loss: -2.701] \n",
      "3944 [D loss: (-0.583)(R -4.240, F 3.075)]  [G loss: -2.576] \n",
      "3944 [D loss: (-0.669)(R -3.989, F 2.652)]  [G loss: -2.404] \n",
      "3945 [D loss: (-0.769)(R -4.232, F 2.695)]  [G loss: -2.914] \n",
      "3945 [D loss: (-0.709)(R -3.996, F 2.578)]  [G loss: -2.544] \n",
      "3946 [D loss: (-0.654)(R -3.802, F 2.495)]  [G loss: -2.227] \n",
      "3946 [D loss: (-0.629)(R -4.224, F 2.965)]  [G loss: -2.677] \n",
      "3947 [D loss: (-0.998)(R -4.182, F 2.186)]  [G loss: -2.276] \n",
      "3947 [D loss: (-0.794)(R -4.012, F 2.425)]  [G loss: -2.484] \n",
      "3948 [D loss: (-0.824)(R -4.007, F 2.360)]  [G loss: -2.538] \n",
      "3948 [D loss: (-0.727)(R -4.040, F 2.586)]  [G loss: -2.151] \n",
      "3949 [D loss: (-0.716)(R -3.893, F 2.462)]  [G loss: -2.413] \n",
      "3949 [D loss: (-0.739)(R -4.031, F 2.552)]  [G loss: -2.360] \n",
      "3950 [D loss: (-0.930)(R -4.070, F 2.211)]  [G loss: -2.613] \n",
      "3950 [D loss: (-0.891)(R -3.930, F 2.148)]  [G loss: -2.368] \n",
      "3951 [D loss: (-0.956)(R -3.914, F 2.001)]  [G loss: -2.580] \n",
      "3951 [D loss: (-0.795)(R -4.033, F 2.444)]  [G loss: -2.423] \n",
      "3952 [D loss: (-0.649)(R -3.895, F 2.598)]  [G loss: -2.435] \n",
      "3952 [D loss: (-0.919)(R -4.155, F 2.318)]  [G loss: -2.638] \n",
      "3953 [D loss: (-0.669)(R -4.023, F 2.685)]  [G loss: -2.478] \n",
      "3953 [D loss: (-0.622)(R -3.910, F 2.665)]  [G loss: -2.399] \n",
      "3954 [D loss: (-0.428)(R -3.766, F 2.910)]  [G loss: -2.353] \n",
      "3954 [D loss: (-0.745)(R -3.990, F 2.500)]  [G loss: -2.580] \n",
      "3955 [D loss: (-0.832)(R -4.132, F 2.468)]  [G loss: -2.571] \n",
      "3955 [D loss: (-1.011)(R -4.221, F 2.199)]  [G loss: -2.520] \n",
      "3956 [D loss: (-0.632)(R -4.086, F 2.823)]  [G loss: -2.326] \n",
      "3956 [D loss: (-0.658)(R -3.786, F 2.469)]  [G loss: -2.437] \n",
      "3957 [D loss: (-0.704)(R -3.933, F 2.524)]  [G loss: -2.644] \n",
      "3957 [D loss: (-0.678)(R -4.081, F 2.726)]  [G loss: -2.528] \n",
      "3958 [D loss: (-0.909)(R -3.944, F 2.127)]  [G loss: -2.577] \n",
      "3958 [D loss: (-0.597)(R -4.024, F 2.831)]  [G loss: -2.290] \n",
      "3959 [D loss: (-0.562)(R -3.743, F 2.618)]  [G loss: -2.545] \n",
      "3959 [D loss: (-0.768)(R -4.149, F 2.613)]  [G loss: -2.663] \n",
      "3960 [D loss: (-0.547)(R -3.907, F 2.814)]  [G loss: -2.581] \n",
      "3960 [D loss: (-0.667)(R -4.067, F 2.732)]  [G loss: -2.563] \n",
      "3961 [D loss: (-0.640)(R -3.838, F 2.557)]  [G loss: -2.661] \n",
      "3961 [D loss: (-0.592)(R -3.954, F 2.771)]  [G loss: -2.814] \n",
      "3962 [D loss: (-0.763)(R -4.098, F 2.572)]  [G loss: -2.823] \n",
      "3962 [D loss: (-0.969)(R -4.163, F 2.225)]  [G loss: -2.833] \n",
      "3963 [D loss: (-0.756)(R -4.245, F 2.732)]  [G loss: -2.643] \n",
      "3963 [D loss: (-0.529)(R -3.962, F 2.904)]  [G loss: -2.475] \n",
      "3964 [D loss: (-0.434)(R -4.014, F 3.145)]  [G loss: -2.586] \n",
      "3964 [D loss: (-0.853)(R -4.182, F 2.475)]  [G loss: -2.420] \n",
      "3965 [D loss: (-0.631)(R -4.018, F 2.755)]  [G loss: -2.313] \n",
      "3965 [D loss: (-0.912)(R -4.144, F 2.319)]  [G loss: -2.755] \n",
      "3966 [D loss: (-0.687)(R -3.898, F 2.524)]  [G loss: -2.716] \n",
      "3966 [D loss: (-0.650)(R -4.171, F 2.871)]  [G loss: -2.524] \n",
      "3967 [D loss: (-0.597)(R -4.046, F 2.852)]  [G loss: -2.682] \n",
      "3967 [D loss: (-0.554)(R -4.046, F 2.938)]  [G loss: -2.464] \n",
      "3968 [D loss: (-0.749)(R -4.071, F 2.573)]  [G loss: -2.737] \n",
      "3968 [D loss: (-0.445)(R -3.914, F 3.023)]  [G loss: -2.601] \n",
      "3969 [D loss: (-1.189)(R -4.159, F 1.781)]  [G loss: -2.731] \n",
      "3969 [D loss: (-0.678)(R -3.902, F 2.546)]  [G loss: -2.779] \n",
      "3970 [D loss: (-0.998)(R -4.150, F 2.153)]  [G loss: -2.590] \n",
      "3970 [D loss: (-0.840)(R -4.234, F 2.554)]  [G loss: -2.744] \n",
      "3971 [D loss: (-0.500)(R -4.235, F 3.234)]  [G loss: -2.623] \n",
      "3971 [D loss: (-0.753)(R -3.963, F 2.457)]  [G loss: -2.617] \n",
      "3972 [D loss: (-0.750)(R -3.940, F 2.440)]  [G loss: -2.450] \n",
      "3972 [D loss: (-0.615)(R -4.056, F 2.826)]  [G loss: -2.728] \n",
      "3973 [D loss: (-0.351)(R -4.053, F 3.351)]  [G loss: -2.539] \n",
      "3973 [D loss: (-0.905)(R -4.124, F 2.314)]  [G loss: -2.466] \n",
      "3974 [D loss: (-0.530)(R -3.950, F 2.889)]  [G loss: -2.643] \n",
      "3974 [D loss: (-0.707)(R -4.176, F 2.761)]  [G loss: -2.514] \n",
      "3975 [D loss: (-0.701)(R -3.928, F 2.525)]  [G loss: -2.479] \n",
      "3975 [D loss: (-0.877)(R -4.169, F 2.415)]  [G loss: -2.492] \n",
      "3976 [D loss: (-0.519)(R -4.032, F 2.994)]  [G loss: -2.517] \n",
      "3976 [D loss: (-0.723)(R -3.907, F 2.462)]  [G loss: -2.591] \n",
      "3977 [D loss: (-0.897)(R -3.976, F 2.182)]  [G loss: -2.557] \n",
      "3977 [D loss: (-0.709)(R -4.134, F 2.716)]  [G loss: -2.394] \n",
      "3978 [D loss: (-0.680)(R -3.936, F 2.575)]  [G loss: -2.372] \n",
      "3978 [D loss: (-0.534)(R -3.880, F 2.813)]  [G loss: -2.432] \n",
      "3979 [D loss: (-0.534)(R -3.751, F 2.683)]  [G loss: -2.615] \n",
      "3979 [D loss: (-0.561)(R -3.923, F 2.802)]  [G loss: -2.548] \n",
      "3980 [D loss: (-0.788)(R -4.017, F 2.440)]  [G loss: -2.122] \n",
      "3980 [D loss: (-0.903)(R -3.874, F 2.069)]  [G loss: -2.443] \n",
      "3981 [D loss: (-0.842)(R -3.956, F 2.272)]  [G loss: -2.306] \n",
      "3981 [D loss: (-0.475)(R -3.970, F 3.019)]  [G loss: -2.400] \n",
      "3982 [D loss: (-0.653)(R -3.809, F 2.504)]  [G loss: -2.458] \n",
      "3982 [D loss: (-0.819)(R -3.926, F 2.287)]  [G loss: -2.544] \n",
      "3983 [D loss: (-0.687)(R -3.842, F 2.468)]  [G loss: -2.465] \n",
      "3983 [D loss: (-0.512)(R -3.744, F 2.721)]  [G loss: -2.422] \n",
      "3984 [D loss: (-0.542)(R -3.550, F 2.466)]  [G loss: -2.453] \n",
      "3984 [D loss: (-0.803)(R -3.924, F 2.318)]  [G loss: -2.687] \n",
      "3985 [D loss: (-0.944)(R -3.814, F 1.927)]  [G loss: -2.548] \n",
      "3985 [D loss: (-0.862)(R -3.929, F 2.204)]  [G loss: -2.502] \n",
      "3986 [D loss: (-0.855)(R -4.096, F 2.386)]  [G loss: -2.710] \n",
      "3986 [D loss: (-0.794)(R -4.042, F 2.453)]  [G loss: -2.519] \n",
      "3987 [D loss: (-0.534)(R -3.737, F 2.669)]  [G loss: -2.722] \n",
      "3987 [D loss: (-0.659)(R -4.008, F 2.690)]  [G loss: -2.491] \n",
      "3988 [D loss: (-0.833)(R -4.052, F 2.386)]  [G loss: -2.524] \n",
      "3988 [D loss: (-0.620)(R -3.962, F 2.722)]  [G loss: -2.495] \n",
      "3989 [D loss: (-0.777)(R -3.919, F 2.366)]  [G loss: -2.565] \n",
      "3989 [D loss: (-0.657)(R -3.646, F 2.331)]  [G loss: -2.256] \n",
      "3990 [D loss: (-0.718)(R -3.825, F 2.388)]  [G loss: -2.698] \n",
      "3990 [D loss: (-0.437)(R -4.041, F 3.168)]  [G loss: -2.441] \n",
      "3991 [D loss: (-0.748)(R -3.859, F 2.362)]  [G loss: -2.533] \n",
      "3991 [D loss: (-0.623)(R -3.823, F 2.577)]  [G loss: -2.620] \n",
      "3992 [D loss: (-0.549)(R -3.684, F 2.585)]  [G loss: -2.592] \n",
      "3992 [D loss: (-0.471)(R -3.815, F 2.873)]  [G loss: -2.467] \n",
      "3993 [D loss: (-0.561)(R -4.088, F 2.966)]  [G loss: -2.647] \n",
      "3993 [D loss: (-0.737)(R -3.985, F 2.512)]  [G loss: -2.336] \n",
      "3994 [D loss: (-0.743)(R -4.051, F 2.565)]  [G loss: -2.389] \n",
      "3994 [D loss: (-0.598)(R -4.021, F 2.824)]  [G loss: -2.617] \n",
      "3995 [D loss: (-0.533)(R -3.965, F 2.899)]  [G loss: -2.469] \n",
      "3995 [D loss: (-0.857)(R -4.206, F 2.493)]  [G loss: -2.791] \n",
      "3996 [D loss: (-0.695)(R -4.050, F 2.659)]  [G loss: -2.689] \n",
      "3996 [D loss: (-0.568)(R -4.015, F 2.879)]  [G loss: -2.553] \n",
      "3997 [D loss: (-0.591)(R -4.282, F 3.100)]  [G loss: -2.581] \n",
      "3997 [D loss: (-0.675)(R -4.440, F 3.090)]  [G loss: -2.654] \n",
      "3998 [D loss: (-0.541)(R -4.223, F 3.141)]  [G loss: -2.778] \n",
      "3998 [D loss: (-0.576)(R -4.073, F 2.920)]  [G loss: -2.585] \n",
      "3999 [D loss: (-0.671)(R -4.265, F 2.923)]  [G loss: -2.631] \n",
      "3999 [D loss: (-0.344)(R -3.965, F 3.276)]  [G loss: -2.467] \n",
      "4000 [D loss: (-0.583)(R -4.368, F 3.202)]  [G loss: -2.850] \n",
      "4000 [D loss: (-0.690)(R -4.148, F 2.768)]  [G loss: -2.887] \n",
      "4001 [D loss: (-0.727)(R -4.136, F 2.683)]  [G loss: -2.728] \n",
      "4001 [D loss: (-0.575)(R -4.123, F 2.973)]  [G loss: -2.764] \n",
      "4002 [D loss: (-0.654)(R -4.211, F 2.903)]  [G loss: -2.902] \n",
      "4002 [D loss: (-0.611)(R -4.369, F 3.146)]  [G loss: -2.837] \n",
      "4003 [D loss: (-0.593)(R -4.207, F 3.020)]  [G loss: -2.953] \n",
      "4003 [D loss: (-0.319)(R -4.472, F 3.833)]  [G loss: -3.238] \n",
      "4004 [D loss: (-0.598)(R -4.313, F 3.117)]  [G loss: -2.840] \n",
      "4004 [D loss: (-0.337)(R -4.257, F 3.583)]  [G loss: -2.794] \n",
      "4005 [D loss: (-0.810)(R -4.282, F 2.662)]  [G loss: -3.028] \n",
      "4005 [D loss: (-0.931)(R -4.369, F 2.508)]  [G loss: -2.753] \n",
      "4006 [D loss: (-0.687)(R -4.479, F 3.105)]  [G loss: -2.891] \n",
      "4006 [D loss: (-0.795)(R -4.386, F 2.797)]  [G loss: -2.837] \n",
      "4007 [D loss: (-0.637)(R -4.428, F 3.153)]  [G loss: -2.946] \n",
      "4007 [D loss: (-0.580)(R -4.105, F 2.946)]  [G loss: -2.980] \n",
      "4008 [D loss: (-0.682)(R -4.396, F 3.032)]  [G loss: -2.725] \n",
      "4008 [D loss: (-0.329)(R -4.220, F 3.562)]  [G loss: -2.830] \n",
      "4009 [D loss: (-0.755)(R -4.379, F 2.868)]  [G loss: -2.744] \n",
      "4009 [D loss: (-1.075)(R -4.490, F 2.339)]  [G loss: -3.030] \n",
      "4010 [D loss: (-0.896)(R -4.460, F 2.669)]  [G loss: -2.949] \n",
      "4010 [D loss: (-0.886)(R -4.376, F 2.605)]  [G loss: -2.952] \n",
      "4011 [D loss: (-0.776)(R -4.201, F 2.648)]  [G loss: -2.917] \n",
      "4011 [D loss: (-0.716)(R -4.440, F 3.009)]  [G loss: -2.622] \n",
      "4012 [D loss: (-0.513)(R -4.466, F 3.439)]  [G loss: -2.810] \n",
      "4012 [D loss: (-0.664)(R -4.276, F 2.948)]  [G loss: -2.957] \n",
      "4013 [D loss: (-0.634)(R -4.248, F 2.981)]  [G loss: -2.936] \n",
      "4013 [D loss: (-0.976)(R -4.305, F 2.353)]  [G loss: -3.085] \n",
      "4014 [D loss: (-0.751)(R -4.411, F 2.910)]  [G loss: -2.707] \n",
      "4014 [D loss: (-0.647)(R -4.254, F 2.960)]  [G loss: -2.793] \n",
      "4015 [D loss: (-0.736)(R -4.409, F 2.938)]  [G loss: -3.041] \n",
      "4015 [D loss: (-0.922)(R -4.467, F 2.623)]  [G loss: -3.030] \n",
      "4016 [D loss: (-0.583)(R -4.242, F 3.077)]  [G loss: -2.532] \n",
      "4016 [D loss: (-0.734)(R -4.119, F 2.652)]  [G loss: -2.855] \n",
      "4017 [D loss: (-0.952)(R -4.072, F 2.168)]  [G loss: -2.906] \n",
      "4017 [D loss: (-0.459)(R -4.022, F 3.104)]  [G loss: -2.764] \n",
      "4018 [D loss: (-0.452)(R -4.162, F 3.258)]  [G loss: -2.857] \n",
      "4018 [D loss: (-0.691)(R -4.159, F 2.776)]  [G loss: -2.754] \n",
      "4019 [D loss: (-0.616)(R -4.271, F 3.039)]  [G loss: -2.801] \n",
      "4019 [D loss: (-0.878)(R -4.240, F 2.485)]  [G loss: -3.031] \n",
      "4020 [D loss: (-0.896)(R -4.277, F 2.484)]  [G loss: -2.694] \n",
      "4020 [D loss: (-0.647)(R -4.214, F 2.919)]  [G loss: -2.969] \n",
      "4021 [D loss: (-0.696)(R -4.379, F 2.987)]  [G loss: -2.755] \n",
      "4021 [D loss: (-0.621)(R -4.213, F 2.971)]  [G loss: -2.776] \n",
      "4022 [D loss: (-0.465)(R -4.191, F 3.261)]  [G loss: -2.642] \n",
      "4022 [D loss: (-0.625)(R -4.275, F 3.025)]  [G loss: -2.797] \n",
      "4023 [D loss: (-0.526)(R -4.136, F 3.085)]  [G loss: -2.810] \n",
      "4023 [D loss: (-0.525)(R -4.310, F 3.261)]  [G loss: -2.772] \n",
      "4024 [D loss: (-0.608)(R -4.135, F 2.918)]  [G loss: -2.842] \n",
      "4024 [D loss: (-0.508)(R -4.115, F 3.098)]  [G loss: -2.907] \n",
      "4025 [D loss: (-0.657)(R -4.090, F 2.776)]  [G loss: -2.974] \n",
      "4025 [D loss: (-0.542)(R -4.266, F 3.183)]  [G loss: -2.785] \n",
      "4026 [D loss: (-0.460)(R -4.299, F 3.379)]  [G loss: -2.813] \n",
      "4026 [D loss: (-0.585)(R -4.208, F 3.038)]  [G loss: -2.861] \n",
      "4027 [D loss: (-0.733)(R -4.093, F 2.627)]  [G loss: -2.980] \n",
      "4027 [D loss: (-0.694)(R -4.409, F 3.020)]  [G loss: -3.109] \n",
      "4028 [D loss: (-0.806)(R -4.494, F 2.882)]  [G loss: -2.931] \n",
      "4028 [D loss: (-0.573)(R -4.183, F 3.036)]  [G loss: -2.855] \n",
      "4029 [D loss: (-0.862)(R -4.283, F 2.559)]  [G loss: -2.864] \n",
      "4029 [D loss: (-0.663)(R -4.347, F 3.021)]  [G loss: -2.898] \n",
      "4030 [D loss: (-0.583)(R -4.108, F 2.941)]  [G loss: -2.840] \n",
      "4030 [D loss: (-1.134)(R -4.219, F 1.951)]  [G loss: -2.704] \n",
      "4031 [D loss: (-0.400)(R -4.002, F 3.201)]  [G loss: -2.798] \n",
      "4031 [D loss: (-0.674)(R -4.214, F 2.866)]  [G loss: -2.731] \n",
      "4032 [D loss: (-0.884)(R -4.389, F 2.621)]  [G loss: -2.748] \n",
      "4032 [D loss: (-0.779)(R -4.417, F 2.858)]  [G loss: -2.738] \n",
      "4033 [D loss: (-0.944)(R -4.287, F 2.399)]  [G loss: -2.559] \n",
      "4033 [D loss: (-0.648)(R -3.937, F 2.640)]  [G loss: -2.811] \n",
      "4034 [D loss: (-0.555)(R -3.992, F 2.882)]  [G loss: -2.976] \n",
      "4034 [D loss: (-0.743)(R -3.966, F 2.481)]  [G loss: -2.883] \n",
      "4035 [D loss: (-0.650)(R -4.069, F 2.768)]  [G loss: -2.545] \n",
      "4035 [D loss: (-0.760)(R -3.995, F 2.474)]  [G loss: -2.884] \n",
      "4036 [D loss: (-0.718)(R -4.020, F 2.585)]  [G loss: -2.755] \n",
      "4036 [D loss: (-0.584)(R -4.321, F 3.152)]  [G loss: -2.673] \n",
      "4037 [D loss: (-0.925)(R -4.228, F 2.378)]  [G loss: -2.845] \n",
      "4037 [D loss: (-0.704)(R -4.240, F 2.833)]  [G loss: -2.501] \n",
      "4038 [D loss: (-0.471)(R -4.099, F 3.157)]  [G loss: -2.702] \n",
      "4038 [D loss: (-0.644)(R -3.907, F 2.618)]  [G loss: -2.789] \n",
      "4039 [D loss: (-0.664)(R -4.270, F 2.943)]  [G loss: -2.887] \n",
      "4039 [D loss: (-0.889)(R -4.098, F 2.320)]  [G loss: -2.657] \n",
      "4040 [D loss: (-0.740)(R -4.064, F 2.583)]  [G loss: -2.932] \n",
      "4040 [D loss: (-0.858)(R -4.207, F 2.490)]  [G loss: -2.763] \n",
      "4041 [D loss: (-1.099)(R -4.453, F 2.255)]  [G loss: -2.712] \n",
      "4041 [D loss: (-0.695)(R -4.153, F 2.763)]  [G loss: -2.810] \n",
      "4042 [D loss: (-0.824)(R -4.188, F 2.539)]  [G loss: -2.839] \n",
      "4042 [D loss: (-0.839)(R -4.271, F 2.593)]  [G loss: -2.581] \n",
      "4043 [D loss: (-0.539)(R -4.227, F 3.149)]  [G loss: -2.619] \n",
      "4043 [D loss: (-0.633)(R -4.106, F 2.840)]  [G loss: -2.745] \n",
      "4044 [D loss: (-0.551)(R -4.102, F 2.999)]  [G loss: -2.796] \n",
      "4044 [D loss: (-0.946)(R -4.350, F 2.458)]  [G loss: -2.893] \n",
      "4045 [D loss: (-0.608)(R -4.162, F 2.947)]  [G loss: -2.750] \n",
      "4045 [D loss: (-0.436)(R -4.065, F 3.193)]  [G loss: -3.027] \n",
      "4046 [D loss: (-0.547)(R -3.972, F 2.879)]  [G loss: -2.639] \n",
      "4046 [D loss: (-0.704)(R -4.220, F 2.812)]  [G loss: -2.962] \n",
      "4047 [D loss: (-0.693)(R -4.175, F 2.788)]  [G loss: -2.998] \n",
      "4047 [D loss: (-0.895)(R -4.575, F 2.784)]  [G loss: -2.876] \n",
      "4048 [D loss: (-0.301)(R -4.145, F 3.542)]  [G loss: -2.927] \n",
      "4048 [D loss: (-0.568)(R -4.185, F 3.050)]  [G loss: -2.774] \n",
      "4049 [D loss: (-0.447)(R -4.209, F 3.315)]  [G loss: -3.128] \n",
      "4049 [D loss: (-0.457)(R -4.140, F 3.226)]  [G loss: -2.978] \n",
      "4050 [D loss: (-0.553)(R -4.400, F 3.293)]  [G loss: -2.771] \n",
      "4050 [D loss: (-0.644)(R -4.028, F 2.739)]  [G loss: -2.936] \n",
      "4051 [D loss: (-0.541)(R -4.291, F 3.209)]  [G loss: -3.160] \n",
      "4051 [D loss: (-0.779)(R -4.244, F 2.686)]  [G loss: -2.963] \n",
      "4052 [D loss: (-0.593)(R -4.433, F 3.247)]  [G loss: -3.018] \n",
      "4052 [D loss: (-0.772)(R -4.098, F 2.554)]  [G loss: -3.048] \n",
      "4053 [D loss: (-0.508)(R -4.186, F 3.170)]  [G loss: -3.004] \n",
      "4053 [D loss: (-0.756)(R -4.404, F 2.893)]  [G loss: -3.213] \n",
      "4054 [D loss: (-0.586)(R -4.351, F 3.180)]  [G loss: -3.006] \n",
      "4054 [D loss: (-0.678)(R -4.220, F 2.864)]  [G loss: -3.099] \n",
      "4055 [D loss: (-0.561)(R -4.299, F 3.177)]  [G loss: -3.004] \n",
      "4055 [D loss: (-0.922)(R -4.355, F 2.511)]  [G loss: -2.764] \n",
      "4056 [D loss: (-0.661)(R -4.172, F 2.851)]  [G loss: -3.046] \n",
      "4056 [D loss: (-0.855)(R -4.323, F 2.613)]  [G loss: -2.933] \n",
      "4057 [D loss: (-0.554)(R -4.055, F 2.946)]  [G loss: -2.771] \n",
      "4057 [D loss: (-0.679)(R -4.359, F 3.001)]  [G loss: -2.968] \n",
      "4058 [D loss: (-0.479)(R -4.146, F 3.187)]  [G loss: -3.060] \n",
      "4058 [D loss: (-0.910)(R -4.391, F 2.571)]  [G loss: -2.974] \n",
      "4059 [D loss: (-0.583)(R -4.387, F 3.222)]  [G loss: -2.833] \n",
      "4059 [D loss: (-0.943)(R -4.114, F 2.228)]  [G loss: -3.011] \n",
      "4060 [D loss: (-0.511)(R -4.104, F 3.082)]  [G loss: -3.047] \n",
      "4060 [D loss: (-0.697)(R -4.196, F 2.802)]  [G loss: -2.801] \n",
      "4061 [D loss: (-0.786)(R -4.220, F 2.648)]  [G loss: -3.006] \n",
      "4061 [D loss: (-0.381)(R -4.242, F 3.481)]  [G loss: -2.861] \n",
      "4062 [D loss: (-0.590)(R -4.113, F 2.933)]  [G loss: -2.934] \n",
      "4062 [D loss: (-0.505)(R -4.160, F 3.151)]  [G loss: -2.928] \n",
      "4063 [D loss: (-0.857)(R -4.327, F 2.613)]  [G loss: -3.115] \n",
      "4063 [D loss: (-0.348)(R -4.235, F 3.539)]  [G loss: -3.188] \n",
      "4064 [D loss: (-0.631)(R -4.470, F 3.208)]  [G loss: -3.025] \n",
      "4064 [D loss: (-0.453)(R -4.413, F 3.507)]  [G loss: -2.839] \n",
      "4065 [D loss: (-0.414)(R -4.265, F 3.437)]  [G loss: -3.000] \n",
      "4065 [D loss: (-0.621)(R -4.297, F 3.055)]  [G loss: -3.076] \n",
      "4066 [D loss: (-0.606)(R -4.470, F 3.258)]  [G loss: -3.245] \n",
      "4066 [D loss: (-0.818)(R -4.118, F 2.482)]  [G loss: -3.024] \n",
      "4067 [D loss: (-0.820)(R -4.386, F 2.746)]  [G loss: -3.091] \n",
      "4067 [D loss: (-0.899)(R -4.502, F 2.705)]  [G loss: -3.084] \n",
      "4068 [D loss: (-0.689)(R -4.275, F 2.898)]  [G loss: -3.136] \n",
      "4068 [D loss: (-0.696)(R -4.453, F 3.061)]  [G loss: -2.948] \n",
      "4069 [D loss: (-0.492)(R -4.260, F 3.277)]  [G loss: -3.359] \n",
      "4069 [D loss: (-1.159)(R -4.351, F 2.032)]  [G loss: -3.038] \n",
      "4070 [D loss: (-0.755)(R -4.642, F 3.133)]  [G loss: -2.809] \n",
      "4070 [D loss: (-0.670)(R -4.132, F 2.792)]  [G loss: -3.082] \n",
      "4071 [D loss: (-0.603)(R -4.277, F 3.071)]  [G loss: -2.817] \n",
      "4071 [D loss: (-0.675)(R -4.439, F 3.088)]  [G loss: -2.869] \n",
      "4072 [D loss: (-0.615)(R -4.469, F 3.239)]  [G loss: -3.206] \n",
      "4072 [D loss: (-0.796)(R -4.347, F 2.756)]  [G loss: -3.116] \n",
      "4073 [D loss: (-1.064)(R -4.351, F 2.222)]  [G loss: -2.919] \n",
      "4073 [D loss: (-0.709)(R -4.433, F 3.015)]  [G loss: -2.828] \n",
      "4074 [D loss: (-0.698)(R -4.016, F 2.620)]  [G loss: -2.773] \n",
      "4074 [D loss: (-0.474)(R -4.171, F 3.223)]  [G loss: -2.985] \n",
      "4075 [D loss: (-0.903)(R -4.280, F 2.474)]  [G loss: -2.991] \n",
      "4075 [D loss: (-0.563)(R -4.382, F 3.256)]  [G loss: -3.046] \n",
      "4076 [D loss: (-0.515)(R -4.261, F 3.232)]  [G loss: -2.948] \n",
      "4076 [D loss: (-0.690)(R -4.345, F 2.964)]  [G loss: -2.922] \n",
      "4077 [D loss: (-0.689)(R -4.163, F 2.785)]  [G loss: -3.043] \n",
      "4077 [D loss: (-0.995)(R -4.380, F 2.391)]  [G loss: -2.999] \n",
      "4078 [D loss: (-0.760)(R -4.377, F 2.857)]  [G loss: -3.042] \n",
      "4078 [D loss: (-0.719)(R -4.324, F 2.885)]  [G loss: -3.005] \n",
      "4079 [D loss: (-0.817)(R -4.155, F 2.521)]  [G loss: -3.003] \n",
      "4079 [D loss: (-0.572)(R -4.263, F 3.118)]  [G loss: -3.015] \n",
      "4080 [D loss: (-0.734)(R -4.486, F 3.018)]  [G loss: -2.913] \n",
      "4080 [D loss: (-0.510)(R -4.382, F 3.362)]  [G loss: -2.874] \n",
      "4081 [D loss: (-0.866)(R -4.323, F 2.590)]  [G loss: -2.837] \n",
      "4081 [D loss: (-0.948)(R -4.287, F 2.391)]  [G loss: -2.943] \n",
      "4082 [D loss: (-0.494)(R -4.274, F 3.285)]  [G loss: -2.806] \n",
      "4082 [D loss: (-0.668)(R -4.164, F 2.827)]  [G loss: -2.850] \n",
      "4083 [D loss: (-0.847)(R -4.493, F 2.799)]  [G loss: -2.914] \n",
      "4083 [D loss: (-0.768)(R -4.200, F 2.665)]  [G loss: -3.072] \n",
      "4084 [D loss: (-0.636)(R -4.424, F 3.153)]  [G loss: -3.190] \n",
      "4084 [D loss: (-0.696)(R -4.237, F 2.845)]  [G loss: -2.689] \n",
      "4085 [D loss: (-0.621)(R -4.153, F 2.910)]  [G loss: -2.955] \n",
      "4085 [D loss: (-0.598)(R -4.251, F 3.055)]  [G loss: -2.996] \n",
      "4086 [D loss: (-0.693)(R -4.394, F 3.008)]  [G loss: -2.728] \n",
      "4086 [D loss: (-0.667)(R -3.979, F 2.645)]  [G loss: -2.934] \n",
      "4087 [D loss: (-0.916)(R -4.578, F 2.746)]  [G loss: -3.038] \n",
      "4087 [D loss: (-0.838)(R -4.465, F 2.788)]  [G loss: -2.963] \n",
      "4088 [D loss: (-0.561)(R -4.497, F 3.375)]  [G loss: -2.853] \n",
      "4088 [D loss: (-0.708)(R -4.492, F 3.076)]  [G loss: -2.965] \n",
      "4089 [D loss: (-0.602)(R -4.428, F 3.225)]  [G loss: -3.054] \n",
      "4089 [D loss: (-0.634)(R -4.348, F 3.080)]  [G loss: -3.114] \n",
      "4090 [D loss: (-0.758)(R -4.375, F 2.858)]  [G loss: -2.792] \n",
      "4090 [D loss: (-0.602)(R -4.316, F 3.111)]  [G loss: -2.839] \n",
      "4091 [D loss: (-1.001)(R -4.245, F 2.244)]  [G loss: -2.972] \n",
      "4091 [D loss: (-0.603)(R -4.166, F 2.960)]  [G loss: -2.915] \n",
      "4092 [D loss: (-0.801)(R -4.409, F 2.807)]  [G loss: -2.904] \n",
      "4092 [D loss: (-0.481)(R -4.233, F 3.271)]  [G loss: -2.995] \n",
      "4093 [D loss: (-0.264)(R -3.943, F 3.414)]  [G loss: -2.811] \n",
      "4093 [D loss: (-0.742)(R -4.009, F 2.525)]  [G loss: -3.018] \n",
      "4094 [D loss: (-0.630)(R -4.153, F 2.893)]  [G loss: -2.955] \n",
      "4094 [D loss: (-0.993)(R -4.543, F 2.557)]  [G loss: -2.608] \n",
      "4095 [D loss: (-0.591)(R -4.293, F 3.111)]  [G loss: -2.928] \n",
      "4095 [D loss: (-0.570)(R -4.044, F 2.903)]  [G loss: -2.956] \n",
      "4096 [D loss: (-0.839)(R -4.405, F 2.727)]  [G loss: -2.799] \n",
      "4096 [D loss: (-0.700)(R -4.083, F 2.682)]  [G loss: -2.734] \n",
      "4097 [D loss: (-0.338)(R -4.171, F 3.494)]  [G loss: -2.713] \n",
      "4097 [D loss: (-0.543)(R -4.192, F 3.106)]  [G loss: -2.917] \n",
      "4098 [D loss: (-0.514)(R -3.930, F 2.902)]  [G loss: -2.836] \n",
      "4098 [D loss: (-0.688)(R -3.939, F 2.562)]  [G loss: -2.745] \n",
      "4099 [D loss: (-0.649)(R -4.140, F 2.842)]  [G loss: -2.922] \n",
      "4099 [D loss: (-0.579)(R -4.173, F 3.015)]  [G loss: -2.822] \n",
      "4100 [D loss: (-0.795)(R -4.192, F 2.603)]  [G loss: -2.772] \n",
      "4100 [D loss: (-0.752)(R -4.059, F 2.556)]  [G loss: -3.010] \n",
      "4101 [D loss: (-0.394)(R -4.224, F 3.436)]  [G loss: -2.825] \n",
      "4101 [D loss: (-0.601)(R -4.211, F 3.010)]  [G loss: -2.631] \n",
      "4102 [D loss: (-0.721)(R -4.154, F 2.712)]  [G loss: -2.978] \n",
      "4102 [D loss: (-0.506)(R -4.068, F 3.056)]  [G loss: -2.857] \n",
      "4103 [D loss: (-0.573)(R -4.184, F 3.038)]  [G loss: -2.779] \n",
      "4103 [D loss: (-0.500)(R -4.130, F 3.130)]  [G loss: -3.013] \n",
      "4104 [D loss: (-0.514)(R -4.258, F 3.229)]  [G loss: -3.005] \n",
      "4104 [D loss: (-0.520)(R -4.112, F 3.072)]  [G loss: -3.200] \n",
      "4105 [D loss: (-0.872)(R -4.398, F 2.655)]  [G loss: -2.961] \n",
      "4105 [D loss: (-0.539)(R -4.227, F 3.149)]  [G loss: -3.046] \n",
      "4106 [D loss: (-0.512)(R -4.242, F 3.218)]  [G loss: -2.823] \n",
      "4106 [D loss: (-0.808)(R -4.248, F 2.631)]  [G loss: -2.919] \n",
      "4107 [D loss: (-0.442)(R -4.325, F 3.442)]  [G loss: -3.039] \n",
      "4107 [D loss: (-0.363)(R -4.313, F 3.586)]  [G loss: -3.064] \n",
      "4108 [D loss: (-0.954)(R -4.631, F 2.722)]  [G loss: -3.183] \n",
      "4108 [D loss: (-0.722)(R -4.435, F 2.991)]  [G loss: -2.910] \n",
      "4109 [D loss: (-0.781)(R -4.774, F 3.212)]  [G loss: -2.952] \n",
      "4109 [D loss: (-0.691)(R -4.462, F 3.081)]  [G loss: -2.882] \n",
      "4110 [D loss: (-0.775)(R -4.722, F 3.172)]  [G loss: -3.261] \n",
      "4110 [D loss: (-0.756)(R -4.419, F 2.907)]  [G loss: -3.009] \n",
      "4111 [D loss: (-0.579)(R -4.221, F 3.062)]  [G loss: -2.876] \n",
      "4111 [D loss: (-0.526)(R -4.104, F 3.052)]  [G loss: -2.997] \n",
      "4112 [D loss: (-0.668)(R -4.304, F 2.969)]  [G loss: -2.649] \n",
      "4112 [D loss: (-0.648)(R -4.654, F 3.358)]  [G loss: -2.855] \n",
      "4113 [D loss: (-0.516)(R -4.158, F 3.126)]  [G loss: -2.927] \n",
      "4113 [D loss: (-0.647)(R -4.358, F 3.064)]  [G loss: -3.061] \n",
      "4114 [D loss: (-0.492)(R -3.938, F 2.953)]  [G loss: -2.926] \n",
      "4114 [D loss: (-0.699)(R -4.343, F 2.944)]  [G loss: -3.212] \n",
      "4115 [D loss: (-0.747)(R -4.489, F 2.995)]  [G loss: -3.098] \n",
      "4115 [D loss: (-0.531)(R -4.315, F 3.253)]  [G loss: -3.106] \n",
      "4116 [D loss: (-0.565)(R -4.366, F 3.236)]  [G loss: -3.044] \n",
      "4116 [D loss: (-0.778)(R -4.249, F 2.693)]  [G loss: -2.830] \n",
      "4117 [D loss: (-0.658)(R -4.674, F 3.359)]  [G loss: -2.982] \n",
      "4117 [D loss: (-0.523)(R -4.590, F 3.543)]  [G loss: -2.877] \n",
      "4118 [D loss: (-0.807)(R -4.582, F 2.967)]  [G loss: -3.291] \n",
      "4118 [D loss: (-0.685)(R -4.634, F 3.264)]  [G loss: -3.246] \n",
      "4119 [D loss: (-0.609)(R -4.314, F 3.095)]  [G loss: -3.183] \n",
      "4119 [D loss: (-0.618)(R -4.616, F 3.379)]  [G loss: -3.191] \n",
      "4120 [D loss: (-0.341)(R -4.440, F 3.757)]  [G loss: -3.001] \n",
      "4120 [D loss: (-0.834)(R -4.577, F 2.908)]  [G loss: -3.109] \n",
      "4121 [D loss: (-0.485)(R -4.311, F 3.341)]  [G loss: -3.149] \n",
      "4121 [D loss: (-0.586)(R -4.406, F 3.233)]  [G loss: -3.359] \n",
      "4122 [D loss: (-0.608)(R -4.547, F 3.332)]  [G loss: -3.179] \n",
      "4122 [D loss: (-0.385)(R -4.385, F 3.615)]  [G loss: -3.035] \n",
      "4123 [D loss: (-0.541)(R -4.549, F 3.468)]  [G loss: -3.125] \n",
      "4123 [D loss: (-0.689)(R -4.535, F 3.156)]  [G loss: -3.284] \n",
      "4124 [D loss: (-0.684)(R -4.540, F 3.173)]  [G loss: -3.207] \n",
      "4124 [D loss: (-0.829)(R -4.630, F 2.973)]  [G loss: -3.355] \n",
      "4125 [D loss: (-0.471)(R -4.539, F 3.598)]  [G loss: -3.049] \n",
      "4125 [D loss: (-0.496)(R -4.235, F 3.243)]  [G loss: -3.098] \n",
      "4126 [D loss: (-0.826)(R -4.403, F 2.752)]  [G loss: -3.082] \n",
      "4126 [D loss: (-0.471)(R -4.312, F 3.371)]  [G loss: -3.116] \n",
      "4127 [D loss: (-0.782)(R -4.523, F 2.959)]  [G loss: -3.154] \n",
      "4127 [D loss: (-1.096)(R -4.754, F 2.561)]  [G loss: -3.229] \n",
      "4128 [D loss: (-0.554)(R -4.418, F 3.311)]  [G loss: -3.167] \n",
      "4128 [D loss: (-0.506)(R -4.494, F 3.482)]  [G loss: -3.109] \n",
      "4129 [D loss: (-0.666)(R -4.330, F 2.998)]  [G loss: -3.016] \n",
      "4129 [D loss: (-0.551)(R -4.392, F 3.290)]  [G loss: -3.112] \n",
      "4130 [D loss: (-0.449)(R -4.248, F 3.349)]  [G loss: -3.047] \n",
      "4130 [D loss: (-0.621)(R -4.362, F 3.121)]  [G loss: -3.021] \n",
      "4131 [D loss: (-0.656)(R -4.451, F 3.138)]  [G loss: -3.048] \n",
      "4131 [D loss: (-0.764)(R -4.524, F 2.996)]  [G loss: -3.074] \n",
      "4132 [D loss: (-0.491)(R -4.506, F 3.523)]  [G loss: -2.856] \n",
      "4132 [D loss: (-0.802)(R -4.602, F 2.999)]  [G loss: -3.200] \n",
      "4133 [D loss: (-0.616)(R -4.162, F 2.929)]  [G loss: -2.672] \n",
      "4133 [D loss: (-0.755)(R -4.379, F 2.870)]  [G loss: -2.823] \n",
      "4134 [D loss: (-0.692)(R -4.548, F 3.164)]  [G loss: -3.067] \n",
      "4134 [D loss: (-0.872)(R -4.365, F 2.620)]  [G loss: -2.927] \n",
      "4135 [D loss: (-0.747)(R -4.365, F 2.871)]  [G loss: -3.012] \n",
      "4135 [D loss: (-0.710)(R -4.387, F 2.968)]  [G loss: -3.097] \n",
      "4136 [D loss: (-0.724)(R -4.354, F 2.905)]  [G loss: -3.038] \n",
      "4136 [D loss: (-0.823)(R -4.206, F 2.560)]  [G loss: -2.743] \n",
      "4137 [D loss: (-0.602)(R -4.206, F 3.002)]  [G loss: -2.981] \n",
      "4137 [D loss: (-0.919)(R -4.127, F 2.290)]  [G loss: -3.009] \n",
      "4138 [D loss: (-0.560)(R -4.198, F 3.077)]  [G loss: -2.824] \n",
      "4138 [D loss: (-0.622)(R -4.167, F 2.922)]  [G loss: -2.540] \n",
      "4139 [D loss: (-0.384)(R -3.918, F 3.149)]  [G loss: -2.675] \n",
      "4139 [D loss: (-0.487)(R -4.221, F 3.247)]  [G loss: -2.743] \n",
      "4140 [D loss: (-0.481)(R -4.168, F 3.206)]  [G loss: -2.885] \n",
      "4140 [D loss: (-0.723)(R -4.398, F 2.953)]  [G loss: -2.772] \n",
      "4141 [D loss: (-0.674)(R -4.182, F 2.834)]  [G loss: -2.840] \n",
      "4141 [D loss: (-0.674)(R -3.983, F 2.635)]  [G loss: -3.125] \n",
      "4142 [D loss: (-0.556)(R -4.050, F 2.937)]  [G loss: -2.742] \n",
      "4142 [D loss: (-0.657)(R -4.216, F 2.901)]  [G loss: -2.842] \n",
      "4143 [D loss: (-0.766)(R -4.403, F 2.870)]  [G loss: -2.772] \n",
      "4143 [D loss: (-0.667)(R -4.255, F 2.920)]  [G loss: -3.014] \n",
      "4144 [D loss: (-0.671)(R -4.236, F 2.895)]  [G loss: -2.838] \n",
      "4144 [D loss: (-0.722)(R -4.308, F 2.863)]  [G loss: -3.078] \n",
      "4145 [D loss: (-0.843)(R -4.517, F 2.831)]  [G loss: -2.935] \n",
      "4145 [D loss: (-0.776)(R -4.280, F 2.728)]  [G loss: -2.729] \n",
      "4146 [D loss: (-0.455)(R -4.258, F 3.348)]  [G loss: -3.409] \n",
      "4146 [D loss: (-0.684)(R -4.356, F 2.988)]  [G loss: -2.945] \n",
      "4147 [D loss: (-0.430)(R -4.180, F 3.320)]  [G loss: -3.227] \n",
      "4147 [D loss: (-0.587)(R -4.259, F 3.085)]  [G loss: -3.069] \n",
      "4148 [D loss: (-0.583)(R -4.277, F 3.111)]  [G loss: -2.817] \n",
      "4148 [D loss: (-0.707)(R -4.560, F 3.147)]  [G loss: -3.231] \n",
      "4149 [D loss: (-0.718)(R -4.470, F 3.034)]  [G loss: -3.066] \n",
      "4149 [D loss: (-0.539)(R -4.381, F 3.302)]  [G loss: -3.118] \n",
      "4150 [D loss: (-0.708)(R -4.507, F 3.090)]  [G loss: -3.076] \n",
      "4150 [D loss: (-0.428)(R -4.567, F 3.711)]  [G loss: -3.045] \n",
      "4151 [D loss: (-0.180)(R -4.391, F 4.030)]  [G loss: -3.207] \n",
      "4151 [D loss: (-0.741)(R -4.682, F 3.199)]  [G loss: -3.350] \n",
      "4152 [D loss: (-0.555)(R -4.549, F 3.438)]  [G loss: -3.112] \n",
      "4152 [D loss: (-0.531)(R -4.616, F 3.555)]  [G loss: -3.428] \n",
      "4153 [D loss: (-0.629)(R -4.513, F 3.254)]  [G loss: -3.280] \n",
      "4153 [D loss: (-0.697)(R -4.503, F 3.109)]  [G loss: -3.192] \n",
      "4154 [D loss: (-0.736)(R -4.595, F 3.122)]  [G loss: -3.197] \n",
      "4154 [D loss: (-0.390)(R -4.465, F 3.685)]  [G loss: -3.138] \n",
      "4155 [D loss: (-0.760)(R -4.655, F 3.135)]  [G loss: -3.168] \n",
      "4155 [D loss: (-0.860)(R -4.439, F 2.719)]  [G loss: -3.054] \n",
      "4156 [D loss: (-0.534)(R -4.516, F 3.448)]  [G loss: -3.119] \n",
      "4156 [D loss: (-0.718)(R -4.562, F 3.126)]  [G loss: -3.363] \n",
      "4157 [D loss: (-0.750)(R -4.552, F 3.053)]  [G loss: -3.350] \n",
      "4157 [D loss: (-0.681)(R -4.427, F 3.065)]  [G loss: -3.173] \n",
      "4158 [D loss: (-0.704)(R -4.501, F 3.093)]  [G loss: -3.407] \n",
      "4158 [D loss: (-0.688)(R -4.547, F 3.170)]  [G loss: -3.304] \n",
      "4159 [D loss: (-0.453)(R -4.573, F 3.667)]  [G loss: -2.975] \n",
      "4159 [D loss: (-0.594)(R -4.297, F 3.110)]  [G loss: -3.348] \n",
      "4160 [D loss: (-0.732)(R -4.657, F 3.193)]  [G loss: -3.164] \n",
      "4160 [D loss: (-0.634)(R -4.407, F 3.139)]  [G loss: -3.119] \n",
      "4161 [D loss: (-0.588)(R -4.815, F 3.640)]  [G loss: -3.382] \n",
      "4161 [D loss: (-0.398)(R -4.564, F 3.767)]  [G loss: -3.322] \n",
      "4162 [D loss: (-0.670)(R -4.644, F 3.304)]  [G loss: -3.290] \n",
      "4162 [D loss: (-0.610)(R -4.899, F 3.678)]  [G loss: -3.377] \n",
      "4163 [D loss: (-0.729)(R -4.581, F 3.123)]  [G loss: -3.153] \n",
      "4163 [D loss: (-0.836)(R -4.561, F 2.889)]  [G loss: -3.280] \n",
      "4164 [D loss: (-0.541)(R -4.354, F 3.271)]  [G loss: -3.234] \n",
      "4164 [D loss: (-0.838)(R -4.831, F 3.156)]  [G loss: -3.044] \n",
      "4165 [D loss: (-0.755)(R -4.619, F 3.109)]  [G loss: -3.239] \n",
      "4165 [D loss: (-0.662)(R -4.649, F 3.326)]  [G loss: -3.314] \n",
      "4166 [D loss: (-0.759)(R -4.508, F 2.990)]  [G loss: -3.451] \n",
      "4166 [D loss: (-0.559)(R -4.490, F 3.372)]  [G loss: -3.194] \n",
      "4167 [D loss: (-0.686)(R -4.581, F 3.209)]  [G loss: -3.292] \n",
      "4167 [D loss: (-0.425)(R -4.415, F 3.564)]  [G loss: -3.259] \n",
      "4168 [D loss: (-0.575)(R -4.537, F 3.386)]  [G loss: -3.258] \n",
      "4168 [D loss: (-0.482)(R -4.454, F 3.489)]  [G loss: -3.010] \n",
      "4169 [D loss: (-0.775)(R -4.570, F 3.020)]  [G loss: -3.192] \n",
      "4169 [D loss: (-0.681)(R -4.519, F 3.157)]  [G loss: -3.403] \n",
      "4170 [D loss: (-0.728)(R -4.702, F 3.246)]  [G loss: -3.169] \n",
      "4170 [D loss: (-0.826)(R -4.496, F 2.845)]  [G loss: -3.143] \n",
      "4171 [D loss: (-0.872)(R -4.760, F 3.017)]  [G loss: -3.264] \n",
      "4171 [D loss: (-0.479)(R -4.516, F 3.558)]  [G loss: -3.148] \n",
      "4172 [D loss: (-0.476)(R -4.487, F 3.534)]  [G loss: -3.223] \n",
      "4172 [D loss: (-0.806)(R -4.567, F 2.956)]  [G loss: -3.371] \n",
      "4173 [D loss: (-0.498)(R -4.455, F 3.460)]  [G loss: -3.136] \n",
      "4173 [D loss: (-0.686)(R -4.398, F 3.027)]  [G loss: -3.069] \n",
      "4174 [D loss: (-0.560)(R -4.228, F 3.108)]  [G loss: -3.146] \n",
      "4174 [D loss: (-0.723)(R -4.469, F 3.022)]  [G loss: -3.149] \n",
      "4175 [D loss: (-0.576)(R -4.403, F 3.251)]  [G loss: -2.838] \n",
      "4175 [D loss: (-0.536)(R -4.271, F 3.199)]  [G loss: -3.313] \n",
      "4176 [D loss: (-0.670)(R -4.338, F 2.998)]  [G loss: -3.117] \n",
      "4176 [D loss: (-0.615)(R -4.223, F 2.993)]  [G loss: -3.387] \n",
      "4177 [D loss: (-0.508)(R -4.513, F 3.497)]  [G loss: -3.445] \n",
      "4177 [D loss: (-0.807)(R -4.507, F 2.893)]  [G loss: -3.180] \n",
      "4178 [D loss: (-0.531)(R -4.599, F 3.538)]  [G loss: -3.365] \n",
      "4178 [D loss: (-0.606)(R -4.651, F 3.438)]  [G loss: -3.181] \n",
      "4179 [D loss: (-0.888)(R -4.541, F 2.764)]  [G loss: -3.259] \n",
      "4179 [D loss: (-0.673)(R -4.610, F 3.264)]  [G loss: -3.281] \n",
      "4180 [D loss: (-0.894)(R -4.737, F 2.950)]  [G loss: -3.425] \n",
      "4180 [D loss: (-0.423)(R -4.316, F 3.471)]  [G loss: -3.321] \n",
      "4181 [D loss: (-0.566)(R -4.629, F 3.498)]  [G loss: -3.229] \n",
      "4181 [D loss: (-0.551)(R -4.559, F 3.458)]  [G loss: -3.368] \n",
      "4182 [D loss: (-0.614)(R -4.420, F 3.193)]  [G loss: -3.267] \n",
      "4182 [D loss: (-0.734)(R -4.561, F 3.094)]  [G loss: -3.083] \n",
      "4183 [D loss: (-0.744)(R -4.531, F 3.043)]  [G loss: -3.221] \n",
      "4183 [D loss: (-0.598)(R -4.604, F 3.408)]  [G loss: -3.249] \n",
      "4184 [D loss: (-0.588)(R -4.418, F 3.243)]  [G loss: -3.240] \n",
      "4184 [D loss: (-0.689)(R -4.502, F 3.125)]  [G loss: -3.131] \n",
      "4185 [D loss: (-0.846)(R -4.719, F 3.027)]  [G loss: -3.494] \n",
      "4185 [D loss: (-0.525)(R -4.193, F 3.143)]  [G loss: -3.239] \n",
      "4186 [D loss: (-0.885)(R -4.482, F 2.712)]  [G loss: -3.209] \n",
      "4186 [D loss: (-0.680)(R -4.494, F 3.133)]  [G loss: -2.984] \n",
      "4187 [D loss: (-0.593)(R -4.404, F 3.218)]  [G loss: -3.258] \n",
      "4187 [D loss: (-0.668)(R -4.365, F 3.029)]  [G loss: -3.358] \n",
      "4188 [D loss: (-0.805)(R -4.532, F 2.921)]  [G loss: -3.078] \n",
      "4188 [D loss: (-0.688)(R -4.529, F 3.152)]  [G loss: -3.055] \n",
      "4189 [D loss: (-0.797)(R -4.392, F 2.797)]  [G loss: -3.027] \n",
      "4189 [D loss: (-0.565)(R -4.495, F 3.366)]  [G loss: -2.983] \n",
      "4190 [D loss: (-0.606)(R -4.201, F 2.988)]  [G loss: -3.197] \n",
      "4190 [D loss: (-0.793)(R -4.524, F 2.938)]  [G loss: -3.250] \n",
      "4191 [D loss: (-0.537)(R -4.413, F 3.338)]  [G loss: -3.149] \n",
      "4191 [D loss: (-0.524)(R -4.500, F 3.452)]  [G loss: -3.152] \n",
      "4192 [D loss: (-0.581)(R -4.477, F 3.315)]  [G loss: -2.967] \n",
      "4192 [D loss: (-0.790)(R -4.583, F 3.003)]  [G loss: -3.167] \n",
      "4193 [D loss: (-0.678)(R -4.416, F 3.059)]  [G loss: -3.251] \n",
      "4193 [D loss: (-0.650)(R -4.683, F 3.383)]  [G loss: -3.392] \n",
      "4194 [D loss: (-0.542)(R -4.238, F 3.153)]  [G loss: -3.106] \n",
      "4194 [D loss: (-0.682)(R -4.604, F 3.240)]  [G loss: -3.119] \n",
      "4195 [D loss: (-0.857)(R -4.560, F 2.847)]  [G loss: -2.776] \n",
      "4195 [D loss: (-0.481)(R -4.443, F 3.480)]  [G loss: -3.060] \n",
      "4196 [D loss: (-0.412)(R -4.374, F 3.550)]  [G loss: -3.252] \n",
      "4196 [D loss: (-0.727)(R -4.528, F 3.074)]  [G loss: -3.472] \n",
      "4197 [D loss: (-0.626)(R -4.477, F 3.226)]  [G loss: -3.478] \n",
      "4197 [D loss: (-0.674)(R -4.373, F 3.024)]  [G loss: -3.277] \n",
      "4198 [D loss: (-0.334)(R -4.376, F 3.709)]  [G loss: -3.319] \n",
      "4198 [D loss: (-0.562)(R -4.434, F 3.310)]  [G loss: -3.309] \n",
      "4199 [D loss: (-0.651)(R -4.456, F 3.154)]  [G loss: -3.094] \n",
      "4199 [D loss: (-0.689)(R -4.595, F 3.218)]  [G loss: -3.156] \n",
      "4200 [D loss: (-0.815)(R -4.558, F 2.928)]  [G loss: -3.162] \n",
      "4200 [D loss: (-0.556)(R -4.445, F 3.333)]  [G loss: -3.302] \n",
      "4201 [D loss: (-0.916)(R -4.816, F 2.984)]  [G loss: -3.266] \n",
      "4201 [D loss: (-0.618)(R -4.599, F 3.363)]  [G loss: -3.301] \n",
      "4202 [D loss: (-0.533)(R -4.677, F 3.612)]  [G loss: -3.166] \n",
      "4202 [D loss: (-0.735)(R -4.609, F 3.139)]  [G loss: -3.377] \n",
      "4203 [D loss: (-0.608)(R -4.545, F 3.328)]  [G loss: -3.303] \n",
      "4203 [D loss: (-0.793)(R -4.625, F 3.040)]  [G loss: -3.214] \n",
      "4204 [D loss: (-0.573)(R -4.419, F 3.272)]  [G loss: -3.009] \n",
      "4204 [D loss: (-0.614)(R -4.579, F 3.351)]  [G loss: -3.095] \n",
      "4205 [D loss: (-0.559)(R -4.623, F 3.506)]  [G loss: -3.355] \n",
      "4205 [D loss: (-0.635)(R -4.605, F 3.334)]  [G loss: -3.235] \n",
      "4206 [D loss: (-0.625)(R -4.420, F 3.170)]  [G loss: -3.184] \n",
      "4206 [D loss: (-0.527)(R -4.517, F 3.463)]  [G loss: -3.323] \n",
      "4207 [D loss: (-0.661)(R -4.604, F 3.282)]  [G loss: -3.428] \n",
      "4207 [D loss: (-0.662)(R -4.629, F 3.304)]  [G loss: -3.216] \n",
      "4208 [D loss: (-0.470)(R -4.604, F 3.664)]  [G loss: -3.181] \n",
      "4208 [D loss: (-0.615)(R -4.812, F 3.581)]  [G loss: -3.424] \n",
      "4209 [D loss: (-0.543)(R -4.768, F 3.682)]  [G loss: -3.439] \n",
      "4209 [D loss: (-0.650)(R -4.693, F 3.393)]  [G loss: -3.490] \n",
      "4210 [D loss: (-0.551)(R -4.594, F 3.491)]  [G loss: -3.456] \n",
      "4210 [D loss: (-0.403)(R -4.420, F 3.614)]  [G loss: -3.350] \n",
      "4211 [D loss: (-0.654)(R -4.932, F 3.625)]  [G loss: -3.366] \n",
      "4211 [D loss: (-0.596)(R -4.629, F 3.438)]  [G loss: -3.174] \n",
      "4212 [D loss: (-0.794)(R -4.668, F 3.080)]  [G loss: -3.234] \n",
      "4212 [D loss: (-0.355)(R -4.524, F 3.814)]  [G loss: -3.355] \n",
      "4213 [D loss: (-0.762)(R -4.609, F 3.085)]  [G loss: -3.232] \n",
      "4213 [D loss: (-0.790)(R -4.838, F 3.258)]  [G loss: -3.535] \n",
      "4214 [D loss: (-0.567)(R -4.479, F 3.344)]  [G loss: -3.458] \n",
      "4214 [D loss: (-0.757)(R -4.880, F 3.366)]  [G loss: -3.173] \n",
      "4215 [D loss: (-0.504)(R -4.537, F 3.528)]  [G loss: -3.321] \n",
      "4215 [D loss: (-0.604)(R -4.567, F 3.359)]  [G loss: -3.538] \n",
      "4216 [D loss: (-0.730)(R -4.779, F 3.319)]  [G loss: -3.470] \n",
      "4216 [D loss: (-0.479)(R -4.410, F 3.452)]  [G loss: -3.317] \n",
      "4217 [D loss: (-0.707)(R -4.672, F 3.257)]  [G loss: -3.662] \n",
      "4217 [D loss: (-0.605)(R -4.630, F 3.420)]  [G loss: -3.535] \n",
      "4218 [D loss: (-0.430)(R -4.699, F 3.839)]  [G loss: -3.556] \n",
      "4218 [D loss: (-0.551)(R -4.613, F 3.511)]  [G loss: -3.465] \n",
      "4219 [D loss: (-0.386)(R -4.726, F 3.953)]  [G loss: -3.520] \n",
      "4219 [D loss: (-0.488)(R -4.622, F 3.646)]  [G loss: -3.354] \n",
      "4220 [D loss: (-0.679)(R -4.620, F 3.262)]  [G loss: -3.374] \n",
      "4220 [D loss: (-0.510)(R -4.442, F 3.423)]  [G loss: -3.395] \n",
      "4221 [D loss: (-0.879)(R -5.059, F 3.300)]  [G loss: -3.383] \n",
      "4221 [D loss: (-0.778)(R -4.612, F 3.056)]  [G loss: -3.340] \n",
      "4222 [D loss: (-0.691)(R -4.719, F 3.337)]  [G loss: -3.219] \n",
      "4222 [D loss: (-0.651)(R -4.711, F 3.409)]  [G loss: -3.076] \n",
      "4223 [D loss: (-0.937)(R -4.690, F 2.817)]  [G loss: -3.518] \n",
      "4223 [D loss: (-0.467)(R -4.661, F 3.727)]  [G loss: -3.673] \n",
      "4224 [D loss: (-0.607)(R -4.449, F 3.234)]  [G loss: -3.231] \n",
      "4224 [D loss: (-0.794)(R -4.717, F 3.128)]  [G loss: -3.333] \n",
      "4225 [D loss: (-0.488)(R -4.600, F 3.624)]  [G loss: -3.272] \n",
      "4225 [D loss: (-0.561)(R -4.696, F 3.575)]  [G loss: -3.312] \n",
      "4226 [D loss: (-0.858)(R -4.520, F 2.805)]  [G loss: -3.276] \n",
      "4226 [D loss: (-0.633)(R -4.586, F 3.321)]  [G loss: -3.235] \n",
      "4227 [D loss: (-0.741)(R -4.549, F 3.067)]  [G loss: -3.290] \n",
      "4227 [D loss: (-0.533)(R -4.467, F 3.402)]  [G loss: -3.318] \n",
      "4228 [D loss: (-0.538)(R -4.520, F 3.445)]  [G loss: -3.312] \n",
      "4228 [D loss: (-0.804)(R -4.698, F 3.089)]  [G loss: -3.170] \n",
      "4229 [D loss: (-0.820)(R -4.715, F 3.075)]  [G loss: -3.339] \n",
      "4229 [D loss: (-0.654)(R -4.749, F 3.441)]  [G loss: -3.396] \n",
      "4230 [D loss: (-0.460)(R -4.620, F 3.701)]  [G loss: -3.322] \n",
      "4230 [D loss: (-0.672)(R -4.637, F 3.293)]  [G loss: -3.266] \n",
      "4231 [D loss: (-0.583)(R -4.395, F 3.230)]  [G loss: -3.291] \n",
      "4231 [D loss: (-0.508)(R -4.589, F 3.573)]  [G loss: -3.439] \n",
      "4232 [D loss: (-0.748)(R -4.800, F 3.305)]  [G loss: -3.420] \n",
      "4232 [D loss: (-0.494)(R -4.545, F 3.558)]  [G loss: -3.105] \n",
      "4233 [D loss: (-0.613)(R -4.698, F 3.473)]  [G loss: -3.482] \n",
      "4233 [D loss: (-0.697)(R -4.670, F 3.275)]  [G loss: -3.481] \n",
      "4234 [D loss: (-0.444)(R -4.671, F 3.784)]  [G loss: -3.488] \n",
      "4234 [D loss: (-0.593)(R -4.602, F 3.417)]  [G loss: -3.509] \n",
      "4235 [D loss: (-0.429)(R -4.560, F 3.702)]  [G loss: -3.538] \n",
      "4235 [D loss: (-0.713)(R -4.799, F 3.374)]  [G loss: -3.102] \n",
      "4236 [D loss: (-0.805)(R -4.679, F 3.068)]  [G loss: -3.347] \n",
      "4236 [D loss: (-0.529)(R -4.601, F 3.542)]  [G loss: -3.542] \n",
      "4237 [D loss: (-0.487)(R -4.754, F 3.780)]  [G loss: -3.588] \n",
      "4237 [D loss: (-0.789)(R -4.624, F 3.046)]  [G loss: -3.249] \n",
      "4238 [D loss: (-0.491)(R -4.643, F 3.661)]  [G loss: -3.098] \n",
      "4238 [D loss: (-0.687)(R -4.758, F 3.383)]  [G loss: -3.370] \n",
      "4239 [D loss: (-0.834)(R -4.683, F 3.015)]  [G loss: -3.512] \n",
      "4239 [D loss: (-0.654)(R -4.789, F 3.482)]  [G loss: -3.486] \n",
      "4240 [D loss: (-0.666)(R -4.558, F 3.226)]  [G loss: -3.355] \n",
      "4240 [D loss: (-0.887)(R -4.810, F 3.035)]  [G loss: -3.322] \n",
      "4241 [D loss: (-0.562)(R -4.606, F 3.483)]  [G loss: -3.348] \n",
      "4241 [D loss: (-0.628)(R -4.605, F 3.349)]  [G loss: -3.298] \n",
      "4242 [D loss: (-0.575)(R -4.574, F 3.424)]  [G loss: -3.179] \n",
      "4242 [D loss: (-0.633)(R -4.535, F 3.268)]  [G loss: -3.335] \n",
      "4243 [D loss: (-0.611)(R -4.668, F 3.446)]  [G loss: -3.290] \n",
      "4243 [D loss: (-0.654)(R -4.705, F 3.398)]  [G loss: -3.248] \n",
      "4244 [D loss: (-0.708)(R -4.637, F 3.221)]  [G loss: -3.411] \n",
      "4244 [D loss: (-0.599)(R -4.628, F 3.430)]  [G loss: -2.948] \n",
      "4245 [D loss: (-0.782)(R -4.633, F 3.070)]  [G loss: -3.375] \n",
      "4245 [D loss: (-0.702)(R -4.797, F 3.393)]  [G loss: -3.327] \n",
      "4246 [D loss: (-0.807)(R -4.890, F 3.276)]  [G loss: -3.522] \n",
      "4246 [D loss: (-0.565)(R -4.695, F 3.566)]  [G loss: -3.412] \n",
      "4247 [D loss: (-0.634)(R -4.719, F 3.451)]  [G loss: -3.430] \n",
      "4247 [D loss: (-0.649)(R -4.687, F 3.389)]  [G loss: -3.340] \n",
      "4248 [D loss: (-0.557)(R -4.584, F 3.469)]  [G loss: -3.255] \n",
      "4248 [D loss: (-0.474)(R -4.529, F 3.581)]  [G loss: -3.353] \n",
      "4249 [D loss: (-0.600)(R -4.659, F 3.459)]  [G loss: -3.159] \n",
      "4249 [D loss: (-0.538)(R -4.566, F 3.490)]  [G loss: -3.237] \n",
      "4250 [D loss: (-0.878)(R -4.725, F 2.969)]  [G loss: -3.096] \n",
      "4250 [D loss: (-0.977)(R -4.820, F 2.866)]  [G loss: -3.266] \n",
      "4251 [D loss: (-0.633)(R -4.633, F 3.366)]  [G loss: -3.275] \n",
      "4251 [D loss: (-0.591)(R -4.715, F 3.533)]  [G loss: -3.434] \n",
      "4252 [D loss: (-0.559)(R -4.609, F 3.491)]  [G loss: -3.255] \n",
      "4252 [D loss: (-0.619)(R -4.752, F 3.514)]  [G loss: -3.335] \n",
      "4253 [D loss: (-0.591)(R -4.641, F 3.460)]  [G loss: -3.278] \n",
      "4253 [D loss: (-0.412)(R -4.618, F 3.795)]  [G loss: -3.464] \n",
      "4254 [D loss: (-0.771)(R -4.754, F 3.211)]  [G loss: -3.339] \n",
      "4254 [D loss: (-0.553)(R -4.788, F 3.681)]  [G loss: -3.377] \n",
      "4255 [D loss: (-0.617)(R -4.635, F 3.401)]  [G loss: -3.410] \n",
      "4255 [D loss: (-0.718)(R -4.801, F 3.365)]  [G loss: -3.403] \n",
      "4256 [D loss: (-0.895)(R -4.608, F 2.817)]  [G loss: -3.441] \n",
      "4256 [D loss: (-0.655)(R -4.668, F 3.358)]  [G loss: -3.473] \n",
      "4257 [D loss: (-0.630)(R -4.584, F 3.324)]  [G loss: -3.500] \n",
      "4257 [D loss: (-0.538)(R -4.758, F 3.683)]  [G loss: -3.359] \n",
      "4258 [D loss: (-0.502)(R -4.658, F 3.654)]  [G loss: -3.427] \n",
      "4258 [D loss: (-0.498)(R -4.725, F 3.729)]  [G loss: -3.490] \n",
      "4259 [D loss: (-0.612)(R -4.505, F 3.281)]  [G loss: -3.345] \n",
      "4259 [D loss: (-0.673)(R -4.656, F 3.311)]  [G loss: -3.341] \n",
      "4260 [D loss: (-0.444)(R -4.779, F 3.891)]  [G loss: -3.420] \n",
      "4260 [D loss: (-0.775)(R -4.921, F 3.371)]  [G loss: -3.343] \n",
      "4261 [D loss: (-0.485)(R -4.720, F 3.751)]  [G loss: -3.439] \n",
      "4261 [D loss: (-0.714)(R -4.558, F 3.129)]  [G loss: -3.326] \n",
      "4262 [D loss: (-0.573)(R -4.604, F 3.458)]  [G loss: -3.319] \n",
      "4262 [D loss: (-0.887)(R -4.581, F 2.806)]  [G loss: -3.402] \n",
      "4263 [D loss: (-0.879)(R -4.625, F 2.867)]  [G loss: -3.381] \n",
      "4263 [D loss: (-0.511)(R -4.575, F 3.552)]  [G loss: -3.210] \n",
      "4264 [D loss: (-0.743)(R -4.615, F 3.130)]  [G loss: -3.131] \n",
      "4264 [D loss: (-0.663)(R -4.610, F 3.284)]  [G loss: -3.237] \n",
      "4265 [D loss: (-0.840)(R -4.817, F 3.138)]  [G loss: -3.229] \n",
      "4265 [D loss: (-0.706)(R -4.565, F 3.153)]  [G loss: -3.260] \n",
      "4266 [D loss: (-0.631)(R -4.578, F 3.316)]  [G loss: -3.229] \n",
      "4266 [D loss: (-0.699)(R -4.669, F 3.272)]  [G loss: -3.168] \n",
      "4267 [D loss: (-0.634)(R -4.505, F 3.237)]  [G loss: -3.288] \n",
      "4267 [D loss: (-0.782)(R -4.651, F 3.087)]  [G loss: -3.228] \n",
      "4268 [D loss: (-0.789)(R -4.443, F 2.865)]  [G loss: -3.305] \n",
      "4268 [D loss: (-0.761)(R -4.657, F 3.135)]  [G loss: -3.031] \n",
      "4269 [D loss: (-0.822)(R -4.167, F 2.522)]  [G loss: -3.041] \n",
      "4269 [D loss: (-0.744)(R -4.549, F 3.061)]  [G loss: -3.235] \n",
      "4270 [D loss: (-0.580)(R -4.457, F 3.298)]  [G loss: -3.333] \n",
      "4270 [D loss: (-0.778)(R -4.381, F 2.824)]  [G loss: -3.173] \n",
      "4271 [D loss: (-0.854)(R -4.590, F 2.883)]  [G loss: -2.890] \n",
      "4271 [D loss: (-0.844)(R -4.291, F 2.602)]  [G loss: -3.253] \n",
      "4272 [D loss: (-0.477)(R -4.297, F 3.342)]  [G loss: -3.055] \n",
      "4272 [D loss: (-0.762)(R -4.649, F 3.125)]  [G loss: -3.035] \n",
      "4273 [D loss: (-0.787)(R -4.358, F 2.783)]  [G loss: -3.048] \n",
      "4273 [D loss: (-0.494)(R -4.223, F 3.235)]  [G loss: -2.975] \n",
      "4274 [D loss: (-0.627)(R -4.531, F 3.276)]  [G loss: -2.976] \n",
      "4274 [D loss: (-0.572)(R -4.161, F 3.017)]  [G loss: -2.913] \n",
      "4275 [D loss: (-0.635)(R -4.436, F 3.165)]  [G loss: -2.687] \n",
      "4275 [D loss: (-0.604)(R -4.439, F 3.231)]  [G loss: -3.056] \n",
      "4276 [D loss: (-0.277)(R -4.285, F 3.730)]  [G loss: -3.009] \n",
      "4276 [D loss: (-0.552)(R -4.466, F 3.363)]  [G loss: -3.241] \n",
      "4277 [D loss: (-0.796)(R -4.429, F 2.838)]  [G loss: -3.203] \n",
      "4277 [D loss: (-0.477)(R -4.295, F 3.341)]  [G loss: -3.136] \n",
      "4278 [D loss: (-0.664)(R -4.300, F 2.972)]  [G loss: -3.273] \n",
      "4278 [D loss: (-0.528)(R -4.362, F 3.305)]  [G loss: -3.039] \n",
      "4279 [D loss: (-0.489)(R -4.400, F 3.423)]  [G loss: -3.313] \n",
      "4279 [D loss: (-0.742)(R -4.352, F 2.868)]  [G loss: -3.290] \n",
      "4280 [D loss: (-0.690)(R -4.502, F 3.122)]  [G loss: -3.201] \n",
      "4280 [D loss: (-0.978)(R -4.461, F 2.504)]  [G loss: -3.185] \n",
      "4281 [D loss: (-0.604)(R -4.399, F 3.190)]  [G loss: -3.227] \n",
      "4281 [D loss: (-0.632)(R -4.600, F 3.336)]  [G loss: -3.131] \n",
      "4282 [D loss: (-0.634)(R -4.567, F 3.299)]  [G loss: -3.044] \n",
      "4282 [D loss: (-0.295)(R -4.236, F 3.646)]  [G loss: -2.967] \n",
      "4283 [D loss: (-0.429)(R -4.367, F 3.509)]  [G loss: -3.193] \n",
      "4283 [D loss: (-0.653)(R -4.729, F 3.423)]  [G loss: -3.237] \n",
      "4284 [D loss: (-0.794)(R -4.470, F 2.882)]  [G loss: -3.161] \n",
      "4284 [D loss: (-0.602)(R -4.672, F 3.468)]  [G loss: -2.973] \n",
      "4285 [D loss: (-0.518)(R -4.541, F 3.505)]  [G loss: -3.213] \n",
      "4285 [D loss: (-0.701)(R -4.814, F 3.412)]  [G loss: -3.172] \n",
      "4286 [D loss: (-0.613)(R -4.496, F 3.270)]  [G loss: -3.009] \n",
      "4286 [D loss: (-0.684)(R -4.537, F 3.169)]  [G loss: -3.167] \n",
      "4287 [D loss: (-0.655)(R -4.547, F 3.237)]  [G loss: -3.421] \n",
      "4287 [D loss: (-0.643)(R -4.642, F 3.356)]  [G loss: -3.406] \n",
      "4288 [D loss: (-0.621)(R -4.566, F 3.324)]  [G loss: -3.446] \n",
      "4288 [D loss: (-0.634)(R -4.430, F 3.162)]  [G loss: -3.415] \n",
      "4289 [D loss: (-0.760)(R -4.647, F 3.128)]  [G loss: -3.118] \n",
      "4289 [D loss: (-0.624)(R -4.646, F 3.399)]  [G loss: -3.517] \n",
      "4290 [D loss: (-0.697)(R -4.641, F 3.248)]  [G loss: -3.217] \n",
      "4290 [D loss: (-0.678)(R -4.680, F 3.325)]  [G loss: -3.361] \n",
      "4291 [D loss: (-0.764)(R -4.723, F 3.195)]  [G loss: -3.331] \n",
      "4291 [D loss: (-0.963)(R -4.655, F 2.729)]  [G loss: -3.414] \n",
      "4292 [D loss: (-0.841)(R -4.600, F 2.918)]  [G loss: -3.325] \n",
      "4292 [D loss: (-0.563)(R -4.415, F 3.290)]  [G loss: -3.355] \n",
      "4293 [D loss: (-0.714)(R -4.555, F 3.128)]  [G loss: -3.335] \n",
      "4293 [D loss: (-0.594)(R -4.357, F 3.170)]  [G loss: -3.153] \n",
      "4294 [D loss: (-0.824)(R -4.607, F 2.958)]  [G loss: -3.156] \n",
      "4294 [D loss: (-0.676)(R -4.616, F 3.264)]  [G loss: -3.175] \n",
      "4295 [D loss: (-0.749)(R -4.629, F 3.131)]  [G loss: -3.414] \n",
      "4295 [D loss: (-0.713)(R -4.515, F 3.089)]  [G loss: -3.390] \n",
      "4296 [D loss: (-0.640)(R -4.489, F 3.210)]  [G loss: -3.033] \n",
      "4296 [D loss: (-1.001)(R -4.751, F 2.748)]  [G loss: -3.244] \n",
      "4297 [D loss: (-0.731)(R -4.569, F 3.107)]  [G loss: -3.361] \n",
      "4297 [D loss: (-0.641)(R -4.706, F 3.425)]  [G loss: -3.381] \n",
      "4298 [D loss: (-0.421)(R -4.436, F 3.595)]  [G loss: -3.309] \n",
      "4298 [D loss: (-0.779)(R -4.698, F 3.140)]  [G loss: -3.363] \n",
      "4299 [D loss: (-0.975)(R -4.645, F 2.695)]  [G loss: -3.163] \n",
      "4299 [D loss: (-0.752)(R -4.561, F 3.057)]  [G loss: -3.134] \n",
      "4300 [D loss: (-0.819)(R -4.640, F 3.001)]  [G loss: -3.213] \n",
      "4300 [D loss: (-0.783)(R -4.537, F 2.970)]  [G loss: -3.264] \n",
      "4301 [D loss: (-0.562)(R -4.479, F 3.356)]  [G loss: -3.479] \n",
      "4301 [D loss: (-0.640)(R -4.449, F 3.169)]  [G loss: -3.222] \n",
      "4302 [D loss: (-0.796)(R -4.614, F 3.021)]  [G loss: -3.010] \n",
      "4302 [D loss: (-0.419)(R -4.455, F 3.618)]  [G loss: -3.719] \n",
      "4303 [D loss: (-0.865)(R -4.667, F 2.938)]  [G loss: -3.219] \n",
      "4303 [D loss: (-0.612)(R -4.439, F 3.216)]  [G loss: -3.123] \n",
      "4304 [D loss: (-0.523)(R -4.645, F 3.598)]  [G loss: -3.288] \n",
      "4304 [D loss: (-0.681)(R -4.648, F 3.286)]  [G loss: -3.338] \n",
      "4305 [D loss: (-0.781)(R -4.745, F 3.183)]  [G loss: -3.551] \n",
      "4305 [D loss: (-0.546)(R -4.670, F 3.579)]  [G loss: -3.573] \n",
      "4306 [D loss: (-0.904)(R -4.593, F 2.786)]  [G loss: -3.589] \n",
      "4306 [D loss: (-1.051)(R -4.848, F 2.745)]  [G loss: -3.539] \n",
      "4307 [D loss: (-0.722)(R -4.766, F 3.322)]  [G loss: -3.476] \n",
      "4307 [D loss: (-0.708)(R -4.728, F 3.311)]  [G loss: -3.532] \n",
      "4308 [D loss: (-0.643)(R -4.779, F 3.494)]  [G loss: -3.481] \n",
      "4308 [D loss: (-0.570)(R -4.900, F 3.759)]  [G loss: -3.405] \n",
      "4309 [D loss: (-0.684)(R -4.763, F 3.395)]  [G loss: -3.404] \n",
      "4309 [D loss: (-0.758)(R -4.970, F 3.454)]  [G loss: -3.392] \n",
      "4310 [D loss: (-0.571)(R -4.841, F 3.699)]  [G loss: -3.417] \n",
      "4310 [D loss: (-0.711)(R -4.974, F 3.551)]  [G loss: -3.609] \n",
      "4311 [D loss: (-0.302)(R -4.639, F 4.036)]  [G loss: -3.497] \n",
      "4311 [D loss: (-0.657)(R -4.719, F 3.405)]  [G loss: -3.480] \n",
      "4312 [D loss: (-0.547)(R -4.752, F 3.659)]  [G loss: -3.661] \n",
      "4312 [D loss: (-0.443)(R -4.636, F 3.749)]  [G loss: -3.499] \n",
      "4313 [D loss: (-0.552)(R -4.800, F 3.697)]  [G loss: -3.574] \n",
      "4313 [D loss: (-0.787)(R -5.040, F 3.465)]  [G loss: -3.579] \n",
      "4314 [D loss: (-0.605)(R -4.872, F 3.663)]  [G loss: -3.509] \n",
      "4314 [D loss: (-0.789)(R -4.941, F 3.363)]  [G loss: -3.804] \n",
      "4315 [D loss: (-0.822)(R -4.872, F 3.229)]  [G loss: -3.658] \n",
      "4315 [D loss: (-0.540)(R -4.795, F 3.714)]  [G loss: -3.553] \n",
      "4316 [D loss: (-0.623)(R -4.811, F 3.565)]  [G loss: -3.694] \n",
      "4316 [D loss: (-0.788)(R -5.018, F 3.442)]  [G loss: -3.733] \n",
      "4317 [D loss: (-0.372)(R -4.745, F 4.000)]  [G loss: -3.714] \n",
      "4317 [D loss: (-0.466)(R -4.795, F 3.862)]  [G loss: -3.540] \n",
      "4318 [D loss: (-0.631)(R -4.981, F 3.718)]  [G loss: -3.451] \n",
      "4318 [D loss: (-0.803)(R -4.939, F 3.333)]  [G loss: -3.632] \n",
      "4319 [D loss: (-0.605)(R -4.826, F 3.616)]  [G loss: -3.641] \n",
      "4319 [D loss: (-0.588)(R -4.929, F 3.753)]  [G loss: -3.464] \n",
      "4320 [D loss: (-0.643)(R -4.963, F 3.677)]  [G loss: -3.753] \n",
      "4320 [D loss: (-0.576)(R -5.022, F 3.869)]  [G loss: -3.701] \n",
      "4321 [D loss: (-0.644)(R -4.907, F 3.619)]  [G loss: -3.536] \n",
      "4321 [D loss: (-0.621)(R -4.850, F 3.608)]  [G loss: -3.667] \n",
      "4322 [D loss: (-0.506)(R -4.874, F 3.862)]  [G loss: -3.516] \n",
      "4322 [D loss: (-0.821)(R -5.005, F 3.364)]  [G loss: -3.560] \n",
      "4323 [D loss: (-0.452)(R -4.826, F 3.922)]  [G loss: -3.761] \n",
      "4323 [D loss: (-0.739)(R -4.927, F 3.448)]  [G loss: -3.460] \n",
      "4324 [D loss: (-0.384)(R -4.857, F 4.089)]  [G loss: -3.585] \n",
      "4324 [D loss: (-0.544)(R -4.722, F 3.634)]  [G loss: -3.581] \n",
      "4325 [D loss: (-0.521)(R -4.771, F 3.729)]  [G loss: -3.806] \n",
      "4325 [D loss: (-0.573)(R -5.011, F 3.865)]  [G loss: -3.813] \n",
      "4326 [D loss: (-0.559)(R -4.994, F 3.875)]  [G loss: -3.782] \n",
      "4326 [D loss: (-0.506)(R -5.028, F 4.016)]  [G loss: -3.641] \n",
      "4327 [D loss: (-0.563)(R -5.026, F 3.900)]  [G loss: -3.727] \n",
      "4327 [D loss: (-0.624)(R -5.097, F 3.849)]  [G loss: -3.686] \n",
      "4328 [D loss: (-0.531)(R -5.092, F 4.030)]  [G loss: -3.803] \n",
      "4328 [D loss: (-0.586)(R -4.918, F 3.746)]  [G loss: -3.589] \n",
      "4329 [D loss: (-0.625)(R -5.031, F 3.780)]  [G loss: -3.839] \n",
      "4329 [D loss: (-0.747)(R -5.064, F 3.570)]  [G loss: -3.763] \n",
      "4330 [D loss: (-0.727)(R -4.929, F 3.474)]  [G loss: -3.664] \n",
      "4330 [D loss: (-0.493)(R -4.858, F 3.872)]  [G loss: -3.681] \n",
      "4331 [D loss: (-0.842)(R -4.926, F 3.241)]  [G loss: -3.628] \n",
      "4331 [D loss: (-0.619)(R -5.074, F 3.835)]  [G loss: -3.806] \n",
      "4332 [D loss: (-0.555)(R -4.779, F 3.668)]  [G loss: -3.644] \n",
      "4332 [D loss: (-0.653)(R -5.026, F 3.720)]  [G loss: -3.726] \n",
      "4333 [D loss: (-0.709)(R -5.173, F 3.754)]  [G loss: -3.580] \n",
      "4333 [D loss: (-0.765)(R -5.096, F 3.565)]  [G loss: -3.687] \n",
      "4334 [D loss: (-0.779)(R -5.030, F 3.473)]  [G loss: -3.880] \n",
      "4334 [D loss: (-0.397)(R -5.015, F 4.221)]  [G loss: -3.663] \n",
      "4335 [D loss: (-0.689)(R -4.972, F 3.595)]  [G loss: -3.847] \n",
      "4335 [D loss: (-0.683)(R -5.015, F 3.648)]  [G loss: -3.639] \n",
      "4336 [D loss: (-0.737)(R -5.048, F 3.574)]  [G loss: -4.025] \n",
      "4336 [D loss: (-0.694)(R -5.270, F 3.882)]  [G loss: -3.683] \n",
      "4337 [D loss: (-0.619)(R -5.021, F 3.784)]  [G loss: -3.792] \n",
      "4337 [D loss: (-0.553)(R -5.052, F 3.947)]  [G loss: -3.816] \n",
      "4338 [D loss: (-0.627)(R -5.093, F 3.839)]  [G loss: -3.820] \n",
      "4338 [D loss: (-0.701)(R -5.096, F 3.693)]  [G loss: -3.948] \n",
      "4339 [D loss: (-0.810)(R -5.142, F 3.521)]  [G loss: -4.015] \n",
      "4339 [D loss: (-0.641)(R -5.138, F 3.855)]  [G loss: -3.776] \n",
      "4340 [D loss: (-0.330)(R -5.055, F 4.394)]  [G loss: -3.878] \n",
      "4340 [D loss: (-0.771)(R -5.264, F 3.722)]  [G loss: -4.101] \n",
      "4341 [D loss: (-0.595)(R -5.103, F 3.913)]  [G loss: -3.867] \n",
      "4341 [D loss: (-0.602)(R -5.012, F 3.808)]  [G loss: -3.648] \n",
      "4342 [D loss: (-0.605)(R -4.963, F 3.752)]  [G loss: -3.816] \n",
      "4342 [D loss: (-0.713)(R -5.279, F 3.853)]  [G loss: -3.890] \n",
      "4343 [D loss: (-0.563)(R -5.096, F 3.971)]  [G loss: -3.819] \n",
      "4343 [D loss: (-0.730)(R -5.064, F 3.603)]  [G loss: -3.718] \n",
      "4344 [D loss: (-0.618)(R -5.037, F 3.800)]  [G loss: -3.904] \n",
      "4344 [D loss: (-0.531)(R -5.043, F 3.982)]  [G loss: -3.625] \n",
      "4345 [D loss: (-0.439)(R -5.172, F 4.295)]  [G loss: -3.946] \n",
      "4345 [D loss: (-0.727)(R -5.033, F 3.580)]  [G loss: -3.477] \n",
      "4346 [D loss: (-0.647)(R -5.042, F 3.747)]  [G loss: -3.838] \n",
      "4346 [D loss: (-0.592)(R -5.018, F 3.834)]  [G loss: -3.704] \n",
      "4347 [D loss: (-0.858)(R -5.079, F 3.364)]  [G loss: -3.725] \n",
      "4347 [D loss: (-0.686)(R -5.073, F 3.702)]  [G loss: -3.738] \n",
      "4348 [D loss: (-0.621)(R -4.909, F 3.668)]  [G loss: -3.606] \n",
      "4348 [D loss: (-0.672)(R -5.092, F 3.747)]  [G loss: -3.926] \n",
      "4349 [D loss: (-0.652)(R -4.968, F 3.665)]  [G loss: -3.716] \n",
      "4349 [D loss: (-0.537)(R -4.995, F 3.920)]  [G loss: -3.511] \n",
      "4350 [D loss: (-0.764)(R -4.956, F 3.427)]  [G loss: -3.758] \n",
      "4350 [D loss: (-0.862)(R -5.090, F 3.367)]  [G loss: -3.713] \n",
      "4351 [D loss: (-0.647)(R -5.007, F 3.713)]  [G loss: -3.617] \n",
      "4351 [D loss: (-0.640)(R -4.868, F 3.588)]  [G loss: -3.792] \n",
      "4352 [D loss: (-0.700)(R -5.020, F 3.620)]  [G loss: -3.551] \n",
      "4352 [D loss: (-0.786)(R -4.984, F 3.413)]  [G loss: -3.435] \n",
      "4353 [D loss: (-0.646)(R -4.846, F 3.555)]  [G loss: -3.698] \n",
      "4353 [D loss: (-0.736)(R -5.096, F 3.624)]  [G loss: -3.644] \n",
      "4354 [D loss: (-0.666)(R -4.913, F 3.581)]  [G loss: -3.656] \n",
      "4354 [D loss: (-0.672)(R -5.015, F 3.670)]  [G loss: -3.741] \n",
      "4355 [D loss: (-0.699)(R -4.943, F 3.546)]  [G loss: -3.712] \n",
      "4355 [D loss: (-0.550)(R -4.935, F 3.834)]  [G loss: -3.833] \n",
      "4356 [D loss: (-0.683)(R -5.060, F 3.694)]  [G loss: -3.580] \n",
      "4356 [D loss: (-0.740)(R -5.044, F 3.564)]  [G loss: -3.463] \n",
      "4357 [D loss: (-0.531)(R -4.969, F 3.907)]  [G loss: -3.627] \n",
      "4357 [D loss: (-0.597)(R -4.843, F 3.650)]  [G loss: -3.470] \n",
      "4358 [D loss: (-0.660)(R -4.966, F 3.646)]  [G loss: -3.659] \n",
      "4358 [D loss: (-0.386)(R -4.834, F 4.063)]  [G loss: -3.784] \n",
      "4359 [D loss: (-0.640)(R -5.116, F 3.836)]  [G loss: -3.571] \n",
      "4359 [D loss: (-0.603)(R -4.838, F 3.632)]  [G loss: -3.735] \n",
      "4360 [D loss: (-0.541)(R -4.873, F 3.791)]  [G loss: -3.679] \n",
      "4360 [D loss: (-0.785)(R -4.854, F 3.285)]  [G loss: -3.591] \n",
      "4361 [D loss: (-0.639)(R -5.001, F 3.724)]  [G loss: -3.732] \n",
      "4361 [D loss: (-0.771)(R -4.909, F 3.366)]  [G loss: -3.866] \n",
      "4362 [D loss: (-0.777)(R -4.943, F 3.389)]  [G loss: -3.588] \n",
      "4362 [D loss: (-0.844)(R -5.164, F 3.476)]  [G loss: -3.782] \n",
      "4363 [D loss: (-0.743)(R -4.965, F 3.480)]  [G loss: -3.728] \n",
      "4363 [D loss: (-0.767)(R -4.968, F 3.434)]  [G loss: -3.620] \n",
      "4364 [D loss: (-0.703)(R -5.072, F 3.666)]  [G loss: -3.697] \n",
      "4364 [D loss: (-0.755)(R -5.037, F 3.526)]  [G loss: -3.832] \n",
      "4365 [D loss: (-0.546)(R -4.943, F 3.851)]  [G loss: -3.706] \n",
      "4365 [D loss: (-0.386)(R -4.954, F 4.182)]  [G loss: -3.853] \n",
      "4366 [D loss: (-0.556)(R -5.004, F 3.892)]  [G loss: -3.676] \n",
      "4366 [D loss: (-0.595)(R -5.153, F 3.963)]  [G loss: -3.851] \n",
      "4367 [D loss: (-0.539)(R -4.931, F 3.852)]  [G loss: -3.553] \n",
      "4367 [D loss: (-0.654)(R -4.940, F 3.632)]  [G loss: -3.763] \n",
      "4368 [D loss: (-0.723)(R -5.187, F 3.741)]  [G loss: -3.911] \n",
      "4368 [D loss: (-0.701)(R -5.062, F 3.659)]  [G loss: -3.696] \n",
      "4369 [D loss: (-0.814)(R -5.227, F 3.598)]  [G loss: -3.857] \n",
      "4369 [D loss: (-0.634)(R -4.960, F 3.692)]  [G loss: -3.784] \n",
      "4370 [D loss: (-0.652)(R -5.039, F 3.736)]  [G loss: -3.441] \n",
      "4370 [D loss: (-0.675)(R -5.096, F 3.746)]  [G loss: -3.682] \n",
      "4371 [D loss: (-0.687)(R -5.039, F 3.665)]  [G loss: -3.652] \n",
      "4371 [D loss: (-0.686)(R -5.219, F 3.847)]  [G loss: -3.826] \n",
      "4372 [D loss: (-0.570)(R -4.932, F 3.792)]  [G loss: -3.720] \n",
      "4372 [D loss: (-0.597)(R -5.031, F 3.837)]  [G loss: -3.758] \n",
      "4373 [D loss: (-0.712)(R -5.169, F 3.746)]  [G loss: -3.876] \n",
      "4373 [D loss: (-0.649)(R -5.052, F 3.755)]  [G loss: -3.893] \n",
      "4374 [D loss: (-0.409)(R -5.019, F 4.201)]  [G loss: -3.918] \n",
      "4374 [D loss: (-0.520)(R -5.201, F 4.160)]  [G loss: -3.798] \n",
      "4375 [D loss: (-0.556)(R -4.956, F 3.843)]  [G loss: -3.738] \n",
      "4375 [D loss: (-0.724)(R -5.283, F 3.835)]  [G loss: -3.921] \n",
      "4376 [D loss: (-0.603)(R -5.176, F 3.969)]  [G loss: -3.796] \n",
      "4376 [D loss: (-0.672)(R -5.025, F 3.680)]  [G loss: -3.882] \n",
      "4377 [D loss: (-0.624)(R -5.168, F 3.920)]  [G loss: -3.827] \n",
      "4377 [D loss: (-0.691)(R -5.197, F 3.815)]  [G loss: -3.876] \n",
      "4378 [D loss: (-0.500)(R -5.105, F 4.106)]  [G loss: -3.724] \n",
      "4378 [D loss: (-0.394)(R -4.982, F 4.195)]  [G loss: -3.999] \n",
      "4379 [D loss: (-0.532)(R -5.204, F 4.141)]  [G loss: -3.972] \n",
      "4379 [D loss: (-0.600)(R -5.057, F 3.857)]  [G loss: -3.865] \n",
      "4380 [D loss: (-0.761)(R -5.151, F 3.629)]  [G loss: -3.861] \n",
      "4380 [D loss: (-0.633)(R -5.040, F 3.774)]  [G loss: -3.759] \n",
      "4381 [D loss: (-0.483)(R -4.984, F 4.018)]  [G loss: -3.879] \n",
      "4381 [D loss: (-0.592)(R -5.099, F 3.914)]  [G loss: -3.751] \n",
      "4382 [D loss: (-0.461)(R -5.019, F 4.097)]  [G loss: -3.929] \n",
      "4382 [D loss: (-0.804)(R -5.227, F 3.619)]  [G loss: -4.020] \n",
      "4383 [D loss: (-0.565)(R -5.249, F 4.120)]  [G loss: -3.766] \n",
      "4383 [D loss: (-0.612)(R -5.118, F 3.894)]  [G loss: -3.914] \n",
      "4384 [D loss: (-0.634)(R -5.212, F 3.943)]  [G loss: -3.766] \n",
      "4384 [D loss: (-0.751)(R -5.050, F 3.549)]  [G loss: -3.982] \n",
      "4385 [D loss: (-0.765)(R -5.228, F 3.698)]  [G loss: -3.771] \n",
      "4385 [D loss: (-0.435)(R -4.950, F 4.079)]  [G loss: -3.938] \n",
      "4386 [D loss: (-0.702)(R -5.227, F 3.824)]  [G loss: -3.913] \n",
      "4386 [D loss: (-0.577)(R -5.255, F 4.101)]  [G loss: -3.870] \n",
      "4387 [D loss: (-0.588)(R -5.284, F 4.108)]  [G loss: -4.016] \n",
      "4387 [D loss: (-0.723)(R -5.261, F 3.816)]  [G loss: -3.982] \n",
      "4388 [D loss: (-0.803)(R -5.186, F 3.579)]  [G loss: -3.800] \n",
      "4388 [D loss: (-0.533)(R -5.178, F 4.111)]  [G loss: -3.955] \n",
      "4389 [D loss: (-0.841)(R -5.416, F 3.735)]  [G loss: -3.998] \n",
      "4389 [D loss: (-0.705)(R -5.244, F 3.834)]  [G loss: -4.023] \n",
      "4390 [D loss: (-0.739)(R -5.206, F 3.727)]  [G loss: -3.946] \n",
      "4390 [D loss: (-0.620)(R -5.236, F 3.996)]  [G loss: -3.990] \n",
      "4391 [D loss: (-0.623)(R -5.033, F 3.787)]  [G loss: -3.881] \n",
      "4391 [D loss: (-0.636)(R -5.313, F 4.042)]  [G loss: -3.823] \n",
      "4392 [D loss: (-0.659)(R -5.089, F 3.771)]  [G loss: -3.874] \n",
      "4392 [D loss: (-0.592)(R -5.115, F 3.931)]  [G loss: -3.889] \n",
      "4393 [D loss: (-0.577)(R -5.241, F 4.087)]  [G loss: -3.824] \n",
      "4393 [D loss: (-0.603)(R -5.345, F 4.139)]  [G loss: -3.858] \n",
      "4394 [D loss: (-0.505)(R -5.016, F 4.005)]  [G loss: -3.930] \n",
      "4394 [D loss: (-0.771)(R -5.286, F 3.744)]  [G loss: -4.026] \n",
      "4395 [D loss: (-0.704)(R -5.298, F 3.891)]  [G loss: -3.740] \n",
      "4395 [D loss: (-0.637)(R -5.182, F 3.907)]  [G loss: -3.995] \n",
      "4396 [D loss: (-0.575)(R -5.114, F 3.964)]  [G loss: -3.879] \n",
      "4396 [D loss: (-0.570)(R -5.200, F 4.061)]  [G loss: -3.756] \n",
      "4397 [D loss: (-0.594)(R -5.130, F 3.943)]  [G loss: -4.083] \n",
      "4397 [D loss: (-0.538)(R -5.219, F 4.142)]  [G loss: -3.972] \n",
      "4398 [D loss: (-0.579)(R -5.328, F 4.169)]  [G loss: -3.757] \n",
      "4398 [D loss: (-0.764)(R -5.246, F 3.719)]  [G loss: -4.009] \n",
      "4399 [D loss: (-0.490)(R -5.013, F 4.034)]  [G loss: -3.997] \n",
      "4399 [D loss: (-0.497)(R -5.102, F 4.108)]  [G loss: -3.870] \n",
      "4400 [D loss: (-0.533)(R -5.101, F 4.036)]  [G loss: -3.772] \n",
      "4400 [D loss: (-0.668)(R -5.288, F 3.952)]  [G loss: -3.947] \n",
      "4401 [D loss: (-0.576)(R -5.258, F 4.107)]  [G loss: -3.657] \n",
      "4401 [D loss: (-0.710)(R -5.385, F 3.966)]  [G loss: -3.766] \n",
      "4402 [D loss: (-0.659)(R -5.224, F 3.905)]  [G loss: -4.034] \n",
      "4402 [D loss: (-0.643)(R -5.125, F 3.839)]  [G loss: -3.870] \n",
      "4403 [D loss: (-0.814)(R -5.288, F 3.660)]  [G loss: -3.854] \n",
      "4403 [D loss: (-0.622)(R -5.299, F 4.055)]  [G loss: -3.926] \n",
      "4404 [D loss: (-0.722)(R -5.434, F 3.990)]  [G loss: -4.086] \n",
      "4404 [D loss: (-0.688)(R -5.349, F 3.972)]  [G loss: -4.058] \n",
      "4405 [D loss: (-0.706)(R -5.314, F 3.901)]  [G loss: -3.885] \n",
      "4405 [D loss: (-0.569)(R -5.151, F 4.013)]  [G loss: -3.969] \n",
      "4406 [D loss: (-0.778)(R -5.285, F 3.729)]  [G loss: -3.915] \n",
      "4406 [D loss: (-0.555)(R -5.225, F 4.115)]  [G loss: -3.947] \n",
      "4407 [D loss: (-0.684)(R -5.404, F 4.036)]  [G loss: -4.197] \n",
      "4407 [D loss: (-0.619)(R -5.406, F 4.169)]  [G loss: -3.975] \n",
      "4408 [D loss: (-0.553)(R -5.420, F 4.314)]  [G loss: -4.013] \n",
      "4408 [D loss: (-0.505)(R -5.303, F 4.293)]  [G loss: -4.054] \n",
      "4409 [D loss: (-0.821)(R -5.448, F 3.805)]  [G loss: -4.052] \n",
      "4409 [D loss: (-0.578)(R -5.251, F 4.095)]  [G loss: -3.993] \n",
      "4410 [D loss: (-0.706)(R -5.280, F 3.869)]  [G loss: -3.942] \n",
      "4410 [D loss: (-0.684)(R -5.365, F 3.998)]  [G loss: -4.191] \n",
      "4411 [D loss: (-0.718)(R -5.250, F 3.814)]  [G loss: -3.950] \n",
      "4411 [D loss: (-0.436)(R -5.212, F 4.340)]  [G loss: -3.956] \n",
      "4412 [D loss: (-0.656)(R -5.267, F 3.955)]  [G loss: -3.906] \n",
      "4412 [D loss: (-0.677)(R -5.329, F 3.975)]  [G loss: -4.064] \n",
      "4413 [D loss: (-0.526)(R -5.134, F 4.082)]  [G loss: -3.798] \n",
      "4413 [D loss: (-0.516)(R -5.214, F 4.183)]  [G loss: -4.109] \n",
      "4414 [D loss: (-0.567)(R -5.184, F 4.050)]  [G loss: -3.911] \n",
      "4414 [D loss: (-0.744)(R -5.410, F 3.923)]  [G loss: -3.848] \n",
      "4415 [D loss: (-0.751)(R -5.394, F 3.893)]  [G loss: -4.107] \n",
      "4415 [D loss: (-0.769)(R -5.419, F 3.880)]  [G loss: -3.880] \n",
      "4416 [D loss: (-0.701)(R -5.351, F 3.950)]  [G loss: -3.920] \n",
      "4416 [D loss: (-0.631)(R -5.345, F 4.083)]  [G loss: -3.928] \n",
      "4417 [D loss: (-0.513)(R -5.202, F 4.176)]  [G loss: -3.824] \n",
      "4417 [D loss: (-0.743)(R -5.320, F 3.834)]  [G loss: -3.911] \n",
      "4418 [D loss: (-0.605)(R -5.183, F 3.973)]  [G loss: -4.020] \n",
      "4418 [D loss: (-0.533)(R -5.269, F 4.204)]  [G loss: -3.881] \n",
      "4419 [D loss: (-0.724)(R -5.332, F 3.883)]  [G loss: -3.948] \n",
      "4419 [D loss: (-0.701)(R -5.324, F 3.923)]  [G loss: -3.926] \n",
      "4420 [D loss: (-0.763)(R -5.393, F 3.867)]  [G loss: -3.891] \n",
      "4420 [D loss: (-0.603)(R -5.260, F 4.054)]  [G loss: -3.845] \n",
      "4421 [D loss: (-0.603)(R -5.256, F 4.051)]  [G loss: -3.936] \n",
      "4421 [D loss: (-0.776)(R -5.429, F 3.877)]  [G loss: -4.002] \n",
      "4422 [D loss: (-0.683)(R -5.224, F 3.858)]  [G loss: -3.976] \n",
      "4422 [D loss: (-0.680)(R -5.329, F 3.969)]  [G loss: -3.783] \n",
      "4423 [D loss: (-0.557)(R -5.161, F 4.048)]  [G loss: -3.970] \n",
      "4423 [D loss: (-0.629)(R -5.219, F 3.961)]  [G loss: -4.029] \n",
      "4424 [D loss: (-0.919)(R -5.430, F 3.593)]  [G loss: -3.756] \n",
      "4424 [D loss: (-0.626)(R -5.256, F 4.003)]  [G loss: -3.871] \n",
      "4425 [D loss: (-0.651)(R -5.345, F 4.043)]  [G loss: -3.899] \n",
      "4425 [D loss: (-0.795)(R -5.226, F 3.637)]  [G loss: -3.948] \n",
      "4426 [D loss: (-0.915)(R -5.453, F 3.623)]  [G loss: -3.932] \n",
      "4426 [D loss: (-0.767)(R -5.315, F 3.781)]  [G loss: -3.845] \n",
      "4427 [D loss: (-0.531)(R -5.214, F 4.152)]  [G loss: -3.901] \n",
      "4427 [D loss: (-0.553)(R -5.216, F 4.109)]  [G loss: -3.856] \n",
      "4428 [D loss: (-0.716)(R -5.457, F 4.025)]  [G loss: -3.921] \n",
      "4428 [D loss: (-0.756)(R -5.311, F 3.798)]  [G loss: -3.838] \n",
      "4429 [D loss: (-0.511)(R -5.015, F 3.994)]  [G loss: -3.816] \n",
      "4429 [D loss: (-0.759)(R -5.255, F 3.737)]  [G loss: -3.903] \n",
      "4430 [D loss: (-0.711)(R -5.169, F 3.747)]  [G loss: -4.061] \n",
      "4430 [D loss: (-0.805)(R -5.370, F 3.760)]  [G loss: -3.861] \n",
      "4431 [D loss: (-0.567)(R -5.249, F 4.116)]  [G loss: -3.792] \n",
      "4431 [D loss: (-0.656)(R -5.254, F 3.942)]  [G loss: -3.933] \n",
      "4432 [D loss: (-0.712)(R -5.275, F 3.851)]  [G loss: -3.853] \n",
      "4432 [D loss: (-0.587)(R -5.067, F 3.892)]  [G loss: -3.746] \n",
      "4433 [D loss: (-0.482)(R -5.310, F 4.345)]  [G loss: -3.736] \n",
      "4433 [D loss: (-0.504)(R -5.151, F 4.143)]  [G loss: -3.992] \n",
      "4434 [D loss: (-0.722)(R -5.406, F 3.961)]  [G loss: -3.835] \n",
      "4434 [D loss: (-0.722)(R -5.350, F 3.905)]  [G loss: -3.917] \n",
      "4435 [D loss: (-0.706)(R -5.386, F 3.975)]  [G loss: -3.854] \n",
      "4435 [D loss: (-0.607)(R -5.315, F 4.100)]  [G loss: -4.110] \n",
      "4436 [D loss: (-0.749)(R -5.218, F 3.720)]  [G loss: -3.965] \n",
      "4436 [D loss: (-0.762)(R -5.421, F 3.897)]  [G loss: -3.936] \n",
      "4437 [D loss: (-0.593)(R -5.373, F 4.186)]  [G loss: -3.909] \n",
      "4437 [D loss: (-0.774)(R -5.541, F 3.994)]  [G loss: -4.118] \n",
      "4438 [D loss: (-0.676)(R -5.308, F 3.955)]  [G loss: -3.851] \n",
      "4438 [D loss: (-0.593)(R -5.276, F 4.090)]  [G loss: -3.861] \n",
      "4439 [D loss: (-0.617)(R -5.354, F 4.120)]  [G loss: -4.016] \n",
      "4439 [D loss: (-0.707)(R -5.313, F 3.898)]  [G loss: -3.854] \n",
      "4440 [D loss: (-0.668)(R -5.507, F 4.170)]  [G loss: -3.950] \n",
      "4440 [D loss: (-0.809)(R -5.407, F 3.790)]  [G loss: -4.183] \n",
      "4441 [D loss: (-0.528)(R -5.248, F 4.192)]  [G loss: -4.044] \n",
      "4441 [D loss: (-0.596)(R -5.361, F 4.168)]  [G loss: -3.927] \n",
      "4442 [D loss: (-0.573)(R -5.410, F 4.265)]  [G loss: -4.052] \n",
      "4442 [D loss: (-0.705)(R -5.408, F 3.999)]  [G loss: -4.058] \n",
      "4443 [D loss: (-0.732)(R -5.380, F 3.916)]  [G loss: -4.074] \n",
      "4443 [D loss: (-0.852)(R -5.506, F 3.801)]  [G loss: -3.990] \n",
      "4444 [D loss: (-0.651)(R -5.493, F 4.192)]  [G loss: -4.122] \n",
      "4444 [D loss: (-0.658)(R -5.449, F 4.133)]  [G loss: -4.159] \n",
      "4445 [D loss: (-0.757)(R -5.340, F 3.826)]  [G loss: -4.155] \n",
      "4445 [D loss: (-0.760)(R -5.363, F 3.842)]  [G loss: -4.021] \n",
      "4446 [D loss: (-0.564)(R -5.283, F 4.155)]  [G loss: -4.003] \n",
      "4446 [D loss: (-0.687)(R -5.450, F 4.076)]  [G loss: -3.939] \n",
      "4447 [D loss: (-0.698)(R -5.290, F 3.894)]  [G loss: -4.131] \n",
      "4447 [D loss: (-0.806)(R -5.387, F 3.774)]  [G loss: -3.915] \n",
      "4448 [D loss: (-0.828)(R -5.401, F 3.745)]  [G loss: -4.026] \n",
      "4448 [D loss: (-0.693)(R -5.367, F 3.981)]  [G loss: -4.040] \n",
      "4449 [D loss: (-0.681)(R -5.262, F 3.899)]  [G loss: -3.875] \n",
      "4449 [D loss: (-0.677)(R -5.241, F 3.887)]  [G loss: -3.967] \n",
      "4450 [D loss: (-0.692)(R -5.235, F 3.850)]  [G loss: -3.794] \n",
      "4450 [D loss: (-0.601)(R -5.352, F 4.150)]  [G loss: -3.844] \n",
      "4451 [D loss: (-0.567)(R -5.222, F 4.087)]  [G loss: -3.954] \n",
      "4451 [D loss: (-0.770)(R -5.180, F 3.640)]  [G loss: -3.931] \n",
      "4452 [D loss: (-0.813)(R -5.233, F 3.607)]  [G loss: -3.882] \n",
      "4452 [D loss: (-0.528)(R -5.098, F 4.042)]  [G loss: -3.836] \n",
      "4453 [D loss: (-0.686)(R -5.215, F 3.843)]  [G loss: -3.935] \n",
      "4453 [D loss: (-0.584)(R -5.232, F 4.065)]  [G loss: -3.872] \n",
      "4454 [D loss: (-0.774)(R -5.212, F 3.663)]  [G loss: -3.741] \n",
      "4454 [D loss: (-0.711)(R -5.120, F 3.698)]  [G loss: -3.753] \n",
      "4455 [D loss: (-0.724)(R -5.096, F 3.648)]  [G loss: -3.919] \n",
      "4455 [D loss: (-0.641)(R -5.016, F 3.734)]  [G loss: -3.662] \n",
      "4456 [D loss: (-0.622)(R -5.071, F 3.827)]  [G loss: -3.689] \n",
      "4456 [D loss: (-0.697)(R -5.174, F 3.780)]  [G loss: -3.658] \n",
      "4457 [D loss: (-0.576)(R -4.939, F 3.787)]  [G loss: -3.646] \n",
      "4457 [D loss: (-0.615)(R -4.864, F 3.634)]  [G loss: -3.695] \n",
      "4458 [D loss: (-0.696)(R -4.935, F 3.542)]  [G loss: -3.653] \n",
      "4458 [D loss: (-0.731)(R -5.045, F 3.583)]  [G loss: -3.586] \n",
      "4459 [D loss: (-0.576)(R -5.126, F 3.974)]  [G loss: -3.576] \n",
      "4459 [D loss: (-0.615)(R -4.875, F 3.646)]  [G loss: -3.661] \n",
      "4460 [D loss: (-0.718)(R -4.888, F 3.452)]  [G loss: -3.496] \n",
      "4460 [D loss: (-0.600)(R -4.760, F 3.560)]  [G loss: -3.561] \n",
      "4461 [D loss: (-0.471)(R -4.920, F 3.978)]  [G loss: -3.526] \n",
      "4461 [D loss: (-0.672)(R -4.991, F 3.648)]  [G loss: -3.603] \n",
      "4462 [D loss: (-0.567)(R -4.872, F 3.738)]  [G loss: -3.602] \n",
      "4462 [D loss: (-0.589)(R -5.045, F 3.867)]  [G loss: -3.644] \n",
      "4463 [D loss: (-0.777)(R -5.065, F 3.511)]  [G loss: -3.597] \n",
      "4463 [D loss: (-0.690)(R -4.915, F 3.534)]  [G loss: -3.836] \n",
      "4464 [D loss: (-0.591)(R -4.917, F 3.734)]  [G loss: -3.620] \n",
      "4464 [D loss: (-0.622)(R -4.854, F 3.611)]  [G loss: -3.378] \n",
      "4465 [D loss: (-0.720)(R -4.767, F 3.326)]  [G loss: -3.569] \n",
      "4465 [D loss: (-0.677)(R -4.797, F 3.444)]  [G loss: -3.616] \n",
      "4466 [D loss: (-0.805)(R -5.011, F 3.400)]  [G loss: -3.454] \n",
      "4466 [D loss: (-0.632)(R -4.947, F 3.683)]  [G loss: -3.478] \n",
      "4467 [D loss: (-0.678)(R -4.881, F 3.524)]  [G loss: -3.533] \n",
      "4467 [D loss: (-0.660)(R -4.902, F 3.582)]  [G loss: -3.520] \n",
      "4468 [D loss: (-0.608)(R -4.878, F 3.662)]  [G loss: -3.510] \n",
      "4468 [D loss: (-0.860)(R -4.913, F 3.193)]  [G loss: -3.469] \n",
      "4469 [D loss: (-0.692)(R -4.757, F 3.372)]  [G loss: -3.423] \n",
      "4469 [D loss: (-0.569)(R -4.839, F 3.701)]  [G loss: -3.617] \n",
      "4470 [D loss: (-0.615)(R -4.893, F 3.663)]  [G loss: -3.380] \n",
      "4470 [D loss: (-0.475)(R -4.731, F 3.781)]  [G loss: -3.530] \n",
      "4471 [D loss: (-0.491)(R -4.760, F 3.778)]  [G loss: -3.534] \n",
      "4471 [D loss: (-0.665)(R -4.816, F 3.485)]  [G loss: -3.701] \n",
      "4472 [D loss: (-0.747)(R -4.882, F 3.388)]  [G loss: -3.594] \n",
      "4472 [D loss: (-0.705)(R -4.922, F 3.511)]  [G loss: -3.735] \n",
      "4473 [D loss: (-0.592)(R -4.966, F 3.782)]  [G loss: -3.743] \n",
      "4473 [D loss: (-0.621)(R -4.826, F 3.585)]  [G loss: -3.427] \n",
      "4474 [D loss: (-0.594)(R -5.012, F 3.824)]  [G loss: -3.390] \n",
      "4474 [D loss: (-0.664)(R -4.943, F 3.615)]  [G loss: -3.465] \n",
      "4475 [D loss: (-0.599)(R -4.700, F 3.502)]  [G loss: -3.619] \n",
      "4475 [D loss: (-0.669)(R -4.836, F 3.499)]  [G loss: -3.544] \n",
      "4476 [D loss: (-0.661)(R -4.973, F 3.652)]  [G loss: -3.522] \n",
      "4476 [D loss: (-0.694)(R -5.033, F 3.645)]  [G loss: -3.706] \n",
      "4477 [D loss: (-0.760)(R -5.020, F 3.500)]  [G loss: -3.528] \n",
      "4477 [D loss: (-0.741)(R -4.918, F 3.437)]  [G loss: -3.405] \n",
      "4478 [D loss: (-0.653)(R -4.738, F 3.432)]  [G loss: -3.579] \n",
      "4478 [D loss: (-0.539)(R -4.828, F 3.749)]  [G loss: -3.577] \n",
      "4479 [D loss: (-0.672)(R -4.980, F 3.635)]  [G loss: -3.465] \n",
      "4479 [D loss: (-0.705)(R -4.890, F 3.481)]  [G loss: -3.567] \n",
      "4480 [D loss: (-0.752)(R -4.883, F 3.379)]  [G loss: -3.580] \n",
      "4480 [D loss: (-0.672)(R -4.884, F 3.541)]  [G loss: -3.523] \n",
      "4481 [D loss: (-0.622)(R -4.790, F 3.545)]  [G loss: -3.612] \n",
      "4481 [D loss: (-0.663)(R -4.912, F 3.585)]  [G loss: -3.466] \n",
      "4482 [D loss: (-0.691)(R -4.984, F 3.603)]  [G loss: -3.483] \n",
      "4482 [D loss: (-0.652)(R -4.933, F 3.630)]  [G loss: -3.631] \n",
      "4483 [D loss: (-0.734)(R -4.942, F 3.474)]  [G loss: -3.756] \n",
      "4483 [D loss: (-0.699)(R -5.110, F 3.712)]  [G loss: -3.849] \n",
      "4484 [D loss: (-0.766)(R -5.192, F 3.659)]  [G loss: -3.658] \n",
      "4484 [D loss: (-0.670)(R -4.962, F 3.621)]  [G loss: -3.488] \n",
      "4485 [D loss: (-0.705)(R -4.954, F 3.545)]  [G loss: -3.651] \n",
      "4485 [D loss: (-0.521)(R -4.814, F 3.773)]  [G loss: -3.433] \n",
      "4486 [D loss: (-0.731)(R -5.093, F 3.632)]  [G loss: -3.485] \n",
      "4486 [D loss: (-0.709)(R -4.811, F 3.393)]  [G loss: -3.556] \n",
      "4487 [D loss: (-0.820)(R -4.906, F 3.266)]  [G loss: -3.816] \n",
      "4487 [D loss: (-0.694)(R -4.872, F 3.483)]  [G loss: -3.553] \n",
      "4488 [D loss: (-0.800)(R -4.903, F 3.303)]  [G loss: -3.434] \n",
      "4488 [D loss: (-0.604)(R -4.803, F 3.595)]  [G loss: -3.459] \n",
      "4489 [D loss: (-0.567)(R -4.794, F 3.660)]  [G loss: -3.659] \n",
      "4489 [D loss: (-0.683)(R -4.680, F 3.315)]  [G loss: -3.567] \n",
      "4490 [D loss: (-0.716)(R -4.723, F 3.290)]  [G loss: -3.206] \n",
      "4490 [D loss: (-0.641)(R -4.661, F 3.379)]  [G loss: -3.492] \n",
      "4491 [D loss: (-0.760)(R -4.928, F 3.408)]  [G loss: -3.520] \n",
      "4491 [D loss: (-0.667)(R -4.823, F 3.490)]  [G loss: -3.415] \n",
      "4492 [D loss: (-0.620)(R -4.637, F 3.398)]  [G loss: -3.312] \n",
      "4492 [D loss: (-0.698)(R -4.706, F 3.311)]  [G loss: -3.453] \n",
      "4493 [D loss: (-0.736)(R -4.809, F 3.338)]  [G loss: -3.447] \n",
      "4493 [D loss: (-0.811)(R -4.985, F 3.364)]  [G loss: -3.468] \n",
      "4494 [D loss: (-0.556)(R -4.531, F 3.418)]  [G loss: -3.414] \n",
      "4494 [D loss: (-0.621)(R -4.838, F 3.597)]  [G loss: -3.312] \n",
      "4495 [D loss: (-0.697)(R -4.868, F 3.473)]  [G loss: -3.509] \n",
      "4495 [D loss: (-0.680)(R -4.928, F 3.568)]  [G loss: -3.443] \n",
      "4496 [D loss: (-0.854)(R -5.022, F 3.315)]  [G loss: -3.599] \n",
      "4496 [D loss: (-0.787)(R -4.969, F 3.395)]  [G loss: -3.365] \n",
      "4497 [D loss: (-0.702)(R -4.703, F 3.299)]  [G loss: -3.576] \n",
      "4497 [D loss: (-0.667)(R -4.897, F 3.564)]  [G loss: -3.376] \n",
      "4498 [D loss: (-0.629)(R -4.911, F 3.653)]  [G loss: -3.447] \n",
      "4498 [D loss: (-0.698)(R -4.943, F 3.548)]  [G loss: -3.610] \n",
      "4499 [D loss: (-0.663)(R -4.873, F 3.547)]  [G loss: -3.644] \n",
      "4499 [D loss: (-0.665)(R -4.869, F 3.539)]  [G loss: -3.619] \n",
      "4500 [D loss: (-0.649)(R -4.705, F 3.408)]  [G loss: -3.459] \n",
      "4500 [D loss: (-0.691)(R -4.809, F 3.428)]  [G loss: -3.500] \n",
      "4501 [D loss: (-0.610)(R -4.940, F 3.720)]  [G loss: -3.481] \n",
      "4501 [D loss: (-0.645)(R -4.807, F 3.518)]  [G loss: -3.622] \n",
      "4502 [D loss: (-0.581)(R -4.776, F 3.613)]  [G loss: -3.358] \n",
      "4502 [D loss: (-0.686)(R -4.983, F 3.611)]  [G loss: -3.673] \n",
      "4503 [D loss: (-0.678)(R -4.992, F 3.636)]  [G loss: -3.639] \n",
      "4503 [D loss: (-0.682)(R -4.896, F 3.533)]  [G loss: -3.555] \n",
      "4504 [D loss: (-0.698)(R -4.881, F 3.486)]  [G loss: -3.516] \n",
      "4504 [D loss: (-0.551)(R -4.875, F 3.774)]  [G loss: -3.691] \n",
      "4505 [D loss: (-0.721)(R -4.914, F 3.473)]  [G loss: -3.629] \n",
      "4505 [D loss: (-0.754)(R -5.001, F 3.493)]  [G loss: -3.518] \n",
      "4506 [D loss: (-0.716)(R -5.134, F 3.702)]  [G loss: -3.380] \n",
      "4506 [D loss: (-0.623)(R -5.084, F 3.837)]  [G loss: -3.478] \n",
      "4507 [D loss: (-0.830)(R -5.149, F 3.488)]  [G loss: -3.385] \n",
      "4507 [D loss: (-0.744)(R -5.008, F 3.519)]  [G loss: -3.524] \n",
      "4508 [D loss: (-0.696)(R -5.064, F 3.671)]  [G loss: -3.526] \n",
      "4508 [D loss: (-0.640)(R -4.963, F 3.683)]  [G loss: -3.598] \n",
      "4509 [D loss: (-0.590)(R -4.940, F 3.760)]  [G loss: -3.459] \n",
      "4509 [D loss: (-0.655)(R -4.932, F 3.622)]  [G loss: -3.652] \n",
      "4510 [D loss: (-0.704)(R -5.123, F 3.714)]  [G loss: -3.485] \n",
      "4510 [D loss: (-0.769)(R -4.881, F 3.344)]  [G loss: -3.368] \n",
      "4511 [D loss: (-0.867)(R -5.016, F 3.281)]  [G loss: -3.486] \n",
      "4511 [D loss: (-0.638)(R -4.915, F 3.639)]  [G loss: -3.761] \n",
      "4512 [D loss: (-0.718)(R -4.950, F 3.513)]  [G loss: -3.579] \n",
      "4512 [D loss: (-0.761)(R -5.061, F 3.538)]  [G loss: -3.793] \n",
      "4513 [D loss: (-0.666)(R -4.817, F 3.485)]  [G loss: -3.687] \n",
      "4513 [D loss: (-0.614)(R -4.919, F 3.691)]  [G loss: -3.507] \n",
      "4514 [D loss: (-0.684)(R -5.004, F 3.636)]  [G loss: -3.732] \n",
      "4514 [D loss: (-0.821)(R -4.957, F 3.316)]  [G loss: -3.474] \n",
      "4515 [D loss: (-0.808)(R -5.112, F 3.496)]  [G loss: -3.442] \n",
      "4515 [D loss: (-0.644)(R -4.961, F 3.673)]  [G loss: -3.315] \n",
      "4516 [D loss: (-0.633)(R -4.946, F 3.681)]  [G loss: -3.580] \n",
      "4516 [D loss: (-0.673)(R -4.924, F 3.579)]  [G loss: -3.557] \n",
      "4517 [D loss: (-0.724)(R -4.932, F 3.485)]  [G loss: -3.409] \n",
      "4517 [D loss: (-0.589)(R -4.811, F 3.633)]  [G loss: -3.558] \n",
      "4518 [D loss: (-0.606)(R -5.000, F 3.787)]  [G loss: -3.541] \n",
      "4518 [D loss: (-0.624)(R -4.900, F 3.652)]  [G loss: -3.310] \n",
      "4519 [D loss: (-0.766)(R -4.858, F 3.326)]  [G loss: -3.577] \n",
      "4519 [D loss: (-0.772)(R -4.934, F 3.389)]  [G loss: -3.527] \n",
      "4520 [D loss: (-0.735)(R -4.838, F 3.368)]  [G loss: -3.422] \n",
      "4520 [D loss: (-0.978)(R -4.939, F 2.983)]  [G loss: -3.209] \n",
      "4521 [D loss: (-0.793)(R -4.806, F 3.219)]  [G loss: -3.457] \n",
      "4521 [D loss: (-0.709)(R -4.816, F 3.398)]  [G loss: -3.378] \n",
      "4522 [D loss: (-0.767)(R -4.852, F 3.317)]  [G loss: -3.379] \n",
      "4522 [D loss: (-0.747)(R -4.807, F 3.312)]  [G loss: -3.293] \n",
      "4523 [D loss: (-0.757)(R -4.747, F 3.233)]  [G loss: -3.433] \n",
      "4523 [D loss: (-0.619)(R -4.785, F 3.546)]  [G loss: -3.394] \n",
      "4524 [D loss: (-0.916)(R -4.951, F 3.118)]  [G loss: -3.345] \n",
      "4524 [D loss: (-0.784)(R -4.834, F 3.266)]  [G loss: -3.220] \n",
      "4525 [D loss: (-0.748)(R -4.693, F 3.196)]  [G loss: -3.479] \n",
      "4525 [D loss: (-0.588)(R -4.482, F 3.307)]  [G loss: -3.321] \n",
      "4526 [D loss: (-0.700)(R -4.881, F 3.481)]  [G loss: -3.364] \n",
      "4526 [D loss: (-0.742)(R -4.781, F 3.298)]  [G loss: -3.376] \n",
      "4527 [D loss: (-0.668)(R -4.738, F 3.403)]  [G loss: -3.409] \n",
      "4527 [D loss: (-0.601)(R -4.787, F 3.584)]  [G loss: -3.512] \n",
      "4528 [D loss: (-0.616)(R -4.682, F 3.451)]  [G loss: -3.305] \n",
      "4528 [D loss: (-0.714)(R -4.764, F 3.336)]  [G loss: -3.434] \n",
      "4529 [D loss: (-0.759)(R -4.758, F 3.240)]  [G loss: -3.483] \n",
      "4529 [D loss: (-0.740)(R -4.749, F 3.268)]  [G loss: -3.470] \n",
      "4530 [D loss: (-0.734)(R -4.828, F 3.360)]  [G loss: -3.299] \n",
      "4530 [D loss: (-0.730)(R -4.832, F 3.373)]  [G loss: -3.408] \n",
      "4531 [D loss: (-0.630)(R -4.767, F 3.508)]  [G loss: -3.174] \n",
      "4531 [D loss: (-0.860)(R -4.804, F 3.083)]  [G loss: -3.334] \n",
      "4532 [D loss: (-0.775)(R -4.872, F 3.322)]  [G loss: -3.467] \n",
      "4532 [D loss: (-0.746)(R -4.834, F 3.342)]  [G loss: -3.251] \n",
      "4533 [D loss: (-0.592)(R -4.565, F 3.381)]  [G loss: -3.272] \n",
      "4533 [D loss: (-0.834)(R -4.748, F 3.080)]  [G loss: -3.258] \n",
      "4534 [D loss: (-0.547)(R -4.530, F 3.436)]  [G loss: -3.358] \n",
      "4534 [D loss: (-0.595)(R -4.619, F 3.429)]  [G loss: -3.347] \n",
      "4535 [D loss: (-0.623)(R -4.675, F 3.429)]  [G loss: -3.412] \n",
      "4535 [D loss: (-0.783)(R -4.730, F 3.163)]  [G loss: -3.162] \n",
      "4536 [D loss: (-0.848)(R -4.822, F 3.126)]  [G loss: -3.265] \n",
      "4536 [D loss: (-0.679)(R -4.731, F 3.373)]  [G loss: -3.416] \n",
      "4537 [D loss: (-0.630)(R -4.763, F 3.503)]  [G loss: -3.406] \n",
      "4537 [D loss: (-0.671)(R -4.728, F 3.385)]  [G loss: -3.212] \n",
      "4538 [D loss: (-0.635)(R -4.784, F 3.514)]  [G loss: -3.512] \n",
      "4538 [D loss: (-0.705)(R -4.881, F 3.471)]  [G loss: -3.462] \n",
      "4539 [D loss: (-0.693)(R -4.798, F 3.412)]  [G loss: -3.402] \n",
      "4539 [D loss: (-0.727)(R -4.723, F 3.270)]  [G loss: -3.231] \n",
      "4540 [D loss: (-0.748)(R -4.905, F 3.409)]  [G loss: -3.496] \n",
      "4540 [D loss: (-0.722)(R -4.810, F 3.367)]  [G loss: -3.381] \n",
      "4541 [D loss: (-0.670)(R -4.770, F 3.431)]  [G loss: -3.386] \n",
      "4541 [D loss: (-0.573)(R -4.808, F 3.663)]  [G loss: -3.386] \n",
      "4542 [D loss: (-0.621)(R -4.851, F 3.610)]  [G loss: -3.332] \n",
      "4542 [D loss: (-0.738)(R -4.909, F 3.433)]  [G loss: -3.135] \n",
      "4543 [D loss: (-0.717)(R -4.812, F 3.379)]  [G loss: -3.661] \n",
      "4543 [D loss: (-0.665)(R -4.886, F 3.556)]  [G loss: -3.409] \n",
      "4544 [D loss: (-0.848)(R -4.838, F 3.142)]  [G loss: -3.499] \n",
      "4544 [D loss: (-0.780)(R -4.940, F 3.381)]  [G loss: -3.510] \n",
      "4545 [D loss: (-0.659)(R -4.843, F 3.525)]  [G loss: -3.318] \n",
      "4545 [D loss: (-0.796)(R -4.926, F 3.335)]  [G loss: -3.509] \n",
      "4546 [D loss: (-0.514)(R -4.683, F 3.654)]  [G loss: -3.557] \n",
      "4546 [D loss: (-0.799)(R -4.936, F 3.338)]  [G loss: -3.462] \n",
      "4547 [D loss: (-0.734)(R -4.806, F 3.338)]  [G loss: -3.466] \n",
      "4547 [D loss: (-0.652)(R -4.833, F 3.529)]  [G loss: -3.387] \n",
      "4548 [D loss: (-0.852)(R -4.974, F 3.269)]  [G loss: -3.474] \n",
      "4548 [D loss: (-0.718)(R -4.806, F 3.371)]  [G loss: -3.419] \n",
      "4549 [D loss: (-0.765)(R -4.807, F 3.276)]  [G loss: -3.558] \n",
      "4549 [D loss: (-0.708)(R -4.846, F 3.430)]  [G loss: -3.479] \n",
      "4550 [D loss: (-0.621)(R -4.850, F 3.609)]  [G loss: -3.569] \n",
      "4550 [D loss: (-0.676)(R -4.880, F 3.529)]  [G loss: -3.484] \n",
      "4551 [D loss: (-0.668)(R -4.838, F 3.503)]  [G loss: -3.491] \n",
      "4551 [D loss: (-0.718)(R -5.059, F 3.623)]  [G loss: -3.466] \n",
      "4552 [D loss: (-0.716)(R -4.968, F 3.537)]  [G loss: -3.519] \n",
      "4552 [D loss: (-0.845)(R -4.924, F 3.233)]  [G loss: -3.437] \n",
      "4553 [D loss: (-0.676)(R -4.985, F 3.632)]  [G loss: -3.577] \n",
      "4553 [D loss: (-0.648)(R -4.931, F 3.636)]  [G loss: -3.552] \n",
      "4554 [D loss: (-0.706)(R -5.006, F 3.594)]  [G loss: -3.684] \n",
      "4554 [D loss: (-0.727)(R -4.860, F 3.407)]  [G loss: -3.520] \n",
      "4555 [D loss: (-0.610)(R -4.754, F 3.535)]  [G loss: -3.507] \n",
      "4555 [D loss: (-0.634)(R -4.806, F 3.539)]  [G loss: -3.481] \n",
      "4556 [D loss: (-0.837)(R -5.128, F 3.454)]  [G loss: -3.531] \n",
      "4556 [D loss: (-0.801)(R -4.865, F 3.264)]  [G loss: -3.478] \n",
      "4557 [D loss: (-0.711)(R -4.997, F 3.576)]  [G loss: -3.298] \n",
      "4557 [D loss: (-0.771)(R -4.931, F 3.389)]  [G loss: -3.497] \n",
      "4558 [D loss: (-0.644)(R -4.787, F 3.500)]  [G loss: -3.436] \n",
      "4558 [D loss: (-0.781)(R -4.967, F 3.404)]  [G loss: -3.464] \n",
      "4559 [D loss: (-0.745)(R -4.882, F 3.392)]  [G loss: -3.656] \n",
      "4559 [D loss: (-0.647)(R -4.945, F 3.652)]  [G loss: -3.423] \n",
      "4560 [D loss: (-0.795)(R -5.090, F 3.500)]  [G loss: -3.541] \n",
      "4560 [D loss: (-0.665)(R -4.779, F 3.450)]  [G loss: -3.342] \n",
      "4561 [D loss: (-0.686)(R -4.861, F 3.489)]  [G loss: -3.542] \n",
      "4561 [D loss: (-0.780)(R -4.944, F 3.384)]  [G loss: -3.582] \n",
      "4562 [D loss: (-0.703)(R -4.883, F 3.477)]  [G loss: -3.594] \n",
      "4562 [D loss: (-0.738)(R -4.860, F 3.383)]  [G loss: -3.416] \n",
      "4563 [D loss: (-0.713)(R -4.992, F 3.565)]  [G loss: -3.622] \n",
      "4563 [D loss: (-0.729)(R -4.982, F 3.523)]  [G loss: -3.601] \n",
      "4564 [D loss: (-0.754)(R -5.000, F 3.492)]  [G loss: -3.430] \n",
      "4564 [D loss: (-0.822)(R -5.047, F 3.403)]  [G loss: -3.487] \n",
      "4565 [D loss: (-0.763)(R -4.861, F 3.335)]  [G loss: -3.336] \n",
      "4565 [D loss: (-0.840)(R -4.916, F 3.237)]  [G loss: -3.447] \n",
      "4566 [D loss: (-0.744)(R -4.951, F 3.462)]  [G loss: -3.373] \n",
      "4566 [D loss: (-0.712)(R -4.822, F 3.398)]  [G loss: -3.501] \n",
      "4567 [D loss: (-0.643)(R -4.784, F 3.499)]  [G loss: -3.400] \n",
      "4567 [D loss: (-0.862)(R -4.931, F 3.207)]  [G loss: -3.532] \n",
      "4568 [D loss: (-0.847)(R -4.986, F 3.292)]  [G loss: -3.395] \n",
      "4568 [D loss: (-0.819)(R -4.957, F 3.318)]  [G loss: -3.433] \n",
      "4569 [D loss: (-0.554)(R -4.861, F 3.753)]  [G loss: -3.291] \n",
      "4569 [D loss: (-0.594)(R -4.808, F 3.620)]  [G loss: -3.413] \n",
      "4570 [D loss: (-0.709)(R -4.741, F 3.323)]  [G loss: -3.586] \n",
      "4570 [D loss: (-0.671)(R -4.887, F 3.545)]  [G loss: -3.427] \n",
      "4571 [D loss: (-0.685)(R -4.794, F 3.424)]  [G loss: -3.388] \n",
      "4571 [D loss: (-0.687)(R -4.877, F 3.502)]  [G loss: -3.360] \n",
      "4572 [D loss: (-0.718)(R -4.810, F 3.374)]  [G loss: -3.417] \n",
      "4572 [D loss: (-0.731)(R -4.865, F 3.404)]  [G loss: -3.251] \n",
      "4573 [D loss: (-0.627)(R -4.836, F 3.582)]  [G loss: -3.457] \n",
      "4573 [D loss: (-0.646)(R -4.690, F 3.397)]  [G loss: -3.506] \n",
      "4574 [D loss: (-0.690)(R -4.833, F 3.453)]  [G loss: -3.598] \n",
      "4574 [D loss: (-0.694)(R -4.831, F 3.442)]  [G loss: -3.423] \n",
      "4575 [D loss: (-0.697)(R -4.808, F 3.414)]  [G loss: -3.454] \n",
      "4575 [D loss: (-0.656)(R -4.768, F 3.456)]  [G loss: -3.500] \n",
      "4576 [D loss: (-0.672)(R -4.825, F 3.481)]  [G loss: -3.575] \n",
      "4576 [D loss: (-0.659)(R -4.713, F 3.395)]  [G loss: -3.421] \n",
      "4577 [D loss: (-0.619)(R -4.830, F 3.592)]  [G loss: -3.331] \n",
      "4577 [D loss: (-0.616)(R -4.898, F 3.666)]  [G loss: -3.498] \n",
      "4578 [D loss: (-0.710)(R -4.821, F 3.401)]  [G loss: -3.322] \n",
      "4578 [D loss: (-0.631)(R -4.837, F 3.576)]  [G loss: -3.577] \n",
      "4579 [D loss: (-0.712)(R -4.813, F 3.389)]  [G loss: -3.490] \n",
      "4579 [D loss: (-0.598)(R -4.822, F 3.625)]  [G loss: -3.474] \n",
      "4580 [D loss: (-0.498)(R -4.758, F 3.762)]  [G loss: -3.465] \n",
      "4580 [D loss: (-0.819)(R -4.994, F 3.355)]  [G loss: -3.444] \n",
      "4581 [D loss: (-0.713)(R -4.960, F 3.533)]  [G loss: -3.544] \n",
      "4581 [D loss: (-0.638)(R -4.859, F 3.583)]  [G loss: -3.586] \n",
      "4582 [D loss: (-0.637)(R -5.002, F 3.727)]  [G loss: -3.492] \n",
      "4582 [D loss: (-0.722)(R -5.005, F 3.560)]  [G loss: -3.588] \n",
      "4583 [D loss: (-0.682)(R -4.800, F 3.436)]  [G loss: -3.677] \n",
      "4583 [D loss: (-0.645)(R -5.001, F 3.712)]  [G loss: -3.497] \n",
      "4584 [D loss: (-0.671)(R -4.968, F 3.625)]  [G loss: -3.455] \n",
      "4584 [D loss: (-0.674)(R -4.911, F 3.564)]  [G loss: -3.592] \n",
      "4585 [D loss: (-0.629)(R -4.828, F 3.569)]  [G loss: -3.564] \n",
      "4585 [D loss: (-0.692)(R -4.921, F 3.536)]  [G loss: -3.609] \n",
      "4586 [D loss: (-0.644)(R -4.934, F 3.647)]  [G loss: -3.509] \n",
      "4586 [D loss: (-0.612)(R -4.899, F 3.675)]  [G loss: -3.230] \n",
      "4587 [D loss: (-0.712)(R -5.046, F 3.622)]  [G loss: -3.639] \n",
      "4587 [D loss: (-0.759)(R -4.966, F 3.448)]  [G loss: -3.521] \n",
      "4588 [D loss: (-0.619)(R -4.803, F 3.564)]  [G loss: -3.559] \n",
      "4588 [D loss: (-0.820)(R -5.151, F 3.512)]  [G loss: -3.482] \n",
      "4589 [D loss: (-0.668)(R -4.974, F 3.638)]  [G loss: -3.312] \n",
      "4589 [D loss: (-0.656)(R -4.804, F 3.492)]  [G loss: -3.532] \n",
      "4590 [D loss: (-0.776)(R -4.900, F 3.348)]  [G loss: -3.549] \n",
      "4590 [D loss: (-0.683)(R -5.045, F 3.679)]  [G loss: -3.710] \n",
      "4591 [D loss: (-0.804)(R -5.128, F 3.520)]  [G loss: -3.620] \n",
      "4591 [D loss: (-0.657)(R -4.947, F 3.632)]  [G loss: -3.406] \n",
      "4592 [D loss: (-0.605)(R -4.777, F 3.568)]  [G loss: -3.537] \n",
      "4592 [D loss: (-0.862)(R -5.035, F 3.312)]  [G loss: -3.454] \n",
      "4593 [D loss: (-0.755)(R -5.070, F 3.560)]  [G loss: -3.443] \n",
      "4593 [D loss: (-0.540)(R -4.797, F 3.718)]  [G loss: -3.687] \n",
      "4594 [D loss: (-0.598)(R -4.949, F 3.754)]  [G loss: -3.627] \n",
      "4594 [D loss: (-0.743)(R -5.015, F 3.529)]  [G loss: -3.598] \n",
      "4595 [D loss: (-0.623)(R -4.984, F 3.738)]  [G loss: -3.514] \n",
      "4595 [D loss: (-0.579)(R -4.927, F 3.770)]  [G loss: -3.576] \n",
      "4596 [D loss: (-0.700)(R -4.916, F 3.517)]  [G loss: -3.687] \n",
      "4596 [D loss: (-0.741)(R -5.153, F 3.672)]  [G loss: -3.634] \n",
      "4597 [D loss: (-0.651)(R -4.893, F 3.591)]  [G loss: -3.728] \n",
      "4597 [D loss: (-0.748)(R -4.839, F 3.343)]  [G loss: -3.629] \n",
      "4598 [D loss: (-0.709)(R -5.017, F 3.600)]  [G loss: -3.752] \n",
      "4598 [D loss: (-0.588)(R -4.920, F 3.743)]  [G loss: -3.541] \n",
      "4599 [D loss: (-0.886)(R -5.136, F 3.364)]  [G loss: -3.558] \n",
      "4599 [D loss: (-0.611)(R -4.880, F 3.657)]  [G loss: -3.503] \n",
      "4600 [D loss: (-0.634)(R -4.969, F 3.702)]  [G loss: -3.661] \n",
      "4600 [D loss: (-0.735)(R -4.994, F 3.523)]  [G loss: -3.576] \n",
      "4601 [D loss: (-0.685)(R -5.108, F 3.737)]  [G loss: -3.470] \n",
      "4601 [D loss: (-0.715)(R -5.123, F 3.694)]  [G loss: -3.544] \n",
      "4602 [D loss: (-0.682)(R -5.031, F 3.667)]  [G loss: -3.416] \n",
      "4602 [D loss: (-0.670)(R -5.019, F 3.680)]  [G loss: -3.530] \n",
      "4603 [D loss: (-0.714)(R -4.998, F 3.569)]  [G loss: -3.665] \n",
      "4603 [D loss: (-0.713)(R -5.196, F 3.769)]  [G loss: -3.667] \n",
      "4604 [D loss: (-0.631)(R -5.015, F 3.753)]  [G loss: -3.380] \n",
      "4604 [D loss: (-0.709)(R -5.121, F 3.702)]  [G loss: -3.630] \n",
      "4605 [D loss: (-0.737)(R -5.099, F 3.624)]  [G loss: -3.559] \n",
      "4605 [D loss: (-0.687)(R -5.118, F 3.744)]  [G loss: -3.618] \n",
      "4606 [D loss: (-0.727)(R -5.112, F 3.657)]  [G loss: -3.658] \n",
      "4606 [D loss: (-0.746)(R -5.162, F 3.669)]  [G loss: -3.881] \n",
      "4607 [D loss: (-0.785)(R -5.240, F 3.670)]  [G loss: -3.560] \n",
      "4607 [D loss: (-0.719)(R -5.099, F 3.661)]  [G loss: -3.731] \n",
      "4608 [D loss: (-0.649)(R -4.997, F 3.699)]  [G loss: -3.576] \n",
      "4608 [D loss: (-0.666)(R -5.057, F 3.726)]  [G loss: -3.650] \n",
      "4609 [D loss: (-0.750)(R -5.054, F 3.555)]  [G loss: -3.581] \n",
      "4609 [D loss: (-0.697)(R -5.125, F 3.732)]  [G loss: -3.668] \n",
      "4610 [D loss: (-0.665)(R -5.092, F 3.762)]  [G loss: -3.592] \n",
      "4610 [D loss: (-0.770)(R -5.109, F 3.569)]  [G loss: -3.620] \n",
      "4611 [D loss: (-0.545)(R -4.973, F 3.883)]  [G loss: -3.685] \n",
      "4611 [D loss: (-0.787)(R -5.227, F 3.653)]  [G loss: -3.701] \n",
      "4612 [D loss: (-0.801)(R -5.264, F 3.663)]  [G loss: -3.696] \n",
      "4612 [D loss: (-0.829)(R -5.284, F 3.626)]  [G loss: -3.633] \n",
      "4613 [D loss: (-0.708)(R -5.147, F 3.731)]  [G loss: -3.675] \n",
      "4613 [D loss: (-0.635)(R -5.052, F 3.781)]  [G loss: -3.862] \n",
      "4614 [D loss: (-0.692)(R -5.159, F 3.775)]  [G loss: -3.662] \n",
      "4614 [D loss: (-0.746)(R -5.092, F 3.600)]  [G loss: -3.629] \n",
      "4615 [D loss: (-0.651)(R -5.120, F 3.818)]  [G loss: -3.692] \n",
      "4615 [D loss: (-0.713)(R -5.168, F 3.742)]  [G loss: -3.795] \n",
      "4616 [D loss: (-0.672)(R -4.978, F 3.635)]  [G loss: -3.684] \n",
      "4616 [D loss: (-0.593)(R -5.071, F 3.886)]  [G loss: -3.775] \n",
      "4617 [D loss: (-0.624)(R -5.126, F 3.878)]  [G loss: -3.625] \n",
      "4617 [D loss: (-0.540)(R -5.042, F 3.963)]  [G loss: -3.752] \n",
      "4618 [D loss: (-0.624)(R -5.175, F 3.927)]  [G loss: -3.933] \n",
      "4618 [D loss: (-0.738)(R -5.181, F 3.705)]  [G loss: -3.778] \n",
      "4619 [D loss: (-0.725)(R -5.234, F 3.784)]  [G loss: -3.760] \n",
      "4619 [D loss: (-0.724)(R -5.203, F 3.756)]  [G loss: -3.756] \n",
      "4620 [D loss: (-0.597)(R -5.081, F 3.887)]  [G loss: -3.793] \n",
      "4620 [D loss: (-0.731)(R -5.286, F 3.824)]  [G loss: -3.695] \n",
      "4621 [D loss: (-0.754)(R -5.318, F 3.811)]  [G loss: -3.857] \n",
      "4621 [D loss: (-0.689)(R -5.248, F 3.871)]  [G loss: -3.631] \n",
      "4622 [D loss: (-0.738)(R -5.256, F 3.780)]  [G loss: -3.800] \n",
      "4622 [D loss: (-0.611)(R -5.199, F 3.977)]  [G loss: -3.760] \n",
      "4623 [D loss: (-0.669)(R -5.174, F 3.835)]  [G loss: -3.838] \n",
      "4623 [D loss: (-0.741)(R -5.197, F 3.715)]  [G loss: -3.807] \n",
      "4624 [D loss: (-0.803)(R -5.273, F 3.666)]  [G loss: -3.599] \n",
      "4624 [D loss: (-0.675)(R -5.165, F 3.815)]  [G loss: -3.795] \n",
      "4625 [D loss: (-0.754)(R -5.276, F 3.768)]  [G loss: -3.736] \n",
      "4625 [D loss: (-0.642)(R -5.187, F 3.903)]  [G loss: -3.748] \n",
      "4626 [D loss: (-0.638)(R -5.234, F 3.958)]  [G loss: -3.764] \n",
      "4626 [D loss: (-0.620)(R -5.072, F 3.831)]  [G loss: -3.798] \n",
      "4627 [D loss: (-0.658)(R -5.208, F 3.892)]  [G loss: -3.695] \n",
      "4627 [D loss: (-0.769)(R -5.237, F 3.699)]  [G loss: -3.742] \n",
      "4628 [D loss: (-0.651)(R -5.240, F 3.938)]  [G loss: -3.681] \n",
      "4628 [D loss: (-0.661)(R -5.165, F 3.842)]  [G loss: -3.888] \n",
      "4629 [D loss: (-0.637)(R -5.240, F 3.966)]  [G loss: -3.903] \n",
      "4629 [D loss: (-0.643)(R -5.261, F 3.974)]  [G loss: -3.789] \n",
      "4630 [D loss: (-0.784)(R -5.369, F 3.800)]  [G loss: -3.618] \n",
      "4630 [D loss: (-0.726)(R -5.262, F 3.811)]  [G loss: -3.779] \n",
      "4631 [D loss: (-0.666)(R -5.277, F 3.945)]  [G loss: -3.892] \n",
      "4631 [D loss: (-0.701)(R -5.234, F 3.833)]  [G loss: -3.969] \n",
      "4632 [D loss: (-0.603)(R -5.243, F 4.038)]  [G loss: -3.893] \n",
      "4632 [D loss: (-0.702)(R -5.312, F 3.909)]  [G loss: -3.889] \n",
      "4633 [D loss: (-0.705)(R -5.389, F 3.979)]  [G loss: -3.830] \n",
      "4633 [D loss: (-0.577)(R -5.256, F 4.102)]  [G loss: -3.963] \n",
      "4634 [D loss: (-0.737)(R -5.516, F 4.041)]  [G loss: -4.078] \n",
      "4634 [D loss: (-0.710)(R -5.405, F 3.984)]  [G loss: -3.994] \n",
      "4635 [D loss: (-0.693)(R -5.466, F 4.080)]  [G loss: -4.006] \n",
      "4635 [D loss: (-0.614)(R -5.359, F 4.132)]  [G loss: -3.982] \n",
      "4636 [D loss: (-0.686)(R -5.430, F 4.059)]  [G loss: -3.940] \n",
      "4636 [D loss: (-0.774)(R -5.374, F 3.825)]  [G loss: -3.976] \n",
      "4637 [D loss: (-0.751)(R -5.343, F 3.840)]  [G loss: -4.088] \n",
      "4637 [D loss: (-0.665)(R -5.423, F 4.092)]  [G loss: -4.016] \n",
      "4638 [D loss: (-0.702)(R -5.407, F 4.003)]  [G loss: -3.962] \n",
      "4638 [D loss: (-0.756)(R -5.335, F 3.823)]  [G loss: -3.950] \n",
      "4639 [D loss: (-0.733)(R -5.462, F 3.997)]  [G loss: -3.913] \n",
      "4639 [D loss: (-0.651)(R -5.259, F 3.957)]  [G loss: -3.868] \n",
      "4640 [D loss: (-0.764)(R -5.429, F 3.901)]  [G loss: -3.960] \n",
      "4640 [D loss: (-0.683)(R -5.268, F 3.902)]  [G loss: -3.842] \n",
      "4641 [D loss: (-0.811)(R -5.414, F 3.791)]  [G loss: -3.845] \n",
      "4641 [D loss: (-0.642)(R -5.285, F 4.001)]  [G loss: -3.855] \n",
      "4642 [D loss: (-0.781)(R -5.324, F 3.761)]  [G loss: -3.857] \n",
      "4642 [D loss: (-0.781)(R -5.365, F 3.804)]  [G loss: -3.902] \n",
      "4643 [D loss: (-0.796)(R -5.337, F 3.746)]  [G loss: -3.852] \n",
      "4643 [D loss: (-0.801)(R -5.403, F 3.800)]  [G loss: -3.862] \n",
      "4644 [D loss: (-0.752)(R -5.318, F 3.815)]  [G loss: -3.824] \n",
      "4644 [D loss: (-0.682)(R -5.297, F 3.934)]  [G loss: -3.778] \n",
      "4645 [D loss: (-0.613)(R -5.136, F 3.909)]  [G loss: -3.944] \n",
      "4645 [D loss: (-0.730)(R -5.405, F 3.946)]  [G loss: -3.972] \n",
      "4646 [D loss: (-0.685)(R -5.163, F 3.794)]  [G loss: -3.751] \n",
      "4646 [D loss: (-0.738)(R -5.296, F 3.820)]  [G loss: -3.728] \n",
      "4647 [D loss: (-0.632)(R -5.130, F 3.867)]  [G loss: -3.829] \n",
      "4647 [D loss: (-0.781)(R -5.271, F 3.710)]  [G loss: -3.983] \n",
      "4648 [D loss: (-0.692)(R -5.277, F 3.893)]  [G loss: -3.786] \n",
      "4648 [D loss: (-0.689)(R -5.211, F 3.834)]  [G loss: -3.867] \n",
      "4649 [D loss: (-0.741)(R -5.267, F 3.785)]  [G loss: -3.777] \n",
      "4649 [D loss: (-0.708)(R -5.247, F 3.832)]  [G loss: -3.833] \n",
      "4650 [D loss: (-0.610)(R -5.208, F 3.987)]  [G loss: -3.908] \n",
      "4650 [D loss: (-0.699)(R -5.367, F 3.970)]  [G loss: -3.985] \n",
      "4651 [D loss: (-0.698)(R -5.272, F 3.877)]  [G loss: -3.904] \n",
      "4651 [D loss: (-0.693)(R -5.292, F 3.905)]  [G loss: -3.890] \n",
      "4652 [D loss: (-0.700)(R -5.266, F 3.865)]  [G loss: -3.879] \n",
      "4652 [D loss: (-0.720)(R -5.308, F 3.869)]  [G loss: -3.833] \n",
      "4653 [D loss: (-0.746)(R -5.258, F 3.767)]  [G loss: -3.754] \n",
      "4653 [D loss: (-0.718)(R -5.276, F 3.840)]  [G loss: -3.921] \n",
      "4654 [D loss: (-0.795)(R -5.384, F 3.795)]  [G loss: -3.903] \n",
      "4654 [D loss: (-0.780)(R -5.338, F 3.779)]  [G loss: -3.843] \n",
      "4655 [D loss: (-0.687)(R -5.205, F 3.831)]  [G loss: -3.886] \n",
      "4655 [D loss: (-0.725)(R -5.348, F 3.899)]  [G loss: -3.813] \n",
      "4656 [D loss: (-0.655)(R -5.168, F 3.858)]  [G loss: -3.640] \n",
      "4656 [D loss: (-0.611)(R -5.125, F 3.903)]  [G loss: -3.862] \n",
      "4657 [D loss: (-0.697)(R -5.238, F 3.843)]  [G loss: -3.805] \n",
      "4657 [D loss: (-0.671)(R -5.229, F 3.886)]  [G loss: -3.824] \n",
      "4658 [D loss: (-0.673)(R -5.198, F 3.852)]  [G loss: -3.914] \n",
      "4658 [D loss: (-0.778)(R -5.355, F 3.799)]  [G loss: -3.911] \n",
      "4659 [D loss: (-0.740)(R -5.385, F 3.905)]  [G loss: -3.815] \n",
      "4659 [D loss: (-0.672)(R -5.342, F 3.997)]  [G loss: -3.894] \n",
      "4660 [D loss: (-0.733)(R -5.315, F 3.850)]  [G loss: -3.784] \n",
      "4660 [D loss: (-0.801)(R -5.456, F 3.854)]  [G loss: -3.843] \n",
      "4661 [D loss: (-0.703)(R -5.337, F 3.931)]  [G loss: -3.660] \n",
      "4661 [D loss: (-0.816)(R -5.351, F 3.719)]  [G loss: -3.839] \n",
      "4662 [D loss: (-0.887)(R -5.389, F 3.616)]  [G loss: -3.889] \n",
      "4662 [D loss: (-0.680)(R -5.261, F 3.901)]  [G loss: -3.878] \n",
      "4663 [D loss: (-0.770)(R -5.255, F 3.715)]  [G loss: -3.697] \n",
      "4663 [D loss: (-0.686)(R -5.106, F 3.733)]  [G loss: -3.665] \n",
      "4664 [D loss: (-0.695)(R -5.270, F 3.880)]  [G loss: -3.782] \n",
      "4664 [D loss: (-0.746)(R -5.291, F 3.799)]  [G loss: -3.949] \n",
      "4665 [D loss: (-0.714)(R -5.219, F 3.792)]  [G loss: -3.752] \n",
      "4665 [D loss: (-0.825)(R -5.371, F 3.722)]  [G loss: -3.971] \n",
      "4666 [D loss: (-0.604)(R -5.073, F 3.866)]  [G loss: -3.946] \n",
      "4666 [D loss: (-0.767)(R -5.248, F 3.713)]  [G loss: -3.741] \n",
      "4667 [D loss: (-0.732)(R -5.256, F 3.791)]  [G loss: -3.790] \n",
      "4667 [D loss: (-0.715)(R -5.127, F 3.697)]  [G loss: -3.688] \n",
      "4668 [D loss: (-0.721)(R -5.188, F 3.747)]  [G loss: -3.687] \n",
      "4668 [D loss: (-0.783)(R -5.220, F 3.655)]  [G loss: -3.738] \n",
      "4669 [D loss: (-0.754)(R -5.237, F 3.728)]  [G loss: -3.857] \n",
      "4669 [D loss: (-0.725)(R -5.215, F 3.764)]  [G loss: -3.739] \n",
      "4670 [D loss: (-0.774)(R -5.226, F 3.678)]  [G loss: -3.749] \n",
      "4670 [D loss: (-0.717)(R -5.225, F 3.791)]  [G loss: -3.837] \n",
      "4671 [D loss: (-0.668)(R -5.120, F 3.784)]  [G loss: -3.667] \n",
      "4671 [D loss: (-0.709)(R -5.132, F 3.713)]  [G loss: -3.723] \n",
      "4672 [D loss: (-0.751)(R -5.178, F 3.677)]  [G loss: -3.696] \n",
      "4672 [D loss: (-0.652)(R -5.111, F 3.807)]  [G loss: -3.668] \n",
      "4673 [D loss: (-0.735)(R -5.182, F 3.712)]  [G loss: -3.902] \n",
      "4673 [D loss: (-0.762)(R -5.355, F 3.832)]  [G loss: -3.741] \n",
      "4674 [D loss: (-0.751)(R -5.194, F 3.691)]  [G loss: -3.707] \n",
      "4674 [D loss: (-0.834)(R -5.312, F 3.644)]  [G loss: -3.669] \n",
      "4675 [D loss: (-0.673)(R -5.146, F 3.800)]  [G loss: -3.802] \n",
      "4675 [D loss: (-0.792)(R -5.285, F 3.700)]  [G loss: -3.664] \n",
      "4676 [D loss: (-0.706)(R -5.187, F 3.775)]  [G loss: -3.786] \n",
      "4676 [D loss: (-0.683)(R -5.095, F 3.730)]  [G loss: -3.634] \n",
      "4677 [D loss: (-0.686)(R -5.244, F 3.872)]  [G loss: -3.702] \n",
      "4677 [D loss: (-0.681)(R -5.087, F 3.724)]  [G loss: -3.720] \n",
      "4678 [D loss: (-0.733)(R -5.288, F 3.822)]  [G loss: -3.836] \n",
      "4678 [D loss: (-0.675)(R -5.128, F 3.777)]  [G loss: -3.759] \n",
      "4679 [D loss: (-0.640)(R -5.116, F 3.835)]  [G loss: -3.607] \n",
      "4679 [D loss: (-0.686)(R -5.163, F 3.791)]  [G loss: -3.747] \n",
      "4680 [D loss: (-0.536)(R -4.946, F 3.875)]  [G loss: -3.714] \n",
      "4680 [D loss: (-0.751)(R -5.289, F 3.786)]  [G loss: -3.738] \n",
      "4681 [D loss: (-0.600)(R -5.199, F 4.000)]  [G loss: -3.976] \n",
      "4681 [D loss: (-0.714)(R -5.164, F 3.735)]  [G loss: -3.740] \n",
      "4682 [D loss: (-0.658)(R -5.131, F 3.814)]  [G loss: -3.832] \n",
      "4682 [D loss: (-0.829)(R -5.382, F 3.725)]  [G loss: -3.916] \n",
      "4683 [D loss: (-0.720)(R -5.270, F 3.830)]  [G loss: -3.780] \n",
      "4683 [D loss: (-0.845)(R -5.293, F 3.604)]  [G loss: -3.668] \n",
      "4684 [D loss: (-0.708)(R -5.240, F 3.825)]  [G loss: -3.861] \n",
      "4684 [D loss: (-0.759)(R -5.240, F 3.722)]  [G loss: -3.765] \n",
      "4685 [D loss: (-0.756)(R -5.201, F 3.690)]  [G loss: -3.960] \n",
      "4685 [D loss: (-0.704)(R -5.282, F 3.874)]  [G loss: -3.775] \n",
      "4686 [D loss: (-0.626)(R -5.097, F 3.845)]  [G loss: -3.615] \n",
      "4686 [D loss: (-0.747)(R -5.351, F 3.856)]  [G loss: -3.767] \n",
      "4687 [D loss: (-0.707)(R -5.238, F 3.824)]  [G loss: -3.910] \n",
      "4687 [D loss: (-0.707)(R -5.313, F 3.899)]  [G loss: -3.801] \n",
      "4688 [D loss: (-0.732)(R -5.320, F 3.855)]  [G loss: -3.745] \n",
      "4688 [D loss: (-0.773)(R -5.283, F 3.737)]  [G loss: -3.971] \n",
      "4689 [D loss: (-0.698)(R -5.269, F 3.874)]  [G loss: -3.889] \n",
      "4689 [D loss: (-0.671)(R -5.295, F 3.954)]  [G loss: -3.778] \n",
      "4690 [D loss: (-0.691)(R -5.289, F 3.908)]  [G loss: -3.795] \n",
      "4690 [D loss: (-0.776)(R -5.302, F 3.749)]  [G loss: -3.872] \n",
      "4691 [D loss: (-0.650)(R -5.278, F 3.978)]  [G loss: -3.867] \n",
      "4691 [D loss: (-0.771)(R -5.278, F 3.736)]  [G loss: -3.743] \n",
      "4692 [D loss: (-0.712)(R -5.258, F 3.834)]  [G loss: -3.813] \n",
      "4692 [D loss: (-0.758)(R -5.415, F 3.898)]  [G loss: -3.794] \n",
      "4693 [D loss: (-0.725)(R -5.196, F 3.747)]  [G loss: -3.962] \n",
      "4693 [D loss: (-0.746)(R -5.170, F 3.679)]  [G loss: -3.769] \n",
      "4694 [D loss: (-0.770)(R -5.325, F 3.784)]  [G loss: -3.777] \n",
      "4694 [D loss: (-0.796)(R -5.258, F 3.665)]  [G loss: -3.729] \n",
      "4695 [D loss: (-0.747)(R -5.210, F 3.716)]  [G loss: -3.679] \n",
      "4695 [D loss: (-0.654)(R -5.113, F 3.804)]  [G loss: -3.754] \n",
      "4696 [D loss: (-0.689)(R -5.186, F 3.808)]  [G loss: -3.745] \n",
      "4696 [D loss: (-0.762)(R -5.230, F 3.707)]  [G loss: -3.808] \n",
      "4697 [D loss: (-0.704)(R -5.189, F 3.782)]  [G loss: -3.775] \n",
      "4697 [D loss: (-0.796)(R -5.290, F 3.697)]  [G loss: -3.771] \n",
      "4698 [D loss: (-0.714)(R -5.195, F 3.767)]  [G loss: -3.776] \n",
      "4698 [D loss: (-0.595)(R -4.949, F 3.760)]  [G loss: -3.759] \n",
      "4699 [D loss: (-0.774)(R -5.247, F 3.698)]  [G loss: -3.694] \n",
      "4699 [D loss: (-0.687)(R -5.157, F 3.784)]  [G loss: -3.810] \n",
      "4700 [D loss: (-0.777)(R -5.196, F 3.643)]  [G loss: -3.673] \n",
      "4700 [D loss: (-0.725)(R -5.186, F 3.736)]  [G loss: -3.791] \n",
      "4701 [D loss: (-0.798)(R -5.423, F 3.826)]  [G loss: -3.699] \n",
      "4701 [D loss: (-0.768)(R -5.250, F 3.713)]  [G loss: -3.702] \n",
      "4702 [D loss: (-0.673)(R -5.217, F 3.871)]  [G loss: -3.866] \n",
      "4702 [D loss: (-0.769)(R -5.294, F 3.756)]  [G loss: -3.671] \n",
      "4703 [D loss: (-0.724)(R -5.205, F 3.757)]  [G loss: -3.756] \n",
      "4703 [D loss: (-0.666)(R -5.127, F 3.796)]  [G loss: -3.837] \n",
      "4704 [D loss: (-0.708)(R -5.142, F 3.726)]  [G loss: -3.750] \n",
      "4704 [D loss: (-0.808)(R -5.455, F 3.840)]  [G loss: -3.768] \n",
      "4705 [D loss: (-0.683)(R -5.187, F 3.821)]  [G loss: -3.759] \n",
      "4705 [D loss: (-0.643)(R -5.172, F 3.887)]  [G loss: -3.684] \n",
      "4706 [D loss: (-0.741)(R -5.189, F 3.708)]  [G loss: -3.713] \n",
      "4706 [D loss: (-0.731)(R -5.173, F 3.712)]  [G loss: -3.637] \n",
      "4707 [D loss: (-0.813)(R -5.300, F 3.675)]  [G loss: -3.762] \n",
      "4707 [D loss: (-0.763)(R -5.269, F 3.744)]  [G loss: -3.744] \n",
      "4708 [D loss: (-0.747)(R -5.366, F 3.872)]  [G loss: -3.631] \n",
      "4708 [D loss: (-0.725)(R -5.256, F 3.805)]  [G loss: -3.846] \n",
      "4709 [D loss: (-0.721)(R -5.187, F 3.745)]  [G loss: -3.918] \n",
      "4709 [D loss: (-0.704)(R -5.290, F 3.883)]  [G loss: -3.795] \n",
      "4710 [D loss: (-0.764)(R -5.277, F 3.749)]  [G loss: -3.788] \n",
      "4710 [D loss: (-0.710)(R -5.233, F 3.813)]  [G loss: -3.790] \n",
      "4711 [D loss: (-0.777)(R -5.339, F 3.784)]  [G loss: -3.798] \n",
      "4711 [D loss: (-0.841)(R -5.469, F 3.786)]  [G loss: -3.830] \n",
      "4712 [D loss: (-0.728)(R -5.297, F 3.840)]  [G loss: -3.797] \n",
      "4712 [D loss: (-0.681)(R -5.148, F 3.785)]  [G loss: -3.781] \n",
      "4713 [D loss: (-0.723)(R -5.217, F 3.771)]  [G loss: -3.811] \n",
      "4713 [D loss: (-0.717)(R -5.332, F 3.898)]  [G loss: -3.756] \n",
      "4714 [D loss: (-0.731)(R -5.218, F 3.756)]  [G loss: -3.734] \n",
      "4714 [D loss: (-0.801)(R -5.375, F 3.774)]  [G loss: -3.638] \n",
      "4715 [D loss: (-0.752)(R -5.258, F 3.754)]  [G loss: -3.778] \n",
      "4715 [D loss: (-0.847)(R -5.348, F 3.654)]  [G loss: -3.573] \n",
      "4716 [D loss: (-0.719)(R -5.245, F 3.808)]  [G loss: -3.727] \n",
      "4716 [D loss: (-0.763)(R -5.316, F 3.789)]  [G loss: -3.686] \n",
      "4717 [D loss: (-0.799)(R -5.405, F 3.807)]  [G loss: -3.807] \n",
      "4717 [D loss: (-0.760)(R -5.311, F 3.790)]  [G loss: -3.746] \n",
      "4718 [D loss: (-0.820)(R -5.406, F 3.767)]  [G loss: -3.900] \n",
      "4718 [D loss: (-0.853)(R -5.519, F 3.813)]  [G loss: -3.771] \n",
      "4719 [D loss: (-0.714)(R -5.225, F 3.798)]  [G loss: -3.713] \n",
      "4719 [D loss: (-0.753)(R -5.203, F 3.698)]  [G loss: -3.665] \n",
      "4720 [D loss: (-0.771)(R -5.261, F 3.720)]  [G loss: -4.007] \n",
      "4720 [D loss: (-0.667)(R -5.223, F 3.889)]  [G loss: -3.776] \n",
      "4721 [D loss: (-0.685)(R -5.134, F 3.764)]  [G loss: -3.944] \n",
      "4721 [D loss: (-0.812)(R -5.377, F 3.753)]  [G loss: -3.820] \n",
      "4722 [D loss: (-0.729)(R -5.196, F 3.738)]  [G loss: -3.883] \n",
      "4722 [D loss: (-0.723)(R -5.165, F 3.720)]  [G loss: -3.723] \n",
      "4723 [D loss: (-0.685)(R -5.207, F 3.837)]  [G loss: -3.735] \n",
      "4723 [D loss: (-0.816)(R -5.352, F 3.719)]  [G loss: -3.751] \n",
      "4724 [D loss: (-0.713)(R -5.150, F 3.725)]  [G loss: -3.690] \n",
      "4724 [D loss: (-0.653)(R -5.057, F 3.752)]  [G loss: -3.760] \n",
      "4725 [D loss: (-0.627)(R -5.068, F 3.813)]  [G loss: -3.632] \n",
      "4725 [D loss: (-0.752)(R -5.240, F 3.736)]  [G loss: -3.643] \n",
      "4726 [D loss: (-0.664)(R -5.172, F 3.843)]  [G loss: -3.813] \n",
      "4726 [D loss: (-0.810)(R -5.166, F 3.546)]  [G loss: -3.717] \n",
      "4727 [D loss: (-0.685)(R -5.108, F 3.738)]  [G loss: -3.707] \n",
      "4727 [D loss: (-0.734)(R -5.128, F 3.660)]  [G loss: -3.754] \n",
      "4728 [D loss: (-0.713)(R -5.095, F 3.669)]  [G loss: -3.609] \n",
      "4728 [D loss: (-0.782)(R -5.223, F 3.658)]  [G loss: -3.673] \n",
      "4729 [D loss: (-0.714)(R -5.071, F 3.642)]  [G loss: -3.682] \n",
      "4729 [D loss: (-0.764)(R -5.197, F 3.669)]  [G loss: -3.805] \n",
      "4730 [D loss: (-0.723)(R -5.166, F 3.720)]  [G loss: -3.639] \n",
      "4730 [D loss: (-0.737)(R -5.308, F 3.834)]  [G loss: -3.620] \n",
      "4731 [D loss: (-0.650)(R -5.156, F 3.857)]  [G loss: -3.789] \n",
      "4731 [D loss: (-0.740)(R -5.287, F 3.807)]  [G loss: -3.785] \n",
      "4732 [D loss: (-0.759)(R -5.310, F 3.793)]  [G loss: -3.915] \n",
      "4732 [D loss: (-0.746)(R -5.111, F 3.618)]  [G loss: -3.711] \n",
      "4733 [D loss: (-0.721)(R -5.206, F 3.764)]  [G loss: -3.759] \n",
      "4733 [D loss: (-0.627)(R -5.106, F 3.853)]  [G loss: -3.779] \n",
      "4734 [D loss: (-0.805)(R -5.365, F 3.755)]  [G loss: -3.846] \n",
      "4734 [D loss: (-0.796)(R -5.317, F 3.726)]  [G loss: -3.730] \n",
      "4735 [D loss: (-0.814)(R -5.181, F 3.552)]  [G loss: -3.767] \n",
      "4735 [D loss: (-0.699)(R -5.258, F 3.859)]  [G loss: -3.906] \n",
      "4736 [D loss: (-0.732)(R -5.248, F 3.784)]  [G loss: -3.841] \n",
      "4736 [D loss: (-0.776)(R -5.331, F 3.780)]  [G loss: -3.825] \n",
      "4737 [D loss: (-0.705)(R -5.157, F 3.747)]  [G loss: -3.874] \n",
      "4737 [D loss: (-0.733)(R -5.308, F 3.843)]  [G loss: -3.676] \n",
      "4738 [D loss: (-0.835)(R -5.356, F 3.687)]  [G loss: -3.738] \n",
      "4738 [D loss: (-0.840)(R -5.424, F 3.744)]  [G loss: -3.816] \n",
      "4739 [D loss: (-0.808)(R -5.372, F 3.756)]  [G loss: -3.845] \n",
      "4739 [D loss: (-0.811)(R -5.378, F 3.756)]  [G loss: -3.880] \n",
      "4740 [D loss: (-0.681)(R -5.145, F 3.784)]  [G loss: -3.836] \n",
      "4740 [D loss: (-0.858)(R -5.375, F 3.659)]  [G loss: -3.721] \n",
      "4741 [D loss: (-0.708)(R -5.118, F 3.703)]  [G loss: -3.776] \n",
      "4741 [D loss: (-0.690)(R -5.156, F 3.776)]  [G loss: -3.838] \n",
      "4742 [D loss: (-0.772)(R -5.199, F 3.655)]  [G loss: -3.783] \n",
      "4742 [D loss: (-0.731)(R -5.168, F 3.706)]  [G loss: -3.745] \n",
      "4743 [D loss: (-0.736)(R -5.211, F 3.739)]  [G loss: -3.845] \n",
      "4743 [D loss: (-0.770)(R -5.169, F 3.629)]  [G loss: -3.665] \n",
      "4744 [D loss: (-0.707)(R -5.176, F 3.763)]  [G loss: -3.577] \n",
      "4744 [D loss: (-0.685)(R -5.086, F 3.717)]  [G loss: -3.673] \n",
      "4745 [D loss: (-0.676)(R -5.114, F 3.762)]  [G loss: -3.818] \n",
      "4745 [D loss: (-0.750)(R -5.135, F 3.635)]  [G loss: -3.702] \n",
      "4746 [D loss: (-0.771)(R -5.139, F 3.597)]  [G loss: -3.546] \n",
      "4746 [D loss: (-0.735)(R -5.184, F 3.713)]  [G loss: -3.638] \n",
      "4747 [D loss: (-0.616)(R -4.999, F 3.767)]  [G loss: -3.623] \n",
      "4747 [D loss: (-0.744)(R -5.149, F 3.661)]  [G loss: -3.773] \n",
      "4748 [D loss: (-0.838)(R -5.312, F 3.635)]  [G loss: -3.728] \n",
      "4748 [D loss: (-0.665)(R -5.006, F 3.677)]  [G loss: -3.605] \n",
      "4749 [D loss: (-0.704)(R -5.183, F 3.775)]  [G loss: -3.612] \n",
      "4749 [D loss: (-0.642)(R -4.987, F 3.703)]  [G loss: -3.619] \n",
      "4750 [D loss: (-0.722)(R -5.120, F 3.675)]  [G loss: -3.743] \n",
      "4750 [D loss: (-0.721)(R -5.107, F 3.665)]  [G loss: -3.698] \n",
      "4751 [D loss: (-0.670)(R -5.156, F 3.816)]  [G loss: -3.787] \n",
      "4751 [D loss: (-0.708)(R -5.059, F 3.644)]  [G loss: -3.569] \n",
      "4752 [D loss: (-0.742)(R -5.140, F 3.655)]  [G loss: -3.765] \n",
      "4752 [D loss: (-0.745)(R -5.145, F 3.656)]  [G loss: -3.789] \n",
      "4753 [D loss: (-0.697)(R -5.179, F 3.786)]  [G loss: -3.781] \n",
      "4753 [D loss: (-0.746)(R -5.109, F 3.618)]  [G loss: -3.807] \n",
      "4754 [D loss: (-0.724)(R -5.177, F 3.730)]  [G loss: -3.700] \n",
      "4754 [D loss: (-0.769)(R -5.283, F 3.745)]  [G loss: -3.755] \n",
      "4755 [D loss: (-0.810)(R -5.251, F 3.632)]  [G loss: -3.690] \n",
      "4755 [D loss: (-0.687)(R -5.118, F 3.744)]  [G loss: -3.740] \n",
      "4756 [D loss: (-0.695)(R -5.169, F 3.779)]  [G loss: -3.712] \n",
      "4756 [D loss: (-0.755)(R -5.285, F 3.775)]  [G loss: -3.830] \n",
      "4757 [D loss: (-0.685)(R -5.081, F 3.712)]  [G loss: -3.622] \n",
      "4757 [D loss: (-0.695)(R -5.178, F 3.787)]  [G loss: -3.766] \n",
      "4758 [D loss: (-0.808)(R -5.325, F 3.708)]  [G loss: -3.592] \n",
      "4758 [D loss: (-0.652)(R -5.042, F 3.738)]  [G loss: -3.759] \n",
      "4759 [D loss: (-0.680)(R -5.161, F 3.801)]  [G loss: -3.765] \n",
      "4759 [D loss: (-0.762)(R -5.229, F 3.706)]  [G loss: -3.706] \n",
      "4760 [D loss: (-0.677)(R -5.199, F 3.845)]  [G loss: -3.831] \n",
      "4760 [D loss: (-0.700)(R -5.084, F 3.683)]  [G loss: -3.692] \n",
      "4761 [D loss: (-0.736)(R -5.143, F 3.671)]  [G loss: -3.712] \n",
      "4761 [D loss: (-0.660)(R -5.199, F 3.880)]  [G loss: -3.643] \n",
      "4762 [D loss: (-0.743)(R -5.351, F 3.865)]  [G loss: -3.642] \n",
      "4762 [D loss: (-0.704)(R -5.126, F 3.719)]  [G loss: -3.774] \n",
      "4763 [D loss: (-0.672)(R -5.115, F 3.770)]  [G loss: -3.803] \n",
      "4763 [D loss: (-0.777)(R -5.257, F 3.703)]  [G loss: -3.812] \n",
      "4764 [D loss: (-0.675)(R -5.169, F 3.819)]  [G loss: -3.668] \n",
      "4764 [D loss: (-0.766)(R -5.286, F 3.753)]  [G loss: -3.924] \n",
      "4765 [D loss: (-0.788)(R -5.384, F 3.809)]  [G loss: -3.647] \n",
      "4765 [D loss: (-0.661)(R -5.179, F 3.857)]  [G loss: -3.779] \n",
      "4766 [D loss: (-0.646)(R -5.197, F 3.905)]  [G loss: -3.862] \n",
      "4766 [D loss: (-0.556)(R -5.080, F 3.968)]  [G loss: -3.701] \n",
      "4767 [D loss: (-0.701)(R -5.179, F 3.777)]  [G loss: -3.802] \n",
      "4767 [D loss: (-0.743)(R -5.286, F 3.800)]  [G loss: -3.794] \n",
      "4768 [D loss: (-0.633)(R -5.120, F 3.855)]  [G loss: -3.796] \n",
      "4768 [D loss: (-0.667)(R -5.244, F 3.911)]  [G loss: -3.728] \n",
      "4769 [D loss: (-0.727)(R -5.254, F 3.800)]  [G loss: -3.823] \n",
      "4769 [D loss: (-0.766)(R -5.282, F 3.751)]  [G loss: -3.915] \n",
      "4770 [D loss: (-0.766)(R -5.224, F 3.693)]  [G loss: -3.772] \n",
      "4770 [D loss: (-0.637)(R -5.060, F 3.785)]  [G loss: -3.620] \n",
      "4771 [D loss: (-0.721)(R -5.329, F 3.887)]  [G loss: -3.767] \n",
      "4771 [D loss: (-0.722)(R -5.266, F 3.822)]  [G loss: -3.978] \n",
      "4772 [D loss: (-0.731)(R -5.263, F 3.801)]  [G loss: -3.972] \n",
      "4772 [D loss: (-0.681)(R -5.291, F 3.928)]  [G loss: -3.907] \n",
      "4773 [D loss: (-0.766)(R -5.358, F 3.826)]  [G loss: -3.741] \n",
      "4773 [D loss: (-0.694)(R -5.254, F 3.866)]  [G loss: -3.780] \n",
      "4774 [D loss: (-0.778)(R -5.402, F 3.847)]  [G loss: -3.851] \n",
      "4774 [D loss: (-0.718)(R -5.234, F 3.798)]  [G loss: -3.768] \n",
      "4775 [D loss: (-0.745)(R -5.342, F 3.851)]  [G loss: -3.853] \n",
      "4775 [D loss: (-0.747)(R -5.328, F 3.834)]  [G loss: -3.725] \n",
      "4776 [D loss: (-0.696)(R -5.230, F 3.837)]  [G loss: -3.816] \n",
      "4776 [D loss: (-0.755)(R -5.337, F 3.828)]  [G loss: -3.799] \n",
      "4777 [D loss: (-0.715)(R -5.276, F 3.846)]  [G loss: -3.825] \n",
      "4777 [D loss: (-0.693)(R -5.255, F 3.869)]  [G loss: -3.827] \n",
      "4778 [D loss: (-0.751)(R -5.314, F 3.813)]  [G loss: -3.826] \n",
      "4778 [D loss: (-0.739)(R -5.306, F 3.828)]  [G loss: -3.821] \n",
      "4779 [D loss: (-0.615)(R -5.105, F 3.875)]  [G loss: -3.706] \n",
      "4779 [D loss: (-0.759)(R -5.253, F 3.736)]  [G loss: -3.908] \n",
      "4780 [D loss: (-0.687)(R -5.203, F 3.830)]  [G loss: -3.924] \n",
      "4780 [D loss: (-0.663)(R -5.155, F 3.830)]  [G loss: -3.714] \n",
      "4781 [D loss: (-0.640)(R -5.247, F 3.968)]  [G loss: -3.814] \n",
      "4781 [D loss: (-0.791)(R -5.305, F 3.724)]  [G loss: -3.980] \n",
      "4782 [D loss: (-0.771)(R -5.273, F 3.731)]  [G loss: -3.789] \n",
      "4782 [D loss: (-0.654)(R -5.161, F 3.852)]  [G loss: -3.794] \n",
      "4783 [D loss: (-0.697)(R -5.194, F 3.800)]  [G loss: -3.680] \n",
      "4783 [D loss: (-0.688)(R -5.198, F 3.822)]  [G loss: -3.848] \n",
      "4784 [D loss: (-0.593)(R -5.098, F 3.911)]  [G loss: -3.797] \n",
      "4784 [D loss: (-0.718)(R -5.181, F 3.745)]  [G loss: -3.660] \n",
      "4785 [D loss: (-0.739)(R -5.225, F 3.747)]  [G loss: -3.824] \n",
      "4785 [D loss: (-0.811)(R -5.302, F 3.679)]  [G loss: -3.781] \n",
      "4786 [D loss: (-0.700)(R -5.169, F 3.768)]  [G loss: -3.875] \n",
      "4786 [D loss: (-0.785)(R -5.367, F 3.797)]  [G loss: -3.724] \n",
      "4787 [D loss: (-0.788)(R -5.273, F 3.698)]  [G loss: -3.759] \n",
      "4787 [D loss: (-0.759)(R -5.206, F 3.688)]  [G loss: -3.727] \n",
      "4788 [D loss: (-0.718)(R -5.200, F 3.763)]  [G loss: -3.628] \n",
      "4788 [D loss: (-0.740)(R -5.255, F 3.775)]  [G loss: -3.564] \n",
      "4789 [D loss: (-0.766)(R -5.191, F 3.660)]  [G loss: -3.731] \n",
      "4789 [D loss: (-0.646)(R -5.041, F 3.749)]  [G loss: -3.637] \n",
      "4790 [D loss: (-0.641)(R -5.068, F 3.787)]  [G loss: -3.739] \n",
      "4790 [D loss: (-0.637)(R -5.083, F 3.810)]  [G loss: -3.824] \n",
      "4791 [D loss: (-0.696)(R -5.159, F 3.766)]  [G loss: -3.804] \n",
      "4791 [D loss: (-0.731)(R -5.268, F 3.805)]  [G loss: -3.817] \n",
      "4792 [D loss: (-0.661)(R -5.188, F 3.867)]  [G loss: -3.823] \n",
      "4792 [D loss: (-0.769)(R -5.290, F 3.752)]  [G loss: -3.911] \n",
      "4793 [D loss: (-0.650)(R -5.101, F 3.800)]  [G loss: -3.826] \n",
      "4793 [D loss: (-0.681)(R -5.129, F 3.767)]  [G loss: -3.805] \n",
      "4794 [D loss: (-0.657)(R -5.074, F 3.760)]  [G loss: -3.666] \n",
      "4794 [D loss: (-0.718)(R -5.214, F 3.778)]  [G loss: -3.782] \n",
      "4795 [D loss: (-0.799)(R -5.372, F 3.774)]  [G loss: -3.666] \n",
      "4795 [D loss: (-0.762)(R -5.297, F 3.774)]  [G loss: -3.816] \n",
      "4796 [D loss: (-0.736)(R -5.266, F 3.795)]  [G loss: -3.821] \n",
      "4796 [D loss: (-0.736)(R -5.332, F 3.861)]  [G loss: -3.772] \n",
      "4797 [D loss: (-0.748)(R -5.276, F 3.779)]  [G loss: -3.663] \n",
      "4797 [D loss: (-0.726)(R -5.240, F 3.789)]  [G loss: -3.806] \n",
      "4798 [D loss: (-0.749)(R -5.348, F 3.851)]  [G loss: -3.912] \n",
      "4798 [D loss: (-0.636)(R -5.161, F 3.889)]  [G loss: -3.844] \n",
      "4799 [D loss: (-0.729)(R -5.293, F 3.834)]  [G loss: -3.845] \n",
      "4799 [D loss: (-0.799)(R -5.379, F 3.782)]  [G loss: -3.706] \n",
      "4800 [D loss: (-0.822)(R -5.446, F 3.803)]  [G loss: -3.799] \n",
      "4800 [D loss: (-0.747)(R -5.208, F 3.714)]  [G loss: -3.728] \n",
      "4801 [D loss: (-0.735)(R -5.240, F 3.769)]  [G loss: -3.779] \n",
      "4801 [D loss: (-0.749)(R -5.327, F 3.830)]  [G loss: -3.772] \n",
      "4802 [D loss: (-0.789)(R -5.287, F 3.710)]  [G loss: -3.811] \n",
      "4802 [D loss: (-0.723)(R -5.238, F 3.792)]  [G loss: -3.766] \n",
      "4803 [D loss: (-0.742)(R -5.260, F 3.775)]  [G loss: -3.683] \n",
      "4803 [D loss: (-0.759)(R -5.312, F 3.793)]  [G loss: -3.725] \n",
      "4804 [D loss: (-0.789)(R -5.397, F 3.818)]  [G loss: -3.768] \n",
      "4804 [D loss: (-0.694)(R -5.074, F 3.687)]  [G loss: -3.785] \n",
      "4805 [D loss: (-0.786)(R -5.188, F 3.616)]  [G loss: -3.673] \n",
      "4805 [D loss: (-0.778)(R -5.274, F 3.718)]  [G loss: -3.762] \n",
      "4806 [D loss: (-0.781)(R -5.170, F 3.608)]  [G loss: -3.640] \n",
      "4806 [D loss: (-0.690)(R -5.103, F 3.723)]  [G loss: -3.660] \n",
      "4807 [D loss: (-0.784)(R -5.288, F 3.719)]  [G loss: -3.877] \n",
      "4807 [D loss: (-0.710)(R -5.216, F 3.797)]  [G loss: -3.722] \n",
      "4808 [D loss: (-0.705)(R -5.105, F 3.696)]  [G loss: -3.785] \n",
      "4808 [D loss: (-0.787)(R -5.303, F 3.728)]  [G loss: -3.631] \n",
      "4809 [D loss: (-0.699)(R -5.148, F 3.750)]  [G loss: -3.707] \n",
      "4809 [D loss: (-0.744)(R -5.200, F 3.712)]  [G loss: -3.795] \n",
      "4810 [D loss: (-0.742)(R -5.128, F 3.643)]  [G loss: -3.758] \n",
      "4810 [D loss: (-0.783)(R -5.194, F 3.628)]  [G loss: -3.698] \n",
      "4811 [D loss: (-0.726)(R -5.098, F 3.646)]  [G loss: -3.581] \n",
      "4811 [D loss: (-0.813)(R -5.319, F 3.694)]  [G loss: -3.648] \n",
      "4812 [D loss: (-0.804)(R -5.211, F 3.603)]  [G loss: -3.658] \n",
      "4812 [D loss: (-0.697)(R -5.086, F 3.692)]  [G loss: -3.669] \n",
      "4813 [D loss: (-0.759)(R -5.190, F 3.671)]  [G loss: -3.657] \n",
      "4813 [D loss: (-0.712)(R -5.132, F 3.709)]  [G loss: -3.772] \n",
      "4814 [D loss: (-0.797)(R -5.300, F 3.706)]  [G loss: -3.820] \n",
      "4814 [D loss: (-0.667)(R -5.103, F 3.769)]  [G loss: -3.676] \n",
      "4815 [D loss: (-0.761)(R -5.117, F 3.595)]  [G loss: -3.768] \n",
      "4815 [D loss: (-0.869)(R -5.329, F 3.590)]  [G loss: -3.781] \n",
      "4816 [D loss: (-0.760)(R -5.198, F 3.678)]  [G loss: -3.707] \n",
      "4816 [D loss: (-0.758)(R -5.226, F 3.711)]  [G loss: -3.759] \n",
      "4817 [D loss: (-0.694)(R -5.164, F 3.776)]  [G loss: -3.757] \n",
      "4817 [D loss: (-0.651)(R -5.019, F 3.716)]  [G loss: -3.731] \n",
      "4818 [D loss: (-0.650)(R -5.002, F 3.701)]  [G loss: -3.624] \n",
      "4818 [D loss: (-0.748)(R -5.143, F 3.648)]  [G loss: -3.814] \n",
      "4819 [D loss: (-0.624)(R -4.977, F 3.729)]  [G loss: -3.647] \n",
      "4819 [D loss: (-0.741)(R -5.155, F 3.672)]  [G loss: -3.695] \n",
      "4820 [D loss: (-0.815)(R -5.175, F 3.546)]  [G loss: -3.599] \n",
      "4820 [D loss: (-0.765)(R -5.126, F 3.597)]  [G loss: -3.672] \n",
      "4821 [D loss: (-0.706)(R -5.054, F 3.641)]  [G loss: -3.563] \n",
      "4821 [D loss: (-0.714)(R -5.074, F 3.645)]  [G loss: -3.547] \n",
      "4822 [D loss: (-0.712)(R -5.070, F 3.647)]  [G loss: -3.653] \n",
      "4822 [D loss: (-0.716)(R -5.177, F 3.745)]  [G loss: -3.577] \n",
      "4823 [D loss: (-0.689)(R -5.040, F 3.662)]  [G loss: -3.674] \n",
      "4823 [D loss: (-0.653)(R -5.055, F 3.749)]  [G loss: -3.749] \n",
      "4824 [D loss: (-0.788)(R -5.221, F 3.644)]  [G loss: -3.748] \n",
      "4824 [D loss: (-0.782)(R -5.274, F 3.711)]  [G loss: -3.625] \n",
      "4825 [D loss: (-0.689)(R -5.131, F 3.752)]  [G loss: -3.867] \n",
      "4825 [D loss: (-0.752)(R -5.195, F 3.691)]  [G loss: -3.670] \n",
      "4826 [D loss: (-0.619)(R -5.045, F 3.806)]  [G loss: -3.667] \n",
      "4826 [D loss: (-0.747)(R -5.187, F 3.692)]  [G loss: -3.607] \n",
      "4827 [D loss: (-0.788)(R -5.246, F 3.670)]  [G loss: -3.610] \n",
      "4827 [D loss: (-0.805)(R -5.335, F 3.725)]  [G loss: -3.689] \n",
      "4828 [D loss: (-0.744)(R -5.183, F 3.695)]  [G loss: -3.714] \n",
      "4828 [D loss: (-0.718)(R -5.170, F 3.733)]  [G loss: -3.630] \n",
      "4829 [D loss: (-0.736)(R -5.217, F 3.744)]  [G loss: -3.645] \n",
      "4829 [D loss: (-0.740)(R -5.313, F 3.833)]  [G loss: -3.783] \n",
      "4830 [D loss: (-0.668)(R -5.067, F 3.731)]  [G loss: -3.770] \n",
      "4830 [D loss: (-0.631)(R -5.013, F 3.752)]  [G loss: -3.709] \n",
      "4831 [D loss: (-0.775)(R -5.137, F 3.587)]  [G loss: -3.817] \n",
      "4831 [D loss: (-0.720)(R -5.151, F 3.711)]  [G loss: -3.636] \n",
      "4832 [D loss: (-0.714)(R -5.041, F 3.613)]  [G loss: -3.657] \n",
      "4832 [D loss: (-0.744)(R -5.164, F 3.676)]  [G loss: -3.673] \n",
      "4833 [D loss: (-0.650)(R -4.947, F 3.647)]  [G loss: -3.648] \n",
      "4833 [D loss: (-0.747)(R -5.228, F 3.734)]  [G loss: -3.631] \n",
      "4834 [D loss: (-0.636)(R -4.878, F 3.605)]  [G loss: -3.708] \n",
      "4834 [D loss: (-0.698)(R -5.086, F 3.689)]  [G loss: -3.768] \n",
      "4835 [D loss: (-0.734)(R -5.091, F 3.623)]  [G loss: -3.740] \n",
      "4835 [D loss: (-0.680)(R -5.029, F 3.669)]  [G loss: -3.624] \n",
      "4836 [D loss: (-0.776)(R -5.083, F 3.530)]  [G loss: -3.689] \n",
      "4836 [D loss: (-0.612)(R -5.014, F 3.789)]  [G loss: -3.504] \n",
      "4837 [D loss: (-0.782)(R -5.120, F 3.556)]  [G loss: -3.570] \n",
      "4837 [D loss: (-0.791)(R -5.330, F 3.747)]  [G loss: -3.499] \n",
      "4838 [D loss: (-0.713)(R -5.066, F 3.641)]  [G loss: -3.692] \n",
      "4838 [D loss: (-0.733)(R -5.077, F 3.611)]  [G loss: -3.696] \n",
      "4839 [D loss: (-0.800)(R -5.209, F 3.609)]  [G loss: -3.630] \n",
      "4839 [D loss: (-0.706)(R -5.056, F 3.643)]  [G loss: -3.648] \n",
      "4840 [D loss: (-0.789)(R -5.119, F 3.541)]  [G loss: -3.586] \n",
      "4840 [D loss: (-0.714)(R -4.904, F 3.476)]  [G loss: -3.599] \n",
      "4841 [D loss: (-0.630)(R -4.920, F 3.661)]  [G loss: -3.726] \n",
      "4841 [D loss: (-0.715)(R -5.072, F 3.642)]  [G loss: -3.594] \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "wandb.init(project=\"深層学習_最終課題_transposed\")\n",
    "\n",
    "d_history = []\n",
    "g_history = []\n",
    "save_fig_path = os.path.abspath(\"gan_pokemon_transposed\")\n",
    "save_model_path = os.path.abspath(\"model_transposed\")\n",
    "\n",
    "\n",
    "def train(data, n_epochs=6000, batch_size=256, crip_threshold=0.01):\n",
    "    \n",
    "    batch_per_epoch = int(data.shape[0] / batch_size)\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = -np.ones((batch_size, 1))\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for i in range(batch_per_epoch):\n",
    "            \n",
    "            for j in range(5):\n",
    "                idx = np.random.randint(0, len(data[0]), batch_size)\n",
    "                true_imgs = data[idx]\n",
    "\n",
    "                z = np.random.normal(0, 1, (batch_size, z_dims))\n",
    "                gen_imgs = gen.predict(z)\n",
    "\n",
    "                d_loss_real = disc.train_on_batch(true_imgs, valid)\n",
    "                d_loss_fake = disc.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "\n",
    "                for l in disc.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -crip_threshold, crip_threshold) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "            \n",
    "\n",
    "            z = np.random.normal(0, 1, (batch_size, z_dims))\n",
    "            g_loss = gan.train_on_batch(z, valid)\n",
    "            g_history.append(g_loss)\n",
    "            \n",
    "            print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)]  [G loss: %.3f] \" % (epoch, d_loss, d_loss_real, d_loss_fake, g_loss))\n",
    "            \n",
    "            wandb.log({\"d_loss\": d_loss,\n",
    "                       \"g_loss\": g_loss})\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            sample_images(epoch)\n",
    "            save_model(epoch)\n",
    "            \n",
    "        K.set_value(disc.optimizer.learning_rate, K.get_value(disc.optimizer.learning_rate)*0.999)\n",
    "        K.set_value(gan.optimizer.learning_rate, K.get_value(gan.optimizer.learning_rate)*0.999)\n",
    "    \n",
    "def sample_images(epoch):\n",
    "    r, c = 5, 5\n",
    "    z = np.random.normal(0, 1, (25, z_dims))\n",
    "    gen_imgs = gen.predict(z)\n",
    "\n",
    "\n",
    "    gen_imgs = 0.5 * (gen_imgs + 1)\n",
    "    gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "\n",
    "    fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]))\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(os.path.join(save_fig_path, f\"epoch_{epoch}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def save_model(epoch):\n",
    "    save_folder = os.path.join(save_model_path, f\"model_epoch{epoch}\")\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    disc.save(os.path.join(save_folder, 'discriminator.h5'))\n",
    "    gen.save(os.path.join(save_folder, 'generator.h5'))\n",
    "    gan.save(os.path.join(save_folder, 'gan.h5'))\n",
    "    \n",
    "train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
